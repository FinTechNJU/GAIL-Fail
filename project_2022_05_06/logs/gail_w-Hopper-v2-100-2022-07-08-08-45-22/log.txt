2022-07-08 08:45:22.856759 - utils/flags.py:257 - log_dir = logs/gail_w-Hopper-v2-100-2022-07-08-08-45-22
2022-07-08 08:46:24.032125 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Hopper-v2
2022-07-08 08:46:32.743979 - gail/main.py:80 - Expert Reward 3582.436530
2022-07-08 08:46:33.027817 - gail/main.py:84 - Original dataset size 3000
2022-07-08 08:46:33.056602 - gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 08:46:33.058283 - gail/main.py:87 - np random: 864 random : 786
2022-07-08 08:46:33.061016 - gail/main.py:91 - Sampled obs: 0.4652, acs: 0.0749
2022-07-08 08:46:34.003553 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 08:46:41.293120 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 08:46:41.300109 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.3966653  -0.06165453 -0.19472611 -0.4584401   0.18350822  2.5732448
   0.00400542 -0.00549955 -0.04755233 -0.02386179  0.00759995]] 
 scale:[[0.16755195 0.05883223 0.15990146 0.34682125 0.5992658  0.6461788
  1.5187451  0.8811966  2.0685835  3.6282625  5.862049  ]]
2022-07-08 08:46:44.929438 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 08:46:44.930489 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(14, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 08:46:44.933170 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 08:46:45.862189 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 08:47:05.329211 - gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 240.1615 lengths = 229 } discounted_episode={ returns = 182.4166 lengths = 192 } 
2022-07-08 08:47:05.333988 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 08:47:15.358630 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 08:47:15.646641 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 08:47:16.177625 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 08:47:16.462560 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 08:47:18.082350 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 08:47:21.289388 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 08:47:21.612167 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 08:47:21.937680 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 08:47:22.419157 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 08:47:23.190662 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 08:47:23.477837 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 08:47:23.772339 - gail/main.py:174 - [TRPO] iter = 1000 dist_mean = -0.0000 dist_std = 1.0000 vf_loss = 0.3574 grad_norm = 0.2691 nat_grad_norm = 0.3367 cg_residual = 0.0000 step_size = 0.5255 reward = 0.0000 fps = 26 mse_loss = 0.3189 
2022-07-08 08:47:31.287651 - gail/main.py:174 - [TRPO] iter = 2000 dist_mean = -0.0418 dist_std = 0.9919 vf_loss = 0.2640 grad_norm = 0.3809 nat_grad_norm = 0.3659 cg_residual = 0.0000 step_size = 0.4041 reward = -0.0000 fps = 22 mse_loss = 0.3278 
2022-07-08 08:47:38.390736 - gail/main.py:174 - [TRPO] iter = 3000 dist_mean = -0.0849 dist_std = 0.9892 vf_loss = 0.4147 grad_norm = 0.4320 nat_grad_norm = 0.3771 cg_residual = 0.0000 step_size = 0.3703 reward = -0.0000 fps = 19 mse_loss = 0.3524 
2022-07-08 08:47:45.263473 - gail/main.py:174 - [TRPO] iter = 4000 dist_mean = -0.1135 dist_std = 0.9857 vf_loss = 0.3278 grad_norm = 0.5239 nat_grad_norm = 0.3955 cg_residual = 0.0000 step_size = 0.3332 reward = 0.0000 fps = 16 mse_loss = 0.3733 
2022-07-08 08:47:52.230788 - gail/main.py:174 - [TRPO] iter = 5000 dist_mean = -0.1550 dist_std = 0.9854 vf_loss = 0.1677 grad_norm = 0.5997 nat_grad_norm = 0.3996 cg_residual = 0.0000 step_size = 0.3147 reward = -0.0000 fps = 15 mse_loss = 0.4267 
2022-07-08 08:47:52.232266 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 08:47:54.540018 - gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.8033 grad_norm = 14.1450 grad_penalty = 1.6640 regularization = 0.0000 true_logits = 0.1373 fake_logits = 0.2766 true_prob = 0.5342 fake_prob = 0.5681 
2022-07-08 08:47:55.294200 - gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = 6.3892 lengths = 8 } discounted_episode={ returns = 6.3658 lengths = 8 } 
2022-07-08 08:48:01.923871 - gail/main.py:174 - [TRPO] iter = 6000 dist_mean = -0.1886 dist_std = 0.9808 vf_loss = 0.1538 grad_norm = 0.6919 nat_grad_norm = 0.4945 cg_residual = 0.0000 step_size = 0.2684 reward = -0.0000 fps = 135 mse_loss = 0.4764 
2022-07-08 08:48:08.408306 - gail/main.py:174 - [TRPO] iter = 7000 dist_mean = -0.2040 dist_std = 0.9784 vf_loss = 0.1224 grad_norm = 0.6576 nat_grad_norm = 0.4556 cg_residual = 0.0000 step_size = 0.2908 reward = -0.0000 fps = 72 mse_loss = 0.5055 
2022-07-08 08:48:15.577368 - gail/main.py:174 - [TRPO] iter = 8000 dist_mean = -0.2119 dist_std = 0.9686 vf_loss = 0.0941 grad_norm = 0.6527 nat_grad_norm = 0.4851 cg_residual = 0.0000 step_size = 0.2902 reward = -0.0000 fps = 47 mse_loss = 0.6055 
2022-07-08 08:48:22.851618 - gail/main.py:174 - [TRPO] iter = 9000 dist_mean = -0.2275 dist_std = 0.9663 vf_loss = 0.0433 grad_norm = 0.6643 nat_grad_norm = 0.3796 cg_residual = 0.0000 step_size = 0.3156 reward = -0.0000 fps = 35 mse_loss = 0.5589 
2022-07-08 08:48:30.097465 - gail/main.py:174 - [TRPO] iter = 10000 dist_mean = -0.2371 dist_std = 0.9523 vf_loss = 0.0697 grad_norm = 0.9271 nat_grad_norm = 0.5174 cg_residual = 0.0000 step_size = 0.2397 reward = 0.0000 fps = 28 mse_loss = 0.6872 
2022-07-08 08:48:30.373427 - gail/main.py:201 - [Discriminator] iter = 10000 loss = 0.7527 grad_norm = 10.2307 grad_penalty = 0.9303 regularization = 0.0000 true_logits = 0.1793 fake_logits = 0.0016 true_prob = 0.5444 fake_prob = 0.5004 
2022-07-08 08:48:31.133803 - gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = 5.1844 lengths = 7 } discounted_episode={ returns = 5.1619 lengths = 7 } 
2022-07-08 08:48:38.375497 - gail/main.py:174 - [TRPO] iter = 11000 dist_mean = -0.2417 dist_std = 0.9433 vf_loss = 0.0765 grad_norm = 0.4937 nat_grad_norm = 0.4567 cg_residual = 0.0000 step_size = 0.3915 reward = 0.0000 fps = 125 mse_loss = 0.6568 
2022-07-08 08:48:45.816755 - gail/main.py:174 - [TRPO] iter = 12000 dist_mean = -0.1846 dist_std = 0.9488 vf_loss = 0.0802 grad_norm = 0.8081 nat_grad_norm = 0.4370 cg_residual = 0.0000 step_size = 0.2797 reward = -0.0000 fps = 64 mse_loss = 0.7678 
2022-07-08 08:48:54.285429 - gail/main.py:174 - [TRPO] iter = 13000 dist_mean = -0.1087 dist_std = 0.9544 vf_loss = 0.1944 grad_norm = 0.8456 nat_grad_norm = 0.4429 cg_residual = 0.0000 step_size = 0.2699 reward = 0.0000 fps = 41 mse_loss = 0.7624 
2022-07-08 08:49:03.011706 - gail/main.py:174 - [TRPO] iter = 14000 dist_mean = -0.0262 dist_std = 0.9598 vf_loss = 0.1499 grad_norm = 0.9175 nat_grad_norm = 0.4038 cg_residual = 0.0001 step_size = 0.2737 reward = 0.0000 fps = 30 mse_loss = 0.7241 
2022-07-08 08:49:10.701822 - gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.0650 dist_std = 0.9696 vf_loss = 0.3418 grad_norm = 0.7095 nat_grad_norm = 0.3949 cg_residual = 0.0001 step_size = 0.3453 reward = -0.0000 fps = 24 mse_loss = 0.7734 
2022-07-08 08:49:10.898968 - gail/main.py:201 - [Discriminator] iter = 15000 loss = 0.2675 grad_norm = 9.3622 grad_penalty = 0.8053 regularization = 0.0000 true_logits = 0.1699 fake_logits = -0.3679 true_prob = 0.5421 fake_prob = 0.4098 
2022-07-08 08:49:11.739583 - gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = 7.0108 lengths = 8 } discounted_episode={ returns = 6.9283 lengths = 8 } 
2022-07-08 08:49:19.041009 - gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.1152 dist_std = 0.9731 vf_loss = 0.7711 grad_norm = 0.6561 nat_grad_norm = 0.4857 cg_residual = 0.0002 step_size = 0.3495 reward = 0.0000 fps = 122 mse_loss = 0.7549 
2022-07-08 08:49:26.275554 - gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.2029 dist_std = 0.9789 vf_loss = 1.0896 grad_norm = 0.9064 nat_grad_norm = 0.4460 cg_residual = 0.0002 step_size = 0.3226 reward = 0.0000 fps = 65 mse_loss = 0.6663 
2022-07-08 08:49:33.304903 - gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.2949 dist_std = 0.9795 vf_loss = 1.1573 grad_norm = 0.6880 nat_grad_norm = 0.3413 cg_residual = 0.0001 step_size = 0.4171 reward = -0.0000 fps = 44 mse_loss = 0.6356 
2022-07-08 08:49:40.636568 - gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.3943 dist_std = 0.9769 vf_loss = 0.9078 grad_norm = 0.6216 nat_grad_norm = 0.4148 cg_residual = 0.0003 step_size = 0.4246 reward = 0.0000 fps = 33 mse_loss = 0.6088 
2022-07-08 08:49:48.315283 - gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.4521 dist_std = 0.9696 vf_loss = 0.6548 grad_norm = 0.5477 nat_grad_norm = 0.4194 cg_residual = 0.0005 step_size = 0.4512 reward = 0.0000 fps = 26 mse_loss = 0.6332 
2022-07-08 08:49:48.551651 - gail/main.py:201 - [Discriminator] iter = 20000 loss = 0.1210 grad_norm = 7.5911 grad_penalty = 0.7161 regularization = 0.0000 true_logits = 0.1708 fake_logits = -0.4243 true_prob = 0.5423 fake_prob = 0.3992 
2022-07-08 08:49:50.894714 - gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = 42.8747 lengths = 26 } discounted_episode={ returns = 42.4595 lengths = 26 } 
2022-07-08 08:49:57.979120 - gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.5415 dist_std = 0.9672 vf_loss = 0.5183 grad_norm = 0.5880 nat_grad_norm = 0.4213 cg_residual = 0.0004 step_size = 0.4887 reward = 0.0000 fps = 106 mse_loss = 0.6711 
2022-07-08 08:50:08.767359 - gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.5634 dist_std = 0.9626 vf_loss = 0.6609 grad_norm = 0.5888 nat_grad_norm = 0.3654 cg_residual = 0.0002 step_size = 0.5419 reward = -0.0000 fps = 49 mse_loss = 0.5915 
2022-07-08 08:50:17.479996 - gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.6269 dist_std = 0.9774 vf_loss = 0.6671 grad_norm = 0.5416 nat_grad_norm = 0.3692 cg_residual = 0.0004 step_size = 0.5371 reward = -0.0000 fps = 34 mse_loss = 0.7073 
2022-07-08 08:50:24.888763 - gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.6573 dist_std = 0.9738 vf_loss = 0.7807 grad_norm = 0.5731 nat_grad_norm = 0.3741 cg_residual = 0.0004 step_size = 0.4858 reward = -0.0000 fps = 27 mse_loss = 0.6677 
2022-07-08 08:50:31.785453 - gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.7123 dist_std = 0.9778 vf_loss = 0.4616 grad_norm = 0.2867 nat_grad_norm = 0.3990 cg_residual = 0.0002 step_size = 0.5736 reward = -0.0000 fps = 23 mse_loss = 0.6863 
2022-07-08 08:50:32.046727 - gail/main.py:201 - [Discriminator] iter = 25000 loss = -0.0958 grad_norm = 7.0769 grad_penalty = 0.5709 regularization = 0.0000 true_logits = 0.1609 fake_logits = -0.5058 true_prob = 0.5400 fake_prob = 0.3805 
2022-07-08 08:50:35.101987 - gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = 58.1177 lengths = 32 } discounted_episode={ returns = 55.9372 lengths = 32 } 
2022-07-08 08:50:41.920607 - gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.7209 dist_std = 0.9708 vf_loss = 0.4822 grad_norm = 0.4500 nat_grad_norm = 0.5168 cg_residual = 0.0008 step_size = 0.4318 reward = 0.0000 fps = 101 mse_loss = 0.6766 
2022-07-08 08:50:48.989671 - gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.7876 dist_std = 0.9630 vf_loss = 0.2973 grad_norm = 0.3041 nat_grad_norm = 0.4988 cg_residual = 0.0003 step_size = 0.5218 reward = 0.0000 fps = 59 mse_loss = 0.9345 
2022-07-08 08:50:56.044299 - gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.8056 dist_std = 0.9527 vf_loss = 0.0968 grad_norm = 0.4463 nat_grad_norm = 0.8827 cg_residual = 0.0031 step_size = 0.3198 reward = 0.0000 fps = 41 mse_loss = 0.9025 
2022-07-08 08:51:03.147329 - gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.8140 dist_std = 0.9474 vf_loss = 0.0384 grad_norm = 0.6375 nat_grad_norm = 0.3497 cg_residual = 0.0009 step_size = 0.4928 reward = 0.0000 fps = 32 mse_loss = 0.9494 
2022-07-08 08:51:10.545042 - gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.7770 dist_std = 0.9419 vf_loss = 0.4743 grad_norm = 0.6228 nat_grad_norm = 0.4241 cg_residual = 0.0004 step_size = 0.4214 reward = -0.0000 fps = 25 mse_loss = 1.0505 
2022-07-08 08:51:10.796403 - gail/main.py:201 - [Discriminator] iter = 30000 loss = -0.4463 grad_norm = 5.7779 grad_penalty = 0.4365 regularization = 0.0000 true_logits = 0.1872 fake_logits = -0.6956 true_prob = 0.5465 fake_prob = 0.3369 
2022-07-08 08:51:13.344110 - gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = 51.6469 lengths = 28 } discounted_episode={ returns = 51.7192 lengths = 29 } 
2022-07-08 08:51:20.419723 - gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.8377 dist_std = 0.9461 vf_loss = 0.0927 grad_norm = 0.3548 nat_grad_norm = 0.5218 cg_residual = 0.0003 step_size = 0.4612 reward = -0.0000 fps = 104 mse_loss = 1.0872 
2022-07-08 08:51:27.407253 - gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.7896 dist_std = 0.9454 vf_loss = 0.3697 grad_norm = 0.4464 nat_grad_norm = 0.4199 cg_residual = 0.0004 step_size = 0.5709 reward = -0.0000 fps = 60 mse_loss = 1.0838 
2022-07-08 08:51:34.061741 - gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.7411 dist_std = 0.9415 vf_loss = 0.3741 grad_norm = 0.4630 nat_grad_norm = 0.6322 cg_residual = 0.0006 step_size = 0.3914 reward = -0.0000 fps = 43 mse_loss = 1.1672 
2022-07-08 08:51:40.934860 - gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.7547 dist_std = 0.9288 vf_loss = 0.4857 grad_norm = 0.3495 nat_grad_norm = 0.5340 cg_residual = 0.0016 step_size = 0.4376 reward = -0.0000 fps = 33 mse_loss = 1.2405 
2022-07-08 08:51:47.975072 - gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.7295 dist_std = 0.9284 vf_loss = 0.3742 grad_norm = 0.5956 nat_grad_norm = 0.3946 cg_residual = 0.0014 step_size = 0.4965 reward = -0.0000 fps = 26 mse_loss = 1.1892 
2022-07-08 08:51:48.178697 - gail/main.py:201 - [Discriminator] iter = 35000 loss = -0.5368 grad_norm = 6.5702 grad_penalty = 0.4853 regularization = 0.0000 true_logits = 0.2125 fake_logits = -0.8096 true_prob = 0.5525 fake_prob = 0.3130 
2022-07-08 08:51:55.707063 - gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 163.0135 lengths = 82 } discounted_episode={ returns = 156.9647 lengths = 82 } 
2022-07-08 08:52:02.839936 - gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.6776 dist_std = 0.9316 vf_loss = 0.9834 grad_norm = 0.4905 nat_grad_norm = 0.4160 cg_residual = 0.0017 step_size = 0.5207 reward = 0.0000 fps = 68 mse_loss = 1.1556 
2022-07-08 08:52:09.648478 - gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.6672 dist_std = 0.9254 vf_loss = 0.8459 grad_norm = 0.4990 nat_grad_norm = 0.4375 cg_residual = 0.0019 step_size = 0.4593 reward = 0.0000 fps = 46 mse_loss = 1.1309 
2022-07-08 08:52:16.399585 - gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.5651 dist_std = 0.9228 vf_loss = 0.7592 grad_norm = 0.6071 nat_grad_norm = 0.3827 cg_residual = 0.0007 step_size = 0.5143 reward = -0.0000 fps = 35 mse_loss = 1.4162 
2022-07-08 08:52:23.207783 - gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.5351 dist_std = 0.9288 vf_loss = 0.2841 grad_norm = 0.2969 nat_grad_norm = 0.5160 cg_residual = 0.0009 step_size = 0.5063 reward = -0.0000 fps = 28 mse_loss = 1.2868 
2022-07-08 08:52:30.164561 - gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.5679 dist_std = 0.9194 vf_loss = 1.2305 grad_norm = 0.7006 nat_grad_norm = 0.4145 cg_residual = 0.0011 step_size = 0.5140 reward = 0.0000 fps = 23 mse_loss = 1.3432 
2022-07-08 08:52:30.420643 - gail/main.py:201 - [Discriminator] iter = 40000 loss = -0.6865 grad_norm = 5.4451 grad_penalty = 0.4159 regularization = 0.0000 true_logits = 0.2434 fake_logits = -0.8589 true_prob = 0.5598 fake_prob = 0.3056 
2022-07-08 08:52:38.107002 - gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 168.2817 lengths = 86 } discounted_episode={ returns = 159.7298 lengths = 85 } 
2022-07-08 08:52:45.164312 - gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.5769 dist_std = 0.9088 vf_loss = 0.4685 grad_norm = 0.5993 nat_grad_norm = 0.4945 cg_residual = 0.0020 step_size = 0.4217 reward = -0.0000 fps = 67 mse_loss = 1.3647 
2022-07-08 08:52:52.095909 - gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.5473 dist_std = 0.8964 vf_loss = 0.2064 grad_norm = 0.4519 nat_grad_norm = 0.4190 cg_residual = 0.0010 step_size = 0.5287 reward = -0.0000 fps = 46 mse_loss = 1.4639 
2022-07-08 08:52:58.712355 - gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.5404 dist_std = 0.8962 vf_loss = 0.1299 grad_norm = 0.4854 nat_grad_norm = 0.3794 cg_residual = 0.0008 step_size = 0.5880 reward = -0.0000 fps = 35 mse_loss = 1.4822 
2022-07-08 08:53:05.652681 - gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.5292 dist_std = 0.8873 vf_loss = 0.0935 grad_norm = 0.7211 nat_grad_norm = 0.3524 cg_residual = 0.0021 step_size = 0.5868 reward = -0.0000 fps = 28 mse_loss = 1.6774 
2022-07-08 08:53:12.267187 - gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.5173 dist_std = 0.8917 vf_loss = 0.0871 grad_norm = 0.3734 nat_grad_norm = 0.3750 cg_residual = 0.0039 step_size = 0.5331 reward = 0.0000 fps = 23 mse_loss = 1.7029 
2022-07-08 08:53:12.500577 - gail/main.py:201 - [Discriminator] iter = 45000 loss = -0.9852 grad_norm = 5.4907 grad_penalty = 0.3566 regularization = 0.0000 true_logits = 0.2534 fake_logits = -1.0884 true_prob = 0.5628 fake_prob = 0.2630 
2022-07-08 08:53:19.812509 - gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 170.5472 lengths = 86 } discounted_episode={ returns = 163.8191 lengths = 86 } 
2022-07-08 08:53:27.456392 - gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.5092 dist_std = 0.8876 vf_loss = 0.1011 grad_norm = 0.4509 nat_grad_norm = 0.3416 cg_residual = 0.0041 step_size = 0.6083 reward = 0.0000 fps = 66 mse_loss = 1.9560 
2022-07-08 08:53:34.731047 - gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.4968 dist_std = 0.8894 vf_loss = 0.0999 grad_norm = 0.9281 nat_grad_norm = 0.3419 cg_residual = 0.0023 step_size = 0.5472 reward = -0.0000 fps = 45 mse_loss = 2.0934 
2022-07-08 08:53:41.707738 - gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.4934 dist_std = 0.8897 vf_loss = 0.0656 grad_norm = 0.5337 nat_grad_norm = 0.2786 cg_residual = 0.0022 step_size = 0.6237 reward = -0.0000 fps = 34 mse_loss = 1.9838 
2022-07-08 08:53:48.383710 - gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.4584 dist_std = 0.8914 vf_loss = 0.1338 grad_norm = 0.5772 nat_grad_norm = 0.4218 cg_residual = 0.0011 step_size = 0.4829 reward = 0.0000 fps = 27 mse_loss = 1.9014 
2022-07-08 08:53:55.353175 - gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.4384 dist_std = 0.8984 vf_loss = 0.2332 grad_norm = 0.4594 nat_grad_norm = 0.3777 cg_residual = 0.0015 step_size = 0.5775 reward = 0.0000 fps = 23 mse_loss = 1.9332 
2022-07-08 08:53:55.563336 - gail/main.py:201 - [Discriminator] iter = 50000 loss = -1.3182 grad_norm = 5.9404 grad_penalty = 0.3510 regularization = 0.0000 true_logits = 0.2834 fake_logits = -1.3857 true_prob = 0.5703 fake_prob = 0.2116 
2022-07-08 08:54:03.220901 - gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 176.0997 lengths = 87 } discounted_episode={ returns = 168.2833 lengths = 87 } 
2022-07-08 08:54:10.132483 - gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.3933 dist_std = 0.9140 vf_loss = 0.7275 grad_norm = 0.8694 nat_grad_norm = 0.4526 cg_residual = 0.0069 step_size = 0.4377 reward = -0.0000 fps = 68 mse_loss = 1.6682 
2022-07-08 08:54:16.778481 - gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.3754 dist_std = 0.9057 vf_loss = 0.7750 grad_norm = 0.6964 nat_grad_norm = 0.3580 cg_residual = 0.0022 step_size = 0.5337 reward = -0.0000 fps = 47 mse_loss = 2.0820 
2022-07-08 08:54:23.318376 - gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.3621 dist_std = 0.9042 vf_loss = 0.4576 grad_norm = 0.7426 nat_grad_norm = 0.4180 cg_residual = 0.0026 step_size = 0.4876 reward = 0.0000 fps = 36 mse_loss = 2.1630 
2022-07-08 08:54:30.277454 - gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.3679 dist_std = 0.9054 vf_loss = 0.5284 grad_norm = 0.9583 nat_grad_norm = 0.4327 cg_residual = 0.0026 step_size = 0.4651 reward = -0.0000 fps = 28 mse_loss = 2.1887 
2022-07-08 08:54:36.998391 - gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.2603 dist_std = 0.9111 vf_loss = 0.8399 grad_norm = 0.6902 nat_grad_norm = 0.3766 cg_residual = 0.0039 step_size = 0.4860 reward = 0.0000 fps = 24 mse_loss = 2.1801 
2022-07-08 08:54:37.214913 - gail/main.py:201 - [Discriminator] iter = 55000 loss = -1.1817 grad_norm = 5.9638 grad_penalty = 0.3965 regularization = 0.0000 true_logits = 0.2650 fake_logits = -1.3132 true_prob = 0.5657 fake_prob = 0.2400 
2022-07-08 08:54:48.799840 - gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 356.5532 lengths = 132 } discounted_episode={ returns = 328.3238 lengths = 131 } 
2022-07-08 08:54:56.502496 - gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.2316 dist_std = 0.9124 vf_loss = 1.4375 grad_norm = 0.4441 nat_grad_norm = 0.5232 cg_residual = 0.0087 step_size = 0.4640 reward = 0.0000 fps = 51 mse_loss = 2.2865 
2022-07-08 08:55:04.525815 - gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.2538 dist_std = 0.9088 vf_loss = 0.6714 grad_norm = 0.4708 nat_grad_norm = 0.4552 cg_residual = 0.0040 step_size = 0.5474 reward = -0.0000 fps = 36 mse_loss = 2.3254 
2022-07-08 08:55:12.404632 - gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.2417 dist_std = 0.9047 vf_loss = 0.6122 grad_norm = 0.5712 nat_grad_norm = 0.3768 cg_residual = 0.0252 step_size = 0.5539 reward = 0.0000 fps = 28 mse_loss = 1.8674 
2022-07-08 08:55:19.426344 - gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.1907 dist_std = 0.9040 vf_loss = 0.3965 grad_norm = 0.8715 nat_grad_norm = 0.3661 cg_residual = 0.0058 step_size = 0.4872 reward = 0.0000 fps = 23 mse_loss = 1.6482 
2022-07-08 08:55:25.933724 - gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.2082 dist_std = 0.9004 vf_loss = 0.5181 grad_norm = 0.5867 nat_grad_norm = 0.4825 cg_residual = 0.0097 step_size = 0.4791 reward = -0.0000 fps = 20 mse_loss = 2.0913 
2022-07-08 08:55:26.151720 - gail/main.py:201 - [Discriminator] iter = 60000 loss = -1.2082 grad_norm = 4.1893 grad_penalty = 0.3212 regularization = 0.0000 true_logits = 0.2855 fake_logits = -1.2439 true_prob = 0.5700 fake_prob = 0.2594 
2022-07-08 08:55:37.527454 - gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 361.5098 lengths = 133 } discounted_episode={ returns = 336.6801 lengths = 134 } 
2022-07-08 08:55:44.439641 - gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.1827 dist_std = 0.9003 vf_loss = 0.2488 grad_norm = 0.7036 nat_grad_norm = 0.4701 cg_residual = 0.0236 step_size = 0.4611 reward = -0.0000 fps = 54 mse_loss = 2.1821 
2022-07-08 08:55:51.004375 - gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.2008 dist_std = 0.8984 vf_loss = 0.8491 grad_norm = 0.7639 nat_grad_norm = 0.4179 cg_residual = 0.0064 step_size = 0.4888 reward = 0.0000 fps = 40 mse_loss = 1.8931 
2022-07-08 08:55:57.618372 - gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.1576 dist_std = 0.8907 vf_loss = 0.3278 grad_norm = 0.4739 nat_grad_norm = 0.4952 cg_residual = 0.0054 step_size = 0.4961 reward = 0.0000 fps = 31 mse_loss = 1.8793 
2022-07-08 08:56:04.423861 - gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.1326 dist_std = 0.8907 vf_loss = 0.1538 grad_norm = 0.5786 nat_grad_norm = 0.3239 cg_residual = 0.0145 step_size = 0.5741 reward = -0.0000 fps = 26 mse_loss = 1.8274 
2022-07-08 08:56:11.185270 - gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.1232 dist_std = 0.8898 vf_loss = 0.2242 grad_norm = 0.3853 nat_grad_norm = 0.4221 cg_residual = 0.0072 step_size = 0.5819 reward = -0.0000 fps = 22 mse_loss = 1.8265 
2022-07-08 08:56:11.386099 - gail/main.py:201 - [Discriminator] iter = 65000 loss = -1.2111 grad_norm = 3.9685 grad_penalty = 0.2584 regularization = 0.0000 true_logits = 0.2646 fake_logits = -1.2050 true_prob = 0.5661 fake_prob = 0.2636 
2022-07-08 08:56:22.865157 - gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 367.9163 lengths = 134 } discounted_episode={ returns = 339.1315 lengths = 134 } 
2022-07-08 08:56:30.116149 - gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.1507 dist_std = 0.8791 vf_loss = 0.4105 grad_norm = 0.4977 nat_grad_norm = 0.4865 cg_residual = 0.0200 step_size = 0.4943 reward = -0.0000 fps = 53 mse_loss = 2.1266 
2022-07-08 08:56:36.842179 - gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.0900 dist_std = 0.8796 vf_loss = 0.1316 grad_norm = 0.6765 nat_grad_norm = 0.3990 cg_residual = 0.0080 step_size = 0.4809 reward = -0.0000 fps = 39 mse_loss = 2.1442 
2022-07-08 08:56:43.992024 - gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.1242 dist_std = 0.8753 vf_loss = 0.2533 grad_norm = 0.5203 nat_grad_norm = 0.4411 cg_residual = 0.0210 step_size = 0.4585 reward = 0.0000 fps = 30 mse_loss = 2.2570 
2022-07-08 08:56:50.763063 - gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.0802 dist_std = 0.8675 vf_loss = 0.2473 grad_norm = 0.5411 nat_grad_norm = 0.4504 cg_residual = 0.0074 step_size = 0.5357 reward = -0.0000 fps = 25 mse_loss = 2.1206 
2022-07-08 08:56:57.685842 - gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.0763 dist_std = 0.8600 vf_loss = 0.4136 grad_norm = 0.4340 nat_grad_norm = 0.4471 cg_residual = 0.0045 step_size = 0.5363 reward = -0.0000 fps = 21 mse_loss = 2.1090 
2022-07-08 08:56:57.944543 - gail/main.py:201 - [Discriminator] iter = 70000 loss = -1.1361 grad_norm = 4.1502 grad_penalty = 0.2577 regularization = 0.0000 true_logits = 0.2368 fake_logits = -1.1570 true_prob = 0.5593 fake_prob = 0.2681 
2022-07-08 08:57:09.366893 - gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 368.7367 lengths = 133 } discounted_episode={ returns = 341.6655 lengths = 133 } 
2022-07-08 08:57:16.047968 - gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.1020 dist_std = 0.8531 vf_loss = 0.5181 grad_norm = 0.6046 nat_grad_norm = 0.5351 cg_residual = 0.0345 step_size = 0.4413 reward = -0.0000 fps = 55 mse_loss = 2.3122 
2022-07-08 08:57:22.871710 - gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.0702 dist_std = 0.8503 vf_loss = 0.4171 grad_norm = 0.7913 nat_grad_norm = 0.4486 cg_residual = 0.0044 step_size = 0.4551 reward = 0.0000 fps = 40 mse_loss = 2.5385 
2022-07-08 08:57:29.527245 - gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.1008 dist_std = 0.8374 vf_loss = 0.2934 grad_norm = 0.4907 nat_grad_norm = 0.4426 cg_residual = 0.0083 step_size = 0.5097 reward = 0.0000 fps = 31 mse_loss = 2.5867 
2022-07-08 08:57:36.218683 - gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.0685 dist_std = 0.8427 vf_loss = 0.2148 grad_norm = 0.5664 nat_grad_norm = 0.5562 cg_residual = 0.0056 step_size = 0.4389 reward = 0.0000 fps = 26 mse_loss = 2.9007 
2022-07-08 08:57:42.993309 - gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.1487 dist_std = 0.8380 vf_loss = 0.9815 grad_norm = 0.4018 nat_grad_norm = 0.4334 cg_residual = 0.0081 step_size = 0.5006 reward = -0.0000 fps = 22 mse_loss = 3.0840 
2022-07-08 08:57:43.207887 - gail/main.py:201 - [Discriminator] iter = 75000 loss = -1.2195 grad_norm = 3.5920 grad_penalty = 0.2277 regularization = 0.0000 true_logits = 0.2578 fake_logits = -1.1895 true_prob = 0.5638 fake_prob = 0.2617 
2022-07-08 08:57:54.503966 - gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 372.1138 lengths = 132 } discounted_episode={ returns = 345.6081 lengths = 132 } 
2022-07-08 08:58:01.300345 - gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.1144 dist_std = 0.8384 vf_loss = 0.8335 grad_norm = 0.6104 nat_grad_norm = 0.4854 cg_residual = 0.0095 step_size = 0.4273 reward = -0.0000 fps = 55 mse_loss = 2.9822 
2022-07-08 08:58:07.894705 - gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.0962 dist_std = 0.8358 vf_loss = 0.3069 grad_norm = 0.4504 nat_grad_norm = 0.4008 cg_residual = 0.0057 step_size = 0.5356 reward = -0.0000 fps = 40 mse_loss = 2.6065 
2022-07-08 08:58:14.684077 - gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.0761 dist_std = 0.8438 vf_loss = 0.4224 grad_norm = 0.5614 nat_grad_norm = 0.4573 cg_residual = 0.0065 step_size = 0.4935 reward = -0.0000 fps = 31 mse_loss = 2.9169 
2022-07-08 08:58:21.478160 - gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.0237 dist_std = 0.8464 vf_loss = 0.3076 grad_norm = 0.9428 nat_grad_norm = 0.4041 cg_residual = 0.0306 step_size = 0.4326 reward = -0.0000 fps = 26 mse_loss = 3.0375 
2022-07-08 08:58:28.271103 - gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.0922 dist_std = 0.8457 vf_loss = 0.3097 grad_norm = 0.6210 nat_grad_norm = 0.4697 cg_residual = 0.0052 step_size = 0.4676 reward = 0.0000 fps = 22 mse_loss = 3.4385 
2022-07-08 08:58:28.487555 - gail/main.py:201 - [Discriminator] iter = 80000 loss = -1.2556 grad_norm = 3.2026 grad_penalty = 0.2100 regularization = 0.0000 true_logits = 0.2659 fake_logits = -1.1996 true_prob = 0.5648 fake_prob = 0.2584 
2022-07-08 08:58:42.604585 - gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 538.4054 lengths = 163 } discounted_episode={ returns = 496.1930 lengths = 164 } 
2022-07-08 08:58:49.226448 - gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.0807 dist_std = 0.8376 vf_loss = 0.5825 grad_norm = 0.4656 nat_grad_norm = 0.4550 cg_residual = 0.0080 step_size = 0.4971 reward = 0.0000 fps = 48 mse_loss = 3.1830 
2022-07-08 08:58:55.817285 - gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.0950 dist_std = 0.8308 vf_loss = 0.2855 grad_norm = 0.6459 nat_grad_norm = 0.4278 cg_residual = 0.0067 step_size = 0.4782 reward = -0.0000 fps = 36 mse_loss = 2.5232 
2022-07-08 08:59:02.665324 - gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.0452 dist_std = 0.8321 vf_loss = 0.4082 grad_norm = 0.3958 nat_grad_norm = 0.4710 cg_residual = 0.0076 step_size = 0.5117 reward = -0.0000 fps = 29 mse_loss = 2.3774 
2022-07-08 08:59:09.445678 - gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.0307 dist_std = 0.8244 vf_loss = 0.2257 grad_norm = 0.5369 nat_grad_norm = 0.3935 cg_residual = 0.0101 step_size = 0.5321 reward = 0.0000 fps = 24 mse_loss = 2.2745 
2022-07-08 08:59:15.894727 - gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.1094 dist_std = 0.8273 vf_loss = 0.5351 grad_norm = 0.3473 nat_grad_norm = 0.3724 cg_residual = 0.0067 step_size = 0.5913 reward = 0.0000 fps = 21 mse_loss = 2.7244 
2022-07-08 08:59:16.137097 - gail/main.py:201 - [Discriminator] iter = 85000 loss = -1.1206 grad_norm = 3.0256 grad_penalty = 0.2185 regularization = 0.0000 true_logits = 0.2625 fake_logits = -1.0767 true_prob = 0.5641 fake_prob = 0.2786 
2022-07-08 08:59:33.040445 - gail/main.py:142 - [Evaluate] iter = 85000 episode={ returns = 634.2728 lengths = 196 } discounted_episode={ returns = 571.0632 lengths = 198 } 
2022-07-08 08:59:39.928800 - gail/main.py:174 - [TRPO] iter = 86000 dist_mean = 0.0855 dist_std = 0.8258 vf_loss = 0.3083 grad_norm = 0.7959 nat_grad_norm = 0.5326 cg_residual = 0.0104 step_size = 0.4105 reward = 0.0000 fps = 42 mse_loss = 3.0095 
2022-07-08 08:59:46.930364 - gail/main.py:174 - [TRPO] iter = 87000 dist_mean = 0.0486 dist_std = 0.8199 vf_loss = 0.1784 grad_norm = 0.4004 nat_grad_norm = 0.3275 cg_residual = 0.0075 step_size = 0.6153 reward = 0.0000 fps = 32 mse_loss = 2.9775 
2022-07-08 08:59:53.440325 - gail/main.py:174 - [TRPO] iter = 88000 dist_mean = 0.0314 dist_std = 0.8084 vf_loss = 0.1910 grad_norm = 0.7179 nat_grad_norm = 0.3255 cg_residual = 0.0050 step_size = 0.5111 reward = 0.0000 fps = 26 mse_loss = 2.7618 
2022-07-08 09:00:00.449276 - gail/main.py:174 - [TRPO] iter = 89000 dist_mean = 0.0701 dist_std = 0.8008 vf_loss = 0.3850 grad_norm = 0.4671 nat_grad_norm = 0.3681 cg_residual = 0.0089 step_size = 0.5871 reward = -0.0000 fps = 22 mse_loss = 2.8423 
2022-07-08 09:00:08.083495 - gail/main.py:174 - [TRPO] iter = 90000 dist_mean = 0.1348 dist_std = 0.7879 vf_loss = 0.2708 grad_norm = 0.3719 nat_grad_norm = 0.3947 cg_residual = 0.0058 step_size = 0.5487 reward = -0.0000 fps = 19 mse_loss = 2.8077 
2022-07-08 09:00:08.391163 - gail/main.py:201 - [Discriminator] iter = 90000 loss = -1.0707 grad_norm = 3.6936 grad_penalty = 0.1944 regularization = 0.0000 true_logits = 0.2815 fake_logits = -0.9835 true_prob = 0.5676 fake_prob = 0.2989 
2022-07-08 09:00:34.024396 - gail/main.py:142 - [Evaluate] iter = 90000 episode={ returns = 743.1623 lengths = 236 } discounted_episode={ returns = 651.1291 lengths = 233 } 
2022-07-08 09:00:42.922523 - gail/main.py:174 - [TRPO] iter = 91000 dist_mean = 0.0475 dist_std = 0.7807 vf_loss = 0.3834 grad_norm = 0.4952 nat_grad_norm = 0.4243 cg_residual = 0.0101 step_size = 0.5058 reward = -0.0000 fps = 28 mse_loss = 3.2945 
2022-07-08 09:00:49.727324 - gail/main.py:174 - [TRPO] iter = 92000 dist_mean = 0.0922 dist_std = 0.7713 vf_loss = 0.2254 grad_norm = 0.5571 nat_grad_norm = 0.4236 cg_residual = 0.0086 step_size = 0.4926 reward = 0.0000 fps = 24 mse_loss = 3.0645 
2022-07-08 09:00:56.379741 - gail/main.py:174 - [TRPO] iter = 93000 dist_mean = 0.1363 dist_std = 0.7740 vf_loss = 0.3540 grad_norm = 0.6232 nat_grad_norm = 0.3831 cg_residual = 0.0136 step_size = 0.4916 reward = 0.0000 fps = 20 mse_loss = 3.3094 
2022-07-08 09:01:02.896886 - gail/main.py:174 - [TRPO] iter = 94000 dist_mean = 0.0633 dist_std = 0.7672 vf_loss = 0.1656 grad_norm = 0.4585 nat_grad_norm = 0.4103 cg_residual = 0.0077 step_size = 0.5503 reward = -0.0000 fps = 18 mse_loss = 3.4096 
2022-07-08 09:01:09.609543 - gail/main.py:174 - [TRPO] iter = 95000 dist_mean = 0.0180 dist_std = 0.7554 vf_loss = 0.1012 grad_norm = 0.5788 nat_grad_norm = 0.4186 cg_residual = 0.0215 step_size = 0.4909 reward = -0.0000 fps = 16 mse_loss = 3.5430 
2022-07-08 09:01:09.875989 - gail/main.py:201 - [Discriminator] iter = 95000 loss = -1.0215 grad_norm = 3.1959 grad_penalty = 0.2238 regularization = 0.0000 true_logits = 0.3303 fake_logits = -0.9149 true_prob = 0.5767 fake_prob = 0.3108 
2022-07-08 09:01:33.266288 - gail/main.py:142 - [Evaluate] iter = 95000 episode={ returns = 822.9413 lengths = 271 } discounted_episode={ returns = 704.5733 lengths = 269 } 
2022-07-08 09:01:39.816059 - gail/main.py:174 - [TRPO] iter = 96000 dist_mean = 0.0811 dist_std = 0.7509 vf_loss = 0.2690 grad_norm = 0.6588 nat_grad_norm = 0.3101 cg_residual = 0.0148 step_size = 0.5385 reward = -0.0000 fps = 33 mse_loss = 3.9468 
2022-07-08 09:01:46.346260 - gail/main.py:174 - [TRPO] iter = 97000 dist_mean = 0.1202 dist_std = 0.7534 vf_loss = 0.1472 grad_norm = 0.4373 nat_grad_norm = 0.4103 cg_residual = 0.0163 step_size = 0.5246 reward = -0.0000 fps = 27 mse_loss = 3.7057 
2022-07-08 09:01:52.741795 - gail/main.py:174 - [TRPO] iter = 98000 dist_mean = 0.1115 dist_std = 0.7476 vf_loss = 0.1173 grad_norm = 0.6929 nat_grad_norm = 0.3586 cg_residual = 0.0142 step_size = 0.5159 reward = 0.0000 fps = 23 mse_loss = 3.5583 
2022-07-08 09:01:59.302780 - gail/main.py:174 - [TRPO] iter = 99000 dist_mean = 0.1585 dist_std = 0.7434 vf_loss = 0.2130 grad_norm = 0.4864 nat_grad_norm = 0.3849 cg_residual = 0.0094 step_size = 0.5299 reward = -0.0000 fps = 20 mse_loss = 3.6496 
2022-07-08 09:02:05.789217 - gail/main.py:174 - [TRPO] iter = 100000 dist_mean = 0.1611 dist_std = 0.7376 vf_loss = 0.1107 grad_norm = 0.5484 nat_grad_norm = 0.3920 cg_residual = 0.0111 step_size = 0.5053 reward = 0.0000 fps = 17 mse_loss = 3.5361 
2022-07-08 09:02:06.030872 - gail/main.py:201 - [Discriminator] iter = 100000 loss = -0.9982 grad_norm = 3.0784 grad_penalty = 0.1814 regularization = 0.0000 true_logits = 0.3529 fake_logits = -0.8266 true_prob = 0.5798 fake_prob = 0.3265 
2022-07-08 09:02:28.924766 - gail/main.py:142 - [Evaluate] iter = 100000 episode={ returns = 499.0815 lengths = 201 } discounted_episode={ returns = 789.8160 lengths = 357 } 
2022-07-08 09:02:35.368106 - gail/main.py:174 - [TRPO] iter = 101000 dist_mean = 0.0622 dist_std = 0.7337 vf_loss = 0.2180 grad_norm = 0.4519 nat_grad_norm = 0.3465 cg_residual = 0.0092 step_size = 0.5853 reward = 0.0000 fps = 34 mse_loss = 3.8340 
2022-07-08 09:02:42.367315 - gail/main.py:174 - [TRPO] iter = 102000 dist_mean = 0.1728 dist_std = 0.7442 vf_loss = 0.2445 grad_norm = 0.3970 nat_grad_norm = 0.3419 cg_residual = 0.0145 step_size = 0.5800 reward = 0.0000 fps = 27 mse_loss = 4.0588 
2022-07-08 09:02:49.804121 - gail/main.py:174 - [TRPO] iter = 103000 dist_mean = 0.1348 dist_std = 0.7488 vf_loss = 0.1566 grad_norm = 0.5123 nat_grad_norm = 0.4240 cg_residual = 0.0166 step_size = 0.5011 reward = -0.0000 fps = 22 mse_loss = 4.1464 
2022-07-08 09:02:56.469561 - gail/main.py:174 - [TRPO] iter = 104000 dist_mean = 0.1455 dist_std = 0.7382 vf_loss = 0.1670 grad_norm = 0.5619 nat_grad_norm = 0.4638 cg_residual = 0.0272 step_size = 0.4939 reward = 0.0000 fps = 19 mse_loss = 4.1245 
2022-07-08 09:03:03.385060 - gail/main.py:174 - [TRPO] iter = 105000 dist_mean = 0.0768 dist_std = 0.7386 vf_loss = 0.1863 grad_norm = 0.7327 nat_grad_norm = 0.5078 cg_residual = 0.0208 step_size = 0.4566 reward = 0.0000 fps = 17 mse_loss = 4.6211 
2022-07-08 09:03:03.679956 - gail/main.py:201 - [Discriminator] iter = 105000 loss = -1.1928 grad_norm = 2.8368 grad_penalty = 0.1707 regularization = 0.0000 true_logits = 0.4077 fake_logits = -0.9559 true_prob = 0.5905 fake_prob = 0.2999 
2022-07-08 09:03:32.896047 - gail/main.py:142 - [Evaluate] iter = 105000 episode={ returns = 991.5684 lengths = 334 } discounted_episode={ returns = 773.4851 lengths = 319 } 
2022-07-08 09:03:39.716538 - gail/main.py:174 - [TRPO] iter = 106000 dist_mean = 0.1352 dist_std = 0.7345 vf_loss = 0.1859 grad_norm = 0.4660 nat_grad_norm = 0.4181 cg_residual = 0.0160 step_size = 0.5243 reward = -0.0000 fps = 27 mse_loss = 4.3937 
2022-07-08 09:03:46.876733 - gail/main.py:174 - [TRPO] iter = 107000 dist_mean = 0.1093 dist_std = 0.7251 vf_loss = 0.1138 grad_norm = 0.5496 nat_grad_norm = 0.5720 cg_residual = 0.0226 step_size = 0.4378 reward = 0.0000 fps = 23 mse_loss = 4.3686 
2022-07-08 09:03:53.919548 - gail/main.py:174 - [TRPO] iter = 108000 dist_mean = 0.1665 dist_std = 0.7257 vf_loss = 0.1784 grad_norm = 0.6250 nat_grad_norm = 0.3937 cg_residual = 0.0155 step_size = 0.4952 reward = 0.0000 fps = 19 mse_loss = 4.2026 
2022-07-08 09:04:00.725751 - gail/main.py:174 - [TRPO] iter = 109000 dist_mean = 0.1401 dist_std = 0.7223 vf_loss = 0.2025 grad_norm = 0.5370 nat_grad_norm = 0.3806 cg_residual = 0.0121 step_size = 0.5214 reward = -0.0000 fps = 17 mse_loss = 4.4035 
2022-07-08 09:04:07.546796 - gail/main.py:174 - [TRPO] iter = 110000 dist_mean = 0.0878 dist_std = 0.7235 vf_loss = 0.2712 grad_norm = 0.5218 nat_grad_norm = 0.3634 cg_residual = 0.0106 step_size = 0.6043 reward = 0.0000 fps = 15 mse_loss = 4.9788 
2022-07-08 09:04:07.786638 - gail/main.py:201 - [Discriminator] iter = 110000 loss = -1.2255 grad_norm = 3.1814 grad_penalty = 0.1587 regularization = 0.0000 true_logits = 0.4022 fake_logits = -0.9820 true_prob = 0.5878 fake_prob = 0.2956 
2022-07-08 09:04:47.112490 - gail/main.py:142 - [Evaluate] iter = 110000 episode={ returns = 879.3837 lengths = 290 } discounted_episode={ returns = 745.5616 lengths = 291 } 
2022-07-08 09:04:59.977161 - gail/main.py:174 - [TRPO] iter = 111000 dist_mean = 0.0918 dist_std = 0.7198 vf_loss = 0.1457 grad_norm = 0.5817 nat_grad_norm = 0.4236 cg_residual = 0.0093 step_size = 0.5025 reward = -0.0000 fps = 19 mse_loss = 4.6888 
2022-07-08 09:05:17.142727 - gail/main.py:174 - [TRPO] iter = 112000 dist_mean = 0.1399 dist_std = 0.7176 vf_loss = 0.1908 grad_norm = 0.5658 nat_grad_norm = 0.4084 cg_residual = 0.0117 step_size = 0.4757 reward = -0.0000 fps = 14 mse_loss = 4.6333 
2022-07-08 09:05:34.225271 - gail/main.py:174 - [TRPO] iter = 113000 dist_mean = 0.0659 dist_std = 0.7190 vf_loss = 0.2092 grad_norm = 0.3994 nat_grad_norm = 0.4101 cg_residual = 0.0163 step_size = 0.5590 reward = -0.0000 fps = 11 mse_loss = 4.6934 
2022-07-08 09:05:50.635064 - gail/main.py:174 - [TRPO] iter = 114000 dist_mean = -0.0447 dist_std = 0.7138 vf_loss = 0.1639 grad_norm = 0.3827 nat_grad_norm = 0.3518 cg_residual = 0.0177 step_size = 0.6225 reward = -0.0000 fps = 9 mse_loss = 4.6102 
2022-07-08 09:06:05.795674 - gail/main.py:174 - [TRPO] iter = 115000 dist_mean = 0.0661 dist_std = 0.7085 vf_loss = 0.1046 grad_norm = 0.5692 nat_grad_norm = 0.4022 cg_residual = 0.0232 step_size = 0.4617 reward = 0.0000 fps = 8 mse_loss = 4.6395 
2022-07-08 09:06:06.267596 - gail/main.py:201 - [Discriminator] iter = 115000 loss = -1.1305 grad_norm = 2.7520 grad_penalty = 0.1554 regularization = 0.0000 true_logits = 0.4174 fake_logits = -0.8685 true_prob = 0.5890 fake_prob = 0.3197 
2022-07-08 09:07:00.004669 - gail/main.py:142 - [Evaluate] iter = 115000 episode={ returns = 857.2916 lengths = 264 } discounted_episode={ returns = 738.6013 lengths = 264 } 
2022-07-08 09:07:16.427167 - gail/main.py:174 - [TRPO] iter = 116000 dist_mean = 0.0536 dist_std = 0.7102 vf_loss = 0.1435 grad_norm = 0.4882 nat_grad_norm = 0.4116 cg_residual = 0.0239 step_size = 0.5192 reward = 0.0000 fps = 14 mse_loss = 4.4441 
2022-07-08 09:07:31.922155 - gail/main.py:174 - [TRPO] iter = 117000 dist_mean = -0.0399 dist_std = 0.7112 vf_loss = 0.3138 grad_norm = 0.5879 nat_grad_norm = 0.4100 cg_residual = 0.0284 step_size = 0.5004 reward = 0.0000 fps = 11 mse_loss = 4.5916 
2022-07-08 09:07:48.336623 - gail/main.py:174 - [TRPO] iter = 118000 dist_mean = 0.0378 dist_std = 0.7099 vf_loss = 0.1391 grad_norm = 0.7174 nat_grad_norm = 0.4187 cg_residual = 0.0352 step_size = 0.4346 reward = -0.0000 fps = 9 mse_loss = 4.5133 
2022-07-08 09:08:04.072260 - gail/main.py:174 - [TRPO] iter = 119000 dist_mean = 0.0537 dist_std = 0.6991 vf_loss = 0.0836 grad_norm = 0.5793 nat_grad_norm = 0.3811 cg_residual = 0.0181 step_size = 0.4997 reward = -0.0000 fps = 8 mse_loss = 4.6971 
2022-07-08 09:08:20.697725 - gail/main.py:174 - [TRPO] iter = 120000 dist_mean = 0.0444 dist_std = 0.6907 vf_loss = 0.1277 grad_norm = 0.7131 nat_grad_norm = 0.4421 cg_residual = 0.0312 step_size = 0.4700 reward = -0.0000 fps = 7 mse_loss = 4.7416 
2022-07-08 09:08:21.223659 - gail/main.py:201 - [Discriminator] iter = 120000 loss = -1.1891 grad_norm = 3.6835 grad_penalty = 0.1654 regularization = 0.0000 true_logits = 0.4664 fake_logits = -0.8881 true_prob = 0.5980 fake_prob = 0.3178 
2022-07-08 09:09:12.020149 - gail/main.py:142 - [Evaluate] iter = 120000 episode={ returns = 627.9279 lengths = 221 } discounted_episode={ returns = 617.8286 lengths = 248 } 
2022-07-08 09:09:36.322293 - gail/main.py:174 - [TRPO] iter = 121000 dist_mean = 0.0511 dist_std = 0.6978 vf_loss = 0.0855 grad_norm = 0.5688 nat_grad_norm = 0.3030 cg_residual = 0.0186 step_size = 0.5996 reward = 0.0000 fps = 13 mse_loss = 5.0881 
2022-07-08 09:09:55.615934 - gail/main.py:174 - [TRPO] iter = 122000 dist_mean = 0.0414 dist_std = 0.6950 vf_loss = 0.1294 grad_norm = 0.6501 nat_grad_norm = 0.4242 cg_residual = 0.0442 step_size = 0.4186 reward = -0.0000 fps = 10 mse_loss = 4.9663 
2022-07-08 09:10:19.356972 - gail/main.py:174 - [TRPO] iter = 123000 dist_mean = 0.0222 dist_std = 0.6911 vf_loss = 0.1239 grad_norm = 0.6644 nat_grad_norm = 0.3587 cg_residual = 0.0175 step_size = 0.5376 reward = -0.0000 fps = 8 mse_loss = 5.1141 
2022-07-08 09:10:45.449870 - gail/main.py:174 - [TRPO] iter = 124000 dist_mean = 0.0818 dist_std = 0.6886 vf_loss = 0.0857 grad_norm = 0.9252 nat_grad_norm = 0.3840 cg_residual = 0.0246 step_size = 0.4185 reward = 0.0000 fps = 6 mse_loss = 5.5966 
2022-07-08 09:11:18.679068 - gail/main.py:174 - [TRPO] iter = 125000 dist_mean = 0.0279 dist_std = 0.6932 vf_loss = 0.0860 grad_norm = 0.6641 nat_grad_norm = 0.4926 cg_residual = 0.0574 step_size = 0.3998 reward = 0.0000 fps = 5 mse_loss = 5.2920 
2022-07-08 09:11:19.499478 - gail/main.py:201 - [Discriminator] iter = 125000 loss = -1.1966 grad_norm = 3.1415 grad_penalty = 0.1570 regularization = 0.0000 true_logits = 0.4793 fake_logits = -0.8743 true_prob = 0.5985 fake_prob = 0.3181 
2022-07-08 09:12:54.939337 - gail/main.py:142 - [Evaluate] iter = 125000 episode={ returns = 845.8787 lengths = 264 } discounted_episode={ returns = 725.3609 lengths = 264 } 
2022-07-08 09:13:23.786095 - gail/main.py:174 - [TRPO] iter = 126000 dist_mean = 0.0115 dist_std = 0.6835 vf_loss = 0.5643 grad_norm = 0.8780 nat_grad_norm = 0.5519 cg_residual = 0.0691 step_size = 0.3398 reward = -0.0000 fps = 8 mse_loss = 5.1077 
2022-07-08 09:13:51.013828 - gail/main.py:174 - [TRPO] iter = 127000 dist_mean = 0.1206 dist_std = 0.6713 vf_loss = 0.1230 grad_norm = 0.6926 nat_grad_norm = 0.4122 cg_residual = 0.0402 step_size = 0.4872 reward = 0.0000 fps = 6 mse_loss = 4.9109 
2022-07-08 09:14:17.276964 - gail/main.py:174 - [TRPO] iter = 128000 dist_mean = 0.0755 dist_std = 0.6712 vf_loss = 0.0885 grad_norm = 0.6113 nat_grad_norm = 0.4946 cg_residual = 0.0364 step_size = 0.4247 reward = -0.0000 fps = 5 mse_loss = 5.1420 
2022-07-08 09:14:45.754946 - gail/main.py:174 - [TRPO] iter = 129000 dist_mean = 0.1010 dist_std = 0.6716 vf_loss = 0.1038 grad_norm = 0.7060 nat_grad_norm = 0.3462 cg_residual = 0.0312 step_size = 0.4885 reward = -0.0000 fps = 4 mse_loss = 5.2429 
2022-07-08 09:15:15.234929 - gail/main.py:174 - [TRPO] iter = 130000 dist_mean = 0.0666 dist_std = 0.6681 vf_loss = 0.1483 grad_norm = 0.8801 nat_grad_norm = 0.4404 cg_residual = 0.0588 step_size = 0.3831 reward = -0.0000 fps = 4 mse_loss = 4.4254 
2022-07-08 09:15:16.073949 - gail/main.py:201 - [Discriminator] iter = 130000 loss = -1.2200 grad_norm = 3.5187 grad_penalty = 0.1450 regularization = 0.0000 true_logits = 0.5131 fake_logits = -0.8519 true_prob = 0.6053 fake_prob = 0.3215 
2022-07-08 09:16:50.539282 - gail/main.py:142 - [Evaluate] iter = 130000 episode={ returns = 835.8429 lengths = 264 } discounted_episode={ returns = 717.2675 lengths = 263 } 
2022-07-08 09:17:18.179972 - gail/main.py:174 - [TRPO] iter = 131000 dist_mean = 0.1217 dist_std = 0.6551 vf_loss = 0.1091 grad_norm = 0.8376 nat_grad_norm = 0.5064 cg_residual = 0.0281 step_size = 0.3761 reward = 0.0000 fps = 8 mse_loss = 4.3832 
2022-07-08 09:17:46.430517 - gail/main.py:174 - [TRPO] iter = 132000 dist_mean = 0.0842 dist_std = 0.6538 vf_loss = 0.0972 grad_norm = 0.7289 nat_grad_norm = 0.3627 cg_residual = 0.0627 step_size = 0.4439 reward = 0.0000 fps = 6 mse_loss = 4.7463 
2022-07-08 09:18:13.386920 - gail/main.py:174 - [TRPO] iter = 133000 dist_mean = 0.1673 dist_std = 0.6496 vf_loss = 0.2760 grad_norm = 0.6006 nat_grad_norm = 0.3634 cg_residual = 0.0364 step_size = 0.4500 reward = -0.0000 fps = 5 mse_loss = 4.9406 
2022-07-08 09:18:40.551783 - gail/main.py:174 - [TRPO] iter = 134000 dist_mean = 0.1250 dist_std = 0.6450 vf_loss = 0.1037 grad_norm = 0.5736 nat_grad_norm = 0.4011 cg_residual = 0.0812 step_size = 0.4632 reward = 0.0000 fps = 4 mse_loss = 4.4741 
2022-07-08 09:19:07.772870 - gail/main.py:174 - [TRPO] iter = 135000 dist_mean = 0.0191 dist_std = 0.6348 vf_loss = 0.1173 grad_norm = 0.9626 nat_grad_norm = 0.3332 cg_residual = 0.0317 step_size = 0.4350 reward = 0.0000 fps = 4 mse_loss = 4.3268 
2022-07-08 09:19:08.537995 - gail/main.py:201 - [Discriminator] iter = 135000 loss = -1.3375 grad_norm = 3.3831 grad_penalty = 0.1450 regularization = 0.0000 true_logits = 0.5477 fake_logits = -0.9348 true_prob = 0.6096 fake_prob = 0.3085 
2022-07-08 09:20:41.621682 - gail/main.py:142 - [Evaluate] iter = 135000 episode={ returns = 833.9434 lengths = 256 } discounted_episode={ returns = 720.8450 lengths = 256 } 
2022-07-08 09:21:08.013901 - gail/main.py:174 - [TRPO] iter = 136000 dist_mean = 0.1096 dist_std = 0.6287 vf_loss = 1.2936 grad_norm = 0.8895 nat_grad_norm = 0.3747 cg_residual = 0.0326 step_size = 0.4561 reward = -0.0000 fps = 8 mse_loss = 4.4208 
2022-07-08 09:21:33.793258 - gail/main.py:174 - [TRPO] iter = 137000 dist_mean = 0.0292 dist_std = 0.6250 vf_loss = 1.1962 grad_norm = 1.1389 nat_grad_norm = 0.4644 cg_residual = 0.0441 step_size = 0.3956 reward = -0.0000 fps = 6 mse_loss = 4.4841 
2022-07-08 09:22:06.433921 - gail/main.py:174 - [TRPO] iter = 138000 dist_mean = 0.0421 dist_std = 0.6266 vf_loss = 1.2255 grad_norm = 0.7413 nat_grad_norm = 0.4014 cg_residual = 0.0937 step_size = 0.4144 reward = 0.0000 fps = 5 mse_loss = 4.5486 
2022-07-08 09:22:33.274303 - gail/main.py:174 - [TRPO] iter = 139000 dist_mean = 0.0196 dist_std = 0.6135 vf_loss = 0.3038 grad_norm = 0.6578 nat_grad_norm = 0.2928 cg_residual = 0.0337 step_size = 0.5317 reward = 0.0000 fps = 4 mse_loss = 4.2980 
2022-07-08 09:23:01.142812 - gail/main.py:174 - [TRPO] iter = 140000 dist_mean = 0.0936 dist_std = 0.6110 vf_loss = 0.2301 grad_norm = 0.5798 nat_grad_norm = 0.3264 cg_residual = 0.0572 step_size = 0.5191 reward = -0.0000 fps = 4 mse_loss = 4.1688 
2022-07-08 09:23:01.936691 - gail/main.py:201 - [Discriminator] iter = 140000 loss = -1.3053 grad_norm = 2.9273 grad_penalty = 0.1366 regularization = 0.0000 true_logits = 0.5945 fake_logits = -0.8474 true_prob = 0.6170 fake_prob = 0.3244 
2022-07-08 09:24:30.527365 - gail/main.py:142 - [Evaluate] iter = 140000 episode={ returns = 839.5763 lengths = 258 } discounted_episode={ returns = 724.3304 lengths = 258 } 
2022-07-08 09:24:56.095452 - gail/main.py:174 - [TRPO] iter = 141000 dist_mean = 0.0522 dist_std = 0.6184 vf_loss = 0.4066 grad_norm = 0.6916 nat_grad_norm = 0.3352 cg_residual = 0.0556 step_size = 0.4613 reward = 0.0000 fps = 8 mse_loss = 4.2894 
2022-07-08 09:25:21.371292 - gail/main.py:174 - [TRPO] iter = 142000 dist_mean = 0.0880 dist_std = 0.6207 vf_loss = 0.1478 grad_norm = 0.7736 nat_grad_norm = 0.3093 cg_residual = 0.0528 step_size = 0.4802 reward = 0.0000 fps = 7 mse_loss = 4.2352 
2022-07-08 09:25:47.243095 - gail/main.py:174 - [TRPO] iter = 143000 dist_mean = 0.1649 dist_std = 0.6127 vf_loss = 0.4464 grad_norm = 0.8371 nat_grad_norm = 0.4465 cg_residual = 0.0864 step_size = 0.3400 reward = 0.0000 fps = 6 mse_loss = 4.7025 
2022-07-08 09:26:15.260571 - gail/main.py:174 - [TRPO] iter = 144000 dist_mean = 0.0436 dist_std = 0.6121 vf_loss = 0.1371 grad_norm = 1.0768 nat_grad_norm = 0.3694 cg_residual = 0.0893 step_size = 0.4035 reward = -0.0000 fps = 5 mse_loss = 4.5115 
2022-07-08 09:26:42.120719 - gail/main.py:174 - [TRPO] iter = 145000 dist_mean = 0.0059 dist_std = 0.6104 vf_loss = 0.1334 grad_norm = 0.6272 nat_grad_norm = 0.3385 cg_residual = 0.0714 step_size = 0.5393 reward = -0.0000 fps = 4 mse_loss = 4.3991 
2022-07-08 09:26:42.836903 - gail/main.py:201 - [Discriminator] iter = 145000 loss = -1.2074 grad_norm = 2.8067 grad_penalty = 0.1240 regularization = 0.0000 true_logits = 0.5476 fake_logits = -0.7838 true_prob = 0.6051 fake_prob = 0.3362 
2022-07-08 09:27:43.631701 - gail/main.py:142 - [Evaluate] iter = 145000 episode={ returns = 439.6705 lengths = 174 } discounted_episode={ returns = 448.0237 lengths = 193 } 
2022-07-08 09:28:08.466281 - gail/main.py:174 - [TRPO] iter = 146000 dist_mean = 0.1191 dist_std = 0.6024 vf_loss = 0.4392 grad_norm = 1.4041 nat_grad_norm = 0.3888 cg_residual = 0.0750 step_size = 0.3305 reward = -0.0000 fps = 11 mse_loss = 4.1198 
2022-07-08 09:28:34.474372 - gail/main.py:174 - [TRPO] iter = 147000 dist_mean = 0.0650 dist_std = 0.5961 vf_loss = 0.1124 grad_norm = 0.8108 nat_grad_norm = 0.4008 cg_residual = 0.0763 step_size = 0.4279 reward = 0.0000 fps = 8 mse_loss = 4.5654 
2022-07-08 09:29:00.107461 - gail/main.py:174 - [TRPO] iter = 148000 dist_mean = -0.0261 dist_std = 0.6003 vf_loss = 0.1216 grad_norm = 0.8771 nat_grad_norm = 0.3330 cg_residual = 0.0632 step_size = 0.4711 reward = -0.0000 fps = 7 mse_loss = 4.2265 
2022-07-08 09:29:26.276093 - gail/main.py:174 - [TRPO] iter = 149000 dist_mean = 0.0607 dist_std = 0.5929 vf_loss = 0.1012 grad_norm = 0.9118 nat_grad_norm = 0.4289 cg_residual = 0.0742 step_size = 0.3753 reward = -0.0000 fps = 6 mse_loss = 4.3257 
2022-07-08 09:29:51.059868 - gail/main.py:174 - [TRPO] iter = 150000 dist_mean = 0.0469 dist_std = 0.5960 vf_loss = 0.1427 grad_norm = 0.6029 nat_grad_norm = 0.4625 cg_residual = 0.1351 step_size = 0.3930 reward = 0.0000 fps = 5 mse_loss = 4.3703 
2022-07-08 09:29:51.805200 - gail/main.py:201 - [Discriminator] iter = 150000 loss = -1.3981 grad_norm = 3.2301 grad_penalty = 0.1351 regularization = 0.0000 true_logits = 0.6731 fake_logits = -0.8602 true_prob = 0.6291 fake_prob = 0.3210 
2022-07-08 09:31:06.565390 - gail/main.py:142 - [Evaluate] iter = 150000 episode={ returns = 620.8168 lengths = 224 } discounted_episode={ returns = 524.8104 lengths = 223 } 
2022-07-08 09:31:32.662665 - gail/main.py:174 - [TRPO] iter = 151000 dist_mean = 0.0273 dist_std = 0.5901 vf_loss = 0.1442 grad_norm = 1.1053 nat_grad_norm = 0.3670 cg_residual = 0.0950 step_size = 0.4008 reward = -0.0000 fps = 9 mse_loss = 4.0232 
2022-07-08 09:31:58.822251 - gail/main.py:174 - [TRPO] iter = 152000 dist_mean = 0.0463 dist_std = 0.5852 vf_loss = 0.1139 grad_norm = 0.5335 nat_grad_norm = 0.3308 cg_residual = 0.0972 step_size = 0.5161 reward = -0.0000 fps = 7 mse_loss = 4.1600 
2022-07-08 09:32:30.307063 - gail/main.py:174 - [TRPO] iter = 153000 dist_mean = 0.0880 dist_std = 0.5789 vf_loss = 0.0729 grad_norm = 0.6722 nat_grad_norm = 0.3477 cg_residual = 0.0757 step_size = 0.4675 reward = 0.0000 fps = 6 mse_loss = 4.2582 
2022-07-08 09:32:55.411689 - gail/main.py:174 - [TRPO] iter = 154000 dist_mean = 0.0867 dist_std = 0.5689 vf_loss = 0.1522 grad_norm = 0.6852 nat_grad_norm = 0.3499 cg_residual = 0.1055 step_size = 0.4743 reward = 0.0000 fps = 5 mse_loss = 4.1967 
2022-07-08 09:33:20.723752 - gail/main.py:174 - [TRPO] iter = 155000 dist_mean = 0.0941 dist_std = 0.5597 vf_loss = 0.1053 grad_norm = 0.5845 nat_grad_norm = 0.4106 cg_residual = 0.1053 step_size = 0.4268 reward = -0.0000 fps = 4 mse_loss = 4.1291 
2022-07-08 09:33:21.536666 - gail/main.py:201 - [Discriminator] iter = 155000 loss = -1.4047 grad_norm = 3.2086 grad_penalty = 0.1536 regularization = 0.0000 true_logits = 0.6866 fake_logits = -0.8717 true_prob = 0.6314 fake_prob = 0.3219 
2022-07-08 09:34:24.787052 - gail/main.py:142 - [Evaluate] iter = 155000 episode={ returns = 472.1131 lengths = 189 } discounted_episode={ returns = 455.2592 lengths = 206 } 
2022-07-08 09:34:50.036868 - gail/main.py:174 - [TRPO] iter = 156000 dist_mean = 0.0973 dist_std = 0.5650 vf_loss = 0.0793 grad_norm = 0.7655 nat_grad_norm = 0.3438 cg_residual = 0.0732 step_size = 0.4531 reward = 0.0000 fps = 11 mse_loss = 3.8329 
2022-07-08 09:35:15.694685 - gail/main.py:174 - [TRPO] iter = 157000 dist_mean = 0.1122 dist_std = 0.5615 vf_loss = 0.0676 grad_norm = 0.8345 nat_grad_norm = 0.3816 cg_residual = 0.2225 step_size = 0.4244 reward = -0.0000 fps = 8 mse_loss = 3.8550 
2022-07-08 09:35:41.652033 - gail/main.py:174 - [TRPO] iter = 158000 dist_mean = 0.1183 dist_std = 0.5575 vf_loss = 0.0842 grad_norm = 0.8454 nat_grad_norm = 0.3857 cg_residual = 0.1099 step_size = 0.4274 reward = -0.0000 fps = 7 mse_loss = 3.7405 
2022-07-08 09:36:06.141730 - gail/main.py:174 - [TRPO] iter = 159000 dist_mean = 0.0963 dist_std = 0.5535 vf_loss = 0.1118 grad_norm = 0.8869 nat_grad_norm = 0.4272 cg_residual = 0.1735 step_size = 0.3781 reward = 0.0000 fps = 6 mse_loss = 3.3801 
2022-07-08 09:36:31.379510 - gail/main.py:174 - [TRPO] iter = 160000 dist_mean = 0.1046 dist_std = 0.5603 vf_loss = 0.4696 grad_norm = 1.5043 nat_grad_norm = 0.3560 cg_residual = 0.1659 step_size = 0.3290 reward = 0.0000 fps = 5 mse_loss = 3.6681 
2022-07-08 09:36:32.133440 - gail/main.py:201 - [Discriminator] iter = 160000 loss = -1.7202 grad_norm = 3.6544 grad_penalty = 0.1430 regularization = 0.0000 true_logits = 0.7075 fake_logits = -1.1557 true_prob = 0.6298 fake_prob = 0.2700 
2022-07-08 09:38:00.946982 - gail/main.py:142 - [Evaluate] iter = 160000 episode={ returns = 859.5015 lengths = 287 } discounted_episode={ returns = 673.1013 lengths = 271 } 
2022-07-08 09:38:26.314994 - gail/main.py:174 - [TRPO] iter = 161000 dist_mean = 0.1327 dist_std = 0.5582 vf_loss = 0.1023 grad_norm = 0.7381 nat_grad_norm = 0.3195 cg_residual = 0.0883 step_size = 0.4677 reward = 0.0000 fps = 8 mse_loss = 3.6926 
2022-07-08 09:38:50.943232 - gail/main.py:174 - [TRPO] iter = 162000 dist_mean = 0.2298 dist_std = 0.5613 vf_loss = 0.1021 grad_norm = 0.8629 nat_grad_norm = 0.3764 cg_residual = 0.0864 step_size = 0.3939 reward = -0.0000 fps = 7 mse_loss = 3.5541 
2022-07-08 09:39:16.029658 - gail/main.py:174 - [TRPO] iter = 163000 dist_mean = 0.2207 dist_std = 0.5548 vf_loss = 0.1246 grad_norm = 1.0699 nat_grad_norm = 0.3293 cg_residual = 0.1597 step_size = 0.4107 reward = -0.0000 fps = 6 mse_loss = 3.3462 
2022-07-08 09:39:41.589702 - gail/main.py:174 - [TRPO] iter = 164000 dist_mean = 0.1539 dist_std = 0.5464 vf_loss = 0.0889 grad_norm = 0.9815 nat_grad_norm = 0.3601 cg_residual = 0.1278 step_size = 0.4131 reward = 0.0000 fps = 5 mse_loss = 3.4531 
2022-07-08 09:40:07.488256 - gail/main.py:174 - [TRPO] iter = 165000 dist_mean = 0.1108 dist_std = 0.5435 vf_loss = 0.1518 grad_norm = 0.7849 nat_grad_norm = 0.3122 cg_residual = 0.1071 step_size = 0.4712 reward = -0.0000 fps = 4 mse_loss = 3.3066 
2022-07-08 09:40:08.241707 - gail/main.py:201 - [Discriminator] iter = 165000 loss = -1.2959 grad_norm = 3.1378 grad_penalty = 0.1404 regularization = 0.0000 true_logits = 0.6951 fake_logits = -0.7412 true_prob = 0.6281 fake_prob = 0.3443 
2022-07-08 09:40:49.212239 - gail/main.py:142 - [Evaluate] iter = 165000 episode={ returns = 463.5958 lengths = 153 } discounted_episode={ returns = 257.8252 lengths = 100 } 
2022-07-08 09:41:13.321236 - gail/main.py:174 - [TRPO] iter = 166000 dist_mean = 0.1220 dist_std = 0.5416 vf_loss = 0.0629 grad_norm = 1.0038 nat_grad_norm = 0.3506 cg_residual = 0.1098 step_size = 0.3884 reward = -0.0000 fps = 15 mse_loss = 3.5294 
2022-07-08 09:41:38.540384 - gail/main.py:174 - [TRPO] iter = 167000 dist_mean = 0.1389 dist_std = 0.5490 vf_loss = 0.1095 grad_norm = 0.9596 nat_grad_norm = 0.5258 cg_residual = 0.2644 step_size = 0.3307 reward = -0.0000 fps = 11 mse_loss = 3.3811 
2022-07-08 09:42:05.321621 - gail/main.py:174 - [TRPO] iter = 168000 dist_mean = 0.1629 dist_std = 0.5455 vf_loss = 0.0705 grad_norm = 0.9253 nat_grad_norm = 0.3498 cg_residual = 0.1423 step_size = 0.4096 reward = 0.0000 fps = 8 mse_loss = 3.1542 
2022-07-08 09:42:33.593252 - gail/main.py:174 - [TRPO] iter = 169000 dist_mean = 0.0813 dist_std = 0.5488 vf_loss = 0.0675 grad_norm = 1.2803 nat_grad_norm = 0.4311 cg_residual = 0.0794 step_size = 0.3706 reward = 0.0000 fps = 6 mse_loss = 2.9983 
2022-07-08 09:42:57.698927 - gail/main.py:174 - [TRPO] iter = 170000 dist_mean = 0.1021 dist_std = 0.5398 vf_loss = 0.0701 grad_norm = 1.0669 nat_grad_norm = 0.3795 cg_residual = 0.1396 step_size = 0.3975 reward = -0.0000 fps = 5 mse_loss = 2.8264 
2022-07-08 09:42:58.387111 - gail/main.py:201 - [Discriminator] iter = 170000 loss = -1.1576 grad_norm = 2.7693 grad_penalty = 0.1235 regularization = 0.0000 true_logits = 0.6905 fake_logits = -0.5906 true_prob = 0.6307 fake_prob = 0.3734 
2022-07-08 09:43:19.778920 - gail/main.py:142 - [Evaluate] iter = 170000 episode={ returns = 227.1747 lengths = 77 } discounted_episode={ returns = 159.7016 lengths = 65 } 
2022-07-08 09:43:43.651577 - gail/main.py:174 - [TRPO] iter = 171000 dist_mean = 0.2230 dist_std = 0.5374 vf_loss = 0.0971 grad_norm = 1.0420 nat_grad_norm = 0.4213 cg_residual = 0.2289 step_size = 0.3324 reward = -0.0000 fps = 22 mse_loss = 2.6786 
2022-07-08 09:44:08.370160 - gail/main.py:174 - [TRPO] iter = 172000 dist_mean = 0.1009 dist_std = 0.5372 vf_loss = 0.1864 grad_norm = 1.1490 nat_grad_norm = 0.4214 cg_residual = 0.1668 step_size = 0.3137 reward = 0.0000 fps = 14 mse_loss = 2.6103 
2022-07-08 09:44:32.250212 - gail/main.py:174 - [TRPO] iter = 173000 dist_mean = 0.0507 dist_std = 0.5317 vf_loss = 0.0807 grad_norm = 1.2141 nat_grad_norm = 0.3549 cg_residual = 0.1123 step_size = 0.3812 reward = -0.0000 fps = 10 mse_loss = 2.9289 
2022-07-08 09:44:56.803187 - gail/main.py:174 - [TRPO] iter = 174000 dist_mean = 0.2603 dist_std = 0.5256 vf_loss = 0.0867 grad_norm = 0.9853 nat_grad_norm = 0.2952 cg_residual = 0.0845 step_size = 0.3949 reward = -0.0000 fps = 8 mse_loss = 2.7334 
2022-07-08 09:45:21.235702 - gail/main.py:174 - [TRPO] iter = 175000 dist_mean = 0.2090 dist_std = 0.5239 vf_loss = 0.0558 grad_norm = 0.7175 nat_grad_norm = 0.3064 cg_residual = 0.0872 step_size = 0.4729 reward = -0.0000 fps = 7 mse_loss = 2.6911 
2022-07-08 09:45:21.975990 - gail/main.py:201 - [Discriminator] iter = 175000 loss = -1.5562 grad_norm = 3.2376 grad_penalty = 0.1317 regularization = 0.0000 true_logits = 0.7652 fake_logits = -0.9227 true_prob = 0.6414 fake_prob = 0.3115 
2022-07-08 09:45:48.970771 - gail/main.py:142 - [Evaluate] iter = 175000 episode={ returns = 379.2316 lengths = 120 } discounted_episode={ returns = 135.7739 lengths = 57 } 
2022-07-08 09:46:12.286168 - gail/main.py:174 - [TRPO] iter = 176000 dist_mean = 0.1400 dist_std = 0.5225 vf_loss = 0.1106 grad_norm = 0.9115 nat_grad_norm = 0.3658 cg_residual = 0.1262 step_size = 0.3738 reward = 0.0000 fps = 19 mse_loss = 2.6389 
2022-07-08 09:46:35.777972 - gail/main.py:174 - [TRPO] iter = 177000 dist_mean = 0.2271 dist_std = 0.5215 vf_loss = 0.0918 grad_norm = 0.9349 nat_grad_norm = 0.3394 cg_residual = 0.1617 step_size = 0.4359 reward = 0.0000 fps = 13 mse_loss = 2.3326 
2022-07-08 09:47:00.473426 - gail/main.py:174 - [TRPO] iter = 178000 dist_mean = 0.0751 dist_std = 0.5172 vf_loss = 0.0508 grad_norm = 1.0409 nat_grad_norm = 0.2847 cg_residual = 0.0978 step_size = 0.4222 reward = -0.0000 fps = 10 mse_loss = 2.3246 
2022-07-08 09:47:24.378170 - gail/main.py:174 - [TRPO] iter = 179000 dist_mean = 0.2079 dist_std = 0.5183 vf_loss = 0.1473 grad_norm = 0.7227 nat_grad_norm = 0.3028 cg_residual = 0.0896 step_size = 0.4621 reward = 0.0000 fps = 8 mse_loss = 2.2443 
2022-07-08 09:47:49.555519 - gail/main.py:174 - [TRPO] iter = 180000 dist_mean = 0.2472 dist_std = 0.5191 vf_loss = 0.0989 grad_norm = 0.9395 nat_grad_norm = 0.4543 cg_residual = 0.2747 step_size = 0.3401 reward = -0.0000 fps = 6 mse_loss = 2.0395 
2022-07-08 09:47:50.271459 - gail/main.py:201 - [Discriminator] iter = 180000 loss = -1.2828 grad_norm = 3.4111 grad_penalty = 0.1265 regularization = 0.0000 true_logits = 0.6536 fake_logits = -0.7557 true_prob = 0.6269 fake_prob = 0.3457 
2022-07-08 09:49:39.242346 - gail/main.py:142 - [Evaluate] iter = 180000 episode={ returns = 1328.2858 lengths = 387 } discounted_episode={ returns = 792.7831 lengths = 314 } 
2022-07-08 09:50:06.896773 - gail/main.py:174 - [TRPO] iter = 181000 dist_mean = 0.0862 dist_std = 0.5154 vf_loss = 0.0735 grad_norm = 1.3133 nat_grad_norm = 0.3065 cg_residual = 0.0973 step_size = 0.4048 reward = -0.0000 fps = 7 mse_loss = 1.9636 
2022-07-08 09:50:32.088634 - gail/main.py:174 - [TRPO] iter = 182000 dist_mean = 0.1983 dist_std = 0.5131 vf_loss = 0.1116 grad_norm = 0.9670 nat_grad_norm = 0.3356 cg_residual = 0.1086 step_size = 0.4151 reward = 0.0000 fps = 6 mse_loss = 2.0556 
2022-07-08 09:50:55.947874 - gail/main.py:174 - [TRPO] iter = 183000 dist_mean = 0.2206 dist_std = 0.5128 vf_loss = 0.0630 grad_norm = 0.7610 nat_grad_norm = 0.3730 cg_residual = 0.1994 step_size = 0.4362 reward = -0.0000 fps = 5 mse_loss = 2.0090 
2022-07-08 09:51:19.195122 - gail/main.py:174 - [TRPO] iter = 184000 dist_mean = 0.1972 dist_std = 0.5120 vf_loss = 0.3941 grad_norm = 1.6034 nat_grad_norm = 0.5069 cg_residual = 0.4070 step_size = 0.2678 reward = -0.0000 fps = 4 mse_loss = 2.0962 
2022-07-08 09:51:43.004631 - gail/main.py:174 - [TRPO] iter = 185000 dist_mean = 0.1649 dist_std = 0.5082 vf_loss = 0.0969 grad_norm = 0.9371 nat_grad_norm = 0.3659 cg_residual = 0.2057 step_size = 0.3881 reward = -0.0000 fps = 4 mse_loss = 2.1688 
2022-07-08 09:51:43.762613 - gail/main.py:201 - [Discriminator] iter = 185000 loss = -1.2399 grad_norm = 3.1184 grad_penalty = 0.1284 regularization = 0.0000 true_logits = 0.5670 fake_logits = -0.8013 true_prob = 0.6072 fake_prob = 0.3387 
2022-07-08 09:52:59.504581 - gail/main.py:142 - [Evaluate] iter = 185000 episode={ returns = 698.2622 lengths = 221 } discounted_episode={ returns = 550.1519 lengths = 215 } 
2022-07-08 09:53:23.834050 - gail/main.py:174 - [TRPO] iter = 186000 dist_mean = 0.2076 dist_std = 0.5034 vf_loss = 0.0502 grad_norm = 1.1322 nat_grad_norm = 0.2682 cg_residual = 0.0759 step_size = 0.4045 reward = 0.0000 fps = 9 mse_loss = 1.8345 
2022-07-08 09:53:48.968716 - gail/main.py:174 - [TRPO] iter = 187000 dist_mean = 0.1174 dist_std = 0.5004 vf_loss = 0.0909 grad_norm = 0.9646 nat_grad_norm = 0.3030 cg_residual = 0.1082 step_size = 0.4269 reward = 0.0000 fps = 7 mse_loss = 1.9970 
2022-07-08 09:54:13.823898 - gail/main.py:174 - [TRPO] iter = 188000 dist_mean = 0.2330 dist_std = 0.5021 vf_loss = 0.0893 grad_norm = 1.1034 nat_grad_norm = 0.2864 cg_residual = 0.1267 step_size = 0.3911 reward = -0.0000 fps = 6 mse_loss = 1.8322 
2022-07-08 09:54:38.593050 - gail/main.py:174 - [TRPO] iter = 189000 dist_mean = 0.1804 dist_std = 0.5010 vf_loss = 0.1060 grad_norm = 0.8614 nat_grad_norm = 0.3624 cg_residual = 0.1690 step_size = 0.4131 reward = 0.0000 fps = 5 mse_loss = 1.9332 
2022-07-08 09:55:02.425923 - gail/main.py:174 - [TRPO] iter = 190000 dist_mean = 0.1905 dist_std = 0.4928 vf_loss = 0.1456 grad_norm = 1.4432 nat_grad_norm = 0.2688 cg_residual = 0.1359 step_size = 0.4165 reward = -0.0000 fps = 5 mse_loss = 1.8124 
2022-07-08 09:55:03.101538 - gail/main.py:201 - [Discriminator] iter = 190000 loss = -1.0617 grad_norm = 2.9598 grad_penalty = 0.1034 regularization = 0.0000 true_logits = 0.5382 fake_logits = -0.6269 true_prob = 0.6064 fake_prob = 0.3716 
2022-07-08 09:57:06.694584 - gail/main.py:142 - [Evaluate] iter = 190000 episode={ returns = 1346.6817 lengths = 404 } discounted_episode={ returns = 1125.9525 lengths = 454 } 
2022-07-08 09:57:30.273576 - gail/main.py:174 - [TRPO] iter = 191000 dist_mean = 0.1226 dist_std = 0.4911 vf_loss = 0.1062 grad_norm = 1.0867 nat_grad_norm = 0.3940 cg_residual = 0.2072 step_size = 0.3196 reward = 0.0000 fps = 6 mse_loss = 1.6872 
2022-07-08 09:57:53.570307 - gail/main.py:174 - [TRPO] iter = 192000 dist_mean = 0.1910 dist_std = 0.4862 vf_loss = 0.1061 grad_norm = 0.9047 nat_grad_norm = 0.4389 cg_residual = 0.2038 step_size = 0.3137 reward = 0.0000 fps = 5 mse_loss = 1.4979 
2022-07-08 09:58:17.366639 - gail/main.py:174 - [TRPO] iter = 193000 dist_mean = 0.2398 dist_std = 0.4834 vf_loss = 0.0859 grad_norm = 1.2515 nat_grad_norm = 0.2774 cg_residual = 0.1825 step_size = 0.3886 reward = 0.0000 fps = 5 mse_loss = 1.5783 
2022-07-08 09:58:41.744818 - gail/main.py:174 - [TRPO] iter = 194000 dist_mean = 0.1500 dist_std = 0.4832 vf_loss = 0.1413 grad_norm = 1.1724 nat_grad_norm = 0.3156 cg_residual = 0.0907 step_size = 0.4151 reward = -0.0000 fps = 4 mse_loss = 1.4465 
2022-07-08 09:59:05.708581 - gail/main.py:174 - [TRPO] iter = 195000 dist_mean = 0.1070 dist_std = 0.4782 vf_loss = 0.2755 grad_norm = 0.9103 nat_grad_norm = 0.3268 cg_residual = 0.1189 step_size = 0.4221 reward = -0.0000 fps = 4 mse_loss = 1.4313 
2022-07-08 09:59:06.381393 - gail/main.py:201 - [Discriminator] iter = 195000 loss = -1.2822 grad_norm = 3.1466 grad_penalty = 0.1157 regularization = 0.0000 true_logits = 0.5266 fake_logits = -0.8713 true_prob = 0.6046 fake_prob = 0.3288 
2022-07-08 10:01:06.221862 - gail/main.py:142 - [Evaluate] iter = 195000 episode={ returns = 1171.6628 lengths = 337 } discounted_episode={ returns = 1148.0912 lengths = 406 } 
2022-07-08 10:01:31.397729 - gail/main.py:174 - [TRPO] iter = 196000 dist_mean = 0.2059 dist_std = 0.4749 vf_loss = 0.1247 grad_norm = 1.5658 nat_grad_norm = 0.2866 cg_residual = 0.2051 step_size = 0.3745 reward = -0.0000 fps = 6 mse_loss = 1.3964 
2022-07-08 10:02:00.705013 - gail/main.py:174 - [TRPO] iter = 197000 dist_mean = 0.2002 dist_std = 0.4746 vf_loss = 0.1410 grad_norm = 0.9901 nat_grad_norm = 0.4396 cg_residual = 0.5683 step_size = 0.3085 reward = -0.0000 fps = 5 mse_loss = 1.4426 
2022-07-08 10:02:31.678122 - gail/main.py:174 - [TRPO] iter = 198000 dist_mean = 0.1473 dist_std = 0.4735 vf_loss = 0.0891 grad_norm = 0.7773 nat_grad_norm = 0.3272 cg_residual = 0.1880 step_size = 0.4044 reward = -0.0000 fps = 4 mse_loss = 1.5201 
2022-07-08 10:02:59.022803 - gail/main.py:174 - [TRPO] iter = 199000 dist_mean = 0.1345 dist_std = 0.4662 vf_loss = 0.1011 grad_norm = 1.0280 nat_grad_norm = 0.2960 cg_residual = 0.1814 step_size = 0.3908 reward = 0.0000 fps = 4 mse_loss = 1.3562 
2022-07-08 10:03:24.889421 - gail/main.py:174 - [TRPO] iter = 200000 dist_mean = 0.1892 dist_std = 0.4663 vf_loss = 0.0933 grad_norm = 1.4766 nat_grad_norm = 0.2834 cg_residual = 0.1352 step_size = 0.4202 reward = 0.0000 fps = 3 mse_loss = 1.2669 
2022-07-08 10:03:25.671973 - gail/main.py:201 - [Discriminator] iter = 200000 loss = -1.1043 grad_norm = 3.2735 grad_penalty = 0.1194 regularization = 0.0000 true_logits = 0.3927 fake_logits = -0.8311 true_prob = 0.5791 fake_prob = 0.3426 
2022-07-08 10:04:58.328066 - gail/main.py:142 - [Evaluate] iter = 200000 episode={ returns = 846.7593 lengths = 261 } discounted_episode={ returns = 668.1629 lengths = 251 } 
2022-07-08 10:05:25.694540 - gail/main.py:174 - [TRPO] iter = 201000 dist_mean = 0.1022 dist_std = 0.4624 vf_loss = 0.0999 grad_norm = 0.9701 nat_grad_norm = 0.3148 cg_residual = 0.3110 step_size = 0.3997 reward = 0.0000 fps = 8 mse_loss = 1.3279 
2022-07-08 10:05:53.618057 - gail/main.py:174 - [TRPO] iter = 202000 dist_mean = 0.1475 dist_std = 0.4649 vf_loss = 0.1936 grad_norm = 1.5845 nat_grad_norm = 0.3158 cg_residual = 0.2047 step_size = 0.3552 reward = 0.0000 fps = 6 mse_loss = 1.2781 
2022-07-08 10:06:21.212096 - gail/main.py:174 - [TRPO] iter = 203000 dist_mean = 0.1215 dist_std = 0.4656 vf_loss = 0.1362 grad_norm = 1.4384 nat_grad_norm = 0.3288 cg_residual = 0.2851 step_size = 0.3647 reward = -0.0000 fps = 5 mse_loss = 1.1878 
2022-07-08 10:06:48.745835 - gail/main.py:174 - [TRPO] iter = 204000 dist_mean = 0.1205 dist_std = 0.4610 vf_loss = 0.1136 grad_norm = 1.3217 nat_grad_norm = 0.2898 cg_residual = 0.1695 step_size = 0.4065 reward = 0.0000 fps = 4 mse_loss = 1.2435 
2022-07-08 10:07:16.285217 - gail/main.py:174 - [TRPO] iter = 205000 dist_mean = 0.1549 dist_std = 0.4634 vf_loss = 0.2040 grad_norm = 0.9848 nat_grad_norm = 0.3066 cg_residual = 0.2330 step_size = 0.4257 reward = 0.0000 fps = 4 mse_loss = 1.0422 
2022-07-08 10:07:17.096531 - gail/main.py:201 - [Discriminator] iter = 205000 loss = -1.2621 grad_norm = 3.9344 grad_penalty = 0.1180 regularization = 0.0000 true_logits = 0.1942 fake_logits = -1.1860 true_prob = 0.5458 fake_prob = 0.2886 
2022-07-08 10:09:25.257646 - gail/main.py:142 - [Evaluate] iter = 205000 episode={ returns = 1208.9413 lengths = 350 } discounted_episode={ returns = 1051.6426 lengths = 381 } 
2022-07-08 10:09:53.500315 - gail/main.py:174 - [TRPO] iter = 206000 dist_mean = 0.2751 dist_std = 0.4627 vf_loss = 0.2563 grad_norm = 1.4134 nat_grad_norm = 0.2499 cg_residual = 0.2039 step_size = 0.4215 reward = -0.0000 fps = 6 mse_loss = 1.1345 
2022-07-08 10:10:20.204477 - gail/main.py:174 - [TRPO] iter = 207000 dist_mean = 0.1413 dist_std = 0.4571 vf_loss = 0.1704 grad_norm = 1.1458 nat_grad_norm = 0.2628 cg_residual = 0.1530 step_size = 0.4268 reward = 0.0000 fps = 5 mse_loss = 1.1131 
2022-07-08 10:10:47.186434 - gail/main.py:174 - [TRPO] iter = 208000 dist_mean = 0.1006 dist_std = 0.4496 vf_loss = 0.1338 grad_norm = 1.3149 nat_grad_norm = 0.2836 cg_residual = 0.1934 step_size = 0.3711 reward = 0.0000 fps = 4 mse_loss = 1.1240 
2022-07-08 10:11:14.914579 - gail/main.py:174 - [TRPO] iter = 209000 dist_mean = 0.1601 dist_std = 0.4460 vf_loss = 0.1330 grad_norm = 1.3805 nat_grad_norm = 0.2324 cg_residual = 0.1409 step_size = 0.4375 reward = -0.0000 fps = 4 mse_loss = 1.0306 
2022-07-08 10:11:43.072084 - gail/main.py:174 - [TRPO] iter = 210000 dist_mean = 0.1388 dist_std = 0.4423 vf_loss = 0.4030 grad_norm = 1.3364 nat_grad_norm = 0.2579 cg_residual = 0.1163 step_size = 0.4541 reward = -0.0000 fps = 3 mse_loss = 1.0436 
2022-07-08 10:11:43.975512 - gail/main.py:201 - [Discriminator] iter = 210000 loss = -1.2609 grad_norm = 3.3313 grad_penalty = 0.1276 regularization = 0.0000 true_logits = 0.1096 fake_logits = -1.2789 true_prob = 0.5290 fake_prob = 0.2700 
2022-07-08 10:13:49.500368 - gail/main.py:142 - [Evaluate] iter = 210000 episode={ returns = 1181.6376 lengths = 349 } discounted_episode={ returns = 858.4260 lengths = 317 } 
2022-07-08 10:14:17.357338 - gail/main.py:174 - [TRPO] iter = 211000 dist_mean = 0.1425 dist_std = 0.4415 vf_loss = 0.1594 grad_norm = 1.4860 nat_grad_norm = 0.2467 cg_residual = 0.1124 step_size = 0.4336 reward = 0.0000 fps = 6 mse_loss = 1.0302 
2022-07-08 10:14:44.650236 - gail/main.py:174 - [TRPO] iter = 212000 dist_mean = 0.1868 dist_std = 0.4466 vf_loss = 0.1724 grad_norm = 1.1016 nat_grad_norm = 0.2564 cg_residual = 0.1169 step_size = 0.4529 reward = -0.0000 fps = 5 mse_loss = 1.0194 
2022-07-08 10:15:12.115768 - gail/main.py:174 - [TRPO] iter = 213000 dist_mean = 0.1618 dist_std = 0.4451 vf_loss = 0.1519 grad_norm = 1.0890 nat_grad_norm = 0.2919 cg_residual = 0.2403 step_size = 0.3779 reward = -0.0000 fps = 4 mse_loss = 1.0116 
2022-07-08 10:15:40.170606 - gail/main.py:174 - [TRPO] iter = 214000 dist_mean = 0.1043 dist_std = 0.4423 vf_loss = 0.2013 grad_norm = 1.7971 nat_grad_norm = 0.2809 cg_residual = 0.1267 step_size = 0.3715 reward = 0.0000 fps = 4 mse_loss = 1.0041 
2022-07-08 10:16:08.318730 - gail/main.py:174 - [TRPO] iter = 215000 dist_mean = 0.1540 dist_std = 0.4406 vf_loss = 0.1451 grad_norm = 0.8753 nat_grad_norm = 0.2197 cg_residual = 0.1619 step_size = 0.4767 reward = -0.0000 fps = 3 mse_loss = 0.9663 
2022-07-08 10:16:09.067841 - gail/main.py:201 - [Discriminator] iter = 215000 loss = -1.3139 grad_norm = 3.3243 grad_penalty = 0.1249 regularization = 0.0000 true_logits = 0.0362 fake_logits = -1.4025 true_prob = 0.5166 fake_prob = 0.2489 
2022-07-08 10:18:15.012396 - gail/main.py:142 - [Evaluate] iter = 215000 episode={ returns = 1195.9274 lengths = 354 } discounted_episode={ returns = 1027.5779 lengths = 365 } 
2022-07-08 10:18:40.881921 - gail/main.py:174 - [TRPO] iter = 216000 dist_mean = 0.1420 dist_std = 0.4406 vf_loss = 0.2495 grad_norm = 0.9484 nat_grad_norm = 0.2175 cg_residual = 0.1101 step_size = 0.4681 reward = 0.0000 fps = 6 mse_loss = 0.9847 
2022-07-08 10:19:05.852054 - gail/main.py:174 - [TRPO] iter = 217000 dist_mean = 0.0512 dist_std = 0.4424 vf_loss = 0.1036 grad_norm = 1.5021 nat_grad_norm = 0.3118 cg_residual = 0.3755 step_size = 0.3297 reward = -0.0000 fps = 5 mse_loss = 0.9721 
2022-07-08 10:19:32.625223 - gail/main.py:174 - [TRPO] iter = 218000 dist_mean = 0.1784 dist_std = 0.4388 vf_loss = 0.2015 grad_norm = 1.1832 nat_grad_norm = 0.2942 cg_residual = 0.1964 step_size = 0.3836 reward = 0.0000 fps = 4 mse_loss = 0.9410 
2022-07-08 10:19:59.045022 - gail/main.py:174 - [TRPO] iter = 219000 dist_mean = 0.1641 dist_std = 0.4378 vf_loss = 0.2094 grad_norm = 1.0749 nat_grad_norm = 0.2604 cg_residual = 0.2769 step_size = 0.4371 reward = -0.0000 fps = 4 mse_loss = 0.9785 
2022-07-08 10:20:25.930343 - gail/main.py:174 - [TRPO] iter = 220000 dist_mean = 0.1562 dist_std = 0.4346 vf_loss = 0.2275 grad_norm = 0.9213 nat_grad_norm = 0.2253 cg_residual = 0.1603 step_size = 0.4999 reward = -0.0000 fps = 3 mse_loss = 0.9311 
2022-07-08 10:20:26.750491 - gail/main.py:201 - [Discriminator] iter = 220000 loss = -1.1721 grad_norm = 2.9332 grad_penalty = 0.1163 regularization = 0.0000 true_logits = -0.1431 fake_logits = -1.4315 true_prob = 0.4756 fake_prob = 0.2411 
2022-07-08 10:22:34.065373 - gail/main.py:142 - [Evaluate] iter = 220000 episode={ returns = 1137.5725 lengths = 341 } discounted_episode={ returns = 961.3536 lengths = 354 } 
2022-07-08 10:23:01.589785 - gail/main.py:174 - [TRPO] iter = 221000 dist_mean = 0.1003 dist_std = 0.4340 vf_loss = 0.1529 grad_norm = 0.9378 nat_grad_norm = 0.2192 cg_residual = 0.1636 step_size = 0.4806 reward = -0.0000 fps = 6 mse_loss = 0.9651 
2022-07-08 10:23:28.341603 - gail/main.py:174 - [TRPO] iter = 222000 dist_mean = 0.0997 dist_std = 0.4279 vf_loss = 0.2607 grad_norm = 1.1317 nat_grad_norm = 0.2563 cg_residual = 0.1918 step_size = 0.4474 reward = -0.0000 fps = 5 mse_loss = 0.8758 
2022-07-08 10:23:54.994219 - gail/main.py:174 - [TRPO] iter = 223000 dist_mean = 0.1444 dist_std = 0.4264 vf_loss = 0.1465 grad_norm = 1.0577 nat_grad_norm = 0.2388 cg_residual = 0.1266 step_size = 0.4663 reward = -0.0000 fps = 4 mse_loss = 0.9439 
2022-07-08 10:24:21.798334 - gail/main.py:174 - [TRPO] iter = 224000 dist_mean = 0.2121 dist_std = 0.4323 vf_loss = 0.2817 grad_norm = 1.1085 nat_grad_norm = 0.2956 cg_residual = 0.2117 step_size = 0.3862 reward = -0.0000 fps = 4 mse_loss = 0.8379 
2022-07-08 10:24:48.635810 - gail/main.py:174 - [TRPO] iter = 225000 dist_mean = 0.1737 dist_std = 0.4304 vf_loss = 0.4047 grad_norm = 0.9975 nat_grad_norm = 0.3038 cg_residual = 0.1799 step_size = 0.4095 reward = 0.0000 fps = 3 mse_loss = 0.8598 
2022-07-08 10:24:49.358299 - gail/main.py:201 - [Discriminator] iter = 225000 loss = -0.9708 grad_norm = 2.8084 grad_penalty = 0.0973 regularization = 0.0000 true_logits = -0.2422 fake_logits = -1.3104 true_prob = 0.4539 fake_prob = 0.2482 
2022-07-08 10:27:23.756927 - gail/main.py:142 - [Evaluate] iter = 225000 episode={ returns = 1577.9904 lengths = 440 } discounted_episode={ returns = 1163.7880 lengths = 416 } 
2022-07-08 10:27:52.203438 - gail/main.py:174 - [TRPO] iter = 226000 dist_mean = 0.0751 dist_std = 0.4246 vf_loss = 0.3607 grad_norm = 1.4919 nat_grad_norm = 0.1954 cg_residual = 0.1255 step_size = 0.4594 reward = -0.0000 fps = 5 mse_loss = 0.8668 
2022-07-08 10:28:20.067989 - gail/main.py:174 - [TRPO] iter = 227000 dist_mean = 0.1158 dist_std = 0.4246 vf_loss = 0.1227 grad_norm = 0.7908 nat_grad_norm = 0.2719 cg_residual = 0.1758 step_size = 0.4499 reward = 0.0000 fps = 4 mse_loss = 0.8893 
2022-07-08 10:28:47.643133 - gail/main.py:174 - [TRPO] iter = 228000 dist_mean = 0.1548 dist_std = 0.4224 vf_loss = 0.1694 grad_norm = 1.0830 nat_grad_norm = 0.2658 cg_residual = 0.1457 step_size = 0.3960 reward = 0.0000 fps = 4 mse_loss = 0.8440 
2022-07-08 10:29:15.223166 - gail/main.py:174 - [TRPO] iter = 229000 dist_mean = 0.0350 dist_std = 0.4255 vf_loss = 0.1119 grad_norm = 0.8785 nat_grad_norm = 0.2110 cg_residual = 0.1114 step_size = 0.4944 reward = -0.0000 fps = 3 mse_loss = 0.8291 
2022-07-08 10:29:43.317023 - gail/main.py:174 - [TRPO] iter = 230000 dist_mean = -0.0236 dist_std = 0.4226 vf_loss = 0.1240 grad_norm = 1.0887 nat_grad_norm = 0.2283 cg_residual = 0.1713 step_size = 0.4350 reward = -0.0000 fps = 3 mse_loss = 0.8018 
2022-07-08 10:29:44.159535 - gail/main.py:201 - [Discriminator] iter = 230000 loss = -0.9411 grad_norm = 2.9050 grad_penalty = 0.0927 regularization = 0.0000 true_logits = -0.3218 fake_logits = -1.3555 true_prob = 0.4364 fake_prob = 0.2350 
2022-07-08 10:32:08.150917 - gail/main.py:142 - [Evaluate] iter = 230000 episode={ returns = 1405.4619 lengths = 405 } discounted_episode={ returns = 1107.0601 lengths = 401 } 
2022-07-08 10:32:15.344797 - gail/main.py:174 - [TRPO] iter = 231000 dist_mean = 0.0610 dist_std = 0.4150 vf_loss = 0.1706 grad_norm = 0.8870 nat_grad_norm = 0.2903 cg_residual = 0.2473 step_size = 0.3976 reward = 0.0000 fps = 6 mse_loss = 0.8564 
2022-07-08 10:32:23.731145 - gail/main.py:174 - [TRPO] iter = 232000 dist_mean = 0.0537 dist_std = 0.4137 vf_loss = 0.1387 grad_norm = 1.4449 nat_grad_norm = 0.2098 cg_residual = 0.1250 step_size = 0.4663 reward = 0.0000 fps = 6 mse_loss = 0.8943 
2022-07-08 10:32:32.377645 - gail/main.py:174 - [TRPO] iter = 233000 dist_mean = 0.0832 dist_std = 0.4165 vf_loss = 0.1250 grad_norm = 1.4644 nat_grad_norm = 0.2832 cg_residual = 0.2741 step_size = 0.3693 reward = -0.0000 fps = 5 mse_loss = 0.8409 
2022-07-08 10:32:41.650021 - gail/main.py:174 - [TRPO] iter = 234000 dist_mean = 0.0610 dist_std = 0.4109 vf_loss = 0.0903 grad_norm = 1.2983 nat_grad_norm = 0.2200 cg_residual = 0.1623 step_size = 0.4393 reward = 0.0000 fps = 5 mse_loss = 0.8460 
2022-07-08 10:32:51.641624 - gail/main.py:174 - [TRPO] iter = 235000 dist_mean = 0.0419 dist_std = 0.4113 vf_loss = 0.1284 grad_norm = 1.2187 nat_grad_norm = 0.1958 cg_residual = 0.0899 step_size = 0.4891 reward = 0.0000 fps = 5 mse_loss = 0.8583 
2022-07-08 10:32:52.219067 - gail/main.py:201 - [Discriminator] iter = 235000 loss = -0.7945 grad_norm = 2.5111 grad_penalty = 0.0891 regularization = 0.0000 true_logits = -0.4101 fake_logits = -1.2937 true_prob = 0.4153 fake_prob = 0.2477 
2022-07-08 10:33:40.582719 - gail/main.py:142 - [Evaluate] iter = 235000 episode={ returns = 1436.6261 lengths = 415 } discounted_episode={ returns = 1051.0354 lengths = 383 } 
2022-07-08 10:33:49.314271 - gail/main.py:174 - [TRPO] iter = 236000 dist_mean = -0.0215 dist_std = 0.4074 vf_loss = 0.0686 grad_norm = 0.8543 nat_grad_norm = 0.2341 cg_residual = 0.2270 step_size = 0.5104 reward = 0.0000 fps = 17 mse_loss = 0.7643 
