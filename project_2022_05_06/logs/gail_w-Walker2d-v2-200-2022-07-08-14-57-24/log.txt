2022-07-08 14:57:24.106876 - utils/flags.py:257 - log_dir = logs/gail_w-Walker2d-v2-200-2022-07-08-14-57-24
2022-07-08 14:58:41.787726 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Walker2d-v2
2022-07-08 14:58:46.513670 - gail/main.py:80 - Expert Reward 5150.674112
2022-07-08 14:58:46.612076 - gail/main.py:84 - Original dataset size 3000
2022-07-08 14:58:46.625422 - gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 14:58:46.626433 - gail/main.py:87 - np random: 864 random : 786
2022-07-08 14:58:46.627782 - gail/main.py:91 - Sampled obs: 0.0531, acs: 0.2269
2022-07-08 14:58:47.008753 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 14:58:48.957253 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 14:58:48.961587 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.2194959e+00  2.4445076e-01 -7.8132987e-02 -2.6673764e-01
   1.8222688e-01 -9.5077172e-02 -3.3649772e-01  5.3370733e-02
   4.1614923e+00  4.1431887e-03  3.8142569e-02 -2.6013174e-03
  -1.0202496e-02  5.6982285e-01  2.9836079e-02 -1.5763690e-01
   1.7689442e-02]] 
 scale:[[0.06687175 0.23681822 0.23042987 0.33821535 0.664349   0.20301929
  0.42807332 0.7138035  0.986894   0.65049744 2.0363257  2.3816926
  3.7250905  6.026913   2.0511289  4.406521   6.1475325 ]]
2022-07-08 14:58:49.886716 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 14:58:49.889649 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(23, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 14:58:49.890522 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 14:58:50.139009 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 14:58:53.817214 - gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 113.4058 lengths = 135 } discounted_episode={ returns = 135.8490 lengths = 156 } 
2022-07-08 14:58:53.818267 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 14:58:56.174858 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 14:58:56.300824 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 14:58:56.425204 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 14:58:56.484408 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 14:58:56.857838 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 14:58:57.501939 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 14:58:57.576342 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 14:58:57.655360 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 14:58:57.773293 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 14:58:58.094034 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 14:58:58.158065 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 14:58:58.228904 - gail/main.py:174 - [TRPO] iter = 1000 dist_mean = 0.0000 dist_std = 1.0000 vf_loss = 0.2127 grad_norm = 0.3176 nat_grad_norm = 0.3986 cg_residual = 0.0000 step_size = 0.5038 reward = 0.0000 fps = 124 mse_loss = 0.4380 
2022-07-08 14:59:00.402574 - gail/main.py:174 - [TRPO] iter = 2000 dist_mean = -0.0148 dist_std = 1.0010 vf_loss = 0.3019 grad_norm = 0.5345 nat_grad_norm = 0.4888 cg_residual = 0.0000 step_size = 0.3417 reward = -0.0000 fps = 97 mse_loss = 0.4759 
2022-07-08 14:59:02.501974 - gail/main.py:174 - [TRPO] iter = 3000 dist_mean = -0.0348 dist_std = 1.0057 vf_loss = 0.1878 grad_norm = 0.5650 nat_grad_norm = 0.4909 cg_residual = 0.0000 step_size = 0.3328 reward = 0.0000 fps = 80 mse_loss = 0.5481 
2022-07-08 14:59:04.665511 - gail/main.py:174 - [TRPO] iter = 4000 dist_mean = -0.0429 dist_std = 1.0060 vf_loss = 0.1870 grad_norm = 0.4669 nat_grad_norm = 0.5075 cg_residual = 0.0000 step_size = 0.3714 reward = 0.0000 fps = 68 mse_loss = 0.6285 
2022-07-08 14:59:06.858714 - gail/main.py:174 - [TRPO] iter = 5000 dist_mean = -0.0506 dist_std = 1.0078 vf_loss = 0.1613 grad_norm = 0.5281 nat_grad_norm = 0.4704 cg_residual = 0.0001 step_size = 0.3728 reward = 0.0000 fps = 59 mse_loss = 0.6875 
2022-07-08 14:59:06.862657 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 14:59:07.446356 - gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.4121 grad_norm = 9.8276 grad_penalty = 1.0169 regularization = 0.0000 true_logits = 0.3014 fake_logits = 0.6966 true_prob = 0.5739 fake_prob = 0.6630 
2022-07-08 14:59:08.073799 - gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = 0.5522 lengths = 26 } discounted_episode={ returns = 0.2826 lengths = 26 } 
2022-07-08 14:59:10.184903 - gail/main.py:174 - [TRPO] iter = 6000 dist_mean = -0.0595 dist_std = 1.0085 vf_loss = 0.3100 grad_norm = 0.4358 nat_grad_norm = 0.4758 cg_residual = 0.0001 step_size = 0.4007 reward = -0.0000 fps = 365 mse_loss = 0.6795 
2022-07-08 14:59:12.511962 - gail/main.py:174 - [TRPO] iter = 7000 dist_mean = -0.0571 dist_std = 1.0104 vf_loss = 0.4002 grad_norm = 0.4682 nat_grad_norm = 0.4719 cg_residual = 0.0001 step_size = 0.3677 reward = -0.0000 fps = 197 mse_loss = 0.6821 
2022-07-08 14:59:14.220630 - gail/main.py:174 - [TRPO] iter = 8000 dist_mean = -0.0578 dist_std = 1.0098 vf_loss = 0.3454 grad_norm = 0.4779 nat_grad_norm = 0.4845 cg_residual = 0.0002 step_size = 0.3702 reward = 0.0000 fps = 147 mse_loss = 0.6815 
2022-07-08 14:59:15.969852 - gail/main.py:174 - [TRPO] iter = 9000 dist_mean = -0.0432 dist_std = 1.0079 vf_loss = 0.3692 grad_norm = 0.4299 nat_grad_norm = 0.4747 cg_residual = 0.0002 step_size = 0.4066 reward = -0.0000 fps = 117 mse_loss = 0.6830 
2022-07-08 14:59:17.900861 - gail/main.py:174 - [TRPO] iter = 10000 dist_mean = -0.0477 dist_std = 1.0020 vf_loss = 0.3104 grad_norm = 0.5218 nat_grad_norm = 0.4771 cg_residual = 0.0001 step_size = 0.3738 reward = 0.0000 fps = 95 mse_loss = 0.7671 
2022-07-08 14:59:18.026319 - gail/main.py:201 - [Discriminator] iter = 10000 loss = 0.7476 grad_norm = 7.4934 grad_penalty = 0.6376 regularization = 0.0000 true_logits = 0.3380 fake_logits = 0.4480 true_prob = 0.5823 fake_prob = 0.6059 
2022-07-08 14:59:18.800626 - gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = -0.5345 lengths = 24 } discounted_episode={ returns = -0.7446 lengths = 24 } 
2022-07-08 14:59:21.128973 - gail/main.py:174 - [TRPO] iter = 11000 dist_mean = -0.0247 dist_std = 1.0060 vf_loss = 0.6413 grad_norm = 0.4589 nat_grad_norm = 0.5094 cg_residual = 0.0001 step_size = 0.3757 reward = 0.0000 fps = 322 mse_loss = 0.7846 
2022-07-08 14:59:23.704539 - gail/main.py:174 - [TRPO] iter = 12000 dist_mean = -0.0201 dist_std = 1.0071 vf_loss = 0.6034 grad_norm = 0.4672 nat_grad_norm = 0.5023 cg_residual = 0.0002 step_size = 0.3789 reward = -0.0000 fps = 176 mse_loss = 0.8191 
2022-07-08 14:59:26.245637 - gail/main.py:174 - [TRPO] iter = 13000 dist_mean = -0.0128 dist_std = 1.0010 vf_loss = 0.4867 grad_norm = 0.4440 nat_grad_norm = 0.5169 cg_residual = 0.0001 step_size = 0.3828 reward = 0.0000 fps = 121 mse_loss = 0.8075 
2022-07-08 14:59:29.252599 - gail/main.py:174 - [TRPO] iter = 14000 dist_mean = 0.0193 dist_std = 0.9993 vf_loss = 0.5215 grad_norm = 0.4364 nat_grad_norm = 0.5285 cg_residual = 0.0002 step_size = 0.4072 reward = 0.0000 fps = 89 mse_loss = 0.7674 
2022-07-08 14:59:32.064449 - gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.0343 dist_std = 0.9990 vf_loss = 0.4964 grad_norm = 0.3391 nat_grad_norm = 0.6331 cg_residual = 0.0004 step_size = 0.3883 reward = -0.0000 fps = 71 mse_loss = 0.7814 
2022-07-08 14:59:32.186541 - gail/main.py:201 - [Discriminator] iter = 15000 loss = 0.4732 grad_norm = 6.6826 grad_penalty = 0.5586 regularization = 0.0000 true_logits = 0.3724 fake_logits = 0.2870 true_prob = 0.5901 fake_prob = 0.5679 
2022-07-08 14:59:33.454977 - gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = -6.3059 lengths = 53 } discounted_episode={ returns = -6.1579 lengths = 53 } 
2022-07-08 14:59:35.303165 - gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.0206 dist_std = 0.9953 vf_loss = 0.5158 grad_norm = 0.4634 nat_grad_norm = 0.6355 cg_residual = 0.0003 step_size = 0.3421 reward = -0.0000 fps = 321 mse_loss = 0.8442 
2022-07-08 14:59:37.216361 - gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.0292 dist_std = 0.9932 vf_loss = 0.4941 grad_norm = 0.4314 nat_grad_norm = 0.5414 cg_residual = 0.0003 step_size = 0.4107 reward = 0.0000 fps = 199 mse_loss = 0.8318 
2022-07-08 14:59:39.020702 - gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.0573 dist_std = 0.9890 vf_loss = 0.4239 grad_norm = 0.5125 nat_grad_norm = 0.8862 cg_residual = 0.0011 step_size = 0.2700 reward = -0.0000 fps = 146 mse_loss = 0.8832 
2022-07-08 14:59:40.864752 - gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.0555 dist_std = 0.9853 vf_loss = 0.4492 grad_norm = 0.4498 nat_grad_norm = 0.5273 cg_residual = 0.0003 step_size = 0.4087 reward = -0.0000 fps = 115 mse_loss = 0.9215 
2022-07-08 14:59:42.650281 - gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.0671 dist_std = 0.9879 vf_loss = 0.4190 grad_norm = 0.4194 nat_grad_norm = 0.5405 cg_residual = 0.0005 step_size = 0.4185 reward = -0.0000 fps = 95 mse_loss = 1.0200 
2022-07-08 14:59:42.726223 - gail/main.py:201 - [Discriminator] iter = 20000 loss = -0.0360 grad_norm = 5.6228 grad_penalty = 0.4297 regularization = 0.0000 true_logits = 0.4111 fake_logits = -0.0546 true_prob = 0.5983 fake_prob = 0.4888 
2022-07-08 14:59:43.741743 - gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = -4.7135 lengths = 43 } discounted_episode={ returns = -4.7646 lengths = 43 } 
2022-07-08 14:59:45.499209 - gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.0647 dist_std = 0.9856 vf_loss = 0.4362 grad_norm = 0.4339 nat_grad_norm = 0.6228 cg_residual = 0.0006 step_size = 0.3783 reward = -0.0000 fps = 361 mse_loss = 0.9953 
2022-07-08 14:59:47.348468 - gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.0853 dist_std = 0.9828 vf_loss = 0.4357 grad_norm = 0.3792 nat_grad_norm = 0.6451 cg_residual = 0.0008 step_size = 0.4088 reward = 0.0000 fps = 216 mse_loss = 1.0481 
2022-07-08 14:59:49.004632 - gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.1101 dist_std = 0.9780 vf_loss = 0.3461 grad_norm = 0.4708 nat_grad_norm = 0.6533 cg_residual = 0.0008 step_size = 0.3732 reward = 0.0000 fps = 159 mse_loss = 1.0675 
2022-07-08 14:59:50.750714 - gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.0873 dist_std = 0.9772 vf_loss = 0.3233 grad_norm = 0.4065 nat_grad_norm = 0.5115 cg_residual = 0.0006 step_size = 0.4599 reward = -0.0000 fps = 124 mse_loss = 0.9797 
2022-07-08 14:59:52.706014 - gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.0927 dist_std = 0.9761 vf_loss = 0.4761 grad_norm = 0.4089 nat_grad_norm = 0.6111 cg_residual = 0.0007 step_size = 0.4001 reward = 0.0000 fps = 100 mse_loss = 0.9725 
2022-07-08 14:59:52.809002 - gail/main.py:201 - [Discriminator] iter = 25000 loss = -0.5987 grad_norm = 5.9976 grad_penalty = 0.4646 regularization = 0.0000 true_logits = 0.4207 fake_logits = -0.6425 true_prob = 0.6008 fake_prob = 0.3580 
2022-07-08 14:59:53.934497 - gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = -1.7825 lengths = 45 } discounted_episode={ returns = -1.9909 lengths = 45 } 
2022-07-08 14:59:55.795066 - gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.1052 dist_std = 0.9684 vf_loss = 0.2581 grad_norm = 0.4134 nat_grad_norm = 0.7290 cg_residual = 0.0012 step_size = 0.3491 reward = 0.0000 fps = 335 mse_loss = 0.8617 
2022-07-08 14:59:57.682096 - gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.1633 dist_std = 0.9644 vf_loss = 0.6257 grad_norm = 0.4227 nat_grad_norm = 0.6857 cg_residual = 0.0017 step_size = 0.3840 reward = -0.0000 fps = 205 mse_loss = 0.8202 
2022-07-08 14:59:59.439397 - gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.1171 dist_std = 0.9611 vf_loss = 0.4123 grad_norm = 0.3889 nat_grad_norm = 0.4879 cg_residual = 0.0008 step_size = 0.4522 reward = -0.0000 fps = 150 mse_loss = 0.8246 
2022-07-08 15:00:01.164531 - gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.1002 dist_std = 0.9574 vf_loss = 0.3837 grad_norm = 0.4005 nat_grad_norm = 0.6260 cg_residual = 0.0009 step_size = 0.3998 reward = -0.0000 fps = 119 mse_loss = 0.8513 
2022-07-08 15:00:03.047055 - gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.1284 dist_std = 0.9607 vf_loss = 0.2642 grad_norm = 0.5805 nat_grad_norm = 0.5599 cg_residual = 0.0008 step_size = 0.3406 reward = 0.0000 fps = 97 mse_loss = 0.8856 
2022-07-08 15:00:03.140929 - gail/main.py:201 - [Discriminator] iter = 30000 loss = -1.2568 grad_norm = 6.3512 grad_penalty = 0.4194 regularization = 0.0000 true_logits = 0.4229 fake_logits = -1.2533 true_prob = 0.6015 fake_prob = 0.2408 
2022-07-08 15:00:04.476029 - gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = 0.3339 lengths = 46 } discounted_episode={ returns = 0.9798 lengths = 46 } 
2022-07-08 15:00:06.495360 - gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.1330 dist_std = 0.9681 vf_loss = 0.3512 grad_norm = 0.3761 nat_grad_norm = 0.6033 cg_residual = 0.0009 step_size = 0.4095 reward = -0.0000 fps = 298 mse_loss = 0.8650 
2022-07-08 15:00:08.161007 - gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.1600 dist_std = 0.9653 vf_loss = 0.8560 grad_norm = 0.4644 nat_grad_norm = 0.6796 cg_residual = 0.0022 step_size = 0.3651 reward = 0.0000 fps = 199 mse_loss = 0.8639 
2022-07-08 15:00:09.803004 - gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.1305 dist_std = 0.9696 vf_loss = 1.0084 grad_norm = 0.3549 nat_grad_norm = 0.5807 cg_residual = 0.0014 step_size = 0.4117 reward = 0.0000 fps = 150 mse_loss = 0.9079 
2022-07-08 15:00:11.543438 - gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.1968 dist_std = 0.9680 vf_loss = 0.6045 grad_norm = 0.4604 nat_grad_norm = 0.6087 cg_residual = 0.0059 step_size = 0.3615 reward = 0.0000 fps = 119 mse_loss = 0.9199 
2022-07-08 15:00:12.766057 - gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.1257 dist_std = 0.9670 vf_loss = 0.8580 grad_norm = 0.4545 nat_grad_norm = 0.7247 cg_residual = 0.0017 step_size = 0.3356 reward = 0.0000 fps = 103 mse_loss = 0.9230 
2022-07-08 15:00:12.814466 - gail/main.py:201 - [Discriminator] iter = 35000 loss = -1.9923 grad_norm = 6.8341 grad_penalty = 0.4406 regularization = 0.0000 true_logits = 0.4978 fake_logits = -1.9352 true_prob = 0.6190 fake_prob = 0.1480 
2022-07-08 15:00:13.528704 - gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 1.4410 lengths = 43 } discounted_episode={ returns = 1.3938 lengths = 44 } 
2022-07-08 15:00:14.728112 - gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.1212 dist_std = 0.9668 vf_loss = 0.4481 grad_norm = 0.4227 nat_grad_norm = 0.6708 cg_residual = 0.0013 step_size = 0.3815 reward = 0.0000 fps = 523 mse_loss = 0.9481 
2022-07-08 15:00:15.959746 - gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.2359 dist_std = 0.9660 vf_loss = 0.4261 grad_norm = 0.3041 nat_grad_norm = 0.5282 cg_residual = 0.0025 step_size = 0.4685 reward = -0.0000 fps = 318 mse_loss = 0.8807 
2022-07-08 15:00:17.179005 - gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.2752 dist_std = 0.9600 vf_loss = 0.5875 grad_norm = 0.3931 nat_grad_norm = 0.5799 cg_residual = 0.0043 step_size = 0.3969 reward = 0.0000 fps = 229 mse_loss = 0.8649 
2022-07-08 15:00:18.401148 - gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.2253 dist_std = 0.9624 vf_loss = 0.4000 grad_norm = 0.3311 nat_grad_norm = 0.5686 cg_residual = 0.0025 step_size = 0.4078 reward = -0.0000 fps = 179 mse_loss = 0.8941 
2022-07-08 15:00:19.613817 - gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.1367 dist_std = 0.9624 vf_loss = 0.6360 grad_norm = 0.3752 nat_grad_norm = 0.7164 cg_residual = 0.0015 step_size = 0.3930 reward = 0.0000 fps = 147 mse_loss = 0.8818 
2022-07-08 15:00:19.665547 - gail/main.py:201 - [Discriminator] iter = 40000 loss = -2.6742 grad_norm = 6.7714 grad_penalty = 0.4004 regularization = 0.0000 true_logits = 0.5178 fake_logits = -2.5568 true_prob = 0.6240 fake_prob = 0.0935 
2022-07-08 15:00:20.773343 - gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 5.7737 lengths = 54 } discounted_episode={ returns = 5.6381 lengths = 54 } 
2022-07-08 15:00:23.124765 - gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.1371 dist_std = 0.9604 vf_loss = 0.5772 grad_norm = 0.3563 nat_grad_norm = 0.7303 cg_residual = 0.0024 step_size = 0.4018 reward = 0.0000 fps = 289 mse_loss = 0.8469 
2022-07-08 15:00:25.794909 - gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.2394 dist_std = 0.9611 vf_loss = 0.3490 grad_norm = 0.3653 nat_grad_norm = 0.5852 cg_residual = 0.0061 step_size = 0.4337 reward = -0.0000 fps = 163 mse_loss = 0.9556 
2022-07-08 15:00:33.313677 - gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.1935 dist_std = 0.9559 vf_loss = 0.7012 grad_norm = 0.4984 nat_grad_norm = 0.6709 cg_residual = 0.0030 step_size = 0.3614 reward = 0.0000 fps = 73 mse_loss = 1.0043 
2022-07-08 15:00:36.275017 - gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.2514 dist_std = 0.9499 vf_loss = 0.2995 grad_norm = 0.4168 nat_grad_norm = 0.6287 cg_residual = 0.0076 step_size = 0.3959 reward = 0.0000 fps = 60 mse_loss = 1.0215 
2022-07-08 15:00:39.734297 - gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.2316 dist_std = 0.9504 vf_loss = 0.3752 grad_norm = 0.4966 nat_grad_norm = 0.5833 cg_residual = 0.0074 step_size = 0.3744 reward = 0.0000 fps = 49 mse_loss = 1.0264 
2022-07-08 15:00:39.875353 - gail/main.py:201 - [Discriminator] iter = 45000 loss = -2.9750 grad_norm = 6.8366 grad_penalty = 0.3779 regularization = 0.0000 true_logits = 0.5895 fake_logits = -2.7633 true_prob = 0.6401 fake_prob = 0.0780 
2022-07-08 15:00:41.993909 - gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 4.5704 lengths = 41 } discounted_episode={ returns = 4.8018 lengths = 42 } 
2022-07-08 15:00:45.347898 - gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.2623 dist_std = 0.9469 vf_loss = 0.5334 grad_norm = 0.4549 nat_grad_norm = 0.6552 cg_residual = 0.0053 step_size = 0.3659 reward = -0.0000 fps = 183 mse_loss = 1.0319 
2022-07-08 15:00:48.832503 - gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.1702 dist_std = 0.9487 vf_loss = 0.4308 grad_norm = 0.5663 nat_grad_norm = 0.6601 cg_residual = 0.0046 step_size = 0.3340 reward = 0.0000 fps = 111 mse_loss = 0.9292 
2022-07-08 15:00:52.239201 - gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.2407 dist_std = 0.9448 vf_loss = 0.3822 grad_norm = 0.3411 nat_grad_norm = 0.5898 cg_residual = 0.0075 step_size = 0.4356 reward = -0.0000 fps = 80 mse_loss = 0.9420 
2022-07-08 15:00:56.782768 - gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.2941 dist_std = 0.9450 vf_loss = 0.3954 grad_norm = 0.4894 nat_grad_norm = 0.5449 cg_residual = 0.0087 step_size = 0.3704 reward = 0.0000 fps = 59 mse_loss = 0.9560 
2022-07-08 15:01:03.163295 - gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.1875 dist_std = 0.9390 vf_loss = 0.4842 grad_norm = 0.4805 nat_grad_norm = 0.6567 cg_residual = 0.0043 step_size = 0.3750 reward = -0.0000 fps = 42 mse_loss = 1.0569 
2022-07-08 15:01:03.347883 - gail/main.py:201 - [Discriminator] iter = 50000 loss = -3.6198 grad_norm = 6.8560 grad_penalty = 0.5160 regularization = 0.0000 true_logits = 0.5974 fake_logits = -3.5384 true_prob = 0.6395 fake_prob = 0.0444 
2022-07-08 15:01:06.487765 - gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 6.2233 lengths = 44 } discounted_episode={ returns = 6.0487 lengths = 44 } 
2022-07-08 15:01:11.142112 - gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.1874 dist_std = 0.9387 vf_loss = 0.3003 grad_norm = 0.4109 nat_grad_norm = 0.6023 cg_residual = 0.0052 step_size = 0.3754 reward = -0.0000 fps = 128 mse_loss = 1.0468 
2022-07-08 15:01:15.190910 - gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.2190 dist_std = 0.9385 vf_loss = 0.3706 grad_norm = 0.3999 nat_grad_norm = 0.6210 cg_residual = 0.0046 step_size = 0.4053 reward = 0.0000 fps = 84 mse_loss = 1.0746 
2022-07-08 15:01:19.660296 - gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.2218 dist_std = 0.9372 vf_loss = 0.2962 grad_norm = 0.4119 nat_grad_norm = 0.7122 cg_residual = 0.0036 step_size = 0.3565 reward = 0.0000 fps = 61 mse_loss = 1.1006 
2022-07-08 15:01:23.717687 - gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.2248 dist_std = 0.9300 vf_loss = 0.3037 grad_norm = 0.4816 nat_grad_norm = 0.6482 cg_residual = 0.0039 step_size = 0.3695 reward = 0.0000 fps = 49 mse_loss = 1.0007 
2022-07-08 15:01:29.171132 - gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.2710 dist_std = 0.9320 vf_loss = 0.4213 grad_norm = 0.4326 nat_grad_norm = 0.5890 cg_residual = 0.0060 step_size = 0.3996 reward = -0.0000 fps = 38 mse_loss = 0.9434 
2022-07-08 15:01:29.348323 - gail/main.py:201 - [Discriminator] iter = 55000 loss = -3.9381 grad_norm = 6.7199 grad_penalty = 0.5112 regularization = 0.0000 true_logits = 0.6652 fake_logits = -3.7841 true_prob = 0.6538 fake_prob = 0.0361 
2022-07-08 15:01:33.021548 - gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 8.3131 lengths = 47 } discounted_episode={ returns = 8.2269 lengths = 47 } 
2022-07-08 15:01:39.131046 - gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.1810 dist_std = 0.9263 vf_loss = 0.4670 grad_norm = 0.4144 nat_grad_norm = 0.5876 cg_residual = 0.0026 step_size = 0.3980 reward = 0.0000 fps = 102 mse_loss = 1.0014 
2022-07-08 15:01:41.605424 - gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.2944 dist_std = 0.9237 vf_loss = 0.3215 grad_norm = 0.4233 nat_grad_norm = 0.5946 cg_residual = 0.0047 step_size = 0.3823 reward = -0.0000 fps = 81 mse_loss = 1.0577 
2022-07-08 15:01:45.114289 - gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.2204 dist_std = 0.9243 vf_loss = 0.4631 grad_norm = 0.4473 nat_grad_norm = 0.5625 cg_residual = 0.0025 step_size = 0.3858 reward = -0.0000 fps = 63 mse_loss = 1.0250 
2022-07-08 15:01:48.513539 - gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.1903 dist_std = 0.9223 vf_loss = 0.3609 grad_norm = 0.3999 nat_grad_norm = 0.6723 cg_residual = 0.0020 step_size = 0.3915 reward = 0.0000 fps = 52 mse_loss = 0.9824 
2022-07-08 15:01:50.925514 - gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.1466 dist_std = 0.9200 vf_loss = 0.3442 grad_norm = 0.3761 nat_grad_norm = 0.6273 cg_residual = 0.0022 step_size = 0.4382 reward = 0.0000 fps = 46 mse_loss = 1.0429 
2022-07-08 15:01:51.039132 - gail/main.py:201 - [Discriminator] iter = 60000 loss = -4.4085 grad_norm = 7.0695 grad_penalty = 0.5008 regularization = 0.0000 true_logits = 0.6154 fake_logits = -4.2938 true_prob = 0.6421 fake_prob = 0.0280 
2022-07-08 15:01:54.595378 - gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 108.0681 lengths = 92 } discounted_episode={ returns = 157.7693 lengths = 117 } 
2022-07-08 15:01:57.528579 - gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.1860 dist_std = 0.9224 vf_loss = 0.3771 grad_norm = 0.4723 nat_grad_norm = 0.5998 cg_residual = 0.0025 step_size = 0.4009 reward = -0.0000 fps = 154 mse_loss = 0.9851 
2022-07-08 15:02:00.292842 - gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.1975 dist_std = 0.9190 vf_loss = 0.4770 grad_norm = 0.4521 nat_grad_norm = 0.6106 cg_residual = 0.0028 step_size = 0.3874 reward = 0.0000 fps = 108 mse_loss = 1.0578 
2022-07-08 15:02:03.801192 - gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.1884 dist_std = 0.9140 vf_loss = 0.3954 grad_norm = 0.4952 nat_grad_norm = 0.6723 cg_residual = 0.0040 step_size = 0.3688 reward = 0.0000 fps = 78 mse_loss = 1.1013 
2022-07-08 15:02:05.733011 - gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.2617 dist_std = 0.9109 vf_loss = 0.5677 grad_norm = 0.5421 nat_grad_norm = 0.7877 cg_residual = 0.0049 step_size = 0.3269 reward = -0.0000 fps = 68 mse_loss = 1.1375 
2022-07-08 15:02:07.403744 - gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.2267 dist_std = 0.9053 vf_loss = 0.4191 grad_norm = 0.3696 nat_grad_norm = 0.6585 cg_residual = 0.0033 step_size = 0.4005 reward = 0.0000 fps = 61 mse_loss = 1.1133 
2022-07-08 15:02:07.456468 - gail/main.py:201 - [Discriminator] iter = 65000 loss = -4.5808 grad_norm = 6.3646 grad_penalty = 0.5854 regularization = 0.0000 true_logits = 0.5310 fake_logits = -4.6353 true_prob = 0.6240 fake_prob = 0.0275 
2022-07-08 15:02:08.266848 - gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 13.0824 lengths = 47 } discounted_episode={ returns = 13.5074 lengths = 48 } 
2022-07-08 15:02:09.506957 - gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.1555 dist_std = 0.9006 vf_loss = 0.3637 grad_norm = 0.4258 nat_grad_norm = 0.6395 cg_residual = 0.0025 step_size = 0.4002 reward = 0.0000 fps = 488 mse_loss = 1.1431 
2022-07-08 15:02:10.858435 - gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.1100 dist_std = 0.9000 vf_loss = 0.2426 grad_norm = 0.4613 nat_grad_norm = 0.6808 cg_residual = 0.0046 step_size = 0.3604 reward = -0.0000 fps = 294 mse_loss = 1.2343 
2022-07-08 15:02:12.126195 - gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.1944 dist_std = 0.8979 vf_loss = 0.4120 grad_norm = 0.4434 nat_grad_norm = 0.7677 cg_residual = 0.0035 step_size = 0.3571 reward = 0.0000 fps = 214 mse_loss = 1.1639 
2022-07-08 15:02:13.550941 - gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.1575 dist_std = 0.8982 vf_loss = 0.4667 grad_norm = 0.5421 nat_grad_norm = 0.6744 cg_residual = 0.0045 step_size = 0.3487 reward = -0.0000 fps = 164 mse_loss = 1.2396 
2022-07-08 15:02:15.124070 - gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.1349 dist_std = 0.9002 vf_loss = 0.4991 grad_norm = 0.4481 nat_grad_norm = 0.7015 cg_residual = 0.0049 step_size = 0.3627 reward = -0.0000 fps = 130 mse_loss = 1.2561 
2022-07-08 15:02:15.241947 - gail/main.py:201 - [Discriminator] iter = 70000 loss = -5.0506 grad_norm = 5.6436 grad_penalty = 0.5687 regularization = 0.0000 true_logits = 0.3947 fake_logits = -5.2246 true_prob = 0.5964 fake_prob = 0.0187 
2022-07-08 15:02:17.568860 - gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 13.3618 lengths = 47 } discounted_episode={ returns = 67.6445 lengths = 73 } 
2022-07-08 15:02:20.905384 - gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.1475 dist_std = 0.9007 vf_loss = 0.4650 grad_norm = 0.4612 nat_grad_norm = 0.6117 cg_residual = 0.0039 step_size = 0.3834 reward = -0.0000 fps = 176 mse_loss = 1.3392 
2022-07-08 15:02:22.917213 - gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.1859 dist_std = 0.8971 vf_loss = 0.8065 grad_norm = 0.4457 nat_grad_norm = 0.7325 cg_residual = 0.0035 step_size = 0.3704 reward = -0.0000 fps = 130 mse_loss = 1.2547 
2022-07-08 15:02:24.372816 - gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.1776 dist_std = 0.8897 vf_loss = 0.5365 grad_norm = 0.4466 nat_grad_norm = 0.6857 cg_residual = 0.0047 step_size = 0.3884 reward = 0.0000 fps = 109 mse_loss = 1.3109 
2022-07-08 15:02:25.858253 - gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.1860 dist_std = 0.8917 vf_loss = 0.5662 grad_norm = 0.3924 nat_grad_norm = 0.6508 cg_residual = 0.0043 step_size = 0.4167 reward = -0.0000 fps = 94 mse_loss = 1.3736 
2022-07-08 15:02:27.912881 - gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.1189 dist_std = 0.8879 vf_loss = 0.4245 grad_norm = 0.5028 nat_grad_norm = 0.5736 cg_residual = 0.0047 step_size = 0.3767 reward = -0.0000 fps = 78 mse_loss = 1.5116 
2022-07-08 15:02:28.026887 - gail/main.py:201 - [Discriminator] iter = 75000 loss = -5.5158 grad_norm = 5.2677 grad_penalty = 0.6327 regularization = 0.0000 true_logits = 0.3183 fake_logits = -5.8301 true_prob = 0.5814 fake_prob = 0.0116 
2022-07-08 15:02:29.862721 - gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 46.6813 lengths = 65 } discounted_episode={ returns = 19.8200 lengths = 55 } 
2022-07-08 15:02:32.031807 - gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.2001 dist_std = 0.8849 vf_loss = 0.5033 grad_norm = 0.5011 nat_grad_norm = 0.7767 cg_residual = 0.0057 step_size = 0.3505 reward = -0.0000 fps = 251 mse_loss = 1.3526 
2022-07-08 15:02:35.099251 - gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.1601 dist_std = 0.8838 vf_loss = 0.4115 grad_norm = 0.4499 nat_grad_norm = 0.7143 cg_residual = 0.0085 step_size = 0.3586 reward = 0.0000 fps = 141 mse_loss = 1.4721 
2022-07-08 15:02:36.951800 - gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.1932 dist_std = 0.8834 vf_loss = 0.4288 grad_norm = 0.5260 nat_grad_norm = 0.6130 cg_residual = 0.0053 step_size = 0.3799 reward = 0.0000 fps = 112 mse_loss = 1.4986 
2022-07-08 15:02:38.775855 - gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.1904 dist_std = 0.8792 vf_loss = 0.4562 grad_norm = 0.5452 nat_grad_norm = 0.7967 cg_residual = 0.0048 step_size = 0.3353 reward = -0.0000 fps = 93 mse_loss = 1.4228 
2022-07-08 15:02:40.625008 - gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.1918 dist_std = 0.8770 vf_loss = 0.5160 grad_norm = 0.4734 nat_grad_norm = 0.6886 cg_residual = 0.0044 step_size = 0.3681 reward = -0.0000 fps = 79 mse_loss = 1.4806 
2022-07-08 15:02:40.710497 - gail/main.py:201 - [Discriminator] iter = 80000 loss = -5.3671 grad_norm = 6.1869 grad_penalty = 0.6382 regularization = 0.0000 true_logits = 0.0839 fake_logits = -5.9215 true_prob = 0.5387 fake_prob = 0.0136 
2022-07-08 15:02:42.880552 - gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 54.0510 lengths = 71 } discounted_episode={ returns = 50.0566 lengths = 72 } 
2022-07-08 15:02:44.666073 - gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.1877 dist_std = 0.8757 vf_loss = 0.6044 grad_norm = 0.4683 nat_grad_norm = 0.6974 cg_residual = 0.0043 step_size = 0.3780 reward = -0.0000 fps = 253 mse_loss = 1.4160 
2022-07-08 15:02:46.522698 - gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.1813 dist_std = 0.8759 vf_loss = 0.5302 grad_norm = 0.5283 nat_grad_norm = 0.6621 cg_residual = 0.0090 step_size = 0.3459 reward = -0.0000 fps = 172 mse_loss = 1.4428 
2022-07-08 15:02:48.850019 - gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.1980 dist_std = 0.8707 vf_loss = 0.5808 grad_norm = 0.4946 nat_grad_norm = 0.8027 cg_residual = 0.0060 step_size = 0.3326 reward = 0.0000 fps = 122 mse_loss = 1.4115 
2022-07-08 15:02:51.140972 - gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.2154 dist_std = 0.8672 vf_loss = 0.3656 grad_norm = 0.4865 nat_grad_norm = 0.6390 cg_residual = 0.0082 step_size = 0.3785 reward = -0.0000 fps = 95 mse_loss = 1.4536 
2022-07-08 15:02:54.148259 - gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.2008 dist_std = 0.8635 vf_loss = 0.3132 grad_norm = 0.4922 nat_grad_norm = 0.6417 cg_residual = 0.0070 step_size = 0.3700 reward = 0.0000 fps = 74 mse_loss = 1.4932 
2022-07-08 15:02:54.332973 - gail/main.py:201 - [Discriminator] iter = 85000 loss = -4.9548 grad_norm = 6.5913 grad_penalty = 0.6522 regularization = 0.0000 true_logits = -0.0627 fake_logits = -5.6697 true_prob = 0.5146 fake_prob = 0.0147 
2022-07-08 15:02:58.456735 - gail/main.py:142 - [Evaluate] iter = 85000 episode={ returns = 88.0219 lengths = 121 } discounted_episode={ returns = 159.9880 lengths = 149 } 
2022-07-08 15:03:00.542009 - gail/main.py:174 - [TRPO] iter = 86000 dist_mean = 0.2286 dist_std = 0.8654 vf_loss = 0.4817 grad_norm = 0.5027 nat_grad_norm = 0.6764 cg_residual = 0.0074 step_size = 0.3626 reward = -0.0000 fps = 161 mse_loss = 1.5562 
2022-07-08 15:03:02.528660 - gail/main.py:174 - [TRPO] iter = 87000 dist_mean = 0.2408 dist_std = 0.8659 vf_loss = 0.3223 grad_norm = 0.5170 nat_grad_norm = 0.6872 cg_residual = 0.0070 step_size = 0.3574 reward = 0.0000 fps = 122 mse_loss = 1.6561 
2022-07-08 15:03:04.452462 - gail/main.py:174 - [TRPO] iter = 88000 dist_mean = 0.1966 dist_std = 0.8654 vf_loss = 0.4209 grad_norm = 0.4791 nat_grad_norm = 0.6557 cg_residual = 0.0055 step_size = 0.3773 reward = -0.0000 fps = 98 mse_loss = 1.6073 
2022-07-08 15:03:07.162587 - gail/main.py:174 - [TRPO] iter = 89000 dist_mean = 0.2115 dist_std = 0.8631 vf_loss = 0.2590 grad_norm = 0.5233 nat_grad_norm = 0.7047 cg_residual = 0.0120 step_size = 0.3510 reward = 0.0000 fps = 78 mse_loss = 1.6110 
2022-07-08 15:03:09.528860 - gail/main.py:174 - [TRPO] iter = 90000 dist_mean = 0.1713 dist_std = 0.8648 vf_loss = 0.3515 grad_norm = 0.6072 nat_grad_norm = 0.6819 cg_residual = 0.0114 step_size = 0.3471 reward = 0.0000 fps = 65 mse_loss = 1.6626 
2022-07-08 15:03:09.607622 - gail/main.py:201 - [Discriminator] iter = 90000 loss = -5.2994 grad_norm = 5.9222 grad_penalty = 0.5541 regularization = 0.0000 true_logits = -0.1753 fake_logits = -6.0288 true_prob = 0.4894 fake_prob = 0.0116 
2022-07-08 15:03:11.344185 - gail/main.py:142 - [Evaluate] iter = 90000 episode={ returns = 23.4502 lengths = 50 } discounted_episode={ returns = 71.5056 lengths = 88 } 
2022-07-08 15:03:13.281981 - gail/main.py:174 - [TRPO] iter = 91000 dist_mean = 0.1924 dist_std = 0.8602 vf_loss = 0.3085 grad_norm = 0.5514 nat_grad_norm = 0.7450 cg_residual = 0.0115 step_size = 0.3215 reward = -0.0000 fps = 272 mse_loss = 1.6381 
2022-07-08 15:03:15.119858 - gail/main.py:174 - [TRPO] iter = 92000 dist_mean = 0.1828 dist_std = 0.8545 vf_loss = 0.3015 grad_norm = 0.5334 nat_grad_norm = 0.7707 cg_residual = 0.0069 step_size = 0.3436 reward = 0.0000 fps = 181 mse_loss = 1.5914 
2022-07-08 15:03:17.311603 - gail/main.py:174 - [TRPO] iter = 93000 dist_mean = 0.1876 dist_std = 0.8552 vf_loss = 0.5022 grad_norm = 0.5396 nat_grad_norm = 0.6820 cg_residual = 0.0064 step_size = 0.3554 reward = 0.0000 fps = 129 mse_loss = 1.5952 
2022-07-08 15:03:19.638796 - gail/main.py:174 - [TRPO] iter = 94000 dist_mean = 0.1869 dist_std = 0.8519 vf_loss = 0.5837 grad_norm = 0.6024 nat_grad_norm = 0.7495 cg_residual = 0.0076 step_size = 0.3207 reward = -0.0000 fps = 99 mse_loss = 1.6518 
2022-07-08 15:03:22.433584 - gail/main.py:174 - [TRPO] iter = 95000 dist_mean = 0.1519 dist_std = 0.8454 vf_loss = 0.3851 grad_norm = 0.5092 nat_grad_norm = 0.7309 cg_residual = 0.0149 step_size = 0.3577 reward = -0.0000 fps = 78 mse_loss = 1.6170 
2022-07-08 15:03:22.545747 - gail/main.py:201 - [Discriminator] iter = 95000 loss = -5.4150 grad_norm = 5.5508 grad_penalty = 0.6195 regularization = 0.0000 true_logits = -0.2791 fake_logits = -6.3135 true_prob = 0.4743 fake_prob = 0.0084 
2022-07-08 15:03:28.987010 - gail/main.py:142 - [Evaluate] iter = 95000 episode={ returns = 215.5407 lengths = 225 } discounted_episode={ returns = 181.2739 lengths = 218 } 
2022-07-08 15:03:30.256899 - gail/main.py:174 - [TRPO] iter = 96000 dist_mean = 0.1920 dist_std = 0.8424 vf_loss = 0.4047 grad_norm = 0.5018 nat_grad_norm = 0.6761 cg_residual = 0.0070 step_size = 0.3659 reward = -0.0000 fps = 129 mse_loss = 1.8129 
2022-07-08 15:03:31.517271 - gail/main.py:174 - [TRPO] iter = 97000 dist_mean = 0.1688 dist_std = 0.8382 vf_loss = 0.2296 grad_norm = 0.5145 nat_grad_norm = 0.6094 cg_residual = 0.0109 step_size = 0.3836 reward = 0.0000 fps = 111 mse_loss = 1.8190 
2022-07-08 15:03:33.016301 - gail/main.py:174 - [TRPO] iter = 98000 dist_mean = 0.2112 dist_std = 0.8373 vf_loss = 0.2700 grad_norm = 0.6984 nat_grad_norm = 0.6710 cg_residual = 0.0125 step_size = 0.3375 reward = 0.0000 fps = 95 mse_loss = 1.8840 
2022-07-08 15:03:34.248222 - gail/main.py:174 - [TRPO] iter = 99000 dist_mean = 0.2147 dist_std = 0.8381 vf_loss = 0.2232 grad_norm = 0.5579 nat_grad_norm = 0.7344 cg_residual = 0.0149 step_size = 0.3295 reward = -0.0000 fps = 85 mse_loss = 1.7613 
2022-07-08 15:03:35.931883 - gail/main.py:174 - [TRPO] iter = 100000 dist_mean = 0.2068 dist_std = 0.8389 vf_loss = 0.2864 grad_norm = 0.5531 nat_grad_norm = 0.5474 cg_residual = 0.0116 step_size = 0.3710 reward = -0.0000 fps = 74 mse_loss = 1.9492 
2022-07-08 15:03:35.982711 - gail/main.py:201 - [Discriminator] iter = 100000 loss = -5.1039 grad_norm = 5.7205 grad_penalty = 0.6427 regularization = 0.0000 true_logits = -0.3961 fake_logits = -6.1427 true_prob = 0.4494 fake_prob = 0.0087 
2022-07-08 15:03:40.623435 - gail/main.py:142 - [Evaluate] iter = 100000 episode={ returns = 257.8753 lengths = 325 } discounted_episode={ returns = 146.6206 lengths = 252 } 
2022-07-08 15:03:41.871534 - gail/main.py:174 - [TRPO] iter = 101000 dist_mean = 0.1821 dist_std = 0.8345 vf_loss = 0.3320 grad_norm = 0.6281 nat_grad_norm = 0.7511 cg_residual = 0.0146 step_size = 0.3008 reward = -0.0000 fps = 169 mse_loss = 1.8635 
2022-07-08 15:03:43.104224 - gail/main.py:174 - [TRPO] iter = 102000 dist_mean = 0.1956 dist_std = 0.8309 vf_loss = 0.2954 grad_norm = 0.6509 nat_grad_norm = 0.6642 cg_residual = 0.0126 step_size = 0.3429 reward = 0.0000 fps = 140 mse_loss = 1.9801 
2022-07-08 15:03:44.293119 - gail/main.py:174 - [TRPO] iter = 103000 dist_mean = 0.2299 dist_std = 0.8271 vf_loss = 0.3487 grad_norm = 0.5949 nat_grad_norm = 0.6494 cg_residual = 0.0122 step_size = 0.3586 reward = 0.0000 fps = 120 mse_loss = 2.0253 
2022-07-08 15:03:45.473715 - gail/main.py:174 - [TRPO] iter = 104000 dist_mean = 0.1888 dist_std = 0.8268 vf_loss = 0.3286 grad_norm = 0.4605 nat_grad_norm = 0.5518 cg_residual = 0.0159 step_size = 0.3871 reward = 0.0000 fps = 105 mse_loss = 2.0305 
2022-07-08 15:03:46.763734 - gail/main.py:174 - [TRPO] iter = 105000 dist_mean = 0.1934 dist_std = 0.8237 vf_loss = 0.3581 grad_norm = 0.5614 nat_grad_norm = 0.6298 cg_residual = 0.0110 step_size = 0.3553 reward = 0.0000 fps = 92 mse_loss = 2.0025 
2022-07-08 15:03:46.816537 - gail/main.py:201 - [Discriminator] iter = 105000 loss = -5.7656 grad_norm = 6.0845 grad_penalty = 0.5947 regularization = 0.0000 true_logits = -0.4181 fake_logits = -6.7784 true_prob = 0.4424 fake_prob = 0.0039 
2022-07-08 15:03:50.257633 - gail/main.py:142 - [Evaluate] iter = 105000 episode={ returns = 265.1954 lengths = 233 } discounted_episode={ returns = 235.3025 lengths = 201 } 
2022-07-08 15:03:51.473379 - gail/main.py:174 - [TRPO] iter = 106000 dist_mean = 0.1634 dist_std = 0.8256 vf_loss = 0.2929 grad_norm = 0.6218 nat_grad_norm = 0.7162 cg_residual = 0.0269 step_size = 0.3209 reward = -0.0000 fps = 214 mse_loss = 2.1138 
2022-07-08 15:03:52.702905 - gail/main.py:174 - [TRPO] iter = 107000 dist_mean = 0.1602 dist_std = 0.8235 vf_loss = 0.4505 grad_norm = 0.5939 nat_grad_norm = 0.6561 cg_residual = 0.0111 step_size = 0.3552 reward = -0.0000 fps = 169 mse_loss = 2.0466 
2022-07-08 15:03:54.155781 - gail/main.py:174 - [TRPO] iter = 108000 dist_mean = 0.1753 dist_std = 0.8220 vf_loss = 0.2602 grad_norm = 0.5847 nat_grad_norm = 0.6585 cg_residual = 0.0300 step_size = 0.3518 reward = -0.0000 fps = 136 mse_loss = 1.9584 
2022-07-08 15:03:55.373856 - gail/main.py:174 - [TRPO] iter = 109000 dist_mean = 0.1798 dist_std = 0.8209 vf_loss = 0.3172 grad_norm = 0.6403 nat_grad_norm = 0.5751 cg_residual = 0.0178 step_size = 0.3388 reward = -0.0000 fps = 116 mse_loss = 2.0120 
2022-07-08 15:03:56.609373 - gail/main.py:174 - [TRPO] iter = 110000 dist_mean = 0.1662 dist_std = 0.8205 vf_loss = 0.2517 grad_norm = 0.5867 nat_grad_norm = 0.5416 cg_residual = 0.0132 step_size = 0.3734 reward = 0.0000 fps = 102 mse_loss = 2.1701 
2022-07-08 15:03:56.666225 - gail/main.py:201 - [Discriminator] iter = 110000 loss = -5.3493 grad_norm = 4.9273 grad_penalty = 0.6390 regularization = 0.0000 true_logits = -0.5610 fake_logits = -6.5493 true_prob = 0.4261 fake_prob = 0.0058 
2022-07-08 15:04:01.156370 - gail/main.py:142 - [Evaluate] iter = 110000 episode={ returns = 378.8735 lengths = 213 } discounted_episode={ returns = 328.9171 lengths = 213 } 
2022-07-08 15:04:02.821549 - gail/main.py:174 - [TRPO] iter = 111000 dist_mean = 0.1471 dist_std = 0.8164 vf_loss = 0.2829 grad_norm = 0.6777 nat_grad_norm = 0.4983 cg_residual = 0.0192 step_size = 0.3545 reward = 0.0000 fps = 162 mse_loss = 2.0995 
2022-07-08 15:04:04.441744 - gail/main.py:174 - [TRPO] iter = 112000 dist_mean = 0.1677 dist_std = 0.8116 vf_loss = 0.4609 grad_norm = 0.5068 nat_grad_norm = 0.5776 cg_residual = 0.0135 step_size = 0.3782 reward = -0.0000 fps = 128 mse_loss = 2.0999 
2022-07-08 15:04:06.112359 - gail/main.py:174 - [TRPO] iter = 113000 dist_mean = 0.2068 dist_std = 0.8103 vf_loss = 0.3799 grad_norm = 0.5744 nat_grad_norm = 0.6071 cg_residual = 0.0165 step_size = 0.3634 reward = 0.0000 fps = 105 mse_loss = 2.1714 
2022-07-08 15:04:07.969283 - gail/main.py:174 - [TRPO] iter = 114000 dist_mean = 0.2084 dist_std = 0.8057 vf_loss = 0.3626 grad_norm = 0.6617 nat_grad_norm = 0.6684 cg_residual = 0.0223 step_size = 0.3218 reward = -0.0000 fps = 88 mse_loss = 2.3210 
2022-07-08 15:04:09.574920 - gail/main.py:174 - [TRPO] iter = 115000 dist_mean = 0.1418 dist_std = 0.8054 vf_loss = 0.3860 grad_norm = 0.6716 nat_grad_norm = 0.5564 cg_residual = 0.0334 step_size = 0.3724 reward = -0.0000 fps = 77 mse_loss = 2.1893 
2022-07-08 15:04:09.643751 - gail/main.py:201 - [Discriminator] iter = 115000 loss = -5.3583 grad_norm = 5.3113 grad_penalty = 0.6287 regularization = 0.0000 true_logits = -0.5743 fake_logits = -6.5613 true_prob = 0.4204 fake_prob = 0.0055 
2022-07-08 15:04:13.009134 - gail/main.py:142 - [Evaluate] iter = 115000 episode={ returns = 365.4968 lengths = 185 } discounted_episode={ returns = 326.0316 lengths = 187 } 
2022-07-08 15:04:14.234590 - gail/main.py:174 - [TRPO] iter = 116000 dist_mean = 0.1531 dist_std = 0.8013 vf_loss = 0.3407 grad_norm = 0.5205 nat_grad_norm = 0.6205 cg_residual = 0.0192 step_size = 0.3397 reward = 0.0000 fps = 217 mse_loss = 2.0999 
2022-07-08 15:04:15.438625 - gail/main.py:174 - [TRPO] iter = 117000 dist_mean = 0.1458 dist_std = 0.8000 vf_loss = 0.4123 grad_norm = 0.8522 nat_grad_norm = 0.5421 cg_residual = 0.0278 step_size = 0.3419 reward = -0.0000 fps = 172 mse_loss = 2.2787 
2022-07-08 15:04:16.723426 - gail/main.py:174 - [TRPO] iter = 118000 dist_mean = 0.1837 dist_std = 0.7962 vf_loss = 0.3129 grad_norm = 0.5672 nat_grad_norm = 0.6283 cg_residual = 0.0295 step_size = 0.3420 reward = 0.0000 fps = 141 mse_loss = 2.1970 
2022-07-08 15:04:17.949904 - gail/main.py:174 - [TRPO] iter = 119000 dist_mean = 0.1641 dist_std = 0.7955 vf_loss = 0.3502 grad_norm = 0.5977 nat_grad_norm = 0.7038 cg_residual = 0.0210 step_size = 0.3455 reward = -0.0000 fps = 120 mse_loss = 2.0941 
2022-07-08 15:04:19.163363 - gail/main.py:174 - [TRPO] iter = 120000 dist_mean = 0.1415 dist_std = 0.7933 vf_loss = 0.3646 grad_norm = 0.8855 nat_grad_norm = 0.5164 cg_residual = 0.0198 step_size = 0.3638 reward = 0.0000 fps = 105 mse_loss = 2.0088 
2022-07-08 15:04:19.215262 - gail/main.py:201 - [Discriminator] iter = 120000 loss = -5.1966 grad_norm = 4.4370 grad_penalty = 0.5957 regularization = 0.0000 true_logits = -0.5126 fake_logits = -6.3048 true_prob = 0.4195 fake_prob = 0.0052 
2022-07-08 15:04:22.930956 - gail/main.py:142 - [Evaluate] iter = 120000 episode={ returns = 399.9634 lengths = 229 } discounted_episode={ returns = 354.7249 lengths = 234 } 
2022-07-08 15:04:24.134078 - gail/main.py:174 - [TRPO] iter = 121000 dist_mean = 0.1695 dist_std = 0.7910 vf_loss = 0.2485 grad_norm = 0.7086 nat_grad_norm = 0.5288 cg_residual = 0.0295 step_size = 0.3534 reward = 0.0000 fps = 203 mse_loss = 1.9896 
2022-07-08 15:04:25.332169 - gail/main.py:174 - [TRPO] iter = 122000 dist_mean = 0.1431 dist_std = 0.7892 vf_loss = 0.3050 grad_norm = 0.6717 nat_grad_norm = 0.6215 cg_residual = 0.0329 step_size = 0.2992 reward = -0.0000 fps = 163 mse_loss = 1.9007 
2022-07-08 15:04:26.563174 - gail/main.py:174 - [TRPO] iter = 123000 dist_mean = 0.2150 dist_std = 0.7850 vf_loss = 0.1962 grad_norm = 0.5902 nat_grad_norm = 0.5555 cg_residual = 0.0216 step_size = 0.3941 reward = 0.0000 fps = 136 mse_loss = 2.0278 
2022-07-08 15:04:27.774116 - gail/main.py:174 - [TRPO] iter = 124000 dist_mean = 0.2190 dist_std = 0.7837 vf_loss = 0.3016 grad_norm = 0.5720 nat_grad_norm = 0.5186 cg_residual = 0.0192 step_size = 0.3829 reward = -0.0000 fps = 116 mse_loss = 1.9573 
2022-07-08 15:04:29.000971 - gail/main.py:174 - [TRPO] iter = 125000 dist_mean = 0.1810 dist_std = 0.7855 vf_loss = 0.2739 grad_norm = 0.5880 nat_grad_norm = 0.5306 cg_residual = 0.0253 step_size = 0.3694 reward = -0.0000 fps = 102 mse_loss = 2.0219 
2022-07-08 15:04:29.050258 - gail/main.py:201 - [Discriminator] iter = 125000 loss = -5.6379 grad_norm = 4.5344 grad_penalty = 0.5915 regularization = 0.0000 true_logits = -0.5409 fake_logits = -6.7702 true_prob = 0.4168 fake_prob = 0.0035 
2022-07-08 15:04:32.213874 - gail/main.py:142 - [Evaluate] iter = 125000 episode={ returns = 361.2264 lengths = 194 } discounted_episode={ returns = 327.9038 lengths = 201 } 
2022-07-08 15:04:33.411217 - gail/main.py:174 - [TRPO] iter = 126000 dist_mean = 0.1847 dist_std = 0.7849 vf_loss = 0.3072 grad_norm = 0.5970 nat_grad_norm = 0.5204 cg_residual = 0.0246 step_size = 0.3493 reward = 0.0000 fps = 229 mse_loss = 2.0049 
2022-07-08 15:04:34.620423 - gail/main.py:174 - [TRPO] iter = 127000 dist_mean = 0.1552 dist_std = 0.7840 vf_loss = 0.2559 grad_norm = 0.9925 nat_grad_norm = 0.5641 cg_residual = 0.0255 step_size = 0.3109 reward = 0.0000 fps = 179 mse_loss = 1.9521 
2022-07-08 15:04:35.843564 - gail/main.py:174 - [TRPO] iter = 128000 dist_mean = 0.1944 dist_std = 0.7829 vf_loss = 0.2640 grad_norm = 0.6586 nat_grad_norm = 0.5456 cg_residual = 0.0205 step_size = 0.3417 reward = -0.0000 fps = 147 mse_loss = 1.7900 
2022-07-08 15:04:37.078779 - gail/main.py:174 - [TRPO] iter = 129000 dist_mean = 0.1929 dist_std = 0.7802 vf_loss = 0.2075 grad_norm = 0.5434 nat_grad_norm = 0.5499 cg_residual = 0.0168 step_size = 0.3861 reward = -0.0000 fps = 124 mse_loss = 1.7682 
2022-07-08 15:04:38.292404 - gail/main.py:174 - [TRPO] iter = 130000 dist_mean = 0.2084 dist_std = 0.7825 vf_loss = 0.2557 grad_norm = 0.6470 nat_grad_norm = 0.5860 cg_residual = 0.0317 step_size = 0.3383 reward = 0.0000 fps = 108 mse_loss = 1.6940 
2022-07-08 15:04:38.343949 - gail/main.py:201 - [Discriminator] iter = 130000 loss = -5.2112 grad_norm = 4.6767 grad_penalty = 0.6044 regularization = 0.0000 true_logits = -0.6605 fake_logits = -6.4761 true_prob = 0.3992 fake_prob = 0.0047 
2022-07-08 15:04:41.219848 - gail/main.py:142 - [Evaluate] iter = 130000 episode={ returns = 343.8923 lengths = 177 } discounted_episode={ returns = 313.9495 lengths = 182 } 
2022-07-08 15:04:42.436310 - gail/main.py:174 - [TRPO] iter = 131000 dist_mean = 0.1802 dist_std = 0.7821 vf_loss = 0.2093 grad_norm = 0.6403 nat_grad_norm = 0.5626 cg_residual = 0.0307 step_size = 0.3493 reward = -0.0000 fps = 244 mse_loss = 1.7847 
2022-07-08 15:04:43.636853 - gail/main.py:174 - [TRPO] iter = 132000 dist_mean = 0.1783 dist_std = 0.7748 vf_loss = 0.2059 grad_norm = 0.5844 nat_grad_norm = 0.5589 cg_residual = 0.0251 step_size = 0.3666 reward = 0.0000 fps = 189 mse_loss = 1.8759 
2022-07-08 15:04:44.855101 - gail/main.py:174 - [TRPO] iter = 133000 dist_mean = 0.1951 dist_std = 0.7723 vf_loss = 0.1875 grad_norm = 0.7312 nat_grad_norm = 0.5781 cg_residual = 0.0351 step_size = 0.3243 reward = -0.0000 fps = 153 mse_loss = 1.8433 
2022-07-08 15:04:46.094596 - gail/main.py:174 - [TRPO] iter = 134000 dist_mean = 0.1952 dist_std = 0.7704 vf_loss = 0.2336 grad_norm = 0.6197 nat_grad_norm = 0.4955 cg_residual = 0.0275 step_size = 0.3738 reward = 0.0000 fps = 129 mse_loss = 1.9445 
2022-07-08 15:04:47.305815 - gail/main.py:174 - [TRPO] iter = 135000 dist_mean = 0.2278 dist_std = 0.7673 vf_loss = 0.2015 grad_norm = 0.6848 nat_grad_norm = 0.6164 cg_residual = 0.0324 step_size = 0.3227 reward = 0.0000 fps = 111 mse_loss = 1.9122 
2022-07-08 15:04:47.355940 - gail/main.py:201 - [Discriminator] iter = 135000 loss = -5.2060 grad_norm = 4.7826 grad_penalty = 0.5748 regularization = 0.0000 true_logits = -0.6464 fake_logits = -6.4272 true_prob = 0.4047 fake_prob = 0.0039 
2022-07-08 15:04:49.798930 - gail/main.py:142 - [Evaluate] iter = 135000 episode={ returns = 322.5227 lengths = 157 } discounted_episode={ returns = 282.5102 lengths = 151 } 
2022-07-08 15:04:51.014294 - gail/main.py:174 - [TRPO] iter = 136000 dist_mean = 0.2387 dist_std = 0.7654 vf_loss = 0.1605 grad_norm = 0.6446 nat_grad_norm = 0.5381 cg_residual = 0.0213 step_size = 0.3768 reward = 0.0000 fps = 273 mse_loss = 1.9049 
2022-07-08 15:04:52.266176 - gail/main.py:174 - [TRPO] iter = 137000 dist_mean = 0.1971 dist_std = 0.7626 vf_loss = 0.1545 grad_norm = 0.7562 nat_grad_norm = 0.5192 cg_residual = 0.0407 step_size = 0.3150 reward = 0.0000 fps = 203 mse_loss = 1.8786 
2022-07-08 15:04:53.485539 - gail/main.py:174 - [TRPO] iter = 138000 dist_mean = 0.1817 dist_std = 0.7613 vf_loss = 0.1852 grad_norm = 0.6756 nat_grad_norm = 0.4467 cg_residual = 0.0281 step_size = 0.3745 reward = -0.0000 fps = 163 mse_loss = 1.8679 
2022-07-08 15:04:54.958136 - gail/main.py:174 - [TRPO] iter = 139000 dist_mean = 0.1941 dist_std = 0.7612 vf_loss = 0.1390 grad_norm = 0.7213 nat_grad_norm = 0.4713 cg_residual = 0.0381 step_size = 0.3623 reward = 0.0000 fps = 131 mse_loss = 1.9860 
2022-07-08 15:04:56.615582 - gail/main.py:174 - [TRPO] iter = 140000 dist_mean = 0.2255 dist_std = 0.7543 vf_loss = 0.1460 grad_norm = 0.7024 nat_grad_norm = 0.5692 cg_residual = 0.0353 step_size = 0.3369 reward = 0.0000 fps = 108 mse_loss = 1.7775 
2022-07-08 15:04:56.685211 - gail/main.py:201 - [Discriminator] iter = 140000 loss = -4.7758 grad_norm = 4.8032 grad_penalty = 0.5422 regularization = 0.0000 true_logits = -0.7006 fake_logits = -6.0186 true_prob = 0.3933 fake_prob = 0.0050 
2022-07-08 15:04:58.816400 - gail/main.py:142 - [Evaluate] iter = 140000 episode={ returns = 259.5926 lengths = 123 } discounted_episode={ returns = 242.3194 lengths = 124 } 
2022-07-08 15:05:00.025082 - gail/main.py:174 - [TRPO] iter = 141000 dist_mean = 0.2183 dist_std = 0.7551 vf_loss = 0.2071 grad_norm = 0.6673 nat_grad_norm = 0.4707 cg_residual = 0.0301 step_size = 0.3677 reward = -0.0000 fps = 299 mse_loss = 1.8206 
2022-07-08 15:05:01.228567 - gail/main.py:174 - [TRPO] iter = 142000 dist_mean = 0.2155 dist_std = 0.7526 vf_loss = 0.2029 grad_norm = 0.6012 nat_grad_norm = 0.4008 cg_residual = 0.0239 step_size = 0.4038 reward = 0.0000 fps = 220 mse_loss = 1.8984 
2022-07-08 15:05:02.445822 - gail/main.py:174 - [TRPO] iter = 143000 dist_mean = 0.1903 dist_std = 0.7480 vf_loss = 0.1700 grad_norm = 0.7022 nat_grad_norm = 0.4563 cg_residual = 0.0346 step_size = 0.3562 reward = -0.0000 fps = 173 mse_loss = 2.1140 
2022-07-08 15:05:03.654937 - gail/main.py:174 - [TRPO] iter = 144000 dist_mean = 0.1897 dist_std = 0.7465 vf_loss = 0.1421 grad_norm = 0.7426 nat_grad_norm = 0.5144 cg_residual = 0.0447 step_size = 0.3392 reward = -0.0000 fps = 143 mse_loss = 2.0913 
2022-07-08 15:05:04.881205 - gail/main.py:174 - [TRPO] iter = 145000 dist_mean = 0.2258 dist_std = 0.7430 vf_loss = 0.2450 grad_norm = 0.5975 nat_grad_norm = 0.5041 cg_residual = 0.0332 step_size = 0.4033 reward = 0.0000 fps = 122 mse_loss = 2.0694 
2022-07-08 15:05:04.931972 - gail/main.py:201 - [Discriminator] iter = 145000 loss = -4.6596 grad_norm = 3.3830 grad_penalty = 0.4906 regularization = 0.0000 true_logits = -0.6826 fake_logits = -5.8327 true_prob = 0.4010 fake_prob = 0.0062 
2022-07-08 15:05:06.901463 - gail/main.py:142 - [Evaluate] iter = 145000 episode={ returns = 272.7731 lengths = 122 } discounted_episode={ returns = 255.7544 lengths = 124 } 
2022-07-08 15:05:08.106280 - gail/main.py:174 - [TRPO] iter = 146000 dist_mean = 0.2220 dist_std = 0.7391 vf_loss = 0.1517 grad_norm = 0.7658 nat_grad_norm = 0.5645 cg_residual = 0.0438 step_size = 0.3192 reward = 0.0000 fps = 315 mse_loss = 2.0694 
2022-07-08 15:05:09.284708 - gail/main.py:174 - [TRPO] iter = 147000 dist_mean = 0.2524 dist_std = 0.7333 vf_loss = 0.1805 grad_norm = 0.7263 nat_grad_norm = 0.5195 cg_residual = 0.0506 step_size = 0.3325 reward = 0.0000 fps = 229 mse_loss = 2.1601 
2022-07-08 15:05:10.489940 - gail/main.py:174 - [TRPO] iter = 148000 dist_mean = 0.2027 dist_std = 0.7311 vf_loss = 0.1271 grad_norm = 0.6711 nat_grad_norm = 0.4993 cg_residual = 0.0545 step_size = 0.3619 reward = -0.0000 fps = 180 mse_loss = 2.2235 
2022-07-08 15:05:11.730312 - gail/main.py:174 - [TRPO] iter = 149000 dist_mean = 0.2279 dist_std = 0.7241 vf_loss = 0.1292 grad_norm = 0.7213 nat_grad_norm = 0.5351 cg_residual = 0.0578 step_size = 0.3367 reward = -0.0000 fps = 147 mse_loss = 2.2733 
2022-07-08 15:05:12.936774 - gail/main.py:174 - [TRPO] iter = 150000 dist_mean = 0.2290 dist_std = 0.7215 vf_loss = 0.1347 grad_norm = 0.6115 nat_grad_norm = 0.4704 cg_residual = 0.1001 step_size = 0.3801 reward = -0.0000 fps = 124 mse_loss = 2.2936 
2022-07-08 15:05:12.998212 - gail/main.py:201 - [Discriminator] iter = 150000 loss = -4.6207 grad_norm = 3.2454 grad_penalty = 0.4737 regularization = 0.0000 true_logits = -0.5729 fake_logits = -5.6673 true_prob = 0.4111 fake_prob = 0.0072 
2022-07-08 15:05:14.691077 - gail/main.py:142 - [Evaluate] iter = 150000 episode={ returns = 265.6392 lengths = 109 } discounted_episode={ returns = 249.7423 lengths = 110 } 
2022-07-08 15:05:15.901424 - gail/main.py:174 - [TRPO] iter = 151000 dist_mean = 0.2057 dist_std = 0.7196 vf_loss = 0.1357 grad_norm = 0.5873 nat_grad_norm = 0.4379 cg_residual = 0.0577 step_size = 0.4013 reward = -0.0000 fps = 344 mse_loss = 2.1311 
2022-07-08 15:05:17.104084 - gail/main.py:174 - [TRPO] iter = 152000 dist_mean = 0.2452 dist_std = 0.7158 vf_loss = 0.1164 grad_norm = 0.5946 nat_grad_norm = 0.4797 cg_residual = 0.0404 step_size = 0.3996 reward = -0.0000 fps = 243 mse_loss = 2.1427 
2022-07-08 15:05:18.332689 - gail/main.py:174 - [TRPO] iter = 153000 dist_mean = 0.2519 dist_std = 0.7165 vf_loss = 0.1447 grad_norm = 0.5893 nat_grad_norm = 0.5306 cg_residual = 0.0625 step_size = 0.3407 reward = -0.0000 fps = 187 mse_loss = 2.2019 
2022-07-08 15:05:19.538942 - gail/main.py:174 - [TRPO] iter = 154000 dist_mean = 0.2402 dist_std = 0.7141 vf_loss = 0.1324 grad_norm = 0.9664 nat_grad_norm = 0.4654 cg_residual = 0.0580 step_size = 0.3540 reward = -0.0000 fps = 152 mse_loss = 2.0893 
2022-07-08 15:05:20.766015 - gail/main.py:174 - [TRPO] iter = 155000 dist_mean = 0.2238 dist_std = 0.7129 vf_loss = 0.1266 grad_norm = 0.7247 nat_grad_norm = 0.4900 cg_residual = 0.0582 step_size = 0.3598 reward = -0.0000 fps = 128 mse_loss = 2.1795 
2022-07-08 15:05:20.819855 - gail/main.py:201 - [Discriminator] iter = 155000 loss = -4.7318 grad_norm = 4.1210 grad_penalty = 0.4808 regularization = 0.0000 true_logits = -0.5103 fake_logits = -5.7228 true_prob = 0.4253 fake_prob = 0.0062 
2022-07-08 15:05:22.290946 - gail/main.py:142 - [Evaluate] iter = 155000 episode={ returns = 202.7677 lengths = 89 } discounted_episode={ returns = 193.0897 lengths = 90 } 
2022-07-08 15:05:23.507164 - gail/main.py:174 - [TRPO] iter = 156000 dist_mean = 0.2193 dist_std = 0.7069 vf_loss = 0.0747 grad_norm = 0.8660 nat_grad_norm = 0.4534 cg_residual = 0.0661 step_size = 0.3469 reward = -0.0000 fps = 372 mse_loss = 2.1693 
2022-07-08 15:05:24.723065 - gail/main.py:174 - [TRPO] iter = 157000 dist_mean = 0.2069 dist_std = 0.7012 vf_loss = 0.0881 grad_norm = 0.8157 nat_grad_norm = 0.4714 cg_residual = 0.1265 step_size = 0.3823 reward = 0.0000 fps = 256 mse_loss = 2.0500 
2022-07-08 15:05:25.935090 - gail/main.py:174 - [TRPO] iter = 158000 dist_mean = 0.1978 dist_std = 0.6949 vf_loss = 0.1128 grad_norm = 0.8810 nat_grad_norm = 0.4346 cg_residual = 0.0698 step_size = 0.3784 reward = 0.0000 fps = 195 mse_loss = 2.0232 
2022-07-08 15:05:27.144688 - gail/main.py:174 - [TRPO] iter = 159000 dist_mean = 0.2407 dist_std = 0.6890 vf_loss = 0.0908 grad_norm = 0.7964 nat_grad_norm = 0.4782 cg_residual = 0.0648 step_size = 0.3208 reward = -0.0000 fps = 158 mse_loss = 1.9734 
2022-07-08 15:05:28.363619 - gail/main.py:174 - [TRPO] iter = 160000 dist_mean = 0.2573 dist_std = 0.6823 vf_loss = 0.1699 grad_norm = 0.7726 nat_grad_norm = 0.3744 cg_residual = 0.0426 step_size = 0.3927 reward = -0.0000 fps = 132 mse_loss = 2.0357 
2022-07-08 15:05:28.416159 - gail/main.py:201 - [Discriminator] iter = 160000 loss = -4.7187 grad_norm = 3.3496 grad_penalty = 0.4840 regularization = 0.0000 true_logits = -0.5125 fake_logits = -5.7152 true_prob = 0.4298 fake_prob = 0.0068 
2022-07-08 15:05:29.838002 - gail/main.py:142 - [Evaluate] iter = 160000 episode={ returns = 191.8307 lengths = 89 } discounted_episode={ returns = 178.0072 lengths = 87 } 
2022-07-08 15:05:31.046927 - gail/main.py:174 - [TRPO] iter = 161000 dist_mean = 0.2504 dist_std = 0.6789 vf_loss = 0.1539 grad_norm = 0.8292 nat_grad_norm = 0.5377 cg_residual = 0.0685 step_size = 0.3183 reward = 0.0000 fps = 380 mse_loss = 2.0474 
2022-07-08 15:05:32.285618 - gail/main.py:174 - [TRPO] iter = 162000 dist_mean = 0.2717 dist_std = 0.6740 vf_loss = 0.2268 grad_norm = 0.8033 nat_grad_norm = 0.4468 cg_residual = 0.0580 step_size = 0.3604 reward = -0.0000 fps = 258 mse_loss = 1.9811 
2022-07-08 15:05:33.478592 - gail/main.py:174 - [TRPO] iter = 163000 dist_mean = 0.2155 dist_std = 0.6708 vf_loss = 0.1667 grad_norm = 0.8599 nat_grad_norm = 0.4045 cg_residual = 0.0647 step_size = 0.4011 reward = -0.0000 fps = 197 mse_loss = 2.0445 
2022-07-08 15:05:34.675758 - gail/main.py:174 - [TRPO] iter = 164000 dist_mean = 0.2519 dist_std = 0.6688 vf_loss = 0.1629 grad_norm = 0.9598 nat_grad_norm = 0.3984 cg_residual = 0.0474 step_size = 0.3823 reward = -0.0000 fps = 159 mse_loss = 2.0573 
2022-07-08 15:05:35.898172 - gail/main.py:174 - [TRPO] iter = 165000 dist_mean = 0.2477 dist_std = 0.6677 vf_loss = 0.1610 grad_norm = 0.8742 nat_grad_norm = 0.5369 cg_residual = 0.1151 step_size = 0.3201 reward = -0.0000 fps = 133 mse_loss = 2.1978 
2022-07-08 15:05:35.947861 - gail/main.py:201 - [Discriminator] iter = 165000 loss = -4.5058 grad_norm = 3.5219 grad_penalty = 0.4587 regularization = 0.0000 true_logits = -0.3652 fake_logits = -5.3297 true_prob = 0.4449 fake_prob = 0.0088 
2022-07-08 15:05:37.764480 - gail/main.py:142 - [Evaluate] iter = 165000 episode={ returns = 257.3266 lengths = 112 } discounted_episode={ returns = 241.0041 lengths = 113 } 
2022-07-08 15:05:39.142492 - gail/main.py:174 - [TRPO] iter = 166000 dist_mean = 0.2373 dist_std = 0.6647 vf_loss = 0.2148 grad_norm = 0.8312 nat_grad_norm = 0.4897 cg_residual = 0.0729 step_size = 0.3412 reward = -0.0000 fps = 313 mse_loss = 2.3234 
2022-07-08 15:05:40.340501 - gail/main.py:174 - [TRPO] iter = 167000 dist_mean = 0.1929 dist_std = 0.6620 vf_loss = 0.1724 grad_norm = 0.9565 nat_grad_norm = 0.4031 cg_residual = 0.0871 step_size = 0.3278 reward = -0.0000 fps = 227 mse_loss = 2.3160 
2022-07-08 15:05:41.563267 - gail/main.py:174 - [TRPO] iter = 168000 dist_mean = 0.2424 dist_std = 0.6573 vf_loss = 0.1373 grad_norm = 0.7703 nat_grad_norm = 0.4706 cg_residual = 0.0690 step_size = 0.3625 reward = -0.0000 fps = 178 mse_loss = 2.4822 
2022-07-08 15:05:42.762721 - gail/main.py:174 - [TRPO] iter = 169000 dist_mean = 0.2280 dist_std = 0.6508 vf_loss = 0.1761 grad_norm = 1.0460 nat_grad_norm = 0.5096 cg_residual = 0.1024 step_size = 0.2892 reward = -0.0000 fps = 146 mse_loss = 2.4124 
2022-07-08 15:05:43.978277 - gail/main.py:174 - [TRPO] iter = 170000 dist_mean = 0.1883 dist_std = 0.6466 vf_loss = 0.1616 grad_norm = 0.8129 nat_grad_norm = 0.3915 cg_residual = 0.0978 step_size = 0.3758 reward = -0.0000 fps = 124 mse_loss = 2.3383 
2022-07-08 15:05:44.030678 - gail/main.py:201 - [Discriminator] iter = 170000 loss = -4.3566 grad_norm = 3.3857 grad_penalty = 0.4321 regularization = 0.0000 true_logits = -0.3095 fake_logits = -5.0982 true_prob = 0.4556 fake_prob = 0.0114 
2022-07-08 15:05:45.988958 - gail/main.py:142 - [Evaluate] iter = 170000 episode={ returns = 314.4321 lengths = 125 } discounted_episode={ returns = 284.2395 lengths = 123 } 
2022-07-08 15:05:47.196029 - gail/main.py:174 - [TRPO] iter = 171000 dist_mean = 0.1947 dist_std = 0.6411 vf_loss = 0.1567 grad_norm = 0.8176 nat_grad_norm = 0.3255 cg_residual = 0.0510 step_size = 0.4455 reward = 0.0000 fps = 316 mse_loss = 2.2151 
2022-07-08 15:05:48.410857 - gail/main.py:174 - [TRPO] iter = 172000 dist_mean = 0.1791 dist_std = 0.6338 vf_loss = 0.0731 grad_norm = 0.8183 nat_grad_norm = 0.3541 cg_residual = 0.0402 step_size = 0.3919 reward = 0.0000 fps = 228 mse_loss = 2.1068 
2022-07-08 15:05:49.704624 - gail/main.py:174 - [TRPO] iter = 173000 dist_mean = 0.2009 dist_std = 0.6306 vf_loss = 0.1367 grad_norm = 0.8984 nat_grad_norm = 0.4027 cg_residual = 0.0858 step_size = 0.3321 reward = 0.0000 fps = 176 mse_loss = 2.1429 
2022-07-08 15:05:51.124491 - gail/main.py:174 - [TRPO] iter = 174000 dist_mean = 0.1891 dist_std = 0.6256 vf_loss = 0.0905 grad_norm = 0.8096 nat_grad_norm = 0.4072 cg_residual = 0.1278 step_size = 0.3702 reward = 0.0000 fps = 141 mse_loss = 2.1604 
2022-07-08 15:05:52.830923 - gail/main.py:174 - [TRPO] iter = 175000 dist_mean = 0.2037 dist_std = 0.6191 vf_loss = 0.1061 grad_norm = 0.8131 nat_grad_norm = 0.3942 cg_residual = 0.0989 step_size = 0.3853 reward = 0.0000 fps = 113 mse_loss = 2.1017 
2022-07-08 15:05:52.883112 - gail/main.py:201 - [Discriminator] iter = 175000 loss = -4.2738 grad_norm = 3.4488 grad_penalty = 0.3911 regularization = 0.0000 true_logits = -0.2300 fake_logits = -4.8949 true_prob = 0.4724 fake_prob = 0.0137 
2022-07-08 15:05:55.498255 - gail/main.py:142 - [Evaluate] iter = 175000 episode={ returns = 286.7167 lengths = 124 } discounted_episode={ returns = 306.4920 lengths = 136 } 
2022-07-08 15:05:57.276485 - gail/main.py:174 - [TRPO] iter = 176000 dist_mean = 0.1975 dist_std = 0.6131 vf_loss = 0.1588 grad_norm = 1.2205 nat_grad_norm = 0.3857 cg_residual = 0.0893 step_size = 0.3208 reward = 0.0000 fps = 227 mse_loss = 2.1981 
2022-07-08 15:05:58.721892 - gail/main.py:174 - [TRPO] iter = 177000 dist_mean = 0.2068 dist_std = 0.6134 vf_loss = 0.1523 grad_norm = 0.9944 nat_grad_norm = 0.3186 cg_residual = 0.0610 step_size = 0.3770 reward = -0.0000 fps = 171 mse_loss = 2.1209 
2022-07-08 15:06:00.131368 - gail/main.py:174 - [TRPO] iter = 178000 dist_mean = 0.2178 dist_std = 0.6070 vf_loss = 0.1847 grad_norm = 0.8521 nat_grad_norm = 0.2943 cg_residual = 0.0665 step_size = 0.4241 reward = 0.0000 fps = 138 mse_loss = 2.1225 
2022-07-08 15:06:01.596142 - gail/main.py:174 - [TRPO] iter = 179000 dist_mean = 0.2091 dist_std = 0.5981 vf_loss = 0.2317 grad_norm = 1.0738 nat_grad_norm = 0.3653 cg_residual = 0.0828 step_size = 0.3477 reward = -0.0000 fps = 114 mse_loss = 2.1549 
2022-07-08 15:06:03.022830 - gail/main.py:174 - [TRPO] iter = 180000 dist_mean = 0.2239 dist_std = 0.5951 vf_loss = 0.1265 grad_norm = 0.7490 nat_grad_norm = 0.3745 cg_residual = 0.1183 step_size = 0.3940 reward = 0.0000 fps = 98 mse_loss = 2.0628 
2022-07-08 15:06:03.086073 - gail/main.py:201 - [Discriminator] iter = 180000 loss = -4.1618 grad_norm = 3.3520 grad_penalty = 0.3719 regularization = 0.0000 true_logits = -0.1901 fake_logits = -4.7238 true_prob = 0.4836 fake_prob = 0.0161 
2022-07-08 15:06:05.481697 - gail/main.py:142 - [Evaluate] iter = 180000 episode={ returns = 336.2497 lengths = 137 } discounted_episode={ returns = 309.3978 lengths = 137 } 
2022-07-08 15:06:06.848648 - gail/main.py:174 - [TRPO] iter = 181000 dist_mean = 0.2261 dist_std = 0.5897 vf_loss = 0.1592 grad_norm = 1.0426 nat_grad_norm = 0.3945 cg_residual = 0.1799 step_size = 0.3245 reward = -0.0000 fps = 265 mse_loss = 2.0320 
2022-07-08 15:06:08.080780 - gail/main.py:174 - [TRPO] iter = 182000 dist_mean = 0.2494 dist_std = 0.5888 vf_loss = 0.1206 grad_norm = 0.9284 nat_grad_norm = 0.3964 cg_residual = 0.1228 step_size = 0.3306 reward = -0.0000 fps = 200 mse_loss = 2.0765 
2022-07-08 15:06:09.349817 - gail/main.py:174 - [TRPO] iter = 183000 dist_mean = 0.2556 dist_std = 0.5829 vf_loss = 0.1250 grad_norm = 0.9013 nat_grad_norm = 0.3729 cg_residual = 0.0912 step_size = 0.3522 reward = 0.0000 fps = 159 mse_loss = 2.2049 
2022-07-08 15:06:10.555456 - gail/main.py:174 - [TRPO] iter = 184000 dist_mean = 0.2231 dist_std = 0.5769 vf_loss = 0.1318 grad_norm = 1.0477 nat_grad_norm = 0.3375 cg_residual = 0.1110 step_size = 0.3891 reward = 0.0000 fps = 133 mse_loss = 2.0959 
2022-07-08 15:06:11.782093 - gail/main.py:174 - [TRPO] iter = 185000 dist_mean = 0.2232 dist_std = 0.5710 vf_loss = 0.1361 grad_norm = 1.0797 nat_grad_norm = 0.3193 cg_residual = 0.0811 step_size = 0.3680 reward = -0.0000 fps = 115 mse_loss = 2.2770 
2022-07-08 15:06:11.831599 - gail/main.py:201 - [Discriminator] iter = 185000 loss = -4.2147 grad_norm = 2.9960 grad_penalty = 0.3858 regularization = 0.0000 true_logits = -0.1050 fake_logits = -4.7055 true_prob = 0.4878 fake_prob = 0.0152 
2022-07-08 15:06:14.477000 - gail/main.py:142 - [Evaluate] iter = 185000 episode={ returns = 440.3073 lengths = 164 } discounted_episode={ returns = 409.8731 lengths = 167 } 
2022-07-08 15:06:15.684536 - gail/main.py:174 - [TRPO] iter = 186000 dist_mean = 0.2232 dist_std = 0.5671 vf_loss = 0.0979 grad_norm = 0.9818 nat_grad_norm = 0.3754 cg_residual = 0.1361 step_size = 0.3510 reward = -0.0000 fps = 259 mse_loss = 2.2143 
2022-07-08 15:06:16.896480 - gail/main.py:174 - [TRPO] iter = 187000 dist_mean = 0.2498 dist_std = 0.5637 vf_loss = 0.1333 grad_norm = 0.9345 nat_grad_norm = 0.3582 cg_residual = 0.1106 step_size = 0.3556 reward = 0.0000 fps = 197 mse_loss = 2.2220 
2022-07-08 15:06:18.088652 - gail/main.py:174 - [TRPO] iter = 188000 dist_mean = 0.2171 dist_std = 0.5633 vf_loss = 0.0725 grad_norm = 1.1121 nat_grad_norm = 0.3687 cg_residual = 0.1123 step_size = 0.3720 reward = 0.0000 fps = 159 mse_loss = 2.3770 
2022-07-08 15:06:19.393043 - gail/main.py:174 - [TRPO] iter = 189000 dist_mean = 0.2150 dist_std = 0.5601 vf_loss = 0.1048 grad_norm = 1.0341 nat_grad_norm = 0.2993 cg_residual = 0.0886 step_size = 0.4039 reward = 0.0000 fps = 132 mse_loss = 2.3592 
2022-07-08 15:06:20.821695 - gail/main.py:174 - [TRPO] iter = 190000 dist_mean = 0.2457 dist_std = 0.5606 vf_loss = 0.1436 grad_norm = 0.9114 nat_grad_norm = 0.3103 cg_residual = 0.0823 step_size = 0.3867 reward = 0.0000 fps = 111 mse_loss = 2.2751 
2022-07-08 15:06:20.880698 - gail/main.py:201 - [Discriminator] iter = 190000 loss = -4.3133 grad_norm = 3.8469 grad_penalty = 0.3991 regularization = 0.0000 true_logits = -0.0591 fake_logits = -4.7715 true_prob = 0.5021 fake_prob = 0.0171 
2022-07-08 15:06:24.350801 - gail/main.py:142 - [Evaluate] iter = 190000 episode={ returns = 489.3108 lengths = 176 } discounted_episode={ returns = 420.7507 lengths = 172 } 
2022-07-08 15:06:25.839712 - gail/main.py:174 - [TRPO] iter = 191000 dist_mean = 0.1951 dist_std = 0.5612 vf_loss = 0.1352 grad_norm = 0.8598 nat_grad_norm = 0.2618 cg_residual = 0.0559 step_size = 0.4324 reward = -0.0000 fps = 201 mse_loss = 2.4013 
2022-07-08 15:06:27.565680 - gail/main.py:174 - [TRPO] iter = 192000 dist_mean = 0.2081 dist_std = 0.5561 vf_loss = 0.1033 grad_norm = 1.2182 nat_grad_norm = 0.3846 cg_residual = 0.2155 step_size = 0.3480 reward = 0.0000 fps = 149 mse_loss = 2.4089 
2022-07-08 15:06:29.174958 - gail/main.py:174 - [TRPO] iter = 193000 dist_mean = 0.2543 dist_std = 0.5539 vf_loss = 0.1762 grad_norm = 1.0719 nat_grad_norm = 0.4318 cg_residual = 0.1512 step_size = 0.3218 reward = -0.0000 fps = 120 mse_loss = 2.3371 
2022-07-08 15:06:31.620283 - gail/main.py:174 - [TRPO] iter = 194000 dist_mean = 0.1998 dist_std = 0.5510 vf_loss = 0.0937 grad_norm = 1.4474 nat_grad_norm = 0.3670 cg_residual = 0.1326 step_size = 0.3118 reward = 0.0000 fps = 93 mse_loss = 2.5283 
2022-07-08 15:06:33.797363 - gail/main.py:174 - [TRPO] iter = 195000 dist_mean = 0.2321 dist_std = 0.5504 vf_loss = 0.1077 grad_norm = 1.0073 nat_grad_norm = 0.2920 cg_residual = 0.0845 step_size = 0.4184 reward = 0.0000 fps = 77 mse_loss = 2.4855 
2022-07-08 15:06:33.879159 - gail/main.py:201 - [Discriminator] iter = 195000 loss = -4.2030 grad_norm = 3.8250 grad_penalty = 0.3795 regularization = 0.0000 true_logits = 0.0569 fake_logits = -4.5257 true_prob = 0.5195 fake_prob = 0.0203 
2022-07-08 15:06:39.124193 - gail/main.py:142 - [Evaluate] iter = 195000 episode={ returns = 481.4924 lengths = 176 } discounted_episode={ returns = 456.0381 lengths = 185 } 
2022-07-08 15:06:41.197392 - gail/main.py:174 - [TRPO] iter = 196000 dist_mean = 0.2179 dist_std = 0.5465 vf_loss = 0.1755 grad_norm = 0.9039 nat_grad_norm = 0.3491 cg_residual = 0.1168 step_size = 0.3808 reward = 0.0000 fps = 136 mse_loss = 2.6284 
2022-07-08 15:06:42.956503 - gail/main.py:174 - [TRPO] iter = 197000 dist_mean = 0.1794 dist_std = 0.5464 vf_loss = 0.1106 grad_norm = 1.2483 nat_grad_norm = 0.3179 cg_residual = 0.1304 step_size = 0.3343 reward = -0.0000 fps = 110 mse_loss = 2.4758 
2022-07-08 15:06:44.719838 - gail/main.py:174 - [TRPO] iter = 198000 dist_mean = 0.2031 dist_std = 0.5361 vf_loss = 0.1313 grad_norm = 0.9339 nat_grad_norm = 0.3074 cg_residual = 0.0917 step_size = 0.3835 reward = -0.0000 fps = 92 mse_loss = 2.4288 
2022-07-08 15:06:46.760426 - gail/main.py:174 - [TRPO] iter = 199000 dist_mean = 0.2178 dist_std = 0.5324 vf_loss = 0.1270 grad_norm = 1.3938 nat_grad_norm = 0.3728 cg_residual = 0.1333 step_size = 0.3353 reward = 0.0000 fps = 77 mse_loss = 2.4139 
2022-07-08 15:06:49.142131 - gail/main.py:174 - [TRPO] iter = 200000 dist_mean = 0.2111 dist_std = 0.5303 vf_loss = 0.1475 grad_norm = 1.3861 nat_grad_norm = 0.4039 cg_residual = 0.1209 step_size = 0.3036 reward = 0.0000 fps = 65 mse_loss = 2.5145 
2022-07-08 15:06:49.272932 - gail/main.py:201 - [Discriminator] iter = 200000 loss = -4.1952 grad_norm = 3.2321 grad_penalty = 0.3573 regularization = 0.0000 true_logits = 0.0860 fake_logits = -4.4666 true_prob = 0.5243 fake_prob = 0.0210 
2022-07-08 15:06:54.403890 - gail/main.py:142 - [Evaluate] iter = 200000 episode={ returns = 428.5619 lengths = 155 } discounted_episode={ returns = 446.1850 lengths = 171 } 
2022-07-08 15:06:56.874835 - gail/main.py:174 - [TRPO] iter = 201000 dist_mean = 0.2264 dist_std = 0.5303 vf_loss = 0.1952 grad_norm = 1.0855 nat_grad_norm = 0.3148 cg_residual = 0.1004 step_size = 0.3975 reward = -0.0000 fps = 131 mse_loss = 2.7094 
2022-07-08 15:06:59.259018 - gail/main.py:174 - [TRPO] iter = 202000 dist_mean = 0.2011 dist_std = 0.5244 vf_loss = 0.1259 grad_norm = 1.2154 nat_grad_norm = 0.3084 cg_residual = 0.1271 step_size = 0.3553 reward = -0.0000 fps = 100 mse_loss = 2.7476 
2022-07-08 15:07:01.298705 - gail/main.py:174 - [TRPO] iter = 203000 dist_mean = 0.2584 dist_std = 0.5231 vf_loss = 0.1278 grad_norm = 0.9762 nat_grad_norm = 0.3139 cg_residual = 0.1529 step_size = 0.3696 reward = -0.0000 fps = 83 mse_loss = 2.5630 
2022-07-08 15:07:03.393077 - gail/main.py:174 - [TRPO] iter = 204000 dist_mean = 0.2266 dist_std = 0.5250 vf_loss = 0.1417 grad_norm = 1.0629 nat_grad_norm = 0.3086 cg_residual = 0.1403 step_size = 0.3525 reward = 0.0000 fps = 70 mse_loss = 2.4922 
2022-07-08 15:07:05.565445 - gail/main.py:174 - [TRPO] iter = 205000 dist_mean = 0.1973 dist_std = 0.5195 vf_loss = 0.2112 grad_norm = 1.1769 nat_grad_norm = 0.3846 cg_residual = 0.2292 step_size = 0.3048 reward = -0.0000 fps = 61 mse_loss = 2.5915 
2022-07-08 15:07:05.641891 - gail/main.py:201 - [Discriminator] iter = 205000 loss = -3.9515 grad_norm = 3.6312 grad_penalty = 0.3677 regularization = 0.0000 true_logits = 0.2552 fake_logits = -4.0640 true_prob = 0.5436 fake_prob = 0.0343 
2022-07-08 15:07:09.269508 - gail/main.py:142 - [Evaluate] iter = 205000 episode={ returns = 340.6591 lengths = 130 } discounted_episode={ returns = 316.0213 lengths = 130 } 
2022-07-08 15:07:11.087836 - gail/main.py:174 - [TRPO] iter = 206000 dist_mean = 0.2158 dist_std = 0.5130 vf_loss = 0.1291 grad_norm = 1.2489 nat_grad_norm = 0.3701 cg_residual = 0.1619 step_size = 0.2944 reward = 0.0000 fps = 183 mse_loss = 2.4487 
2022-07-08 15:07:12.987505 - gail/main.py:174 - [TRPO] iter = 207000 dist_mean = 0.2142 dist_std = 0.5139 vf_loss = 0.1601 grad_norm = 0.9408 nat_grad_norm = 0.3344 cg_residual = 0.1900 step_size = 0.3640 reward = -0.0000 fps = 136 mse_loss = 2.4476 
2022-07-08 15:07:14.770618 - gail/main.py:174 - [TRPO] iter = 208000 dist_mean = 0.2215 dist_std = 0.5127 vf_loss = 0.1797 grad_norm = 1.1259 nat_grad_norm = 0.3238 cg_residual = 0.1475 step_size = 0.3847 reward = 0.0000 fps = 109 mse_loss = 2.5497 
2022-07-08 15:07:16.552330 - gail/main.py:174 - [TRPO] iter = 209000 dist_mean = 0.2202 dist_std = 0.5127 vf_loss = 0.2333 grad_norm = 1.1327 nat_grad_norm = 0.3298 cg_residual = 0.1924 step_size = 0.3597 reward = 0.0000 fps = 91 mse_loss = 2.6065 
2022-07-08 15:07:18.380909 - gail/main.py:174 - [TRPO] iter = 210000 dist_mean = 0.2235 dist_std = 0.5094 vf_loss = 0.1169 grad_norm = 0.8998 nat_grad_norm = 0.3091 cg_residual = 0.1823 step_size = 0.3774 reward = -0.0000 fps = 78 mse_loss = 2.5165 
2022-07-08 15:07:18.482070 - gail/main.py:201 - [Discriminator] iter = 210000 loss = -4.4288 grad_norm = 2.9403 grad_penalty = 0.3512 regularization = 0.0000 true_logits = 0.4051 fake_logits = -4.3749 true_prob = 0.5622 fake_prob = 0.0266 
2022-07-08 15:07:21.730463 - gail/main.py:142 - [Evaluate] iter = 210000 episode={ returns = 345.9754 lengths = 131 } discounted_episode={ returns = 320.4293 lengths = 132 } 
2022-07-08 15:07:23.476074 - gail/main.py:174 - [TRPO] iter = 211000 dist_mean = 0.2032 dist_std = 0.5088 vf_loss = 0.1174 grad_norm = 1.2098 nat_grad_norm = 0.2953 cg_residual = 0.1280 step_size = 0.3717 reward = -0.0000 fps = 200 mse_loss = 2.5153 
2022-07-08 15:07:25.194860 - gail/main.py:174 - [TRPO] iter = 212000 dist_mean = 0.2353 dist_std = 0.5089 vf_loss = 0.1121 grad_norm = 1.0736 nat_grad_norm = 0.3067 cg_residual = 0.1436 step_size = 0.3627 reward = 0.0000 fps = 149 mse_loss = 2.4546 
2022-07-08 15:07:26.819965 - gail/main.py:174 - [TRPO] iter = 213000 dist_mean = 0.2020 dist_std = 0.5028 vf_loss = 0.0891 grad_norm = 1.4707 nat_grad_norm = 0.2800 cg_residual = 0.1656 step_size = 0.3480 reward = 0.0000 fps = 119 mse_loss = 2.7001 
2022-07-08 15:07:28.049678 - gail/main.py:174 - [TRPO] iter = 214000 dist_mean = 0.2053 dist_std = 0.4979 vf_loss = 0.2106 grad_norm = 1.0318 nat_grad_norm = 0.3439 cg_residual = 0.1661 step_size = 0.3734 reward = -0.0000 fps = 104 mse_loss = 2.7203 
2022-07-08 15:07:29.246937 - gail/main.py:174 - [TRPO] iter = 215000 dist_mean = 0.2027 dist_std = 0.4977 vf_loss = 0.1284 grad_norm = 1.4411 nat_grad_norm = 0.3223 cg_residual = 0.3286 step_size = 0.3296 reward = -0.0000 fps = 92 mse_loss = 2.6334 
2022-07-08 15:07:29.308334 - gail/main.py:201 - [Discriminator] iter = 215000 loss = -4.2402 grad_norm = 3.9727 grad_penalty = 0.3748 regularization = 0.0000 true_logits = 0.3986 fake_logits = -4.2164 true_prob = 0.5580 fake_prob = 0.0318 
2022-07-08 15:07:31.965649 - gail/main.py:142 - [Evaluate] iter = 215000 episode={ returns = 489.5355 lengths = 166 } discounted_episode={ returns = 459.8151 lengths = 173 } 
2022-07-08 15:07:33.169243 - gail/main.py:174 - [TRPO] iter = 216000 dist_mean = 0.2162 dist_std = 0.4969 vf_loss = 0.1441 grad_norm = 1.1316 nat_grad_norm = 0.3446 cg_residual = 0.1832 step_size = 0.3270 reward = -0.0000 fps = 259 mse_loss = 2.6732 
2022-07-08 15:07:34.378474 - gail/main.py:174 - [TRPO] iter = 217000 dist_mean = 0.2104 dist_std = 0.4981 vf_loss = 0.1776 grad_norm = 1.2573 nat_grad_norm = 0.2850 cg_residual = 0.1466 step_size = 0.3424 reward = 0.0000 fps = 197 mse_loss = 2.6485 
2022-07-08 15:07:35.592066 - gail/main.py:174 - [TRPO] iter = 218000 dist_mean = 0.1911 dist_std = 0.4979 vf_loss = 0.2089 grad_norm = 1.2803 nat_grad_norm = 0.3291 cg_residual = 0.2151 step_size = 0.3117 reward = -0.0000 fps = 159 mse_loss = 2.6499 
2022-07-08 15:07:36.825721 - gail/main.py:174 - [TRPO] iter = 219000 dist_mean = 0.1988 dist_std = 0.4957 vf_loss = 0.1176 grad_norm = 1.1638 nat_grad_norm = 0.3072 cg_residual = 0.2297 step_size = 0.3453 reward = -0.0000 fps = 133 mse_loss = 2.6412 
2022-07-08 15:07:38.072042 - gail/main.py:174 - [TRPO] iter = 220000 dist_mean = 0.2119 dist_std = 0.4953 vf_loss = 0.2113 grad_norm = 1.5238 nat_grad_norm = 0.3444 cg_residual = 0.1843 step_size = 0.3305 reward = -0.0000 fps = 114 mse_loss = 2.7862 
2022-07-08 15:07:38.124571 - gail/main.py:201 - [Discriminator] iter = 220000 loss = -4.2920 grad_norm = 3.2635 grad_penalty = 0.3598 regularization = 0.0000 true_logits = 0.5360 fake_logits = -4.1158 true_prob = 0.5760 fake_prob = 0.0400 
2022-07-08 15:07:40.617987 - gail/main.py:142 - [Evaluate] iter = 220000 episode={ returns = 475.8672 lengths = 161 } discounted_episode={ returns = 400.1663 lengths = 154 } 
2022-07-08 15:07:41.849412 - gail/main.py:174 - [TRPO] iter = 221000 dist_mean = 0.2157 dist_std = 0.4921 vf_loss = 0.1531 grad_norm = 1.1785 nat_grad_norm = 0.2865 cg_residual = 0.1688 step_size = 0.3557 reward = -0.0000 fps = 268 mse_loss = 2.9540 
2022-07-08 15:07:43.064723 - gail/main.py:174 - [TRPO] iter = 222000 dist_mean = 0.2213 dist_std = 0.4953 vf_loss = 0.2226 grad_norm = 0.9333 nat_grad_norm = 0.3341 cg_residual = 0.2050 step_size = 0.3870 reward = -0.0000 fps = 202 mse_loss = 2.8466 
2022-07-08 15:07:44.282488 - gail/main.py:174 - [TRPO] iter = 223000 dist_mean = 0.2171 dist_std = 0.4923 vf_loss = 0.1244 grad_norm = 1.2779 nat_grad_norm = 0.2687 cg_residual = 0.1598 step_size = 0.3861 reward = -0.0000 fps = 162 mse_loss = 2.7215 
2022-07-08 15:07:45.483608 - gail/main.py:174 - [TRPO] iter = 224000 dist_mean = 0.2277 dist_std = 0.4927 vf_loss = 0.1665 grad_norm = 1.6525 nat_grad_norm = 0.4504 cg_residual = 0.3653 step_size = 0.2774 reward = 0.0000 fps = 135 mse_loss = 2.7798 
2022-07-08 15:07:46.702580 - gail/main.py:174 - [TRPO] iter = 225000 dist_mean = 0.2310 dist_std = 0.4891 vf_loss = 0.3044 grad_norm = 1.2566 nat_grad_norm = 0.3299 cg_residual = 0.2227 step_size = 0.3187 reward = -0.0000 fps = 116 mse_loss = 2.7875 
2022-07-08 15:07:46.752775 - gail/main.py:201 - [Discriminator] iter = 225000 loss = -4.5185 grad_norm = 3.6153 grad_penalty = 0.3808 regularization = 0.0000 true_logits = 0.5436 fake_logits = -4.3558 true_prob = 0.5678 fake_prob = 0.0376 
2022-07-08 15:07:49.205320 - gail/main.py:142 - [Evaluate] iter = 225000 episode={ returns = 437.0216 lengths = 153 } discounted_episode={ returns = 395.0673 lengths = 152 } 
2022-07-08 15:07:50.402118 - gail/main.py:174 - [TRPO] iter = 226000 dist_mean = 0.2151 dist_std = 0.4857 vf_loss = 0.2522 grad_norm = 1.1198 nat_grad_norm = 0.3503 cg_residual = 0.1735 step_size = 0.3716 reward = -0.0000 fps = 274 mse_loss = 2.8090 
2022-07-08 15:07:51.610670 - gail/main.py:174 - [TRPO] iter = 227000 dist_mean = 0.1968 dist_std = 0.4858 vf_loss = 0.3416 grad_norm = 1.1791 nat_grad_norm = 0.3253 cg_residual = 0.1871 step_size = 0.3550 reward = 0.0000 fps = 205 mse_loss = 2.7356 
2022-07-08 15:07:52.823104 - gail/main.py:174 - [TRPO] iter = 228000 dist_mean = 0.2224 dist_std = 0.4891 vf_loss = 0.1457 grad_norm = 1.0767 nat_grad_norm = 0.4166 cg_residual = 0.2358 step_size = 0.3133 reward = -0.0000 fps = 164 mse_loss = 2.7454 
2022-07-08 15:07:54.021757 - gail/main.py:174 - [TRPO] iter = 229000 dist_mean = 0.2062 dist_std = 0.4879 vf_loss = 0.1071 grad_norm = 1.0838 nat_grad_norm = 0.3450 cg_residual = 0.1739 step_size = 0.3433 reward = -0.0000 fps = 137 mse_loss = 2.9504 
2022-07-08 15:07:55.206493 - gail/main.py:174 - [TRPO] iter = 230000 dist_mean = 0.2188 dist_std = 0.4866 vf_loss = 0.2520 grad_norm = 1.3989 nat_grad_norm = 0.3499 cg_residual = 0.2020 step_size = 0.3249 reward = 0.0000 fps = 118 mse_loss = 2.9366 
2022-07-08 15:07:55.273938 - gail/main.py:201 - [Discriminator] iter = 230000 loss = -4.1842 grad_norm = 3.4855 grad_penalty = 0.3757 regularization = 0.0000 true_logits = 0.5677 fake_logits = -3.9922 true_prob = 0.5703 fake_prob = 0.0522 
2022-07-08 15:07:58.024524 - gail/main.py:142 - [Evaluate] iter = 230000 episode={ returns = 551.6535 lengths = 180 } discounted_episode={ returns = 456.5833 lengths = 169 } 
2022-07-08 15:07:59.228481 - gail/main.py:174 - [TRPO] iter = 231000 dist_mean = 0.2277 dist_std = 0.4869 vf_loss = 0.2024 grad_norm = 1.1734 nat_grad_norm = 0.3604 cg_residual = 0.2065 step_size = 0.3079 reward = -0.0000 fps = 253 mse_loss = 2.8563 
2022-07-08 15:08:00.428966 - gail/main.py:174 - [TRPO] iter = 232000 dist_mean = 0.2220 dist_std = 0.4867 vf_loss = 0.1269 grad_norm = 1.3207 nat_grad_norm = 0.3323 cg_residual = 0.2095 step_size = 0.3172 reward = 0.0000 fps = 194 mse_loss = 2.7962 
2022-07-08 15:08:01.649120 - gail/main.py:174 - [TRPO] iter = 233000 dist_mean = 0.2068 dist_std = 0.4885 vf_loss = 0.1136 grad_norm = 1.5702 nat_grad_norm = 0.3317 cg_residual = 0.1596 step_size = 0.3306 reward = -0.0000 fps = 156 mse_loss = 2.6709 
2022-07-08 15:08:02.861631 - gail/main.py:174 - [TRPO] iter = 234000 dist_mean = 0.2067 dist_std = 0.4828 vf_loss = 0.1497 grad_norm = 1.3702 nat_grad_norm = 0.3448 cg_residual = 0.1809 step_size = 0.3154 reward = -0.0000 fps = 131 mse_loss = 2.7619 
2022-07-08 15:08:04.064093 - gail/main.py:174 - [TRPO] iter = 235000 dist_mean = 0.2034 dist_std = 0.4788 vf_loss = 0.1327 grad_norm = 1.2851 nat_grad_norm = 0.3052 cg_residual = 0.1432 step_size = 0.3664 reward = 0.0000 fps = 113 mse_loss = 2.8230 
2022-07-08 15:08:04.115064 - gail/main.py:201 - [Discriminator] iter = 235000 loss = -4.3790 grad_norm = 4.0531 grad_penalty = 0.3382 regularization = 0.0000 true_logits = 0.6157 fake_logits = -4.1015 true_prob = 0.5704 fake_prob = 0.0449 
2022-07-08 15:08:06.824672 - gail/main.py:142 - [Evaluate] iter = 235000 episode={ returns = 489.8780 lengths = 171 } discounted_episode={ returns = 445.3355 lengths = 171 } 
2022-07-08 15:08:08.037053 - gail/main.py:174 - [TRPO] iter = 236000 dist_mean = 0.2216 dist_std = 0.4794 vf_loss = 0.1284 grad_norm = 1.1111 nat_grad_norm = 0.3267 cg_residual = 0.1423 step_size = 0.3608 reward = 0.0000 fps = 255 mse_loss = 2.5891 
2022-07-08 15:08:09.268982 - gail/main.py:174 - [TRPO] iter = 237000 dist_mean = 0.2110 dist_std = 0.4778 vf_loss = 0.1828 grad_norm = 1.1742 nat_grad_norm = 0.2545 cg_residual = 0.1476 step_size = 0.4083 reward = 0.0000 fps = 194 mse_loss = 2.7944 
2022-07-08 15:08:10.460933 - gail/main.py:174 - [TRPO] iter = 238000 dist_mean = 0.1983 dist_std = 0.4782 vf_loss = 0.1799 grad_norm = 1.5240 nat_grad_norm = 0.3639 cg_residual = 0.2048 step_size = 0.3195 reward = 0.0000 fps = 157 mse_loss = 2.6742 
2022-07-08 15:08:11.676187 - gail/main.py:174 - [TRPO] iter = 239000 dist_mean = 0.2212 dist_std = 0.4758 vf_loss = 0.1122 grad_norm = 1.3929 nat_grad_norm = 0.3432 cg_residual = 0.2423 step_size = 0.3473 reward = -0.0000 fps = 132 mse_loss = 2.5414 
2022-07-08 15:08:12.872113 - gail/main.py:174 - [TRPO] iter = 240000 dist_mean = 0.2460 dist_std = 0.4725 vf_loss = 0.1451 grad_norm = 1.2542 nat_grad_norm = 0.3512 cg_residual = 0.2118 step_size = 0.3336 reward = 0.0000 fps = 114 mse_loss = 2.6679 
2022-07-08 15:08:12.938154 - gail/main.py:201 - [Discriminator] iter = 240000 loss = -4.3935 grad_norm = 4.7382 grad_penalty = 0.4034 regularization = 0.0000 true_logits = 0.7028 fake_logits = -4.0941 true_prob = 0.5815 fake_prob = 0.0562 
2022-07-08 15:08:15.673465 - gail/main.py:142 - [Evaluate] iter = 240000 episode={ returns = 524.3757 lengths = 174 } discounted_episode={ returns = 466.8763 lengths = 174 } 
2022-07-08 15:08:16.910953 - gail/main.py:174 - [TRPO] iter = 241000 dist_mean = 0.2282 dist_std = 0.4686 vf_loss = 0.2115 grad_norm = 1.2010 nat_grad_norm = 0.3358 cg_residual = 0.1495 step_size = 0.3355 reward = 0.0000 fps = 251 mse_loss = 2.7213 
2022-07-08 15:08:18.120195 - gail/main.py:174 - [TRPO] iter = 242000 dist_mean = 0.2156 dist_std = 0.4626 vf_loss = 0.2206 grad_norm = 1.5239 nat_grad_norm = 0.2904 cg_residual = 0.2046 step_size = 0.3945 reward = -0.0000 fps = 193 mse_loss = 2.6742 
2022-07-08 15:08:19.324540 - gail/main.py:174 - [TRPO] iter = 243000 dist_mean = 0.2233 dist_std = 0.4632 vf_loss = 0.1252 grad_norm = 1.2218 nat_grad_norm = 0.3778 cg_residual = 0.2380 step_size = 0.3101 reward = -0.0000 fps = 156 mse_loss = 2.7003 
2022-07-08 15:08:20.531402 - gail/main.py:174 - [TRPO] iter = 244000 dist_mean = 0.2342 dist_std = 0.4619 vf_loss = 0.1227 grad_norm = 1.3729 nat_grad_norm = 0.4171 cg_residual = 0.3186 step_size = 0.2801 reward = 0.0000 fps = 131 mse_loss = 2.5673 
2022-07-08 15:08:21.781206 - gail/main.py:174 - [TRPO] iter = 245000 dist_mean = 0.2412 dist_std = 0.4607 vf_loss = 0.1555 grad_norm = 0.9590 nat_grad_norm = 0.2975 cg_residual = 0.1710 step_size = 0.4174 reward = 0.0000 fps = 113 mse_loss = 2.6637 
2022-07-08 15:08:21.832131 - gail/main.py:201 - [Discriminator] iter = 245000 loss = -4.2599 grad_norm = 3.4977 grad_penalty = 0.3529 regularization = 0.0000 true_logits = 0.5574 fake_logits = -4.0555 true_prob = 0.5603 fake_prob = 0.0667 
2022-07-08 15:08:25.496835 - gail/main.py:142 - [Evaluate] iter = 245000 episode={ returns = 552.1090 lengths = 180 } discounted_episode={ returns = 521.1610 lengths = 189 } 
2022-07-08 15:08:26.686807 - gail/main.py:174 - [TRPO] iter = 246000 dist_mean = 0.2209 dist_std = 0.4603 vf_loss = 0.1020 grad_norm = 1.1186 nat_grad_norm = 0.3141 cg_residual = 0.2217 step_size = 0.3496 reward = 0.0000 fps = 206 mse_loss = 2.5627 
2022-07-08 15:08:27.880256 - gail/main.py:174 - [TRPO] iter = 247000 dist_mean = 0.2187 dist_std = 0.4603 vf_loss = 0.1132 grad_norm = 1.2227 nat_grad_norm = 0.3446 cg_residual = 0.1898 step_size = 0.3229 reward = 0.0000 fps = 165 mse_loss = 2.5943 
2022-07-08 15:08:29.160029 - gail/main.py:174 - [TRPO] iter = 248000 dist_mean = 0.2566 dist_std = 0.4607 vf_loss = 0.2102 grad_norm = 1.1386 nat_grad_norm = 0.3273 cg_residual = 0.1800 step_size = 0.3600 reward = 0.0000 fps = 136 mse_loss = 2.6666 
2022-07-08 15:08:30.395120 - gail/main.py:174 - [TRPO] iter = 249000 dist_mean = 0.2329 dist_std = 0.4599 vf_loss = 0.1829 grad_norm = 1.9315 nat_grad_norm = 0.3845 cg_residual = 0.2261 step_size = 0.2838 reward = 0.0000 fps = 116 mse_loss = 2.6072 
2022-07-08 15:08:31.591043 - gail/main.py:174 - [TRPO] iter = 250000 dist_mean = 0.2242 dist_std = 0.4591 vf_loss = 0.1591 grad_norm = 1.3849 nat_grad_norm = 0.3323 cg_residual = 0.2196 step_size = 0.3490 reward = 0.0000 fps = 102 mse_loss = 2.6247 
2022-07-08 15:08:31.640050 - gail/main.py:201 - [Discriminator] iter = 250000 loss = -4.0416 grad_norm = 3.4829 grad_penalty = 0.3625 regularization = 0.0000 true_logits = 0.5026 fake_logits = -3.9014 true_prob = 0.5540 fake_prob = 0.0761 
2022-07-08 15:08:34.583333 - gail/main.py:142 - [Evaluate] iter = 250000 episode={ returns = 563.2870 lengths = 183 } discounted_episode={ returns = 548.2852 lengths = 196 } 
2022-07-08 15:08:35.769797 - gail/main.py:174 - [TRPO] iter = 251000 dist_mean = 0.2066 dist_std = 0.4624 vf_loss = 0.1329 grad_norm = 1.3618 nat_grad_norm = 0.3044 cg_residual = 0.2780 step_size = 0.3681 reward = -0.0000 fps = 242 mse_loss = 2.5692 
2022-07-08 15:08:37.049524 - gail/main.py:174 - [TRPO] iter = 252000 dist_mean = 0.2446 dist_std = 0.4612 vf_loss = 0.0935 grad_norm = 1.3356 nat_grad_norm = 0.4052 cg_residual = 0.2078 step_size = 0.2994 reward = -0.0000 fps = 184 mse_loss = 2.4947 
2022-07-08 15:08:38.266747 - gail/main.py:174 - [TRPO] iter = 253000 dist_mean = 0.2413 dist_std = 0.4596 vf_loss = 0.1505 grad_norm = 1.4171 nat_grad_norm = 0.3211 cg_residual = 0.1946 step_size = 0.3263 reward = -0.0000 fps = 150 mse_loss = 2.5868 
2022-07-08 15:08:39.527613 - gail/main.py:174 - [TRPO] iter = 254000 dist_mean = 0.2074 dist_std = 0.4534 vf_loss = 0.2205 grad_norm = 1.2650 nat_grad_norm = 0.3172 cg_residual = 0.1765 step_size = 0.3761 reward = -0.0000 fps = 126 mse_loss = 2.4357 
2022-07-08 15:08:41.431281 - gail/main.py:174 - [TRPO] iter = 255000 dist_mean = 0.2260 dist_std = 0.4518 vf_loss = 0.1633 grad_norm = 1.1491 nat_grad_norm = 0.3720 cg_residual = 0.2601 step_size = 0.3346 reward = -0.0000 fps = 102 mse_loss = 2.4051 
2022-07-08 15:08:41.522900 - gail/main.py:201 - [Discriminator] iter = 255000 loss = -4.3093 grad_norm = 3.9793 grad_penalty = 0.3683 regularization = 0.0000 true_logits = 0.8266 fake_logits = -3.8509 true_prob = 0.5957 fake_prob = 0.0784 
2022-07-08 15:08:46.488863 - gail/main.py:142 - [Evaluate] iter = 255000 episode={ returns = 594.5992 lengths = 191 } discounted_episode={ returns = 415.6827 lengths = 158 } 
2022-07-08 15:08:48.337928 - gail/main.py:174 - [TRPO] iter = 256000 dist_mean = 0.2237 dist_std = 0.4483 vf_loss = 0.1826 grad_norm = 1.3198 nat_grad_norm = 0.3223 cg_residual = 0.2220 step_size = 0.3356 reward = 0.0000 fps = 146 mse_loss = 2.5197 
2022-07-08 15:08:50.020412 - gail/main.py:174 - [TRPO] iter = 257000 dist_mean = 0.2233 dist_std = 0.4445 vf_loss = 0.1239 grad_norm = 1.3732 nat_grad_norm = 0.2886 cg_residual = 0.2210 step_size = 0.3921 reward = 0.0000 fps = 117 mse_loss = 2.4478 
2022-07-08 15:08:51.476503 - gail/main.py:174 - [TRPO] iter = 258000 dist_mean = 0.2388 dist_std = 0.4411 vf_loss = 0.1110 grad_norm = 1.1527 nat_grad_norm = 0.3530 cg_residual = 0.3117 step_size = 0.3474 reward = -0.0000 fps = 100 mse_loss = 2.4255 
2022-07-08 15:08:52.976527 - gail/main.py:174 - [TRPO] iter = 259000 dist_mean = 0.2023 dist_std = 0.4408 vf_loss = 0.1287 grad_norm = 1.2404 nat_grad_norm = 0.2748 cg_residual = 0.1620 step_size = 0.3683 reward = 0.0000 fps = 87 mse_loss = 2.5748 
2022-07-08 15:08:54.721550 - gail/main.py:174 - [TRPO] iter = 260000 dist_mean = 0.2111 dist_std = 0.4420 vf_loss = 0.1375 grad_norm = 1.2694 nat_grad_norm = 0.2984 cg_residual = 0.2217 step_size = 0.3458 reward = -0.0000 fps = 75 mse_loss = 2.4945 
2022-07-08 15:08:54.799018 - gail/main.py:201 - [Discriminator] iter = 260000 loss = -4.2090 grad_norm = 3.6919 grad_penalty = 0.3448 regularization = 0.0000 true_logits = 0.7721 fake_logits = -3.7816 true_prob = 0.5915 fake_prob = 0.0843 
2022-07-08 15:08:59.320527 - gail/main.py:142 - [Evaluate] iter = 260000 episode={ returns = 607.2916 lengths = 193 } discounted_episode={ returns = 577.5903 lengths = 202 } 
2022-07-08 15:09:02.145693 - gail/main.py:174 - [TRPO] iter = 261000 dist_mean = 0.2192 dist_std = 0.4384 vf_loss = 0.1641 grad_norm = 1.3948 nat_grad_norm = 0.3217 cg_residual = 0.1861 step_size = 0.3447 reward = -0.0000 fps = 136 mse_loss = 2.5270 
2022-07-08 15:09:04.485056 - gail/main.py:174 - [TRPO] iter = 262000 dist_mean = 0.2722 dist_std = 0.4357 vf_loss = 0.1371 grad_norm = 1.3906 nat_grad_norm = 0.3133 cg_residual = 0.1734 step_size = 0.3545 reward = 0.0000 fps = 103 mse_loss = 2.6165 
2022-07-08 15:09:06.622056 - gail/main.py:174 - [TRPO] iter = 263000 dist_mean = 0.2102 dist_std = 0.4358 vf_loss = 0.1473 grad_norm = 1.4117 nat_grad_norm = 0.2633 cg_residual = 0.1742 step_size = 0.3680 reward = -0.0000 fps = 84 mse_loss = 2.5466 
2022-07-08 15:09:08.356888 - gail/main.py:174 - [TRPO] iter = 264000 dist_mean = 0.2444 dist_std = 0.4361 vf_loss = 0.1071 grad_norm = 1.3386 nat_grad_norm = 0.3522 cg_residual = 0.1705 step_size = 0.3256 reward = -0.0000 fps = 73 mse_loss = 2.5347 
2022-07-08 15:09:10.122974 - gail/main.py:174 - [TRPO] iter = 265000 dist_mean = 0.2522 dist_std = 0.4346 vf_loss = 0.1636 grad_norm = 1.3278 nat_grad_norm = 0.3349 cg_residual = 0.2850 step_size = 0.3409 reward = 0.0000 fps = 65 mse_loss = 2.5596 
2022-07-08 15:09:10.195568 - gail/main.py:201 - [Discriminator] iter = 265000 loss = -3.8249 grad_norm = 3.3254 grad_penalty = 0.3625 regularization = 0.0000 true_logits = 0.7824 fake_logits = -3.4050 true_prob = 0.5848 fake_prob = 0.1130 
2022-07-08 15:09:14.596718 - gail/main.py:142 - [Evaluate] iter = 265000 episode={ returns = 591.5413 lengths = 183 } discounted_episode={ returns = 579.8921 lengths = 193 } 
2022-07-08 15:09:16.383163 - gail/main.py:174 - [TRPO] iter = 266000 dist_mean = 0.2438 dist_std = 0.4332 vf_loss = 0.1192 grad_norm = 1.2974 nat_grad_norm = 0.3004 cg_residual = 0.2268 step_size = 0.3714 reward = 0.0000 fps = 161 mse_loss = 2.5278 
2022-07-08 15:09:18.846650 - gail/main.py:174 - [TRPO] iter = 267000 dist_mean = 0.2728 dist_std = 0.4340 vf_loss = 0.1565 grad_norm = 1.2824 nat_grad_norm = 0.4120 cg_residual = 0.3121 step_size = 0.2954 reward = -0.0000 fps = 115 mse_loss = 2.7875 
2022-07-08 15:09:20.659020 - gail/main.py:174 - [TRPO] iter = 268000 dist_mean = 0.2305 dist_std = 0.4334 vf_loss = 0.1741 grad_norm = 1.3169 nat_grad_norm = 0.3473 cg_residual = 0.2757 step_size = 0.3479 reward = -0.0000 fps = 95 mse_loss = 2.7412 
2022-07-08 15:09:22.521499 - gail/main.py:174 - [TRPO] iter = 269000 dist_mean = 0.2271 dist_std = 0.4335 vf_loss = 0.1702 grad_norm = 1.1988 nat_grad_norm = 0.3986 cg_residual = 0.3105 step_size = 0.3028 reward = 0.0000 fps = 81 mse_loss = 2.7741 
2022-07-08 15:09:24.263301 - gail/main.py:174 - [TRPO] iter = 270000 dist_mean = 0.2455 dist_std = 0.4349 vf_loss = 0.1509 grad_norm = 1.2871 nat_grad_norm = 0.3429 cg_residual = 0.2115 step_size = 0.3223 reward = -0.0000 fps = 71 mse_loss = 2.6586 
2022-07-08 15:09:24.340650 - gail/main.py:201 - [Discriminator] iter = 270000 loss = -3.8490 grad_norm = 3.4166 grad_penalty = 0.3258 regularization = 0.0000 true_logits = 0.8763 fake_logits = -3.2985 true_prob = 0.5872 fake_prob = 0.1245 
2022-07-08 15:09:28.959465 - gail/main.py:142 - [Evaluate] iter = 270000 episode={ returns = 667.7288 lengths = 195 } discounted_episode={ returns = 579.6023 lengths = 191 } 
2022-07-08 15:09:31.202208 - gail/main.py:174 - [TRPO] iter = 271000 dist_mean = 0.2268 dist_std = 0.4343 vf_loss = 0.1566 grad_norm = 1.3425 nat_grad_norm = 0.3016 cg_residual = 0.2194 step_size = 0.3516 reward = 0.0000 fps = 145 mse_loss = 2.6282 
2022-07-08 15:09:33.443102 - gail/main.py:174 - [TRPO] iter = 272000 dist_mean = 0.2196 dist_std = 0.4367 vf_loss = 0.1378 grad_norm = 1.0779 nat_grad_norm = 0.2929 cg_residual = 0.2634 step_size = 0.3900 reward = -0.0000 fps = 109 mse_loss = 2.6332 
2022-07-08 15:09:35.482028 - gail/main.py:174 - [TRPO] iter = 273000 dist_mean = 0.2234 dist_std = 0.4353 vf_loss = 0.1132 grad_norm = 1.6731 nat_grad_norm = 0.3469 cg_residual = 0.3463 step_size = 0.3154 reward = -0.0000 fps = 89 mse_loss = 2.9250 
2022-07-08 15:09:37.461647 - gail/main.py:174 - [TRPO] iter = 274000 dist_mean = 0.2261 dist_std = 0.4346 vf_loss = 0.1324 grad_norm = 1.1656 nat_grad_norm = 0.3263 cg_residual = 0.2862 step_size = 0.3452 reward = 0.0000 fps = 76 mse_loss = 2.8069 
2022-07-08 15:09:39.412734 - gail/main.py:174 - [TRPO] iter = 275000 dist_mean = 0.2349 dist_std = 0.4334 vf_loss = 0.1978 grad_norm = 1.2624 nat_grad_norm = 0.3792 cg_residual = 0.3215 step_size = 0.3093 reward = -0.0000 fps = 66 mse_loss = 2.6001 
2022-07-08 15:09:39.507062 - gail/main.py:201 - [Discriminator] iter = 275000 loss = -4.0546 grad_norm = 3.5765 grad_penalty = 0.3295 regularization = 0.0000 true_logits = 0.7758 fake_logits = -3.6082 true_prob = 0.5818 fake_prob = 0.0999 
2022-07-08 15:09:44.743071 - gail/main.py:142 - [Evaluate] iter = 275000 episode={ returns = 586.9289 lengths = 195 } discounted_episode={ returns = 587.2162 lengths = 221 } 
2022-07-08 15:09:46.933053 - gail/main.py:174 - [TRPO] iter = 276000 dist_mean = 0.2231 dist_std = 0.4362 vf_loss = 0.1944 grad_norm = 1.1993 nat_grad_norm = 0.2864 cg_residual = 0.2781 step_size = 0.3635 reward = -0.0000 fps = 134 mse_loss = 2.6437 
2022-07-08 15:09:49.803535 - gail/main.py:174 - [TRPO] iter = 277000 dist_mean = 0.2915 dist_std = 0.4364 vf_loss = 0.0898 grad_norm = 1.7187 nat_grad_norm = 0.3942 cg_residual = 0.4131 step_size = 0.2910 reward = 0.0000 fps = 97 mse_loss = 2.6770 
2022-07-08 15:09:52.652908 - gail/main.py:174 - [TRPO] iter = 278000 dist_mean = 0.2084 dist_std = 0.4346 vf_loss = 0.1258 grad_norm = 1.1077 nat_grad_norm = 0.3227 cg_residual = 0.3100 step_size = 0.3690 reward = -0.0000 fps = 76 mse_loss = 2.7017 
2022-07-08 15:09:55.833593 - gail/main.py:174 - [TRPO] iter = 279000 dist_mean = 0.2377 dist_std = 0.4372 vf_loss = 0.1371 grad_norm = 1.4040 nat_grad_norm = 0.3252 cg_residual = 0.2791 step_size = 0.3291 reward = 0.0000 fps = 61 mse_loss = 2.6701 
2022-07-08 15:09:57.513392 - gail/main.py:174 - [TRPO] iter = 280000 dist_mean = 0.2403 dist_std = 0.4368 vf_loss = 0.1317 grad_norm = 1.3208 nat_grad_norm = 0.3202 cg_residual = 0.3671 step_size = 0.3208 reward = -0.0000 fps = 55 mse_loss = 2.7858 
2022-07-08 15:09:57.600921 - gail/main.py:201 - [Discriminator] iter = 280000 loss = -4.0730 grad_norm = 3.9395 grad_penalty = 0.3437 regularization = 0.0000 true_logits = 0.8556 fake_logits = -3.5611 true_prob = 0.5989 fake_prob = 0.1117 
2022-07-08 15:10:02.324004 - gail/main.py:142 - [Evaluate] iter = 280000 episode={ returns = 674.2115 lengths = 200 } discounted_episode={ returns = 721.8582 lengths = 242 } 
2022-07-08 15:10:05.369810 - gail/main.py:174 - [TRPO] iter = 281000 dist_mean = 0.1977 dist_std = 0.4356 vf_loss = 0.1040 grad_norm = 1.1836 nat_grad_norm = 0.2982 cg_residual = 0.2917 step_size = 0.3499 reward = 0.0000 fps = 128 mse_loss = 2.7354 
2022-07-08 15:10:08.405024 - gail/main.py:174 - [TRPO] iter = 282000 dist_mean = 0.2268 dist_std = 0.4360 vf_loss = 0.0933 grad_norm = 1.7864 nat_grad_norm = 0.2602 cg_residual = 0.3297 step_size = 0.3851 reward = 0.0000 fps = 92 mse_loss = 2.7743 
2022-07-08 15:10:11.163191 - gail/main.py:174 - [TRPO] iter = 283000 dist_mean = 0.2389 dist_std = 0.4327 vf_loss = 0.1037 grad_norm = 1.3562 nat_grad_norm = 0.3251 cg_residual = 0.2532 step_size = 0.3406 reward = 0.0000 fps = 73 mse_loss = 2.7974 
2022-07-08 15:10:14.528329 - gail/main.py:174 - [TRPO] iter = 284000 dist_mean = 0.1976 dist_std = 0.4297 vf_loss = 0.1561 grad_norm = 1.2454 nat_grad_norm = 0.3365 cg_residual = 0.3911 step_size = 0.3472 reward = 0.0000 fps = 59 mse_loss = 2.7726 
2022-07-08 15:10:17.589275 - gail/main.py:174 - [TRPO] iter = 285000 dist_mean = 0.2433 dist_std = 0.4274 vf_loss = 0.1048 grad_norm = 1.3996 nat_grad_norm = 0.3637 cg_residual = 0.2672 step_size = 0.2936 reward = 0.0000 fps = 50 mse_loss = 2.7374 
2022-07-08 15:10:17.804305 - gail/main.py:201 - [Discriminator] iter = 285000 loss = -4.2569 grad_norm = 3.6150 grad_penalty = 0.3848 regularization = 0.0000 true_logits = 0.6587 fake_logits = -3.9830 true_prob = 0.5671 fake_prob = 0.0831 
2022-07-08 15:10:28.462163 - gail/main.py:142 - [Evaluate] iter = 285000 episode={ returns = 522.1250 lengths = 160 } discounted_episode={ returns = 434.6796 lengths = 152 } 
2022-07-08 15:10:31.606271 - gail/main.py:174 - [TRPO] iter = 286000 dist_mean = 0.2407 dist_std = 0.4279 vf_loss = 0.0837 grad_norm = 1.5125 nat_grad_norm = 0.3262 cg_residual = 0.3120 step_size = 0.3149 reward = 0.0000 fps = 72 mse_loss = 2.7497 
2022-07-08 15:10:35.130890 - gail/main.py:174 - [TRPO] iter = 287000 dist_mean = 0.2584 dist_std = 0.4265 vf_loss = 0.0946 grad_norm = 1.5870 nat_grad_norm = 0.3394 cg_residual = 0.1980 step_size = 0.3108 reward = 0.0000 fps = 57 mse_loss = 2.6847 
2022-07-08 15:10:45.798573 - gail/main.py:174 - [TRPO] iter = 288000 dist_mean = 0.2286 dist_std = 0.4262 vf_loss = 0.1066 grad_norm = 1.3490 nat_grad_norm = 0.2969 cg_residual = 0.1737 step_size = 0.3358 reward = 0.0000 fps = 35 mse_loss = 2.6810 
2022-07-08 15:10:52.548602 - gail/main.py:174 - [TRPO] iter = 289000 dist_mean = 0.2299 dist_std = 0.4213 vf_loss = 0.1016 grad_norm = 1.3628 nat_grad_norm = 0.3173 cg_residual = 0.2065 step_size = 0.3510 reward = -0.0000 fps = 28 mse_loss = 2.8687 
2022-07-08 15:10:56.370597 - gail/main.py:174 - [TRPO] iter = 290000 dist_mean = 0.2433 dist_std = 0.4178 vf_loss = 0.1223 grad_norm = 1.4836 nat_grad_norm = 0.2867 cg_residual = 0.1908 step_size = 0.3521 reward = -0.0000 fps = 25 mse_loss = 2.5846 
2022-07-08 15:10:56.524250 - gail/main.py:201 - [Discriminator] iter = 290000 loss = -4.2812 grad_norm = 4.1784 grad_penalty = 0.3882 regularization = 0.0000 true_logits = 0.5769 fake_logits = -4.0925 true_prob = 0.5515 fake_prob = 0.0817 
2022-07-08 15:11:02.878745 - gail/main.py:142 - [Evaluate] iter = 290000 episode={ returns = 618.4412 lengths = 184 } discounted_episode={ returns = 548.1876 lengths = 183 } 
2022-07-08 15:11:04.837139 - gail/main.py:174 - [TRPO] iter = 291000 dist_mean = 0.2689 dist_std = 0.4170 vf_loss = 0.1214 grad_norm = 1.6343 nat_grad_norm = 0.3554 cg_residual = 0.4319 step_size = 0.3110 reward = -0.0000 fps = 120 mse_loss = 2.6670 
2022-07-08 15:11:06.848758 - gail/main.py:174 - [TRPO] iter = 292000 dist_mean = 0.2569 dist_std = 0.4166 vf_loss = 0.1086 grad_norm = 1.3171 nat_grad_norm = 0.3762 cg_residual = 0.3239 step_size = 0.3314 reward = 0.0000 fps = 96 mse_loss = 2.7106 
2022-07-08 15:11:08.998647 - gail/main.py:174 - [TRPO] iter = 293000 dist_mean = 0.2464 dist_std = 0.4168 vf_loss = 0.1067 grad_norm = 1.5309 nat_grad_norm = 0.3081 cg_residual = 0.4031 step_size = 0.3055 reward = -0.0000 fps = 80 mse_loss = 2.6968 
2022-07-08 15:11:11.809113 - gail/main.py:174 - [TRPO] iter = 294000 dist_mean = 0.2442 dist_std = 0.4173 vf_loss = 0.0910 grad_norm = 1.8591 nat_grad_norm = 0.3955 cg_residual = 0.3066 step_size = 0.2833 reward = 0.0000 fps = 65 mse_loss = 2.5978 
2022-07-08 15:11:14.154199 - gail/main.py:174 - [TRPO] iter = 295000 dist_mean = 0.2802 dist_std = 0.4165 vf_loss = 0.1318 grad_norm = 1.1921 nat_grad_norm = 0.4436 cg_residual = 0.3483 step_size = 0.2997 reward = -0.0000 fps = 56 mse_loss = 2.5549 
2022-07-08 15:11:14.272910 - gail/main.py:201 - [Discriminator] iter = 295000 loss = -4.2485 grad_norm = 4.5671 grad_penalty = 0.4126 regularization = 0.0000 true_logits = 0.5524 fake_logits = -4.1087 true_prob = 0.5531 fake_prob = 0.0733 
2022-07-08 15:11:18.408247 - gail/main.py:142 - [Evaluate] iter = 295000 episode={ returns = 577.1638 lengths = 172 } discounted_episode={ returns = 533.7977 lengths = 177 } 
2022-07-08 15:11:20.335969 - gail/main.py:174 - [TRPO] iter = 296000 dist_mean = 0.2344 dist_std = 0.4154 vf_loss = 0.1398 grad_norm = 1.4862 nat_grad_norm = 0.3479 cg_residual = 0.4668 step_size = 0.3178 reward = -0.0000 fps = 165 mse_loss = 2.6677 
2022-07-08 15:11:22.335568 - gail/main.py:174 - [TRPO] iter = 297000 dist_mean = 0.2633 dist_std = 0.4124 vf_loss = 0.0730 grad_norm = 1.6468 nat_grad_norm = 0.3452 cg_residual = 0.3421 step_size = 0.3304 reward = -0.0000 fps = 124 mse_loss = 2.5632 
2022-07-08 15:11:24.446812 - gail/main.py:174 - [TRPO] iter = 298000 dist_mean = 0.2103 dist_std = 0.4132 vf_loss = 0.1193 grad_norm = 1.3369 nat_grad_norm = 0.3247 cg_residual = 0.3372 step_size = 0.3307 reward = 0.0000 fps = 98 mse_loss = 2.7056 
2022-07-08 15:11:26.274215 - gail/main.py:174 - [TRPO] iter = 299000 dist_mean = 0.2520 dist_std = 0.4109 vf_loss = 0.1277 grad_norm = 1.2750 nat_grad_norm = 0.3540 cg_residual = 0.4456 step_size = 0.3261 reward = -0.0000 fps = 83 mse_loss = 2.8149 
2022-07-08 15:11:28.461165 - gail/main.py:174 - [TRPO] iter = 300000 dist_mean = 0.2551 dist_std = 0.4106 vf_loss = 0.0930 grad_norm = 1.2390 nat_grad_norm = 0.3627 cg_residual = 0.3723 step_size = 0.3138 reward = -0.0000 fps = 70 mse_loss = 2.7373 
2022-07-08 15:11:28.561437 - gail/main.py:201 - [Discriminator] iter = 300000 loss = -4.0006 grad_norm = 3.7382 grad_penalty = 0.3715 regularization = 0.0000 true_logits = 0.6362 fake_logits = -3.7359 true_prob = 0.5620 fake_prob = 0.1092 
2022-07-08 15:11:33.263260 - gail/main.py:142 - [Evaluate] iter = 300000 episode={ returns = 580.8803 lengths = 181 } discounted_episode={ returns = 497.5265 lengths = 174 } 
2022-07-08 15:11:35.396493 - gail/main.py:174 - [TRPO] iter = 301000 dist_mean = 0.2635 dist_std = 0.4105 vf_loss = 0.1032 grad_norm = 1.2079 nat_grad_norm = 0.4297 cg_residual = 0.4787 step_size = 0.2938 reward = -0.0000 fps = 146 mse_loss = 2.8370 
2022-07-08 15:11:37.515565 - gail/main.py:174 - [TRPO] iter = 302000 dist_mean = 0.2525 dist_std = 0.4092 vf_loss = 0.1323 grad_norm = 1.3277 nat_grad_norm = 0.3281 cg_residual = 0.2906 step_size = 0.3550 reward = -0.0000 fps = 111 mse_loss = 2.6285 
2022-07-08 15:11:39.446006 - gail/main.py:174 - [TRPO] iter = 303000 dist_mean = 0.2475 dist_std = 0.4069 vf_loss = 0.1387 grad_norm = 1.7751 nat_grad_norm = 0.3919 cg_residual = 0.4126 step_size = 0.2708 reward = -0.0000 fps = 91 mse_loss = 2.7295 
2022-07-08 15:11:41.211765 - gail/main.py:174 - [TRPO] iter = 304000 dist_mean = 0.2682 dist_std = 0.4094 vf_loss = 0.0888 grad_norm = 1.6913 nat_grad_norm = 0.4570 cg_residual = 0.3502 step_size = 0.2674 reward = -0.0000 fps = 79 mse_loss = 2.4556 
2022-07-08 15:11:43.158568 - gail/main.py:174 - [TRPO] iter = 305000 dist_mean = 0.2322 dist_std = 0.4097 vf_loss = 0.0853 grad_norm = 1.6791 nat_grad_norm = 0.3829 cg_residual = 0.4942 step_size = 0.3166 reward = -0.0000 fps = 68 mse_loss = 2.7480 
2022-07-08 15:11:43.243743 - gail/main.py:201 - [Discriminator] iter = 305000 loss = -4.2129 grad_norm = 3.7910 grad_penalty = 0.3490 regularization = 0.0000 true_logits = 0.7376 fake_logits = -3.8244 true_prob = 0.5752 fake_prob = 0.0992 
2022-07-08 15:11:47.147039 - gail/main.py:142 - [Evaluate] iter = 305000 episode={ returns = 454.4559 lengths = 149 } discounted_episode={ returns = 470.2027 lengths = 165 } 
2022-07-08 15:11:49.085602 - gail/main.py:174 - [TRPO] iter = 306000 dist_mean = 0.2356 dist_std = 0.4102 vf_loss = 0.1482 grad_norm = 1.5267 nat_grad_norm = 0.3407 cg_residual = 0.3142 step_size = 0.3244 reward = 0.0000 fps = 171 mse_loss = 2.5346 
2022-07-08 15:11:50.931481 - gail/main.py:174 - [TRPO] iter = 307000 dist_mean = 0.2617 dist_std = 0.4085 vf_loss = 0.0772 grad_norm = 1.4512 nat_grad_norm = 0.3853 cg_residual = 0.3744 step_size = 0.2888 reward = -0.0000 fps = 130 mse_loss = 2.6405 
2022-07-08 15:11:52.748342 - gail/main.py:174 - [TRPO] iter = 308000 dist_mean = 0.2343 dist_std = 0.4074 vf_loss = 0.0987 grad_norm = 1.7388 nat_grad_norm = 0.3503 cg_residual = 0.7648 step_size = 0.3382 reward = 0.0000 fps = 105 mse_loss = 2.5823 
2022-07-08 15:11:54.795740 - gail/main.py:174 - [TRPO] iter = 309000 dist_mean = 0.2418 dist_std = 0.4068 vf_loss = 0.0951 grad_norm = 1.4497 nat_grad_norm = 0.3631 cg_residual = 0.4979 step_size = 0.3121 reward = 0.0000 fps = 86 mse_loss = 2.6071 
2022-07-08 15:11:57.800132 - gail/main.py:174 - [TRPO] iter = 310000 dist_mean = 0.2589 dist_std = 0.4045 vf_loss = 0.0814 grad_norm = 2.2286 nat_grad_norm = 0.4353 cg_residual = 0.4403 step_size = 0.2685 reward = 0.0000 fps = 68 mse_loss = 2.6112 
2022-07-08 15:11:57.887211 - gail/main.py:201 - [Discriminator] iter = 310000 loss = -4.2200 grad_norm = 4.4223 grad_penalty = 0.3836 regularization = 0.0000 true_logits = 0.8256 fake_logits = -3.7780 true_prob = 0.5848 fake_prob = 0.0980 
2022-07-08 15:12:03.427315 - gail/main.py:142 - [Evaluate] iter = 310000 episode={ returns = 400.3380 lengths = 137 } discounted_episode={ returns = 375.9541 lengths = 139 } 
2022-07-08 15:12:06.200834 - gail/main.py:174 - [TRPO] iter = 311000 dist_mean = 0.1931 dist_std = 0.4034 vf_loss = 0.1563 grad_norm = 1.6641 nat_grad_norm = 0.3696 cg_residual = 0.5606 step_size = 0.2846 reward = -0.0000 fps = 120 mse_loss = 2.6275 
2022-07-08 15:12:08.485002 - gail/main.py:174 - [TRPO] iter = 312000 dist_mean = 0.2377 dist_std = 0.4027 vf_loss = 0.1066 grad_norm = 1.3453 nat_grad_norm = 0.3388 cg_residual = 0.3811 step_size = 0.3027 reward = 0.0000 fps = 94 mse_loss = 2.5777 
2022-07-08 15:12:11.210750 - gail/main.py:174 - [TRPO] iter = 313000 dist_mean = 0.2017 dist_std = 0.4019 vf_loss = 0.0899 grad_norm = 1.7343 nat_grad_norm = 0.2910 cg_residual = 0.4419 step_size = 0.3049 reward = 0.0000 fps = 75 mse_loss = 2.6715 
2022-07-08 15:12:14.133156 - gail/main.py:174 - [TRPO] iter = 314000 dist_mean = 0.2631 dist_std = 0.4033 vf_loss = 0.1130 grad_norm = 1.6986 nat_grad_norm = 0.4451 cg_residual = 0.7816 step_size = 0.2556 reward = 0.0000 fps = 61 mse_loss = 2.6494 
2022-07-08 15:12:16.473843 - gail/main.py:174 - [TRPO] iter = 315000 dist_mean = 0.2717 dist_std = 0.4032 vf_loss = 0.1563 grad_norm = 1.3121 nat_grad_norm = 0.3921 cg_residual = 0.4744 step_size = 0.3125 reward = 0.0000 fps = 53 mse_loss = 2.6013 
2022-07-08 15:12:16.557232 - gail/main.py:201 - [Discriminator] iter = 315000 loss = -4.4125 grad_norm = 3.8883 grad_penalty = 0.4090 regularization = 0.0000 true_logits = 0.7393 fake_logits = -4.0821 true_prob = 0.5695 fake_prob = 0.0811 
2022-07-08 15:12:20.716902 - gail/main.py:142 - [Evaluate] iter = 315000 episode={ returns = 432.0879 lengths = 143 } discounted_episode={ returns = 373.7389 lengths = 137 } 
2022-07-08 15:12:22.812290 - gail/main.py:174 - [TRPO] iter = 316000 dist_mean = 0.2677 dist_std = 0.4034 vf_loss = 0.1058 grad_norm = 1.5205 nat_grad_norm = 0.3868 cg_residual = 0.3450 step_size = 0.2997 reward = -0.0000 fps = 160 mse_loss = 2.6389 
2022-07-08 15:12:25.196640 - gail/main.py:174 - [TRPO] iter = 317000 dist_mean = 0.2472 dist_std = 0.4038 vf_loss = 0.0940 grad_norm = 1.2188 nat_grad_norm = 0.3111 cg_residual = 0.3833 step_size = 0.3689 reward = -0.0000 fps = 115 mse_loss = 2.6651 
2022-07-08 15:12:27.007702 - gail/main.py:174 - [TRPO] iter = 318000 dist_mean = 0.2279 dist_std = 0.4023 vf_loss = 0.1540 grad_norm = 1.6573 nat_grad_norm = 0.2684 cg_residual = 0.2967 step_size = 0.3517 reward = -0.0000 fps = 95 mse_loss = 2.6923 
2022-07-08 15:12:28.299717 - gail/main.py:174 - [TRPO] iter = 319000 dist_mean = 0.2573 dist_std = 0.4028 vf_loss = 0.1828 grad_norm = 1.5236 nat_grad_norm = 0.2778 cg_residual = 0.3300 step_size = 0.3418 reward = 0.0000 fps = 85 mse_loss = 2.7013 
2022-07-08 15:12:29.529035 - gail/main.py:174 - [TRPO] iter = 320000 dist_mean = 0.2187 dist_std = 0.4027 vf_loss = 0.1561 grad_norm = 1.5806 nat_grad_norm = 0.3298 cg_residual = 0.5270 step_size = 0.3320 reward = -0.0000 fps = 77 mse_loss = 2.6313 
2022-07-08 15:12:29.583071 - gail/main.py:201 - [Discriminator] iter = 320000 loss = -3.6904 grad_norm = 3.7493 grad_penalty = 0.3126 regularization = 0.0000 true_logits = 0.8229 fake_logits = -3.1801 true_prob = 0.5814 fake_prob = 0.1421 
2022-07-08 15:12:31.973481 - gail/main.py:142 - [Evaluate] iter = 320000 episode={ returns = 400.1134 lengths = 137 } discounted_episode={ returns = 467.5225 lengths = 163 } 
2022-07-08 15:12:33.196790 - gail/main.py:174 - [TRPO] iter = 321000 dist_mean = 0.2351 dist_std = 0.4026 vf_loss = 0.1418 grad_norm = 1.7084 nat_grad_norm = 0.3593 cg_residual = 0.3951 step_size = 0.3038 reward = -0.0000 fps = 276 mse_loss = 2.4938 
2022-07-08 15:12:34.413682 - gail/main.py:174 - [TRPO] iter = 322000 dist_mean = 0.2295 dist_std = 0.4020 vf_loss = 0.0824 grad_norm = 1.3632 nat_grad_norm = 0.3318 cg_residual = 0.3994 step_size = 0.3513 reward = -0.0000 fps = 207 mse_loss = 2.6843 
2022-07-08 15:12:35.608943 - gail/main.py:174 - [TRPO] iter = 323000 dist_mean = 0.2541 dist_std = 0.3975 vf_loss = 0.1011 grad_norm = 1.6346 nat_grad_norm = 0.3653 cg_residual = 0.6599 step_size = 0.2947 reward = -0.0000 fps = 166 mse_loss = 2.6851 
2022-07-08 15:12:36.809432 - gail/main.py:174 - [TRPO] iter = 324000 dist_mean = 0.2334 dist_std = 0.3979 vf_loss = 0.0717 grad_norm = 1.6124 nat_grad_norm = 0.3142 cg_residual = 0.4300 step_size = 0.3182 reward = 0.0000 fps = 138 mse_loss = 2.5732 
2022-07-08 15:12:38.054372 - gail/main.py:174 - [TRPO] iter = 325000 dist_mean = 0.2949 dist_std = 0.3965 vf_loss = 0.0894 grad_norm = 1.7550 nat_grad_norm = 0.3466 cg_residual = 0.7022 step_size = 0.2872 reward = -0.0000 fps = 118 mse_loss = 2.6202 
2022-07-08 15:12:38.106969 - gail/main.py:201 - [Discriminator] iter = 325000 loss = -4.0460 grad_norm = 3.4363 grad_penalty = 0.3672 regularization = 0.0000 true_logits = 0.5493 fake_logits = -3.8640 true_prob = 0.5478 fake_prob = 0.0917 
2022-07-08 15:12:40.218293 - gail/main.py:142 - [Evaluate] iter = 325000 episode={ returns = 400.9055 lengths = 137 } discounted_episode={ returns = 342.0012 lengths = 130 } 
2022-07-08 15:12:41.412758 - gail/main.py:174 - [TRPO] iter = 326000 dist_mean = 0.2753 dist_std = 0.3977 vf_loss = 0.0914 grad_norm = 1.7392 nat_grad_norm = 0.3698 cg_residual = 0.4733 step_size = 0.2815 reward = 0.0000 fps = 302 mse_loss = 2.7165 
2022-07-08 15:12:43.044489 - gail/main.py:174 - [TRPO] iter = 327000 dist_mean = 0.2298 dist_std = 0.3948 vf_loss = 0.1322 grad_norm = 1.6638 nat_grad_norm = 0.3970 cg_residual = 0.4809 step_size = 0.2735 reward = 0.0000 fps = 202 mse_loss = 2.7571 
2022-07-08 15:12:44.251885 - gail/main.py:174 - [TRPO] iter = 328000 dist_mean = 0.2714 dist_std = 0.3948 vf_loss = 0.1360 grad_norm = 1.7327 nat_grad_norm = 0.2852 cg_residual = 0.4624 step_size = 0.3154 reward = -0.0000 fps = 162 mse_loss = 2.6857 
2022-07-08 15:12:45.469506 - gail/main.py:174 - [TRPO] iter = 329000 dist_mean = 0.2147 dist_std = 0.3944 vf_loss = 0.0815 grad_norm = 1.5331 nat_grad_norm = 0.3344 cg_residual = 0.6166 step_size = 0.3188 reward = -0.0000 fps = 135 mse_loss = 2.5815 
2022-07-08 15:12:46.676946 - gail/main.py:174 - [TRPO] iter = 330000 dist_mean = 0.2303 dist_std = 0.3927 vf_loss = 0.1183 grad_norm = 1.3677 nat_grad_norm = 0.3242 cg_residual = 0.3831 step_size = 0.3315 reward = 0.0000 fps = 116 mse_loss = 2.6353 
2022-07-08 15:12:46.726314 - gail/main.py:201 - [Discriminator] iter = 330000 loss = -3.9939 grad_norm = 3.1362 grad_penalty = 0.3438 regularization = 0.0000 true_logits = 0.7001 fake_logits = -3.6377 true_prob = 0.5652 fake_prob = 0.1134 
2022-07-08 15:12:49.071351 - gail/main.py:142 - [Evaluate] iter = 330000 episode={ returns = 476.7018 lengths = 147 } discounted_episode={ returns = 440.8335 lengths = 150 } 
2022-07-08 15:12:50.275038 - gail/main.py:174 - [TRPO] iter = 331000 dist_mean = 0.2704 dist_std = 0.3943 vf_loss = 0.1752 grad_norm = 1.3830 nat_grad_norm = 0.3846 cg_residual = 0.4144 step_size = 0.2964 reward = 0.0000 fps = 282 mse_loss = 2.5698 
2022-07-08 15:12:51.601846 - gail/main.py:174 - [TRPO] iter = 332000 dist_mean = 0.2307 dist_std = 0.3955 vf_loss = 0.1056 grad_norm = 1.6432 nat_grad_norm = 0.3195 cg_residual = 0.6110 step_size = 0.3057 reward = -0.0000 fps = 205 mse_loss = 2.6543 
2022-07-08 15:12:52.884994 - gail/main.py:174 - [TRPO] iter = 333000 dist_mean = 0.2229 dist_std = 0.3963 vf_loss = 0.1189 grad_norm = 1.4907 nat_grad_norm = 0.3060 cg_residual = 0.4375 step_size = 0.3171 reward = -0.0000 fps = 162 mse_loss = 2.5697 
2022-07-08 15:12:54.100985 - gail/main.py:174 - [TRPO] iter = 334000 dist_mean = 0.2603 dist_std = 0.3932 vf_loss = 0.1252 grad_norm = 1.5771 nat_grad_norm = 0.3254 cg_residual = 0.4199 step_size = 0.3110 reward = -0.0000 fps = 135 mse_loss = 2.5191 
2022-07-08 15:12:55.321236 - gail/main.py:174 - [TRPO] iter = 335000 dist_mean = 0.2304 dist_std = 0.3948 vf_loss = 0.1155 grad_norm = 1.4974 nat_grad_norm = 0.3644 cg_residual = 0.5513 step_size = 0.3016 reward = 0.0000 fps = 116 mse_loss = 2.4632 
2022-07-08 15:12:55.371485 - gail/main.py:201 - [Discriminator] iter = 335000 loss = -3.6592 grad_norm = 3.6054 grad_penalty = 0.3198 regularization = 0.0000 true_logits = 0.6617 fake_logits = -3.3173 true_prob = 0.5610 fake_prob = 0.1409 
2022-07-08 15:12:57.859092 - gail/main.py:142 - [Evaluate] iter = 335000 episode={ returns = 492.8695 lengths = 154 } discounted_episode={ returns = 468.9461 lengths = 159 } 
2022-07-08 15:12:59.079560 - gail/main.py:174 - [TRPO] iter = 336000 dist_mean = 0.2433 dist_std = 0.3940 vf_loss = 0.1403 grad_norm = 2.1747 nat_grad_norm = 0.2819 cg_residual = 0.6373 step_size = 0.3196 reward = -0.0000 fps = 269 mse_loss = 2.5123 
2022-07-08 15:13:00.304877 - gail/main.py:174 - [TRPO] iter = 337000 dist_mean = 0.2841 dist_std = 0.3941 vf_loss = 0.1041 grad_norm = 1.3673 nat_grad_norm = 0.2895 cg_residual = 0.3674 step_size = 0.3328 reward = 0.0000 fps = 202 mse_loss = 2.5439 
2022-07-08 15:13:01.510307 - gail/main.py:174 - [TRPO] iter = 338000 dist_mean = 0.2838 dist_std = 0.3912 vf_loss = 0.0981 grad_norm = 1.4493 nat_grad_norm = 0.3500 cg_residual = 0.4085 step_size = 0.3276 reward = -0.0000 fps = 162 mse_loss = 2.5109 
2022-07-08 15:13:02.724678 - gail/main.py:174 - [TRPO] iter = 339000 dist_mean = 0.2376 dist_std = 0.3899 vf_loss = 0.0782 grad_norm = 1.8810 nat_grad_norm = 0.3013 cg_residual = 0.2786 step_size = 0.3191 reward = 0.0000 fps = 136 mse_loss = 2.4440 
2022-07-08 15:13:03.956891 - gail/main.py:174 - [TRPO] iter = 340000 dist_mean = 0.2346 dist_std = 0.3874 vf_loss = 0.1348 grad_norm = 1.5510 nat_grad_norm = 0.2873 cg_residual = 0.3751 step_size = 0.3431 reward = 0.0000 fps = 116 mse_loss = 2.4309 
2022-07-08 15:13:04.006223 - gail/main.py:201 - [Discriminator] iter = 340000 loss = -3.9013 grad_norm = 3.1618 grad_penalty = 0.3180 regularization = 0.0000 true_logits = 0.5059 fake_logits = -3.7134 true_prob = 0.5448 fake_prob = 0.1147 
2022-07-08 15:13:07.559594 - gail/main.py:142 - [Evaluate] iter = 340000 episode={ returns = 721.5286 lengths = 222 } discounted_episode={ returns = 674.8420 lengths = 232 } 
2022-07-08 15:13:08.756132 - gail/main.py:174 - [TRPO] iter = 341000 dist_mean = 0.2895 dist_std = 0.3872 vf_loss = 0.0899 grad_norm = 1.7005 nat_grad_norm = 0.3565 cg_residual = 0.5528 step_size = 0.3088 reward = -0.0000 fps = 210 mse_loss = 2.6391 
2022-07-08 15:13:09.997761 - gail/main.py:174 - [TRPO] iter = 342000 dist_mean = 0.2586 dist_std = 0.3874 vf_loss = 0.0917 grad_norm = 1.4432 nat_grad_norm = 0.3202 cg_residual = 0.4340 step_size = 0.3334 reward = -0.0000 fps = 166 mse_loss = 2.6208 
2022-07-08 15:13:11.211129 - gail/main.py:174 - [TRPO] iter = 343000 dist_mean = 0.2804 dist_std = 0.3876 vf_loss = 0.1106 grad_norm = 1.2170 nat_grad_norm = 0.3483 cg_residual = 0.4663 step_size = 0.3318 reward = -0.0000 fps = 138 mse_loss = 2.5972 
2022-07-08 15:13:12.400897 - gail/main.py:174 - [TRPO] iter = 344000 dist_mean = 0.2386 dist_std = 0.3874 vf_loss = 0.1074 grad_norm = 1.6642 nat_grad_norm = 0.3380 cg_residual = 0.4049 step_size = 0.3094 reward = -0.0000 fps = 119 mse_loss = 2.5785 
2022-07-08 15:13:13.597543 - gail/main.py:174 - [TRPO] iter = 345000 dist_mean = 0.2485 dist_std = 0.3860 vf_loss = 0.1080 grad_norm = 1.4216 nat_grad_norm = 0.3741 cg_residual = 0.5312 step_size = 0.3112 reward = 0.0000 fps = 104 mse_loss = 2.5872 
2022-07-08 15:13:13.649333 - gail/main.py:201 - [Discriminator] iter = 345000 loss = -3.6838 grad_norm = 3.5944 grad_penalty = 0.3261 regularization = 0.0000 true_logits = 0.3108 fake_logits = -3.6991 true_prob = 0.5156 fake_prob = 0.1245 
2022-07-08 15:13:16.759232 - gail/main.py:142 - [Evaluate] iter = 345000 episode={ returns = 544.1085 lengths = 182 } discounted_episode={ returns = 565.1926 lengths = 214 } 
2022-07-08 15:13:17.989221 - gail/main.py:174 - [TRPO] iter = 346000 dist_mean = 0.2186 dist_std = 0.3838 vf_loss = 0.1552 grad_norm = 1.8173 nat_grad_norm = 0.2775 cg_residual = 0.5379 step_size = 0.3310 reward = -0.0000 fps = 230 mse_loss = 2.6978 
2022-07-08 15:13:19.229158 - gail/main.py:174 - [TRPO] iter = 347000 dist_mean = 0.2287 dist_std = 0.3816 vf_loss = 0.1484 grad_norm = 1.9458 nat_grad_norm = 0.3248 cg_residual = 0.6827 step_size = 0.3284 reward = -0.0000 fps = 179 mse_loss = 2.6714 
2022-07-08 15:13:20.462884 - gail/main.py:174 - [TRPO] iter = 348000 dist_mean = 0.2447 dist_std = 0.3781 vf_loss = 0.1388 grad_norm = 1.9009 nat_grad_norm = 0.3424 cg_residual = 0.7081 step_size = 0.2866 reward = -0.0000 fps = 146 mse_loss = 2.6254 
2022-07-08 15:13:21.705155 - gail/main.py:174 - [TRPO] iter = 349000 dist_mean = 0.2130 dist_std = 0.3782 vf_loss = 0.1410 grad_norm = 1.4613 nat_grad_norm = 0.3301 cg_residual = 0.5414 step_size = 0.2953 reward = 0.0000 fps = 124 mse_loss = 2.8215 
2022-07-08 15:13:22.946400 - gail/main.py:174 - [TRPO] iter = 350000 dist_mean = 0.2140 dist_std = 0.3778 vf_loss = 0.1124 grad_norm = 1.3322 nat_grad_norm = 0.3273 cg_residual = 0.5481 step_size = 0.3308 reward = 0.0000 fps = 107 mse_loss = 2.6275 
2022-07-08 15:13:22.998294 - gail/main.py:201 - [Discriminator] iter = 350000 loss = -3.8597 grad_norm = 3.4072 grad_penalty = 0.3099 regularization = 0.0000 true_logits = 0.3169 fake_logits = -3.8527 true_prob = 0.5152 fake_prob = 0.1029 
2022-07-08 15:13:28.186757 - gail/main.py:142 - [Evaluate] iter = 350000 episode={ returns = 747.6749 lengths = 224 } discounted_episode={ returns = 820.0292 lengths = 297 } 
2022-07-08 15:13:29.400314 - gail/main.py:174 - [TRPO] iter = 351000 dist_mean = 0.2750 dist_std = 0.3780 vf_loss = 0.1156 grad_norm = 1.3848 nat_grad_norm = 0.3457 cg_residual = 0.3949 step_size = 0.3115 reward = 0.0000 fps = 156 mse_loss = 2.6585 
2022-07-08 15:13:30.614617 - gail/main.py:174 - [TRPO] iter = 352000 dist_mean = 0.2442 dist_std = 0.3781 vf_loss = 0.1314 grad_norm = 1.4034 nat_grad_norm = 0.3459 cg_residual = 0.4356 step_size = 0.3085 reward = -0.0000 fps = 131 mse_loss = 2.6968 
2022-07-08 15:13:31.819611 - gail/main.py:174 - [TRPO] iter = 353000 dist_mean = 0.2269 dist_std = 0.3773 vf_loss = 0.1611 grad_norm = 1.3672 nat_grad_norm = 0.3588 cg_residual = 0.4085 step_size = 0.3067 reward = 0.0000 fps = 113 mse_loss = 2.7808 
2022-07-08 15:13:33.023701 - gail/main.py:174 - [TRPO] iter = 354000 dist_mean = 0.2126 dist_std = 0.3757 vf_loss = 0.1634 grad_norm = 1.5583 nat_grad_norm = 0.2681 cg_residual = 0.4206 step_size = 0.3446 reward = 0.0000 fps = 99 mse_loss = 2.7677 
2022-07-08 15:13:34.233604 - gail/main.py:174 - [TRPO] iter = 355000 dist_mean = 0.1927 dist_std = 0.3749 vf_loss = 0.1059 grad_norm = 1.8409 nat_grad_norm = 0.3452 cg_residual = 0.6823 step_size = 0.2858 reward = -0.0000 fps = 89 mse_loss = 2.7346 
2022-07-08 15:13:34.284539 - gail/main.py:201 - [Discriminator] iter = 355000 loss = -3.6342 grad_norm = 3.8824 grad_penalty = 0.3083 regularization = 0.0000 true_logits = 0.3367 fake_logits = -3.6057 true_prob = 0.5177 fake_prob = 0.1278 
2022-07-08 15:13:37.579407 - gail/main.py:142 - [Evaluate] iter = 355000 episode={ returns = 683.5444 lengths = 219 } discounted_episode={ returns = 529.3146 lengths = 201 } 
2022-07-08 15:13:38.811002 - gail/main.py:174 - [TRPO] iter = 356000 dist_mean = 0.2211 dist_std = 0.3741 vf_loss = 0.1323 grad_norm = 1.6970 nat_grad_norm = 0.3191 cg_residual = 0.7856 step_size = 0.3171 reward = -0.0000 fps = 221 mse_loss = 2.6569 
2022-07-08 15:13:40.016681 - gail/main.py:174 - [TRPO] iter = 357000 dist_mean = 0.2203 dist_std = 0.3743 vf_loss = 0.0877 grad_norm = 1.4033 nat_grad_norm = 0.3273 cg_residual = 0.7732 step_size = 0.3278 reward = 0.0000 fps = 174 mse_loss = 2.5780 
2022-07-08 15:13:41.230993 - gail/main.py:174 - [TRPO] iter = 358000 dist_mean = 0.2125 dist_std = 0.3743 vf_loss = 0.2015 grad_norm = 1.4048 nat_grad_norm = 0.3411 cg_residual = 0.4771 step_size = 0.3152 reward = -0.0000 fps = 144 mse_loss = 2.6442 
2022-07-08 15:13:42.440148 - gail/main.py:174 - [TRPO] iter = 359000 dist_mean = 0.2723 dist_std = 0.3721 vf_loss = 0.0869 grad_norm = 1.5732 nat_grad_norm = 0.3265 cg_residual = 0.4743 step_size = 0.2802 reward = 0.0000 fps = 122 mse_loss = 2.7271 
2022-07-08 15:13:43.645640 - gail/main.py:174 - [TRPO] iter = 360000 dist_mean = 0.1822 dist_std = 0.3734 vf_loss = 0.1269 grad_norm = 1.7723 nat_grad_norm = 0.4118 cg_residual = 0.5714 step_size = 0.2619 reward = -0.0000 fps = 106 mse_loss = 2.6710 
2022-07-08 15:13:43.694790 - gail/main.py:201 - [Discriminator] iter = 360000 loss = -3.6707 grad_norm = 3.2390 grad_penalty = 0.3056 regularization = 0.0000 true_logits = 0.2649 fake_logits = -3.7114 true_prob = 0.5238 fake_prob = 0.1147 
2022-07-08 15:13:47.922294 - gail/main.py:142 - [Evaluate] iter = 360000 episode={ returns = 757.3528 lengths = 252 } discounted_episode={ returns = 746.8654 lengths = 288 } 
2022-07-08 15:13:49.124777 - gail/main.py:174 - [TRPO] iter = 361000 dist_mean = 0.1744 dist_std = 0.3726 vf_loss = 0.1639 grad_norm = 1.6593 nat_grad_norm = 0.3181 cg_residual = 0.5197 step_size = 0.3052 reward = 0.0000 fps = 184 mse_loss = 2.7080 
2022-07-08 15:13:50.338617 - gail/main.py:174 - [TRPO] iter = 362000 dist_mean = 0.2573 dist_std = 0.3704 vf_loss = 0.0678 grad_norm = 1.8258 nat_grad_norm = 0.4453 cg_residual = 0.5270 step_size = 0.2619 reward = 0.0000 fps = 150 mse_loss = 2.7108 
2022-07-08 15:13:51.565779 - gail/main.py:174 - [TRPO] iter = 363000 dist_mean = 0.2070 dist_std = 0.3693 vf_loss = 0.2564 grad_norm = 1.6294 nat_grad_norm = 0.2401 cg_residual = 0.4502 step_size = 0.3729 reward = -0.0000 fps = 127 mse_loss = 2.6342 
2022-07-08 15:13:52.784386 - gail/main.py:174 - [TRPO] iter = 364000 dist_mean = 0.2052 dist_std = 0.3705 vf_loss = 0.1732 grad_norm = 1.3402 nat_grad_norm = 0.4023 cg_residual = 0.6804 step_size = 0.2781 reward = -0.0000 fps = 110 mse_loss = 2.5354 
2022-07-08 15:13:54.022904 - gail/main.py:174 - [TRPO] iter = 365000 dist_mean = 0.2018 dist_std = 0.3694 vf_loss = 0.1792 grad_norm = 1.6012 nat_grad_norm = 0.2875 cg_residual = 0.4359 step_size = 0.3249 reward = 0.0000 fps = 96 mse_loss = 2.4834 
2022-07-08 15:13:54.086470 - gail/main.py:201 - [Discriminator] iter = 365000 loss = -3.5787 grad_norm = 3.5607 grad_penalty = 0.3091 regularization = 0.0000 true_logits = 0.3432 fake_logits = -3.5445 true_prob = 0.5256 fake_prob = 0.1263 
2022-07-08 15:13:58.605554 - gail/main.py:142 - [Evaluate] iter = 365000 episode={ returns = 1019.3067 lengths = 296 } discounted_episode={ returns = 782.1868 lengths = 265 } 
2022-07-08 15:13:59.864455 - gail/main.py:174 - [TRPO] iter = 366000 dist_mean = 0.1969 dist_std = 0.3667 vf_loss = 0.1848 grad_norm = 2.0122 nat_grad_norm = 0.2960 cg_residual = 0.3042 step_size = 0.3374 reward = 0.0000 fps = 173 mse_loss = 2.5735 
2022-07-08 15:14:01.109614 - gail/main.py:174 - [TRPO] iter = 367000 dist_mean = 0.2479 dist_std = 0.3672 vf_loss = 0.1255 grad_norm = 1.4110 nat_grad_norm = 0.3005 cg_residual = 0.5162 step_size = 0.3277 reward = -0.0000 fps = 142 mse_loss = 2.6546 
2022-07-08 15:14:02.362328 - gail/main.py:174 - [TRPO] iter = 368000 dist_mean = 0.2111 dist_std = 0.3666 vf_loss = 0.2184 grad_norm = 1.6426 nat_grad_norm = 0.4373 cg_residual = 0.9200 step_size = 0.2412 reward = 0.0000 fps = 120 mse_loss = 2.5081 
2022-07-08 15:14:03.603530 - gail/main.py:174 - [TRPO] iter = 369000 dist_mean = 0.2317 dist_std = 0.3665 vf_loss = 0.1870 grad_norm = 1.3826 nat_grad_norm = 0.3826 cg_residual = 0.5224 step_size = 0.3077 reward = -0.0000 fps = 105 mse_loss = 2.6143 
2022-07-08 15:14:04.892272 - gail/main.py:174 - [TRPO] iter = 370000 dist_mean = 0.2432 dist_std = 0.3675 vf_loss = 0.1074 grad_norm = 1.5583 nat_grad_norm = 0.4344 cg_residual = 0.7406 step_size = 0.2727 reward = -0.0000 fps = 92 mse_loss = 2.4470 
2022-07-08 15:14:04.949336 - gail/main.py:201 - [Discriminator] iter = 370000 loss = -4.2759 grad_norm = 3.7691 grad_penalty = 0.3599 regularization = 0.0000 true_logits = 0.3125 fake_logits = -4.3233 true_prob = 0.5188 fake_prob = 0.0661 
2022-07-08 15:14:09.659960 - gail/main.py:142 - [Evaluate] iter = 370000 episode={ returns = 1102.4010 lengths = 324 } discounted_episode={ returns = 738.1710 lengths = 272 } 
2022-07-08 15:14:10.850462 - gail/main.py:174 - [TRPO] iter = 371000 dist_mean = 0.2201 dist_std = 0.3665 vf_loss = 0.1234 grad_norm = 1.4084 nat_grad_norm = 0.2949 cg_residual = 0.5147 step_size = 0.3177 reward = -0.0000 fps = 169 mse_loss = 2.4853 
2022-07-08 15:14:12.065205 - gail/main.py:174 - [TRPO] iter = 372000 dist_mean = 0.2147 dist_std = 0.3674 vf_loss = 0.1049 grad_norm = 1.9982 nat_grad_norm = 0.3924 cg_residual = 0.8681 step_size = 0.2690 reward = 0.0000 fps = 140 mse_loss = 2.4118 
2022-07-08 15:14:13.285741 - gail/main.py:174 - [TRPO] iter = 373000 dist_mean = 0.2085 dist_std = 0.3663 vf_loss = 0.1228 grad_norm = 1.6255 nat_grad_norm = 0.2776 cg_residual = 0.4970 step_size = 0.3464 reward = -0.0000 fps = 119 mse_loss = 2.5958 
2022-07-08 15:14:14.485547 - gail/main.py:174 - [TRPO] iter = 374000 dist_mean = 0.2402 dist_std = 0.3666 vf_loss = 0.1360 grad_norm = 1.9900 nat_grad_norm = 0.2964 cg_residual = 0.4302 step_size = 0.3411 reward = 0.0000 fps = 104 mse_loss = 2.5881 
2022-07-08 15:14:15.700240 - gail/main.py:174 - [TRPO] iter = 375000 dist_mean = 0.2758 dist_std = 0.3652 vf_loss = 0.1310 grad_norm = 1.4912 nat_grad_norm = 0.2865 cg_residual = 0.7527 step_size = 0.3317 reward = -0.0000 fps = 93 mse_loss = 2.6433 
2022-07-08 15:14:15.754038 - gail/main.py:201 - [Discriminator] iter = 375000 loss = -3.3216 grad_norm = 4.9102 grad_penalty = 0.3270 regularization = 0.0000 true_logits = 0.2712 fake_logits = -3.3774 true_prob = 0.5153 fake_prob = 0.1272 
2022-07-08 15:14:19.987888 - gail/main.py:142 - [Evaluate] iter = 375000 episode={ returns = 985.9560 lengths = 286 } discounted_episode={ returns = 731.8849 lengths = 262 } 
2022-07-08 15:14:21.164219 - gail/main.py:174 - [TRPO] iter = 376000 dist_mean = 0.2664 dist_std = 0.3664 vf_loss = 0.1073 grad_norm = 1.3990 nat_grad_norm = 0.3059 cg_residual = 0.6121 step_size = 0.3466 reward = -0.0000 fps = 184 mse_loss = 2.6107 
2022-07-08 15:14:22.391019 - gail/main.py:174 - [TRPO] iter = 377000 dist_mean = 0.2276 dist_std = 0.3675 vf_loss = 0.0760 grad_norm = 1.4485 nat_grad_norm = 0.3289 cg_residual = 0.4295 step_size = 0.3142 reward = 0.0000 fps = 150 mse_loss = 2.6841 
2022-07-08 15:14:23.579554 - gail/main.py:174 - [TRPO] iter = 378000 dist_mean = 0.2313 dist_std = 0.3656 vf_loss = 0.1535 grad_norm = 1.5837 nat_grad_norm = 0.2919 cg_residual = 0.4390 step_size = 0.3166 reward = 0.0000 fps = 127 mse_loss = 2.6763 
2022-07-08 15:14:24.767853 - gail/main.py:174 - [TRPO] iter = 379000 dist_mean = 0.2384 dist_std = 0.3671 vf_loss = 0.1163 grad_norm = 2.1721 nat_grad_norm = 0.3477 cg_residual = 0.4326 step_size = 0.2744 reward = 0.0000 fps = 110 mse_loss = 2.7254 
2022-07-08 15:14:25.952068 - gail/main.py:174 - [TRPO] iter = 380000 dist_mean = 0.2217 dist_std = 0.3663 vf_loss = 0.0707 grad_norm = 1.7444 nat_grad_norm = 0.3299 cg_residual = 0.4699 step_size = 0.2993 reward = -0.0000 fps = 98 mse_loss = 2.8689 
2022-07-08 15:14:26.000423 - gail/main.py:201 - [Discriminator] iter = 380000 loss = -3.5836 grad_norm = 3.5660 grad_penalty = 0.2873 regularization = 0.0000 true_logits = 0.3325 fake_logits = -3.5383 true_prob = 0.5117 fake_prob = 0.1401 
2022-07-08 15:14:29.454958 - gail/main.py:142 - [Evaluate] iter = 380000 episode={ returns = 712.5990 lengths = 207 } discounted_episode={ returns = 675.4288 lengths = 242 } 
2022-07-08 15:14:30.647435 - gail/main.py:174 - [TRPO] iter = 381000 dist_mean = 0.2164 dist_std = 0.3657 vf_loss = 0.1792 grad_norm = 1.5151 nat_grad_norm = 0.3443 cg_residual = 0.7559 step_size = 0.3124 reward = -0.0000 fps = 215 mse_loss = 2.7869 
2022-07-08 15:14:31.826956 - gail/main.py:174 - [TRPO] iter = 382000 dist_mean = 0.2309 dist_std = 0.3644 vf_loss = 0.1257 grad_norm = 1.8396 nat_grad_norm = 0.3808 cg_residual = 0.5722 step_size = 0.2821 reward = 0.0000 fps = 171 mse_loss = 2.7714 
2022-07-08 15:14:33.015185 - gail/main.py:174 - [TRPO] iter = 383000 dist_mean = 0.2585 dist_std = 0.3644 vf_loss = 0.0827 grad_norm = 1.5671 nat_grad_norm = 0.3114 cg_residual = 0.5298 step_size = 0.3096 reward = 0.0000 fps = 142 mse_loss = 2.7531 
2022-07-08 15:14:34.210206 - gail/main.py:174 - [TRPO] iter = 384000 dist_mean = 0.2036 dist_std = 0.3646 vf_loss = 0.0874 grad_norm = 2.3811 nat_grad_norm = 0.2609 cg_residual = 0.5284 step_size = 0.3279 reward = -0.0000 fps = 121 mse_loss = 2.7479 
2022-07-08 15:14:35.385618 - gail/main.py:174 - [TRPO] iter = 385000 dist_mean = 0.1983 dist_std = 0.3642 vf_loss = 0.1075 grad_norm = 1.6687 nat_grad_norm = 0.3016 cg_residual = 0.5288 step_size = 0.2990 reward = 0.0000 fps = 106 mse_loss = 2.7693 
2022-07-08 15:14:35.437763 - gail/main.py:201 - [Discriminator] iter = 385000 loss = -3.7131 grad_norm = 3.4468 grad_penalty = 0.2943 regularization = 0.0000 true_logits = 0.1174 fake_logits = -3.8900 true_prob = 0.4938 fake_prob = 0.0963 
2022-07-08 15:14:38.536377 - gail/main.py:142 - [Evaluate] iter = 385000 episode={ returns = 651.0099 lengths = 200 } discounted_episode={ returns = 595.1716 lengths = 203 } 
2022-07-08 15:14:39.720225 - gail/main.py:174 - [TRPO] iter = 386000 dist_mean = 0.1911 dist_std = 0.3627 vf_loss = 0.1824 grad_norm = 1.6669 nat_grad_norm = 0.2861 cg_residual = 0.5063 step_size = 0.3211 reward = -0.0000 fps = 233 mse_loss = 2.8125 
2022-07-08 15:14:40.912895 - gail/main.py:174 - [TRPO] iter = 387000 dist_mean = 0.1900 dist_std = 0.3603 vf_loss = 0.0788 grad_norm = 1.6720 nat_grad_norm = 0.3421 cg_residual = 0.5618 step_size = 0.3193 reward = -0.0000 fps = 182 mse_loss = 2.8436 
2022-07-08 15:14:42.085459 - gail/main.py:174 - [TRPO] iter = 388000 dist_mean = 0.2084 dist_std = 0.3586 vf_loss = 0.1260 grad_norm = 2.1899 nat_grad_norm = 0.2576 cg_residual = 0.5215 step_size = 0.3277 reward = 0.0000 fps = 150 mse_loss = 2.8451 
2022-07-08 15:14:43.275434 - gail/main.py:174 - [TRPO] iter = 389000 dist_mean = 0.2269 dist_std = 0.3584 vf_loss = 0.0923 grad_norm = 1.8432 nat_grad_norm = 0.2475 cg_residual = 0.3848 step_size = 0.3529 reward = -0.0000 fps = 127 mse_loss = 2.7439 
2022-07-08 15:14:44.476315 - gail/main.py:174 - [TRPO] iter = 390000 dist_mean = 0.2152 dist_std = 0.3571 vf_loss = 0.0939 grad_norm = 1.6511 nat_grad_norm = 0.2763 cg_residual = 0.6357 step_size = 0.3291 reward = 0.0000 fps = 110 mse_loss = 2.7684 
2022-07-08 15:14:44.525342 - gail/main.py:201 - [Discriminator] iter = 390000 loss = -4.0301 grad_norm = 3.6772 grad_penalty = 0.3478 regularization = 0.0000 true_logits = 0.1491 fake_logits = -4.2289 true_prob = 0.5033 fake_prob = 0.0857 
2022-07-08 15:14:48.004437 - gail/main.py:142 - [Evaluate] iter = 390000 episode={ returns = 757.2374 lengths = 222 } discounted_episode={ returns = 682.7763 lengths = 227 } 
2022-07-08 15:14:49.215616 - gail/main.py:174 - [TRPO] iter = 391000 dist_mean = 0.2077 dist_std = 0.3556 vf_loss = 0.1399 grad_norm = 1.7032 nat_grad_norm = 0.2780 cg_residual = 0.4569 step_size = 0.3441 reward = -0.0000 fps = 213 mse_loss = 2.6865 
2022-07-08 15:14:50.403452 - gail/main.py:174 - [TRPO] iter = 392000 dist_mean = 0.2408 dist_std = 0.3547 vf_loss = 0.1094 grad_norm = 1.5536 nat_grad_norm = 0.3819 cg_residual = 0.5796 step_size = 0.2799 reward = -0.0000 fps = 170 mse_loss = 2.8208 
2022-07-08 15:14:51.611685 - gail/main.py:174 - [TRPO] iter = 393000 dist_mean = 0.2527 dist_std = 0.3523 vf_loss = 0.0919 grad_norm = 1.6073 nat_grad_norm = 0.3075 cg_residual = 0.4127 step_size = 0.3002 reward = -0.0000 fps = 141 mse_loss = 2.6297 
2022-07-08 15:14:53.021758 - gail/main.py:174 - [TRPO] iter = 394000 dist_mean = 0.2635 dist_std = 0.3513 vf_loss = 0.2127 grad_norm = 1.5946 nat_grad_norm = 0.3308 cg_residual = 0.5991 step_size = 0.3078 reward = 0.0000 fps = 117 mse_loss = 2.7366 
2022-07-08 15:14:54.647913 - gail/main.py:174 - [TRPO] iter = 395000 dist_mean = 0.2818 dist_std = 0.3515 vf_loss = 0.1275 grad_norm = 1.4760 nat_grad_norm = 0.3046 cg_residual = 0.4618 step_size = 0.3356 reward = -0.0000 fps = 98 mse_loss = 2.6723 
2022-07-08 15:14:54.729980 - gail/main.py:201 - [Discriminator] iter = 395000 loss = -3.7353 grad_norm = 3.6969 grad_penalty = 0.3526 regularization = 0.0000 true_logits = 0.0166 fake_logits = -4.0713 true_prob = 0.4839 fake_prob = 0.0889 
2022-07-08 15:14:58.246936 - gail/main.py:142 - [Evaluate] iter = 395000 episode={ returns = 506.9153 lengths = 169 } discounted_episode={ returns = 456.0711 lengths = 168 } 
2022-07-08 15:14:59.882636 - gail/main.py:174 - [TRPO] iter = 396000 dist_mean = 0.2310 dist_std = 0.3523 vf_loss = 0.1435 grad_norm = 1.4215 nat_grad_norm = 0.3007 cg_residual = 0.8117 step_size = 0.3312 reward = -0.0000 fps = 194 mse_loss = 2.6577 
2022-07-08 15:15:01.504298 - gail/main.py:174 - [TRPO] iter = 397000 dist_mean = 0.2680 dist_std = 0.3528 vf_loss = 0.1194 grad_norm = 2.2625 nat_grad_norm = 0.3284 cg_residual = 0.6743 step_size = 0.2852 reward = -0.0000 fps = 147 mse_loss = 2.6904 
2022-07-08 15:15:03.154026 - gail/main.py:174 - [TRPO] iter = 398000 dist_mean = 0.2749 dist_std = 0.3526 vf_loss = 0.1018 grad_norm = 1.4599 nat_grad_norm = 0.3358 cg_residual = 0.4979 step_size = 0.3281 reward = -0.0000 fps = 118 mse_loss = 2.6266 
2022-07-08 15:15:04.639521 - gail/main.py:174 - [TRPO] iter = 399000 dist_mean = 0.1956 dist_std = 0.3511 vf_loss = 0.1145 grad_norm = 1.6240 nat_grad_norm = 0.3191 cg_residual = 0.6488 step_size = 0.3049 reward = -0.0000 fps = 100 mse_loss = 2.7774 
2022-07-08 15:15:05.833815 - gail/main.py:174 - [TRPO] iter = 400000 dist_mean = 0.2375 dist_std = 0.3514 vf_loss = 0.1031 grad_norm = 1.3469 nat_grad_norm = 0.2775 cg_residual = 0.4717 step_size = 0.3317 reward = 0.0000 fps = 90 mse_loss = 2.7741 
2022-07-08 15:15:05.884819 - gail/main.py:201 - [Discriminator] iter = 400000 loss = -3.7350 grad_norm = 3.5265 grad_penalty = 0.3495 regularization = 0.0000 true_logits = 0.1405 fake_logits = -3.9440 true_prob = 0.5019 fake_prob = 0.0939 
2022-07-08 15:15:09.398135 - gail/main.py:142 - [Evaluate] iter = 400000 episode={ returns = 626.6292 lengths = 211 } discounted_episode={ returns = 623.3280 lengths = 235 } 
2022-07-08 15:15:10.582147 - gail/main.py:174 - [TRPO] iter = 401000 dist_mean = 0.2243 dist_std = 0.3497 vf_loss = 0.1951 grad_norm = 1.5665 nat_grad_norm = 0.2799 cg_residual = 0.6753 step_size = 0.3424 reward = -0.0000 fps = 213 mse_loss = 2.6923 
2022-07-08 15:15:11.756694 - gail/main.py:174 - [TRPO] iter = 402000 dist_mean = 0.2035 dist_std = 0.3496 vf_loss = 0.1202 grad_norm = 1.3233 nat_grad_norm = 0.2845 cg_residual = 0.6226 step_size = 0.3381 reward = -0.0000 fps = 170 mse_loss = 2.7757 
2022-07-08 15:15:12.944426 - gail/main.py:174 - [TRPO] iter = 403000 dist_mean = 0.2313 dist_std = 0.3487 vf_loss = 0.0998 grad_norm = 1.6032 nat_grad_norm = 0.2724 cg_residual = 0.6862 step_size = 0.3209 reward = -0.0000 fps = 141 mse_loss = 2.8643 
2022-07-08 15:15:14.149748 - gail/main.py:174 - [TRPO] iter = 404000 dist_mean = 0.2340 dist_std = 0.3483 vf_loss = 0.0960 grad_norm = 1.6539 nat_grad_norm = 0.3614 cg_residual = 0.6706 step_size = 0.2914 reward = -0.0000 fps = 121 mse_loss = 2.7631 
2022-07-08 15:15:15.325372 - gail/main.py:174 - [TRPO] iter = 405000 dist_mean = 0.2068 dist_std = 0.3469 vf_loss = 0.1504 grad_norm = 2.4056 nat_grad_norm = 0.2692 cg_residual = 0.5803 step_size = 0.2941 reward = 0.0000 fps = 105 mse_loss = 2.8725 
2022-07-08 15:15:15.375087 - gail/main.py:201 - [Discriminator] iter = 405000 loss = -3.7177 grad_norm = 2.8807 grad_penalty = 0.2889 regularization = 0.0000 true_logits = 0.1484 fake_logits = -3.8582 true_prob = 0.5020 fake_prob = 0.0991 
2022-07-08 15:15:20.200034 - gail/main.py:142 - [Evaluate] iter = 405000 episode={ returns = 809.4211 lengths = 267 } discounted_episode={ returns = 803.6167 lengths = 358 } 
2022-07-08 15:15:21.391094 - gail/main.py:174 - [TRPO] iter = 406000 dist_mean = 0.2430 dist_std = 0.3454 vf_loss = 0.1007 grad_norm = 1.4759 nat_grad_norm = 0.3379 cg_residual = 0.5440 step_size = 0.3013 reward = -0.0000 fps = 166 mse_loss = 2.9772 
2022-07-08 15:15:22.577858 - gail/main.py:174 - [TRPO] iter = 407000 dist_mean = 0.2296 dist_std = 0.3450 vf_loss = 0.1503 grad_norm = 1.8048 nat_grad_norm = 0.3026 cg_residual = 0.8121 step_size = 0.3056 reward = 0.0000 fps = 138 mse_loss = 3.0132 
2022-07-08 15:15:23.768428 - gail/main.py:174 - [TRPO] iter = 408000 dist_mean = 0.2325 dist_std = 0.3446 vf_loss = 0.1648 grad_norm = 1.7625 nat_grad_norm = 0.3291 cg_residual = 0.4749 step_size = 0.3030 reward = 0.0000 fps = 119 mse_loss = 2.9381 
2022-07-08 15:15:24.965071 - gail/main.py:174 - [TRPO] iter = 409000 dist_mean = 0.2447 dist_std = 0.3432 vf_loss = 0.1145 grad_norm = 1.4732 nat_grad_norm = 0.2947 cg_residual = 0.5446 step_size = 0.3249 reward = 0.0000 fps = 104 mse_loss = 2.9844 
2022-07-08 15:15:26.145110 - gail/main.py:174 - [TRPO] iter = 410000 dist_mean = 0.2344 dist_std = 0.3434 vf_loss = 0.1245 grad_norm = 1.4903 nat_grad_norm = 0.2880 cg_residual = 0.4390 step_size = 0.3324 reward = 0.0000 fps = 92 mse_loss = 2.9159 
2022-07-08 15:15:26.201100 - gail/main.py:201 - [Discriminator] iter = 410000 loss = -3.9209 grad_norm = 2.9880 grad_penalty = 0.3332 regularization = 0.0000 true_logits = 0.0032 fake_logits = -4.2509 true_prob = 0.4871 fake_prob = 0.0841 
2022-07-08 15:15:32.160097 - gail/main.py:142 - [Evaluate] iter = 410000 episode={ returns = 924.1855 lengths = 277 } discounted_episode={ returns = 699.7903 lengths = 245 } 
2022-07-08 15:15:34.138509 - gail/main.py:174 - [TRPO] iter = 411000 dist_mean = 0.2083 dist_std = 0.3433 vf_loss = 0.0961 grad_norm = 2.1753 nat_grad_norm = 0.2885 cg_residual = 0.6976 step_size = 0.3110 reward = 0.0000 fps = 126 mse_loss = 2.8898 
2022-07-08 15:15:36.045430 - gail/main.py:174 - [TRPO] iter = 412000 dist_mean = 0.2003 dist_std = 0.3435 vf_loss = 0.0927 grad_norm = 1.5946 nat_grad_norm = 0.3414 cg_residual = 1.2183 step_size = 0.2868 reward = 0.0000 fps = 101 mse_loss = 3.0044 
2022-07-08 15:15:37.719500 - gail/main.py:174 - [TRPO] iter = 413000 dist_mean = 0.2340 dist_std = 0.3424 vf_loss = 0.0919 grad_norm = 1.9322 nat_grad_norm = 0.3941 cg_residual = 0.6486 step_size = 0.2737 reward = -0.0000 fps = 86 mse_loss = 3.0323 
2022-07-08 15:15:39.461381 - gail/main.py:174 - [TRPO] iter = 414000 dist_mean = 0.1740 dist_std = 0.3413 vf_loss = 0.0986 grad_norm = 1.2778 nat_grad_norm = 0.2272 cg_residual = 0.3739 step_size = 0.3891 reward = -0.0000 fps = 75 mse_loss = 2.9233 
2022-07-08 15:15:41.092043 - gail/main.py:174 - [TRPO] iter = 415000 dist_mean = 0.1816 dist_std = 0.3438 vf_loss = 0.1924 grad_norm = 1.9217 nat_grad_norm = 0.2738 cg_residual = 0.6848 step_size = 0.3041 reward = 0.0000 fps = 67 mse_loss = 2.9829 
2022-07-08 15:15:41.175818 - gail/main.py:201 - [Discriminator] iter = 415000 loss = -3.6472 grad_norm = 3.2856 grad_penalty = 0.3271 regularization = 0.0000 true_logits = -0.3169 fake_logits = -4.2912 true_prob = 0.4469 fake_prob = 0.0893 
2022-07-08 15:15:46.961091 - gail/main.py:142 - [Evaluate] iter = 415000 episode={ returns = 788.7844 lengths = 233 } discounted_episode={ returns = 725.0625 lengths = 242 } 
2022-07-08 15:15:48.719658 - gail/main.py:174 - [TRPO] iter = 416000 dist_mean = 0.1853 dist_std = 0.3441 vf_loss = 0.1008 grad_norm = 2.0818 nat_grad_norm = 0.2791 cg_residual = 0.6044 step_size = 0.3341 reward = 0.0000 fps = 132 mse_loss = 2.9656 
2022-07-08 15:15:50.440395 - gail/main.py:174 - [TRPO] iter = 417000 dist_mean = 0.1655 dist_std = 0.3443 vf_loss = 0.1570 grad_norm = 2.3245 nat_grad_norm = 0.3306 cg_residual = 0.6373 step_size = 0.2705 reward = -0.0000 fps = 108 mse_loss = 3.1104 
2022-07-08 15:15:52.360088 - gail/main.py:174 - [TRPO] iter = 418000 dist_mean = 0.1862 dist_std = 0.3424 vf_loss = 0.0885 grad_norm = 1.5994 nat_grad_norm = 0.2945 cg_residual = 0.6458 step_size = 0.3255 reward = -0.0000 fps = 89 mse_loss = 3.1047 
2022-07-08 15:15:54.283578 - gail/main.py:174 - [TRPO] iter = 419000 dist_mean = 0.1769 dist_std = 0.3422 vf_loss = 0.1117 grad_norm = 1.8363 nat_grad_norm = 0.3420 cg_residual = 0.6184 step_size = 0.2892 reward = -0.0000 fps = 76 mse_loss = 3.0284 
2022-07-08 15:15:56.117345 - gail/main.py:174 - [TRPO] iter = 420000 dist_mean = 0.1668 dist_std = 0.3402 vf_loss = 0.1318 grad_norm = 1.6318 nat_grad_norm = 0.2666 cg_residual = 0.5903 step_size = 0.3534 reward = 0.0000 fps = 66 mse_loss = 3.2119 
2022-07-08 15:15:56.193576 - gail/main.py:201 - [Discriminator] iter = 420000 loss = -3.7430 grad_norm = 3.2641 grad_penalty = 0.2909 regularization = 0.0000 true_logits = -0.1955 fake_logits = -4.2294 true_prob = 0.4591 fake_prob = 0.0824 
2022-07-08 15:16:02.177993 - gail/main.py:142 - [Evaluate] iter = 420000 episode={ returns = 936.1223 lengths = 254 } discounted_episode={ returns = 793.4194 lengths = 253 } 
2022-07-08 15:16:04.015348 - gail/main.py:174 - [TRPO] iter = 421000 dist_mean = 0.1912 dist_std = 0.3413 vf_loss = 0.1375 grad_norm = 1.6418 nat_grad_norm = 0.3155 cg_residual = 0.4827 step_size = 0.3146 reward = -0.0000 fps = 127 mse_loss = 3.0507 
2022-07-08 15:16:05.914326 - gail/main.py:174 - [TRPO] iter = 422000 dist_mean = 0.2276 dist_std = 0.3389 vf_loss = 0.1021 grad_norm = 1.5019 nat_grad_norm = 0.2509 cg_residual = 0.6137 step_size = 0.3756 reward = 0.0000 fps = 102 mse_loss = 3.0329 
2022-07-08 15:16:07.751859 - gail/main.py:174 - [TRPO] iter = 423000 dist_mean = 0.2118 dist_std = 0.3372 vf_loss = 0.1441 grad_norm = 2.0914 nat_grad_norm = 0.3059 cg_residual = 0.5720 step_size = 0.2954 reward = -0.0000 fps = 86 mse_loss = 3.0462 
2022-07-08 15:16:09.649232 - gail/main.py:174 - [TRPO] iter = 424000 dist_mean = 0.2172 dist_std = 0.3364 vf_loss = 0.1126 grad_norm = 1.6522 nat_grad_norm = 0.3130 cg_residual = 0.6805 step_size = 0.3101 reward = 0.0000 fps = 74 mse_loss = 2.9521 
2022-07-08 15:16:11.632462 - gail/main.py:174 - [TRPO] iter = 425000 dist_mean = 0.2185 dist_std = 0.3344 vf_loss = 0.1311 grad_norm = 1.7867 nat_grad_norm = 0.2307 cg_residual = 0.4092 step_size = 0.3642 reward = 0.0000 fps = 64 mse_loss = 2.9600 
2022-07-08 15:16:11.723547 - gail/main.py:201 - [Discriminator] iter = 425000 loss = -3.8714 grad_norm = 3.4424 grad_penalty = 0.3406 regularization = 0.0000 true_logits = -0.2593 fake_logits = -4.4714 true_prob = 0.4530 fake_prob = 0.0693 
2022-07-08 15:16:18.009015 - gail/main.py:142 - [Evaluate] iter = 425000 episode={ returns = 1059.4851 lengths = 300 } discounted_episode={ returns = 773.4132 lengths = 261 } 
2022-07-08 15:16:19.415054 - gail/main.py:174 - [TRPO] iter = 426000 dist_mean = 0.2628 dist_std = 0.3338 vf_loss = 0.1257 grad_norm = 2.1486 nat_grad_norm = 0.2900 cg_residual = 0.6638 step_size = 0.3182 reward = 0.0000 fps = 130 mse_loss = 2.9587 
2022-07-08 15:16:20.619761 - gail/main.py:174 - [TRPO] iter = 427000 dist_mean = 0.2158 dist_std = 0.3323 vf_loss = 0.1620 grad_norm = 1.8465 nat_grad_norm = 0.3637 cg_residual = 1.0267 step_size = 0.2521 reward = 0.0000 fps = 112 mse_loss = 2.9237 
2022-07-08 15:16:21.812017 - gail/main.py:174 - [TRPO] iter = 428000 dist_mean = 0.2374 dist_std = 0.3319 vf_loss = 0.1106 grad_norm = 1.8451 nat_grad_norm = 0.2768 cg_residual = 0.8094 step_size = 0.3374 reward = 0.0000 fps = 99 mse_loss = 3.0619 
2022-07-08 15:16:22.989561 - gail/main.py:174 - [TRPO] iter = 429000 dist_mean = 0.2428 dist_std = 0.3342 vf_loss = 0.1021 grad_norm = 1.8781 nat_grad_norm = 0.3107 cg_residual = 0.7925 step_size = 0.2840 reward = -0.0000 fps = 88 mse_loss = 3.0436 
2022-07-08 15:16:24.188461 - gail/main.py:174 - [TRPO] iter = 430000 dist_mean = 0.2104 dist_std = 0.3349 vf_loss = 0.1294 grad_norm = 1.8668 nat_grad_norm = 0.2089 cg_residual = 0.6256 step_size = 0.3600 reward = -0.0000 fps = 80 mse_loss = 2.9942 
2022-07-08 15:16:24.244140 - gail/main.py:201 - [Discriminator] iter = 430000 loss = -3.3967 grad_norm = 3.7835 grad_penalty = 0.2628 regularization = 0.0000 true_logits = -0.1223 fake_logits = -3.7818 true_prob = 0.4667 fake_prob = 0.1076 
2022-07-08 15:16:31.622476 - gail/main.py:142 - [Evaluate] iter = 430000 episode={ returns = 1323.6430 lengths = 346 } discounted_episode={ returns = 1106.8441 lengths = 361 } 
2022-07-08 15:16:32.803693 - gail/main.py:174 - [TRPO] iter = 431000 dist_mean = 0.2311 dist_std = 0.3350 vf_loss = 0.1320 grad_norm = 1.6076 nat_grad_norm = 0.2263 cg_residual = 0.4343 step_size = 0.3573 reward = -0.0000 fps = 116 mse_loss = 2.9896 
2022-07-08 15:16:33.986143 - gail/main.py:174 - [TRPO] iter = 432000 dist_mean = 0.2105 dist_std = 0.3355 vf_loss = 0.1215 grad_norm = 2.1727 nat_grad_norm = 0.2355 cg_residual = 0.7051 step_size = 0.3363 reward = -0.0000 fps = 102 mse_loss = 3.0216 
2022-07-08 15:16:35.197941 - gail/main.py:174 - [TRPO] iter = 433000 dist_mean = 0.2201 dist_std = 0.3357 vf_loss = 0.0888 grad_norm = 1.8439 nat_grad_norm = 0.3508 cg_residual = 0.5784 step_size = 0.2801 reward = -0.0000 fps = 91 mse_loss = 3.0388 
2022-07-08 15:16:36.383763 - gail/main.py:174 - [TRPO] iter = 434000 dist_mean = 0.2211 dist_std = 0.3345 vf_loss = 0.1416 grad_norm = 1.8456 nat_grad_norm = 0.2482 cg_residual = 0.6232 step_size = 0.3305 reward = -0.0000 fps = 82 mse_loss = 3.1127 
2022-07-08 15:16:37.567534 - gail/main.py:174 - [TRPO] iter = 435000 dist_mean = 0.1779 dist_std = 0.3331 vf_loss = 0.1098 grad_norm = 2.0624 nat_grad_norm = 0.2698 cg_residual = 0.8114 step_size = 0.3189 reward = -0.0000 fps = 75 mse_loss = 3.1123 
2022-07-08 15:16:37.618038 - gail/main.py:201 - [Discriminator] iter = 435000 loss = -3.4723 grad_norm = 3.3067 grad_penalty = 0.2881 regularization = 0.0000 true_logits = -0.1771 fake_logits = -3.9375 true_prob = 0.4608 fake_prob = 0.1130 
2022-07-08 15:16:43.153922 - gail/main.py:142 - [Evaluate] iter = 435000 episode={ returns = 1409.7042 lengths = 386 } discounted_episode={ returns = 983.8163 lengths = 332 } 
2022-07-08 15:16:44.363103 - gail/main.py:174 - [TRPO] iter = 436000 dist_mean = 0.2694 dist_std = 0.3331 vf_loss = 0.0687 grad_norm = 1.7190 nat_grad_norm = 0.3017 cg_residual = 0.7740 step_size = 0.3088 reward = -0.0000 fps = 148 mse_loss = 3.2071 
2022-07-08 15:16:45.558280 - gail/main.py:174 - [TRPO] iter = 437000 dist_mean = 0.2466 dist_std = 0.3331 vf_loss = 0.0817 grad_norm = 2.0056 nat_grad_norm = 0.2583 cg_residual = 0.4091 step_size = 0.3214 reward = -0.0000 fps = 125 mse_loss = 3.1020 
2022-07-08 15:16:46.799431 - gail/main.py:174 - [TRPO] iter = 438000 dist_mean = 0.1870 dist_std = 0.3328 vf_loss = 0.1107 grad_norm = 1.7756 nat_grad_norm = 0.2829 cg_residual = 0.9118 step_size = 0.2884 reward = -0.0000 fps = 108 mse_loss = 3.0462 
2022-07-08 15:16:48.032902 - gail/main.py:174 - [TRPO] iter = 439000 dist_mean = 0.2668 dist_std = 0.3325 vf_loss = 0.1025 grad_norm = 1.8922 nat_grad_norm = 0.2601 cg_residual = 0.5659 step_size = 0.3079 reward = -0.0000 fps = 96 mse_loss = 3.1216 
2022-07-08 15:16:49.248467 - gail/main.py:174 - [TRPO] iter = 440000 dist_mean = 0.1789 dist_std = 0.3315 vf_loss = 0.1197 grad_norm = 1.6154 nat_grad_norm = 0.3278 cg_residual = 1.0992 step_size = 0.2841 reward = 0.0000 fps = 86 mse_loss = 3.1498 
2022-07-08 15:16:49.299681 - gail/main.py:201 - [Discriminator] iter = 440000 loss = -3.3739 grad_norm = 3.4973 grad_penalty = 0.2528 regularization = 0.0000 true_logits = -0.3732 fake_logits = -3.9999 true_prob = 0.4332 fake_prob = 0.1046 
2022-07-08 15:16:53.938881 - gail/main.py:142 - [Evaluate] iter = 440000 episode={ returns = 1038.4465 lengths = 285 } discounted_episode={ returns = 760.6628 lengths = 253 } 
2022-07-08 15:16:55.147471 - gail/main.py:174 - [TRPO] iter = 441000 dist_mean = 0.1451 dist_std = 0.3304 vf_loss = 0.0940 grad_norm = 1.7086 nat_grad_norm = 0.2509 cg_residual = 0.7425 step_size = 0.3054 reward = 0.0000 fps = 171 mse_loss = 3.1910 
2022-07-08 15:16:56.390177 - gail/main.py:174 - [TRPO] iter = 442000 dist_mean = 0.1814 dist_std = 0.3300 vf_loss = 0.0908 grad_norm = 1.7818 nat_grad_norm = 0.3196 cg_residual = 1.0355 step_size = 0.2826 reward = -0.0000 fps = 141 mse_loss = 3.2501 
2022-07-08 15:16:57.666447 - gail/main.py:174 - [TRPO] iter = 443000 dist_mean = 0.1803 dist_std = 0.3291 vf_loss = 0.0627 grad_norm = 1.8734 nat_grad_norm = 0.2489 cg_residual = 0.5069 step_size = 0.3487 reward = 0.0000 fps = 119 mse_loss = 3.2096 
2022-07-08 15:16:58.990938 - gail/main.py:174 - [TRPO] iter = 444000 dist_mean = 0.1719 dist_std = 0.3283 vf_loss = 0.0862 grad_norm = 1.7164 nat_grad_norm = 0.3001 cg_residual = 0.6156 step_size = 0.3040 reward = -0.0000 fps = 103 mse_loss = 3.1375 
2022-07-08 15:17:00.245569 - gail/main.py:174 - [TRPO] iter = 445000 dist_mean = 0.2124 dist_std = 0.3278 vf_loss = 0.0798 grad_norm = 1.7603 nat_grad_norm = 0.2922 cg_residual = 0.6488 step_size = 0.3257 reward = -0.0000 fps = 91 mse_loss = 3.1707 
2022-07-08 15:17:00.300465 - gail/main.py:201 - [Discriminator] iter = 445000 loss = -3.6716 grad_norm = 3.0458 grad_penalty = 0.3025 regularization = 0.0000 true_logits = -0.5788 fake_logits = -4.5528 true_prob = 0.4084 fake_prob = 0.0766 
2022-07-08 15:17:05.257104 - gail/main.py:142 - [Evaluate] iter = 445000 episode={ returns = 1081.0269 lengths = 291 } discounted_episode={ returns = 934.6083 lengths = 301 } 
2022-07-08 15:17:06.783249 - gail/main.py:174 - [TRPO] iter = 446000 dist_mean = 0.1674 dist_std = 0.3253 vf_loss = 0.0844 grad_norm = 1.6415 nat_grad_norm = 0.2499 cg_residual = 0.9058 step_size = 0.3327 reward = -0.0000 fps = 154 mse_loss = 3.1515 
2022-07-08 15:17:07.983441 - gail/main.py:174 - [TRPO] iter = 447000 dist_mean = 0.2040 dist_std = 0.3241 vf_loss = 0.0800 grad_norm = 1.9617 nat_grad_norm = 0.3096 cg_residual = 0.6890 step_size = 0.2985 reward = 0.0000 fps = 130 mse_loss = 3.2160 
2022-07-08 15:17:09.279566 - gail/main.py:174 - [TRPO] iter = 448000 dist_mean = 0.2173 dist_std = 0.3242 vf_loss = 0.1152 grad_norm = 2.1082 nat_grad_norm = 0.2568 cg_residual = 0.5472 step_size = 0.3236 reward = 0.0000 fps = 111 mse_loss = 3.0178 
2022-07-08 15:17:10.547097 - gail/main.py:174 - [TRPO] iter = 449000 dist_mean = 0.2027 dist_std = 0.3218 vf_loss = 0.1004 grad_norm = 1.6573 nat_grad_norm = 0.3330 cg_residual = 0.9081 step_size = 0.2843 reward = -0.0000 fps = 97 mse_loss = 3.1592 
2022-07-08 15:17:11.786438 - gail/main.py:174 - [TRPO] iter = 450000 dist_mean = 0.1897 dist_std = 0.3209 vf_loss = 0.1350 grad_norm = 1.9089 nat_grad_norm = 0.2486 cg_residual = 0.6795 step_size = 0.3266 reward = 0.0000 fps = 87 mse_loss = 3.3143 
2022-07-08 15:17:11.837923 - gail/main.py:201 - [Discriminator] iter = 450000 loss = -3.1901 grad_norm = 2.9507 grad_penalty = 0.2453 regularization = 0.0000 true_logits = -0.5193 fake_logits = -3.9547 true_prob = 0.4199 fake_prob = 0.0903 
2022-07-08 15:17:15.996593 - gail/main.py:142 - [Evaluate] iter = 450000 episode={ returns = 954.1365 lengths = 262 } discounted_episode={ returns = 786.4519 lengths = 254 } 
2022-07-08 15:17:17.223855 - gail/main.py:174 - [TRPO] iter = 451000 dist_mean = 0.1665 dist_std = 0.3198 vf_loss = 0.0899 grad_norm = 1.7979 nat_grad_norm = 0.3091 cg_residual = 0.6449 step_size = 0.2976 reward = -0.0000 fps = 185 mse_loss = 3.4460 
2022-07-08 15:17:18.902283 - gail/main.py:174 - [TRPO] iter = 452000 dist_mean = 0.1767 dist_std = 0.3193 vf_loss = 0.1051 grad_norm = 1.4564 nat_grad_norm = 0.2865 cg_residual = 0.5797 step_size = 0.3317 reward = 0.0000 fps = 141 mse_loss = 3.3731 
2022-07-08 15:17:20.973031 - gail/main.py:174 - [TRPO] iter = 453000 dist_mean = 0.1741 dist_std = 0.3192 vf_loss = 0.1003 grad_norm = 2.0095 nat_grad_norm = 0.2660 cg_residual = 0.8052 step_size = 0.3170 reward = -0.0000 fps = 109 mse_loss = 3.4945 
2022-07-08 15:17:22.697213 - gail/main.py:174 - [TRPO] iter = 454000 dist_mean = 0.1743 dist_std = 0.3177 vf_loss = 0.0835 grad_norm = 2.2845 nat_grad_norm = 0.2887 cg_residual = 0.6882 step_size = 0.2980 reward = 0.0000 fps = 92 mse_loss = 3.3105 
2022-07-08 15:17:24.458035 - gail/main.py:174 - [TRPO] iter = 455000 dist_mean = 0.1582 dist_std = 0.3178 vf_loss = 0.1166 grad_norm = 1.8027 nat_grad_norm = 0.2960 cg_residual = 0.8416 step_size = 0.3076 reward = -0.0000 fps = 79 mse_loss = 3.4605 
2022-07-08 15:17:24.532563 - gail/main.py:201 - [Discriminator] iter = 455000 loss = -3.3932 grad_norm = 3.5402 grad_penalty = 0.2826 regularization = 0.0000 true_logits = -0.5990 fake_logits = -4.2749 true_prob = 0.4140 fake_prob = 0.0890 
2022-07-08 15:17:30.675388 - gail/main.py:142 - [Evaluate] iter = 455000 episode={ returns = 1069.1441 lengths = 288 } discounted_episode={ returns = 835.3907 lengths = 269 } 
2022-07-08 15:17:32.316613 - gail/main.py:174 - [TRPO] iter = 456000 dist_mean = 0.1739 dist_std = 0.3167 vf_loss = 0.0651 grad_norm = 1.9839 nat_grad_norm = 0.2876 cg_residual = 0.8104 step_size = 0.3211 reward = 0.0000 fps = 128 mse_loss = 3.5944 
2022-07-08 15:17:34.350729 - gail/main.py:174 - [TRPO] iter = 457000 dist_mean = 0.1673 dist_std = 0.3163 vf_loss = 0.0595 grad_norm = 1.7607 nat_grad_norm = 0.2590 cg_residual = 0.6037 step_size = 0.3356 reward = -0.0000 fps = 101 mse_loss = 3.5153 
2022-07-08 15:17:36.514142 - gail/main.py:174 - [TRPO] iter = 458000 dist_mean = 0.1930 dist_std = 0.3157 vf_loss = 0.0595 grad_norm = 2.5322 nat_grad_norm = 0.2898 cg_residual = 0.5017 step_size = 0.3052 reward = -0.0000 fps = 83 mse_loss = 3.5332 
2022-07-08 15:17:38.331245 - gail/main.py:174 - [TRPO] iter = 459000 dist_mean = 0.1237 dist_std = 0.3139 vf_loss = 0.0965 grad_norm = 1.9812 nat_grad_norm = 0.2094 cg_residual = 0.5491 step_size = 0.3646 reward = 0.0000 fps = 72 mse_loss = 3.4884 
2022-07-08 15:17:40.406410 - gail/main.py:174 - [TRPO] iter = 460000 dist_mean = 0.1904 dist_std = 0.3130 vf_loss = 0.0831 grad_norm = 2.1029 nat_grad_norm = 0.3803 cg_residual = 1.2140 step_size = 0.2300 reward = 0.0000 fps = 63 mse_loss = 3.5134 
2022-07-08 15:17:40.480506 - gail/main.py:201 - [Discriminator] iter = 460000 loss = -3.3024 grad_norm = 3.3913 grad_penalty = 0.2405 regularization = 0.0000 true_logits = -0.5598 fake_logits = -4.1027 true_prob = 0.4112 fake_prob = 0.0894 
2022-07-08 15:17:49.827953 - gail/main.py:142 - [Evaluate] iter = 460000 episode={ returns = 1649.0489 lengths = 408 } discounted_episode={ returns = 1242.2509 lengths = 391 } 
2022-07-08 15:17:51.716641 - gail/main.py:174 - [TRPO] iter = 461000 dist_mean = 0.1528 dist_std = 0.3127 vf_loss = 0.0765 grad_norm = 1.4836 nat_grad_norm = 0.3126 cg_residual = 0.7188 step_size = 0.3224 reward = 0.0000 fps = 89 mse_loss = 3.4104 
2022-07-08 15:17:53.779494 - gail/main.py:174 - [TRPO] iter = 462000 dist_mean = 0.1888 dist_std = 0.3130 vf_loss = 0.0922 grad_norm = 2.3089 nat_grad_norm = 0.3368 cg_residual = 1.1004 step_size = 0.2452 reward = 0.0000 fps = 75 mse_loss = 3.3861 
2022-07-08 15:17:55.534239 - gail/main.py:174 - [TRPO] iter = 463000 dist_mean = 0.1846 dist_std = 0.3120 vf_loss = 0.0897 grad_norm = 1.4161 nat_grad_norm = 0.2461 cg_residual = 0.4391 step_size = 0.3784 reward = 0.0000 fps = 66 mse_loss = 3.4934 
2022-07-08 15:17:57.213666 - gail/main.py:174 - [TRPO] iter = 464000 dist_mean = 0.1430 dist_std = 0.3119 vf_loss = 0.0879 grad_norm = 1.6283 nat_grad_norm = 0.2369 cg_residual = 0.5735 step_size = 0.3593 reward = 0.0000 fps = 59 mse_loss = 3.4546 
2022-07-08 15:17:59.188406 - gail/main.py:174 - [TRPO] iter = 465000 dist_mean = 0.1500 dist_std = 0.3101 vf_loss = 0.0835 grad_norm = 1.9240 nat_grad_norm = 0.2853 cg_residual = 0.8791 step_size = 0.3138 reward = 0.0000 fps = 53 mse_loss = 3.5008 
2022-07-08 15:17:59.261282 - gail/main.py:201 - [Discriminator] iter = 465000 loss = -3.1336 grad_norm = 3.3773 grad_penalty = 0.2458 regularization = 0.0000 true_logits = -0.6113 fake_logits = -3.9907 true_prob = 0.4052 fake_prob = 0.0998 
2022-07-08 15:18:05.570797 - gail/main.py:142 - [Evaluate] iter = 465000 episode={ returns = 837.9364 lengths = 224 } discounted_episode={ returns = 964.6944 lengths = 300 } 
2022-07-08 15:18:07.374757 - gail/main.py:174 - [TRPO] iter = 466000 dist_mean = 0.1664 dist_std = 0.3085 vf_loss = 0.1126 grad_norm = 2.0964 nat_grad_norm = 0.2952 cg_residual = 0.7359 step_size = 0.3056 reward = 0.0000 fps = 123 mse_loss = 3.4073 
2022-07-08 15:18:09.149849 - gail/main.py:174 - [TRPO] iter = 467000 dist_mean = 0.2192 dist_std = 0.3083 vf_loss = 0.0796 grad_norm = 2.1907 nat_grad_norm = 0.2390 cg_residual = 0.5193 step_size = 0.3356 reward = 0.0000 fps = 101 mse_loss = 3.5402 
2022-07-08 15:18:10.780620 - gail/main.py:174 - [TRPO] iter = 468000 dist_mean = 0.1729 dist_std = 0.3082 vf_loss = 0.0998 grad_norm = 1.7888 nat_grad_norm = 0.2987 cg_residual = 0.7472 step_size = 0.3028 reward = -0.0000 fps = 86 mse_loss = 3.4890 
2022-07-08 15:18:12.133335 - gail/main.py:174 - [TRPO] iter = 469000 dist_mean = 0.1991 dist_std = 0.3085 vf_loss = 0.0664 grad_norm = 1.9534 nat_grad_norm = 0.2622 cg_residual = 0.7085 step_size = 0.2941 reward = -0.0000 fps = 77 mse_loss = 3.4560 
2022-07-08 15:18:13.765624 - gail/main.py:174 - [TRPO] iter = 470000 dist_mean = 0.2051 dist_std = 0.3085 vf_loss = 0.0861 grad_norm = 1.8171 nat_grad_norm = 0.2715 cg_residual = 1.0309 step_size = 0.3382 reward = 0.0000 fps = 68 mse_loss = 3.4656 
2022-07-08 15:18:13.832513 - gail/main.py:201 - [Discriminator] iter = 470000 loss = -3.0881 grad_norm = 3.4624 grad_penalty = 0.2324 regularization = 0.0000 true_logits = -0.6989 fake_logits = -4.0193 true_prob = 0.3964 fake_prob = 0.0953 
2022-07-08 15:18:18.191507 - gail/main.py:142 - [Evaluate] iter = 470000 episode={ returns = 951.4981 lengths = 252 } discounted_episode={ returns = 541.8131 lengths = 183 } 
2022-07-08 15:18:19.829995 - gail/main.py:174 - [TRPO] iter = 471000 dist_mean = 0.1971 dist_std = 0.3080 vf_loss = 0.0732 grad_norm = 2.4958 nat_grad_norm = 0.2859 cg_residual = 0.9381 step_size = 0.2800 reward = -0.0000 fps = 166 mse_loss = 3.4922 
2022-07-08 15:18:21.540101 - gail/main.py:174 - [TRPO] iter = 472000 dist_mean = 0.1868 dist_std = 0.3056 vf_loss = 0.0648 grad_norm = 1.8250 nat_grad_norm = 0.2539 cg_residual = 0.8433 step_size = 0.3512 reward = -0.0000 fps = 129 mse_loss = 3.5636 
2022-07-08 15:18:23.597736 - gail/main.py:174 - [TRPO] iter = 473000 dist_mean = 0.1886 dist_std = 0.3045 vf_loss = 0.0613 grad_norm = 2.2741 nat_grad_norm = 0.2839 cg_residual = 0.7419 step_size = 0.3047 reward = -0.0000 fps = 102 mse_loss = 3.4600 
2022-07-08 15:18:25.673187 - gail/main.py:174 - [TRPO] iter = 474000 dist_mean = 0.2032 dist_std = 0.3035 vf_loss = 0.0750 grad_norm = 2.5167 nat_grad_norm = 0.2833 cg_residual = 1.2907 step_size = 0.2918 reward = 0.0000 fps = 84 mse_loss = 3.4772 
2022-07-08 15:18:28.184629 - gail/main.py:174 - [TRPO] iter = 475000 dist_mean = 0.1909 dist_std = 0.3018 vf_loss = 0.0557 grad_norm = 1.4571 nat_grad_norm = 0.2644 cg_residual = 0.8252 step_size = 0.3308 reward = -0.0000 fps = 69 mse_loss = 3.5566 
2022-07-08 15:18:28.275316 - gail/main.py:201 - [Discriminator] iter = 475000 loss = -3.1251 grad_norm = 3.1319 grad_penalty = 0.2374 regularization = 0.0000 true_logits = -0.8343 fake_logits = -4.1968 true_prob = 0.3752 fake_prob = 0.0780 
2022-07-08 15:18:36.518912 - gail/main.py:142 - [Evaluate] iter = 475000 episode={ returns = 1028.7670 lengths = 283 } discounted_episode={ returns = 916.9609 lengths = 295 } 
2022-07-08 15:18:38.911506 - gail/main.py:174 - [TRPO] iter = 476000 dist_mean = 0.2165 dist_std = 0.2993 vf_loss = 0.0687 grad_norm = 2.1835 nat_grad_norm = 0.2697 cg_residual = 0.8663 step_size = 0.3255 reward = -0.0000 fps = 94 mse_loss = 3.3461 
2022-07-08 15:18:40.836330 - gail/main.py:174 - [TRPO] iter = 477000 dist_mean = 0.1475 dist_std = 0.2964 vf_loss = 0.0608 grad_norm = 2.4368 nat_grad_norm = 0.2267 cg_residual = 0.7138 step_size = 0.3147 reward = 0.0000 fps = 79 mse_loss = 3.5358 
2022-07-08 15:18:42.317595 - gail/main.py:174 - [TRPO] iter = 478000 dist_mean = 0.1957 dist_std = 0.2957 vf_loss = 0.0494 grad_norm = 1.6750 nat_grad_norm = 0.2726 cg_residual = 0.5855 step_size = 0.3352 reward = -0.0000 fps = 71 mse_loss = 3.3834 
2022-07-08 15:18:44.139396 - gail/main.py:174 - [TRPO] iter = 479000 dist_mean = 0.1869 dist_std = 0.2941 vf_loss = 0.0636 grad_norm = 2.1574 nat_grad_norm = 0.3696 cg_residual = 1.0827 step_size = 0.2526 reward = -0.0000 fps = 63 mse_loss = 3.3587 
2022-07-08 15:18:46.088985 - gail/main.py:174 - [TRPO] iter = 480000 dist_mean = 0.2191 dist_std = 0.2927 vf_loss = 0.0666 grad_norm = 1.9290 nat_grad_norm = 0.1974 cg_residual = 0.7935 step_size = 0.3685 reward = -0.0000 fps = 56 mse_loss = 3.5098 
2022-07-08 15:18:46.222247 - gail/main.py:201 - [Discriminator] iter = 480000 loss = -2.7520 grad_norm = 2.9503 grad_penalty = 0.2084 regularization = 0.0000 true_logits = -0.7664 fake_logits = -3.7269 true_prob = 0.3936 fake_prob = 0.0979 
2022-07-08 15:18:53.480316 - gail/main.py:142 - [Evaluate] iter = 480000 episode={ returns = 1121.5517 lengths = 310 } discounted_episode={ returns = 1003.4579 lengths = 337 } 
2022-07-08 15:18:55.197581 - gail/main.py:174 - [TRPO] iter = 481000 dist_mean = 0.1707 dist_std = 0.2917 vf_loss = 0.0674 grad_norm = 1.5603 nat_grad_norm = 0.2526 cg_residual = 0.5369 step_size = 0.3442 reward = -0.0000 fps = 111 mse_loss = 3.3579 
2022-07-08 15:18:57.059361 - gail/main.py:174 - [TRPO] iter = 482000 dist_mean = 0.1674 dist_std = 0.2922 vf_loss = 0.0586 grad_norm = 2.4180 nat_grad_norm = 0.2542 cg_residual = 0.7103 step_size = 0.3064 reward = -0.0000 fps = 92 mse_loss = 3.2814 
2022-07-08 15:18:58.711178 - gail/main.py:174 - [TRPO] iter = 483000 dist_mean = 0.1625 dist_std = 0.2912 vf_loss = 0.0585 grad_norm = 1.6784 nat_grad_norm = 0.2463 cg_residual = 0.5755 step_size = 0.3409 reward = -0.0000 fps = 80 mse_loss = 3.4388 
2022-07-08 15:18:59.954546 - gail/main.py:174 - [TRPO] iter = 484000 dist_mean = 0.1985 dist_std = 0.2914 vf_loss = 0.0545 grad_norm = 1.4757 nat_grad_norm = 0.2311 cg_residual = 0.5322 step_size = 0.3666 reward = 0.0000 fps = 72 mse_loss = 3.4790 
2022-07-08 15:19:01.186663 - gail/main.py:174 - [TRPO] iter = 485000 dist_mean = 0.2001 dist_std = 0.2899 vf_loss = 0.0506 grad_norm = 1.3573 nat_grad_norm = 0.2526 cg_residual = 0.9189 step_size = 0.3657 reward = 0.0000 fps = 66 mse_loss = 3.5556 
2022-07-08 15:19:01.240439 - gail/main.py:201 - [Discriminator] iter = 485000 loss = -3.1035 grad_norm = 2.8062 grad_penalty = 0.2203 regularization = 0.0000 true_logits = -0.7609 fake_logits = -4.0847 true_prob = 0.3917 fake_prob = 0.0749 
2022-07-08 15:19:08.944408 - gail/main.py:142 - [Evaluate] iter = 485000 episode={ returns = 1640.2727 lengths = 432 } discounted_episode={ returns = 1105.7863 lengths = 373 } 
2022-07-08 15:19:10.243451 - gail/main.py:174 - [TRPO] iter = 486000 dist_mean = 0.1783 dist_std = 0.2881 vf_loss = 0.0470 grad_norm = 1.8777 nat_grad_norm = 0.2469 cg_residual = 0.6195 step_size = 0.3344 reward = 0.0000 fps = 111 mse_loss = 3.4310 
2022-07-08 15:19:11.493843 - gail/main.py:174 - [TRPO] iter = 487000 dist_mean = 0.1925 dist_std = 0.2895 vf_loss = 0.0439 grad_norm = 1.7259 nat_grad_norm = 0.2663 cg_residual = 1.1045 step_size = 0.3202 reward = 0.0000 fps = 97 mse_loss = 3.5175 
2022-07-08 15:19:12.721137 - gail/main.py:174 - [TRPO] iter = 488000 dist_mean = 0.1763 dist_std = 0.2884 vf_loss = 0.0341 grad_norm = 2.0803 nat_grad_norm = 0.2260 cg_residual = 0.7125 step_size = 0.3269 reward = -0.0000 fps = 87 mse_loss = 3.5421 
2022-07-08 15:19:13.947924 - gail/main.py:174 - [TRPO] iter = 489000 dist_mean = 0.1724 dist_std = 0.2867 vf_loss = 0.0368 grad_norm = 2.0473 nat_grad_norm = 0.2894 cg_residual = 1.1914 step_size = 0.2970 reward = -0.0000 fps = 78 mse_loss = 3.6633 
2022-07-08 15:19:15.174867 - gail/main.py:174 - [TRPO] iter = 490000 dist_mean = 0.2142 dist_std = 0.2847 vf_loss = 0.0450 grad_norm = 2.1289 nat_grad_norm = 0.2901 cg_residual = 0.7028 step_size = 0.3247 reward = 0.0000 fps = 71 mse_loss = 3.4155 
2022-07-08 15:19:15.224360 - gail/main.py:201 - [Discriminator] iter = 490000 loss = -3.5913 grad_norm = 3.3196 grad_penalty = 0.2858 regularization = 0.0000 true_logits = -0.8168 fake_logits = -4.6938 true_prob = 0.3808 fake_prob = 0.0453 
2022-07-08 15:19:22.632934 - gail/main.py:142 - [Evaluate] iter = 490000 episode={ returns = 1366.7102 lengths = 364 } discounted_episode={ returns = 1107.0543 lengths = 382 } 
2022-07-08 15:19:24.845170 - gail/main.py:174 - [TRPO] iter = 491000 dist_mean = 0.1937 dist_std = 0.2838 vf_loss = 0.0598 grad_norm = 1.9940 nat_grad_norm = 0.2468 cg_residual = 0.9009 step_size = 0.3232 reward = 0.0000 fps = 103 mse_loss = 3.4316 
2022-07-08 15:19:26.711526 - gail/main.py:174 - [TRPO] iter = 492000 dist_mean = 0.1725 dist_std = 0.2834 vf_loss = 0.0491 grad_norm = 2.6224 nat_grad_norm = 0.2628 cg_residual = 0.7874 step_size = 0.3187 reward = 0.0000 fps = 87 mse_loss = 3.6031 
2022-07-08 15:19:28.506804 - gail/main.py:174 - [TRPO] iter = 493000 dist_mean = 0.1882 dist_std = 0.2834 vf_loss = 0.0707 grad_norm = 1.5076 nat_grad_norm = 0.2413 cg_residual = 0.6938 step_size = 0.3398 reward = 0.0000 fps = 75 mse_loss = 3.5843 
2022-07-08 15:19:30.295323 - gail/main.py:174 - [TRPO] iter = 494000 dist_mean = 0.2147 dist_std = 0.2833 vf_loss = 0.0471 grad_norm = 1.8855 nat_grad_norm = 0.2544 cg_residual = 0.9899 step_size = 0.3574 reward = -0.0000 fps = 66 mse_loss = 3.4672 
2022-07-08 15:19:32.100746 - gail/main.py:174 - [TRPO] iter = 495000 dist_mean = 0.1982 dist_std = 0.2831 vf_loss = 0.0508 grad_norm = 1.8759 nat_grad_norm = 0.2272 cg_residual = 0.7944 step_size = 0.3559 reward = 0.0000 fps = 59 mse_loss = 3.5529 
2022-07-08 15:19:32.175684 - gail/main.py:201 - [Discriminator] iter = 495000 loss = -3.1979 grad_norm = 3.1574 grad_penalty = 0.2568 regularization = 0.0000 true_logits = -0.6238 fake_logits = -4.0784 true_prob = 0.4084 fake_prob = 0.0714 
2022-07-08 15:19:40.777541 - gail/main.py:142 - [Evaluate] iter = 495000 episode={ returns = 1405.5468 lengths = 368 } discounted_episode={ returns = 1028.8766 lengths = 347 } 
2022-07-08 15:19:42.501950 - gail/main.py:174 - [TRPO] iter = 496000 dist_mean = 0.2118 dist_std = 0.2831 vf_loss = 0.0567 grad_norm = 2.0134 nat_grad_norm = 0.2297 cg_residual = 0.4969 step_size = 0.3422 reward = 0.0000 fps = 96 mse_loss = 3.5874 
2022-07-08 15:19:44.206216 - gail/main.py:174 - [TRPO] iter = 497000 dist_mean = 0.2112 dist_std = 0.2833 vf_loss = 0.0655 grad_norm = 2.2826 nat_grad_norm = 0.2557 cg_residual = 0.8988 step_size = 0.3303 reward = 0.0000 fps = 83 mse_loss = 3.4710 
2022-07-08 15:19:45.863127 - gail/main.py:174 - [TRPO] iter = 498000 dist_mean = 0.1681 dist_std = 0.2818 vf_loss = 0.0547 grad_norm = 1.8991 nat_grad_norm = 0.2554 cg_residual = 0.7218 step_size = 0.3351 reward = -0.0000 fps = 73 mse_loss = 3.5194 
2022-07-08 15:19:47.679742 - gail/main.py:174 - [TRPO] iter = 499000 dist_mean = 0.1685 dist_std = 0.2805 vf_loss = 0.0596 grad_norm = 2.3906 nat_grad_norm = 0.2268 cg_residual = 1.1516 step_size = 0.3252 reward = -0.0000 fps = 64 mse_loss = 3.4601 
2022-07-08 15:19:49.425298 - gail/main.py:174 - [TRPO] iter = 500000 dist_mean = 0.1897 dist_std = 0.2790 vf_loss = 0.0393 grad_norm = 2.2979 nat_grad_norm = 0.2426 cg_residual = 0.8569 step_size = 0.3292 reward = 0.0000 fps = 57 mse_loss = 3.5474 
2022-07-08 15:19:49.509997 - gail/main.py:201 - [Discriminator] iter = 500000 loss = -2.7384 grad_norm = 3.4188 grad_penalty = 0.2069 regularization = 0.0000 true_logits = -0.6782 fake_logits = -3.6236 true_prob = 0.4036 fake_prob = 0.0948 
2022-07-08 15:19:58.744048 - gail/main.py:142 - [Evaluate] iter = 500000 episode={ returns = 1320.4091 lengths = 345 } discounted_episode={ returns = 1126.5536 lengths = 362 } 
2022-07-08 15:20:00.500033 - gail/main.py:174 - [TRPO] iter = 501000 dist_mean = 0.2060 dist_std = 0.2772 vf_loss = 0.0627 grad_norm = 1.9354 nat_grad_norm = 0.2259 cg_residual = 0.6984 step_size = 0.3544 reward = 0.0000 fps = 99 mse_loss = 3.3808 
2022-07-08 15:20:02.567019 - gail/main.py:174 - [TRPO] iter = 502000 dist_mean = 0.2060 dist_std = 0.2754 vf_loss = 0.0435 grad_norm = 1.9857 nat_grad_norm = 0.2869 cg_residual = 1.0145 step_size = 0.3164 reward = -0.0000 fps = 82 mse_loss = 3.5839 
2022-07-08 15:20:04.466545 - gail/main.py:174 - [TRPO] iter = 503000 dist_mean = 0.2049 dist_std = 0.2752 vf_loss = 0.0504 grad_norm = 2.0547 nat_grad_norm = 0.2545 cg_residual = 1.7055 step_size = 0.3220 reward = -0.0000 fps = 71 mse_loss = 3.6509 
2022-07-08 15:20:06.187914 - gail/main.py:174 - [TRPO] iter = 504000 dist_mean = 0.1876 dist_std = 0.2743 vf_loss = 0.0485 grad_norm = 2.0880 nat_grad_norm = 0.2487 cg_residual = 0.8980 step_size = 0.3161 reward = -0.0000 fps = 63 mse_loss = 3.5388 
2022-07-08 15:20:07.847117 - gail/main.py:174 - [TRPO] iter = 505000 dist_mean = 0.1562 dist_std = 0.2733 vf_loss = 0.0555 grad_norm = 2.7008 nat_grad_norm = 0.2411 cg_residual = 0.8434 step_size = 0.3059 reward = -0.0000 fps = 57 mse_loss = 3.5951 
2022-07-08 15:20:07.933331 - gail/main.py:201 - [Discriminator] iter = 505000 loss = -3.2392 grad_norm = 3.9498 grad_penalty = 0.2170 regularization = 0.0000 true_logits = -0.6494 fake_logits = -4.1056 true_prob = 0.4097 fake_prob = 0.0646 
2022-07-08 15:20:13.739939 - gail/main.py:142 - [Evaluate] iter = 505000 episode={ returns = 1432.3710 lengths = 366 } discounted_episode={ returns = 997.3649 lengths = 327 } 
2022-07-08 15:20:14.941813 - gail/main.py:174 - [TRPO] iter = 506000 dist_mean = 0.1515 dist_std = 0.2722 vf_loss = 0.0341 grad_norm = 2.0261 nat_grad_norm = 0.2024 cg_residual = 0.8222 step_size = 0.3446 reward = 0.0000 fps = 142 mse_loss = 3.6091 
2022-07-08 15:20:16.133545 - gail/main.py:174 - [TRPO] iter = 507000 dist_mean = 0.1606 dist_std = 0.2728 vf_loss = 0.0349 grad_norm = 1.9793 nat_grad_norm = 0.2090 cg_residual = 0.7907 step_size = 0.3375 reward = 0.0000 fps = 122 mse_loss = 3.6104 
2022-07-08 15:20:17.332463 - gail/main.py:174 - [TRPO] iter = 508000 dist_mean = 0.1565 dist_std = 0.2731 vf_loss = 0.0650 grad_norm = 2.6528 nat_grad_norm = 0.2328 cg_residual = 1.0805 step_size = 0.3015 reward = 0.0000 fps = 106 mse_loss = 3.6542 
2022-07-08 15:20:18.515464 - gail/main.py:174 - [TRPO] iter = 509000 dist_mean = 0.2073 dist_std = 0.2730 vf_loss = 0.0526 grad_norm = 2.3822 nat_grad_norm = 0.2268 cg_residual = 1.1576 step_size = 0.3076 reward = -0.0000 fps = 94 mse_loss = 3.4948 
2022-07-08 15:20:19.760744 - gail/main.py:174 - [TRPO] iter = 510000 dist_mean = 0.1827 dist_std = 0.2730 vf_loss = 0.0378 grad_norm = 2.0583 nat_grad_norm = 0.2394 cg_residual = 1.0152 step_size = 0.3363 reward = -0.0000 fps = 84 mse_loss = 3.5965 
2022-07-08 15:20:19.816505 - gail/main.py:201 - [Discriminator] iter = 510000 loss = -2.7470 grad_norm = 3.6681 grad_penalty = 0.1979 regularization = 0.0000 true_logits = -0.7418 fake_logits = -3.6867 true_prob = 0.3968 fake_prob = 0.0884 
2022-07-08 15:20:23.983018 - gail/main.py:142 - [Evaluate] iter = 510000 episode={ returns = 978.2562 lengths = 270 } discounted_episode={ returns = 816.8776 lengths = 265 } 
2022-07-08 15:20:25.239123 - gail/main.py:174 - [TRPO] iter = 511000 dist_mean = 0.1870 dist_std = 0.2718 vf_loss = 0.0364 grad_norm = 2.4111 nat_grad_norm = 0.2257 cg_residual = 0.8075 step_size = 0.3287 reward = -0.0000 fps = 184 mse_loss = 3.6514 
2022-07-08 15:20:26.464286 - gail/main.py:174 - [TRPO] iter = 512000 dist_mean = 0.1922 dist_std = 0.2704 vf_loss = 0.0364 grad_norm = 1.5863 nat_grad_norm = 0.2360 cg_residual = 0.7785 step_size = 0.3383 reward = -0.0000 fps = 150 mse_loss = 3.5955 
2022-07-08 15:20:27.674655 - gail/main.py:174 - [TRPO] iter = 513000 dist_mean = 0.2226 dist_std = 0.2702 vf_loss = 0.0444 grad_norm = 1.7974 nat_grad_norm = 0.2026 cg_residual = 0.8147 step_size = 0.3620 reward = -0.0000 fps = 127 mse_loss = 3.5743 
2022-07-08 15:20:28.870074 - gail/main.py:174 - [TRPO] iter = 514000 dist_mean = 0.2123 dist_std = 0.2697 vf_loss = 0.0421 grad_norm = 2.2956 nat_grad_norm = 0.2317 cg_residual = 0.9831 step_size = 0.3326 reward = 0.0000 fps = 110 mse_loss = 3.7033 
2022-07-08 15:20:30.064945 - gail/main.py:174 - [TRPO] iter = 515000 dist_mean = 0.1678 dist_std = 0.2696 vf_loss = 0.0432 grad_norm = 2.3792 nat_grad_norm = 0.2245 cg_residual = 0.8374 step_size = 0.3059 reward = 0.0000 fps = 97 mse_loss = 3.6992 
2022-07-08 15:20:30.119608 - gail/main.py:201 - [Discriminator] iter = 515000 loss = -3.0465 grad_norm = 2.9112 grad_penalty = 0.2043 regularization = 0.0000 true_logits = -0.8540 fake_logits = -4.1048 true_prob = 0.3790 fake_prob = 0.0757 
2022-07-08 15:20:35.589494 - gail/main.py:142 - [Evaluate] iter = 515000 episode={ returns = 1362.6351 lengths = 354 } discounted_episode={ returns = 1066.7780 lengths = 336 } 
2022-07-08 15:20:36.792379 - gail/main.py:174 - [TRPO] iter = 516000 dist_mean = 0.1412 dist_std = 0.2689 vf_loss = 0.0444 grad_norm = 1.7322 nat_grad_norm = 0.2225 cg_residual = 0.5576 step_size = 0.3299 reward = -0.0000 fps = 149 mse_loss = 3.6250 
2022-07-08 15:20:37.991744 - gail/main.py:174 - [TRPO] iter = 517000 dist_mean = 0.1415 dist_std = 0.2698 vf_loss = 0.0666 grad_norm = 1.9372 nat_grad_norm = 0.2064 cg_residual = 0.7575 step_size = 0.3591 reward = 0.0000 fps = 127 mse_loss = 3.6724 
2022-07-08 15:20:39.190432 - gail/main.py:174 - [TRPO] iter = 518000 dist_mean = 0.1748 dist_std = 0.2699 vf_loss = 0.0709 grad_norm = 1.9001 nat_grad_norm = 0.2434 cg_residual = 1.2903 step_size = 0.3173 reward = -0.0000 fps = 110 mse_loss = 3.6994 
2022-07-08 15:20:40.394680 - gail/main.py:174 - [TRPO] iter = 519000 dist_mean = 0.1676 dist_std = 0.2695 vf_loss = 0.0394 grad_norm = 1.8828 nat_grad_norm = 0.2562 cg_residual = 1.0736 step_size = 0.3210 reward = -0.0000 fps = 97 mse_loss = 3.4840 
2022-07-08 15:20:41.580646 - gail/main.py:174 - [TRPO] iter = 520000 dist_mean = 0.1611 dist_std = 0.2678 vf_loss = 0.0562 grad_norm = 1.8696 nat_grad_norm = 0.2213 cg_residual = 0.8386 step_size = 0.3262 reward = -0.0000 fps = 87 mse_loss = 3.6220 
2022-07-08 15:20:41.630104 - gail/main.py:201 - [Discriminator] iter = 520000 loss = -2.8297 grad_norm = 2.9330 grad_penalty = 0.2026 regularization = 0.0000 true_logits = -0.9791 fake_logits = -4.0114 true_prob = 0.3720 fake_prob = 0.0733 
2022-07-08 15:20:47.305437 - gail/main.py:142 - [Evaluate] iter = 520000 episode={ returns = 1426.7149 lengths = 369 } discounted_episode={ returns = 1051.2275 lengths = 338 } 
2022-07-08 15:20:51.459714 - gail/main.py:174 - [TRPO] iter = 521000 dist_mean = 0.1606 dist_std = 0.2673 vf_loss = 0.0401 grad_norm = 1.8514 nat_grad_norm = 0.2353 cg_residual = 0.9041 step_size = 0.3393 reward = 0.0000 fps = 101 mse_loss = 3.6174 
2022-07-08 15:20:54.411831 - gail/main.py:174 - [TRPO] iter = 522000 dist_mean = 0.1650 dist_std = 0.2673 vf_loss = 0.0377 grad_norm = 2.7964 nat_grad_norm = 0.2140 cg_residual = 0.7080 step_size = 0.3419 reward = 0.0000 fps = 78 mse_loss = 3.4113 
2022-07-08 15:20:55.617629 - gail/main.py:174 - [TRPO] iter = 523000 dist_mean = 0.1828 dist_std = 0.2674 vf_loss = 0.0548 grad_norm = 1.9882 nat_grad_norm = 0.2480 cg_residual = 0.6335 step_size = 0.3241 reward = -0.0000 fps = 71 mse_loss = 3.6433 
2022-07-08 15:20:56.806675 - gail/main.py:174 - [TRPO] iter = 524000 dist_mean = 0.1510 dist_std = 0.2670 vf_loss = 0.0475 grad_norm = 2.1085 nat_grad_norm = 0.2746 cg_residual = 0.8962 step_size = 0.2976 reward = -0.0000 fps = 65 mse_loss = 3.3030 
2022-07-08 15:20:57.983821 - gail/main.py:174 - [TRPO] iter = 525000 dist_mean = 0.1361 dist_std = 0.2655 vf_loss = 0.0468 grad_norm = 2.4521 nat_grad_norm = 0.2312 cg_residual = 1.0686 step_size = 0.3185 reward = -0.0000 fps = 61 mse_loss = 3.4373 
2022-07-08 15:20:58.034185 - gail/main.py:201 - [Discriminator] iter = 525000 loss = -2.9959 grad_norm = 2.6818 grad_penalty = 0.2156 regularization = 0.0000 true_logits = -0.8103 fake_logits = -4.0218 true_prob = 0.3906 fake_prob = 0.0722 
2022-07-08 15:21:04.217564 - gail/main.py:142 - [Evaluate] iter = 525000 episode={ returns = 1502.3764 lengths = 394 } discounted_episode={ returns = 1201.5134 lengths = 393 } 
2022-07-08 15:21:05.864102 - gail/main.py:174 - [TRPO] iter = 526000 dist_mean = 0.1618 dist_std = 0.2666 vf_loss = 0.0409 grad_norm = 2.1311 nat_grad_norm = 0.2442 cg_residual = 0.6797 step_size = 0.3256 reward = 0.0000 fps = 127 mse_loss = 3.4342 
2022-07-08 15:21:07.733905 - gail/main.py:174 - [TRPO] iter = 527000 dist_mean = 0.1617 dist_std = 0.2660 vf_loss = 0.0334 grad_norm = 1.9275 nat_grad_norm = 0.2107 cg_residual = 0.6085 step_size = 0.3412 reward = -0.0000 fps = 103 mse_loss = 3.3435 
2022-07-08 15:21:09.618125 - gail/main.py:174 - [TRPO] iter = 528000 dist_mean = 0.1457 dist_std = 0.2650 vf_loss = 0.0338 grad_norm = 1.9652 nat_grad_norm = 0.2201 cg_residual = 0.5990 step_size = 0.3348 reward = 0.0000 fps = 86 mse_loss = 3.3942 
2022-07-08 15:21:11.502290 - gail/main.py:174 - [TRPO] iter = 529000 dist_mean = 0.1687 dist_std = 0.2656 vf_loss = 0.0486 grad_norm = 2.0086 nat_grad_norm = 0.2412 cg_residual = 0.7508 step_size = 0.3369 reward = -0.0000 fps = 74 mse_loss = 3.4181 
2022-07-08 15:21:13.455815 - gail/main.py:174 - [TRPO] iter = 530000 dist_mean = 0.1470 dist_std = 0.2646 vf_loss = 0.0987 grad_norm = 2.4070 nat_grad_norm = 0.2191 cg_residual = 0.8917 step_size = 0.3497 reward = 0.0000 fps = 64 mse_loss = 3.3173 
2022-07-08 15:21:13.541637 - gail/main.py:201 - [Discriminator] iter = 530000 loss = -3.0867 grad_norm = 3.1163 grad_penalty = 0.2118 regularization = 0.0000 true_logits = -0.7007 fake_logits = -3.9991 true_prob = 0.4120 fake_prob = 0.0741 
2022-07-08 15:21:21.643044 - gail/main.py:142 - [Evaluate] iter = 530000 episode={ returns = 1646.2994 lengths = 423 } discounted_episode={ returns = 1419.7304 lengths = 467 } 
2022-07-08 15:21:24.188470 - gail/main.py:174 - [TRPO] iter = 531000 dist_mean = 0.1592 dist_std = 0.2655 vf_loss = 0.0477 grad_norm = 2.6467 nat_grad_norm = 0.2443 cg_residual = 0.8305 step_size = 0.3164 reward = -0.0000 fps = 93 mse_loss = 3.2774 
2022-07-08 15:21:26.059654 - gail/main.py:174 - [TRPO] iter = 532000 dist_mean = 0.1525 dist_std = 0.2659 vf_loss = 0.0565 grad_norm = 2.6291 nat_grad_norm = 0.2239 cg_residual = 0.7138 step_size = 0.3085 reward = -0.0000 fps = 79 mse_loss = 3.2040 
2022-07-08 15:21:27.836542 - gail/main.py:174 - [TRPO] iter = 533000 dist_mean = 0.2158 dist_std = 0.2657 vf_loss = 0.0462 grad_norm = 1.7501 nat_grad_norm = 0.2268 cg_residual = 0.5755 step_size = 0.3532 reward = 0.0000 fps = 69 mse_loss = 3.2546 
2022-07-08 15:21:29.676427 - gail/main.py:174 - [TRPO] iter = 534000 dist_mean = 0.2041 dist_std = 0.2651 vf_loss = 0.0495 grad_norm = 2.0972 nat_grad_norm = 0.3000 cg_residual = 1.0759 step_size = 0.3094 reward = 0.0000 fps = 62 mse_loss = 3.2422 
2022-07-08 15:21:30.981417 - gail/main.py:174 - [TRPO] iter = 535000 dist_mean = 0.1741 dist_std = 0.2638 vf_loss = 0.0359 grad_norm = 2.8335 nat_grad_norm = 0.2302 cg_residual = 1.0059 step_size = 0.3094 reward = 0.0000 fps = 57 mse_loss = 3.2280 
2022-07-08 15:21:31.058248 - gail/main.py:201 - [Discriminator] iter = 535000 loss = -2.5167 grad_norm = 3.1288 grad_penalty = 0.1821 regularization = 0.0000 true_logits = -0.6772 fake_logits = -3.3760 true_prob = 0.4144 fake_prob = 0.0992 
2022-07-08 15:21:39.229617 - gail/main.py:142 - [Evaluate] iter = 535000 episode={ returns = 1971.9836 lengths = 491 } discounted_episode={ returns = 1478.7786 lengths = 479 } 
2022-07-08 15:21:40.445441 - gail/main.py:174 - [TRPO] iter = 536000 dist_mean = 0.1672 dist_std = 0.2643 vf_loss = 0.0436 grad_norm = 2.1322 nat_grad_norm = 0.2368 cg_residual = 0.7013 step_size = 0.3262 reward = 0.0000 fps = 106 mse_loss = 3.1951 
2022-07-08 15:21:42.087795 - gail/main.py:174 - [TRPO] iter = 537000 dist_mean = 0.1913 dist_std = 0.2648 vf_loss = 0.0371 grad_norm = 2.5847 nat_grad_norm = 0.2178 cg_residual = 0.9038 step_size = 0.3213 reward = 0.0000 fps = 90 mse_loss = 3.2329 
2022-07-08 15:21:43.279188 - gail/main.py:174 - [TRPO] iter = 538000 dist_mean = 0.1020 dist_std = 0.2648 vf_loss = 0.0909 grad_norm = 1.6749 nat_grad_norm = 0.2070 cg_residual = 1.0472 step_size = 0.3425 reward = 0.0000 fps = 81 mse_loss = 3.3523 
2022-07-08 15:21:44.500563 - gail/main.py:174 - [TRPO] iter = 539000 dist_mean = 0.1393 dist_std = 0.2640 vf_loss = 0.0406 grad_norm = 1.8782 nat_grad_norm = 0.2446 cg_residual = 0.5709 step_size = 0.3111 reward = -0.0000 fps = 74 mse_loss = 3.1665 
2022-07-08 15:21:45.711767 - gail/main.py:174 - [TRPO] iter = 540000 dist_mean = 0.1845 dist_std = 0.2636 vf_loss = 0.0456 grad_norm = 2.7058 nat_grad_norm = 0.2505 cg_residual = 0.8033 step_size = 0.3298 reward = 0.0000 fps = 68 mse_loss = 3.2617 
2022-07-08 15:21:45.763189 - gail/main.py:201 - [Discriminator] iter = 540000 loss = -2.8189 grad_norm = 3.3112 grad_penalty = 0.1935 regularization = 0.0000 true_logits = -0.6908 fake_logits = -3.7033 true_prob = 0.4088 fake_prob = 0.0776 
2022-07-08 15:21:53.628980 - gail/main.py:142 - [Evaluate] iter = 540000 episode={ returns = 2092.8879 lengths = 510 } discounted_episode={ returns = 1580.0597 lengths = 511 } 
2022-07-08 15:21:54.832313 - gail/main.py:174 - [TRPO] iter = 541000 dist_mean = 0.1336 dist_std = 0.2630 vf_loss = 0.0270 grad_norm = 1.8669 nat_grad_norm = 0.2464 cg_residual = 1.0724 step_size = 0.3159 reward = 0.0000 fps = 110 mse_loss = 3.2963 
2022-07-08 15:21:56.023716 - gail/main.py:174 - [TRPO] iter = 542000 dist_mean = 0.1464 dist_std = 0.2631 vf_loss = 0.0309 grad_norm = 1.9168 nat_grad_norm = 0.2311 cg_residual = 0.7341 step_size = 0.3294 reward = -0.0000 fps = 97 mse_loss = 3.2601 
2022-07-08 15:21:57.197171 - gail/main.py:174 - [TRPO] iter = 543000 dist_mean = 0.1710 dist_std = 0.2629 vf_loss = 0.0250 grad_norm = 2.3016 nat_grad_norm = 0.2292 cg_residual = 0.9116 step_size = 0.3313 reward = 0.0000 fps = 87 mse_loss = 3.1577 
2022-07-08 15:21:58.380166 - gail/main.py:174 - [TRPO] iter = 544000 dist_mean = 0.1755 dist_std = 0.2630 vf_loss = 0.0366 grad_norm = 1.7377 nat_grad_norm = 0.2939 cg_residual = 0.8051 step_size = 0.2914 reward = -0.0000 fps = 79 mse_loss = 3.1866 
2022-07-08 15:21:59.570491 - gail/main.py:174 - [TRPO] iter = 545000 dist_mean = 0.1341 dist_std = 0.2616 vf_loss = 0.0334 grad_norm = 2.4161 nat_grad_norm = 0.2337 cg_residual = 0.7450 step_size = 0.3095 reward = 0.0000 fps = 72 mse_loss = 3.2641 
2022-07-08 15:21:59.621503 - gail/main.py:201 - [Discriminator] iter = 545000 loss = -3.1662 grad_norm = 3.3863 grad_penalty = 0.2115 regularization = 0.0000 true_logits = -0.8325 fake_logits = -4.2103 true_prob = 0.3906 fake_prob = 0.0707 
2022-07-08 15:22:07.135920 - gail/main.py:142 - [Evaluate] iter = 545000 episode={ returns = 2005.0820 lengths = 488 } discounted_episode={ returns = 1493.2084 lengths = 476 } 
2022-07-08 15:22:08.316696 - gail/main.py:174 - [TRPO] iter = 546000 dist_mean = 0.1322 dist_std = 0.2608 vf_loss = 0.0412 grad_norm = 2.6932 nat_grad_norm = 0.2277 cg_residual = 0.9002 step_size = 0.3229 reward = 0.0000 fps = 115 mse_loss = 3.1763 
2022-07-08 15:22:09.555736 - gail/main.py:174 - [TRPO] iter = 547000 dist_mean = 0.1759 dist_std = 0.2590 vf_loss = 0.0196 grad_norm = 1.9705 nat_grad_norm = 0.2684 cg_residual = 0.7647 step_size = 0.3206 reward = -0.0000 fps = 100 mse_loss = 3.0247 
2022-07-08 15:22:11.206502 - gail/main.py:174 - [TRPO] iter = 548000 dist_mean = 0.1668 dist_std = 0.2581 vf_loss = 0.0201 grad_norm = 2.5916 nat_grad_norm = 0.2662 cg_residual = 1.2799 step_size = 0.2926 reward = 0.0000 fps = 86 mse_loss = 3.1475 
2022-07-08 15:22:12.945661 - gail/main.py:174 - [TRPO] iter = 549000 dist_mean = 0.1791 dist_std = 0.2596 vf_loss = 0.0238 grad_norm = 2.3941 nat_grad_norm = 0.2552 cg_residual = 1.2799 step_size = 0.2844 reward = 0.0000 fps = 75 mse_loss = 3.1994 
2022-07-08 15:22:14.639884 - gail/main.py:174 - [TRPO] iter = 550000 dist_mean = 0.1755 dist_std = 0.2591 vf_loss = 0.0249 grad_norm = 2.1447 nat_grad_norm = 0.1932 cg_residual = 0.7262 step_size = 0.3675 reward = -0.0000 fps = 66 mse_loss = 3.1863 
2022-07-08 15:22:14.716035 - gail/main.py:201 - [Discriminator] iter = 550000 loss = -2.5370 grad_norm = 3.5212 grad_penalty = 0.1847 regularization = 0.0000 true_logits = -0.8671 fake_logits = -3.5888 true_prob = 0.3921 fake_prob = 0.0786 
2022-07-08 15:22:25.330224 - gail/main.py:142 - [Evaluate] iter = 550000 episode={ returns = 1796.1034 lengths = 442 } discounted_episode={ returns = 1377.0495 lengths = 435 } 
2022-07-08 15:22:27.133352 - gail/main.py:174 - [TRPO] iter = 551000 dist_mean = 0.1477 dist_std = 0.2592 vf_loss = 0.0268 grad_norm = 1.7884 nat_grad_norm = 0.2241 cg_residual = 0.7849 step_size = 0.3765 reward = 0.0000 fps = 80 mse_loss = 3.1826 
2022-07-08 15:22:28.986934 - gail/main.py:174 - [TRPO] iter = 552000 dist_mean = 0.1549 dist_std = 0.2585 vf_loss = 0.0362 grad_norm = 2.6027 nat_grad_norm = 0.2408 cg_residual = 1.3059 step_size = 0.3066 reward = -0.0000 fps = 70 mse_loss = 3.2403 
2022-07-08 15:22:30.781638 - gail/main.py:174 - [TRPO] iter = 553000 dist_mean = 0.1472 dist_std = 0.2574 vf_loss = 0.0380 grad_norm = 2.4397 nat_grad_norm = 0.2817 cg_residual = 1.3647 step_size = 0.2916 reward = 0.0000 fps = 62 mse_loss = 3.1995 
2022-07-08 15:22:32.817538 - gail/main.py:174 - [TRPO] iter = 554000 dist_mean = 0.1790 dist_std = 0.2569 vf_loss = 0.0322 grad_norm = 2.4527 nat_grad_norm = 0.2510 cg_residual = 0.9960 step_size = 0.3076 reward = -0.0000 fps = 55 mse_loss = 3.2809 
2022-07-08 15:22:34.642240 - gail/main.py:174 - [TRPO] iter = 555000 dist_mean = 0.1472 dist_std = 0.2561 vf_loss = 0.0264 grad_norm = 2.5758 nat_grad_norm = 0.2200 cg_residual = 0.9809 step_size = 0.3149 reward = -0.0000 fps = 50 mse_loss = 3.2732 
2022-07-08 15:22:34.718553 - gail/main.py:201 - [Discriminator] iter = 555000 loss = -2.6749 grad_norm = 3.3302 grad_penalty = 0.1662 regularization = 0.0000 true_logits = -1.0053 fake_logits = -3.8465 true_prob = 0.3623 fake_prob = 0.0682 
2022-07-08 15:22:44.779694 - gail/main.py:142 - [Evaluate] iter = 555000 episode={ returns = 1983.3213 lengths = 488 } discounted_episode={ returns = 1398.8848 lengths = 450 } 
2022-07-08 15:22:46.552684 - gail/main.py:174 - [TRPO] iter = 556000 dist_mean = 0.1778 dist_std = 0.2556 vf_loss = 0.0377 grad_norm = 2.0588 nat_grad_norm = 0.2317 cg_residual = 0.9055 step_size = 0.3360 reward = -0.0000 fps = 84 mse_loss = 3.3263 
2022-07-08 15:22:48.252092 - gail/main.py:174 - [TRPO] iter = 557000 dist_mean = 0.1285 dist_std = 0.2552 vf_loss = 0.0288 grad_norm = 2.1941 nat_grad_norm = 0.2250 cg_residual = 0.9724 step_size = 0.3200 reward = 0.0000 fps = 73 mse_loss = 3.2547 
2022-07-08 15:22:49.972396 - gail/main.py:174 - [TRPO] iter = 558000 dist_mean = 0.1921 dist_std = 0.2545 vf_loss = 0.0278 grad_norm = 2.4513 nat_grad_norm = 0.2119 cg_residual = 1.0433 step_size = 0.3245 reward = -0.0000 fps = 65 mse_loss = 3.3175 
2022-07-08 15:22:51.793390 - gail/main.py:174 - [TRPO] iter = 559000 dist_mean = 0.1906 dist_std = 0.2535 vf_loss = 0.0265 grad_norm = 2.5052 nat_grad_norm = 0.2026 cg_residual = 0.8578 step_size = 0.3156 reward = 0.0000 fps = 58 mse_loss = 3.1230 
2022-07-08 15:22:53.618027 - gail/main.py:174 - [TRPO] iter = 560000 dist_mean = 0.1771 dist_std = 0.2530 vf_loss = 0.0257 grad_norm = 2.2782 nat_grad_norm = 0.2447 cg_residual = 0.9509 step_size = 0.3171 reward = -0.0000 fps = 52 mse_loss = 3.2742 
2022-07-08 15:22:53.698923 - gail/main.py:201 - [Discriminator] iter = 560000 loss = -2.5165 grad_norm = 2.7339 grad_penalty = 0.1558 regularization = 0.0000 true_logits = -0.9956 fake_logits = -3.6680 true_prob = 0.3627 fake_prob = 0.0673 
2022-07-08 15:23:02.055010 - gail/main.py:142 - [Evaluate] iter = 560000 episode={ returns = 1589.7218 lengths = 406 } discounted_episode={ returns = 1223.8475 lengths = 392 } 
2022-07-08 15:23:03.247334 - gail/main.py:174 - [TRPO] iter = 561000 dist_mean = 0.1374 dist_std = 0.2525 vf_loss = 0.0210 grad_norm = 2.6131 nat_grad_norm = 0.1969 cg_residual = 0.6251 step_size = 0.3432 reward = -0.0000 fps = 104 mse_loss = 3.1378 
2022-07-08 15:23:04.434554 - gail/main.py:174 - [TRPO] iter = 562000 dist_mean = 0.1458 dist_std = 0.2527 vf_loss = 0.0212 grad_norm = 2.5404 nat_grad_norm = 0.2326 cg_residual = 1.2270 step_size = 0.3284 reward = 0.0000 fps = 93 mse_loss = 3.1545 
2022-07-08 15:23:05.620189 - gail/main.py:174 - [TRPO] iter = 563000 dist_mean = 0.1747 dist_std = 0.2525 vf_loss = 0.0228 grad_norm = 1.7159 nat_grad_norm = 0.2383 cg_residual = 0.8039 step_size = 0.3467 reward = 0.0000 fps = 83 mse_loss = 2.9909 
2022-07-08 15:23:06.822854 - gail/main.py:174 - [TRPO] iter = 564000 dist_mean = 0.1447 dist_std = 0.2519 vf_loss = 0.0272 grad_norm = 2.3414 nat_grad_norm = 0.2167 cg_residual = 0.9564 step_size = 0.3277 reward = 0.0000 fps = 76 mse_loss = 3.1411 
2022-07-08 15:23:08.012343 - gail/main.py:174 - [TRPO] iter = 565000 dist_mean = 0.1652 dist_std = 0.2520 vf_loss = 0.0230 grad_norm = 2.4899 nat_grad_norm = 0.2131 cg_residual = 1.2168 step_size = 0.3168 reward = -0.0000 fps = 69 mse_loss = 3.0928 
2022-07-08 15:23:08.072503 - gail/main.py:201 - [Discriminator] iter = 565000 loss = -2.5923 grad_norm = 2.9133 grad_penalty = 0.1798 regularization = 0.0000 true_logits = -1.0925 fake_logits = -3.8646 true_prob = 0.3540 fake_prob = 0.0581 
2022-07-08 15:23:18.982390 - gail/main.py:142 - [Evaluate] iter = 565000 episode={ returns = 2050.6848 lengths = 492 } discounted_episode={ returns = 1625.5115 lengths = 518 } 
2022-07-08 15:23:20.743297 - gail/main.py:174 - [TRPO] iter = 566000 dist_mean = 0.1710 dist_std = 0.2509 vf_loss = 0.0241 grad_norm = 2.0307 nat_grad_norm = 0.2175 cg_residual = 0.7547 step_size = 0.3406 reward = -0.0000 fps = 78 mse_loss = 3.0784 
2022-07-08 15:23:22.394026 - gail/main.py:174 - [TRPO] iter = 567000 dist_mean = 0.1541 dist_std = 0.2506 vf_loss = 0.0164 grad_norm = 1.9978 nat_grad_norm = 0.2194 cg_residual = 0.8180 step_size = 0.3389 reward = 0.0000 fps = 69 mse_loss = 3.0116 
2022-07-08 15:23:24.094757 - gail/main.py:174 - [TRPO] iter = 568000 dist_mean = 0.1077 dist_std = 0.2510 vf_loss = 0.0177 grad_norm = 2.5768 nat_grad_norm = 0.1894 cg_residual = 0.9222 step_size = 0.3412 reward = -0.0000 fps = 62 mse_loss = 3.0805 
2022-07-08 15:23:25.756970 - gail/main.py:174 - [TRPO] iter = 569000 dist_mean = 0.1479 dist_std = 0.2508 vf_loss = 0.0205 grad_norm = 1.9445 nat_grad_norm = 0.2101 cg_residual = 0.7750 step_size = 0.3616 reward = 0.0000 fps = 56 mse_loss = 3.1038 
2022-07-08 15:23:27.396416 - gail/main.py:174 - [TRPO] iter = 570000 dist_mean = 0.1522 dist_std = 0.2515 vf_loss = 0.0206 grad_norm = 2.7471 nat_grad_norm = 0.2780 cg_residual = 1.4076 step_size = 0.2877 reward = -0.0000 fps = 51 mse_loss = 2.9146 
2022-07-08 15:23:27.475638 - gail/main.py:201 - [Discriminator] iter = 570000 loss = -3.1249 grad_norm = 3.0410 grad_penalty = 0.2033 regularization = 0.0000 true_logits = -1.0119 fake_logits = -4.3400 true_prob = 0.3635 fake_prob = 0.0424 
2022-07-08 15:23:37.013001 - gail/main.py:142 - [Evaluate] iter = 570000 episode={ returns = 1756.0352 lengths = 429 } discounted_episode={ returns = 1447.4382 lengths = 452 } 
2022-07-08 15:23:38.676379 - gail/main.py:174 - [TRPO] iter = 571000 dist_mean = 0.1356 dist_std = 0.2496 vf_loss = 0.0169 grad_norm = 2.0579 nat_grad_norm = 0.2015 cg_residual = 1.0230 step_size = 0.3564 reward = -0.0000 fps = 89 mse_loss = 3.0633 
2022-07-08 15:23:40.617742 - gail/main.py:174 - [TRPO] iter = 572000 dist_mean = 0.1330 dist_std = 0.2488 vf_loss = 0.0175 grad_norm = 2.4462 nat_grad_norm = 0.2260 cg_residual = 0.9522 step_size = 0.3081 reward = 0.0000 fps = 76 mse_loss = 3.0391 
2022-07-08 15:23:42.373083 - gail/main.py:174 - [TRPO] iter = 573000 dist_mean = 0.1380 dist_std = 0.2484 vf_loss = 0.0188 grad_norm = 2.6106 nat_grad_norm = 0.1972 cg_residual = 0.8450 step_size = 0.3204 reward = 0.0000 fps = 67 mse_loss = 3.1617 
2022-07-08 15:23:44.286057 - gail/main.py:174 - [TRPO] iter = 574000 dist_mean = 0.1505 dist_std = 0.2484 vf_loss = 0.0129 grad_norm = 2.1592 nat_grad_norm = 0.2492 cg_residual = 1.2971 step_size = 0.3065 reward = 0.0000 fps = 59 mse_loss = 3.0102 
2022-07-08 15:23:46.377428 - gail/main.py:174 - [TRPO] iter = 575000 dist_mean = 0.1533 dist_std = 0.2479 vf_loss = 0.0166 grad_norm = 2.2478 nat_grad_norm = 0.2116 cg_residual = 1.0512 step_size = 0.3265 reward = 0.0000 fps = 52 mse_loss = 3.1524 
2022-07-08 15:23:46.454919 - gail/main.py:201 - [Discriminator] iter = 575000 loss = -2.6252 grad_norm = 2.6051 grad_penalty = 0.1854 regularization = 0.0000 true_logits = -1.0099 fake_logits = -3.8205 true_prob = 0.3616 fake_prob = 0.0655 
2022-07-08 15:23:57.903433 - gail/main.py:142 - [Evaluate] iter = 575000 episode={ returns = 2108.4821 lengths = 507 } discounted_episode={ returns = 1607.2454 lengths = 512 } 
2022-07-08 15:23:59.465368 - gail/main.py:174 - [TRPO] iter = 576000 dist_mean = 0.1400 dist_std = 0.2482 vf_loss = 0.0238 grad_norm = 2.1775 nat_grad_norm = 0.2155 cg_residual = 1.0098 step_size = 0.3564 reward = -0.0000 fps = 76 mse_loss = 3.0746 
2022-07-08 15:24:00.680187 - gail/main.py:174 - [TRPO] iter = 577000 dist_mean = 0.1247 dist_std = 0.2468 vf_loss = 0.0185 grad_norm = 2.5859 nat_grad_norm = 0.2244 cg_residual = 0.9960 step_size = 0.3239 reward = 0.0000 fps = 70 mse_loss = 3.1345 
2022-07-08 15:24:01.878979 - gail/main.py:174 - [TRPO] iter = 578000 dist_mean = 0.1105 dist_std = 0.2466 vf_loss = 0.0183 grad_norm = 2.5635 nat_grad_norm = 0.2351 cg_residual = 1.6182 step_size = 0.2987 reward = -0.0000 fps = 64 mse_loss = 3.1493 
2022-07-08 15:24:03.060096 - gail/main.py:174 - [TRPO] iter = 579000 dist_mean = 0.1613 dist_std = 0.2471 vf_loss = 0.0176 grad_norm = 2.5469 nat_grad_norm = 0.2069 cg_residual = 1.0605 step_size = 0.3369 reward = -0.0000 fps = 60 mse_loss = 3.0412 
2022-07-08 15:24:04.252677 - gail/main.py:174 - [TRPO] iter = 580000 dist_mean = 0.1188 dist_std = 0.2469 vf_loss = 0.0156 grad_norm = 2.4503 nat_grad_norm = 0.2086 cg_residual = 1.2449 step_size = 0.3138 reward = -0.0000 fps = 56 mse_loss = 3.2777 
2022-07-08 15:24:04.307838 - gail/main.py:201 - [Discriminator] iter = 580000 loss = -2.7886 grad_norm = 2.5390 grad_penalty = 0.1872 regularization = 0.0000 true_logits = -1.0010 fake_logits = -3.9767 true_prob = 0.3566 fake_prob = 0.0635 
2022-07-08 15:24:10.413721 - gail/main.py:142 - [Evaluate] iter = 580000 episode={ returns = 1534.3711 lengths = 383 } discounted_episode={ returns = 1311.9647 lengths = 407 } 
2022-07-08 15:24:11.601833 - gail/main.py:174 - [TRPO] iter = 581000 dist_mean = 0.1704 dist_std = 0.2471 vf_loss = 0.0195 grad_norm = 2.6608 nat_grad_norm = 0.2449 cg_residual = 0.9178 step_size = 0.3024 reward = 0.0000 fps = 137 mse_loss = 3.2432 
2022-07-08 15:24:12.812904 - gail/main.py:174 - [TRPO] iter = 582000 dist_mean = 0.1495 dist_std = 0.2477 vf_loss = 0.0224 grad_norm = 2.8079 nat_grad_norm = 0.2305 cg_residual = 0.8195 step_size = 0.3058 reward = 0.0000 fps = 117 mse_loss = 3.3410 
2022-07-08 15:24:14.020098 - gail/main.py:174 - [TRPO] iter = 583000 dist_mean = 0.1611 dist_std = 0.2475 vf_loss = 0.0286 grad_norm = 1.9050 nat_grad_norm = 0.1909 cg_residual = 0.9382 step_size = 0.3640 reward = -0.0000 fps = 102 mse_loss = 3.0882 
2022-07-08 15:24:15.254054 - gail/main.py:174 - [TRPO] iter = 584000 dist_mean = 0.1599 dist_std = 0.2470 vf_loss = 0.0239 grad_norm = 2.3705 nat_grad_norm = 0.2108 cg_residual = 1.0527 step_size = 0.3330 reward = 0.0000 fps = 91 mse_loss = 3.3180 
2022-07-08 15:24:16.534493 - gail/main.py:174 - [TRPO] iter = 585000 dist_mean = 0.1426 dist_std = 0.2465 vf_loss = 0.0194 grad_norm = 2.7456 nat_grad_norm = 0.1887 cg_residual = 1.0236 step_size = 0.3468 reward = 0.0000 fps = 81 mse_loss = 3.2745 
2022-07-08 15:24:16.586850 - gail/main.py:201 - [Discriminator] iter = 585000 loss = -2.8942 grad_norm = 2.6914 grad_penalty = 0.1832 regularization = 0.0000 true_logits = -1.0604 fake_logits = -4.1378 true_prob = 0.3406 fake_prob = 0.0530 
2022-07-08 15:24:22.178990 - gail/main.py:142 - [Evaluate] iter = 585000 episode={ returns = 1471.9802 lengths = 368 } discounted_episode={ returns = 1181.7421 lengths = 365 } 
2022-07-08 15:24:23.367937 - gail/main.py:174 - [TRPO] iter = 586000 dist_mean = 0.1700 dist_std = 0.2472 vf_loss = 0.0284 grad_norm = 1.6874 nat_grad_norm = 0.2246 cg_residual = 0.9423 step_size = 0.3535 reward = -0.0000 fps = 147 mse_loss = 3.2089 
2022-07-08 15:24:24.557388 - gail/main.py:174 - [TRPO] iter = 587000 dist_mean = 0.1265 dist_std = 0.2467 vf_loss = 0.0196 grad_norm = 2.8644 nat_grad_norm = 0.1991 cg_residual = 0.9783 step_size = 0.3121 reward = 0.0000 fps = 125 mse_loss = 3.0670 
2022-07-08 15:24:25.740938 - gail/main.py:174 - [TRPO] iter = 588000 dist_mean = 0.1583 dist_std = 0.2465 vf_loss = 0.0179 grad_norm = 1.8452 nat_grad_norm = 0.2144 cg_residual = 1.0130 step_size = 0.3612 reward = 0.0000 fps = 109 mse_loss = 3.2232 
2022-07-08 15:24:26.936478 - gail/main.py:174 - [TRPO] iter = 589000 dist_mean = 0.1124 dist_std = 0.2457 vf_loss = 0.0606 grad_norm = 2.6654 nat_grad_norm = 0.2236 cg_residual = 1.5703 step_size = 0.3014 reward = 0.0000 fps = 96 mse_loss = 3.2234 
2022-07-08 15:24:28.122650 - gail/main.py:174 - [TRPO] iter = 590000 dist_mean = 0.1544 dist_std = 0.2448 vf_loss = 0.0190 grad_norm = 1.7059 nat_grad_norm = 0.2198 cg_residual = 0.8817 step_size = 0.3504 reward = 0.0000 fps = 86 mse_loss = 3.2785 
2022-07-08 15:24:28.176426 - gail/main.py:201 - [Discriminator] iter = 590000 loss = -2.7886 grad_norm = 2.9584 grad_penalty = 0.2099 regularization = 0.0000 true_logits = -1.1179 fake_logits = -4.1164 true_prob = 0.3408 fake_prob = 0.0465 
2022-07-08 15:24:34.675880 - gail/main.py:142 - [Evaluate] iter = 590000 episode={ returns = 1512.1310 lengths = 373 } discounted_episode={ returns = 1193.8763 lengths = 364 } 
2022-07-08 15:24:35.857883 - gail/main.py:174 - [TRPO] iter = 591000 dist_mean = 0.1208 dist_std = 0.2443 vf_loss = 0.0158 grad_norm = 2.7380 nat_grad_norm = 0.2284 cg_residual = 1.3754 step_size = 0.3149 reward = -0.0000 fps = 130 mse_loss = 3.2180 
2022-07-08 15:24:37.036837 - gail/main.py:174 - [TRPO] iter = 592000 dist_mean = 0.1218 dist_std = 0.2435 vf_loss = 0.0643 grad_norm = 1.8408 nat_grad_norm = 0.2169 cg_residual = 1.4227 step_size = 0.3414 reward = -0.0000 fps = 112 mse_loss = 3.1903 
2022-07-08 15:24:38.230904 - gail/main.py:174 - [TRPO] iter = 593000 dist_mean = 0.1148 dist_std = 0.2424 vf_loss = 0.0256 grad_norm = 2.6898 nat_grad_norm = 0.2070 cg_residual = 0.9663 step_size = 0.3418 reward = 0.0000 fps = 99 mse_loss = 3.4030 
2022-07-08 15:24:39.446790 - gail/main.py:174 - [TRPO] iter = 594000 dist_mean = 0.1398 dist_std = 0.2424 vf_loss = 0.0370 grad_norm = 2.8246 nat_grad_norm = 0.2029 cg_residual = 1.5361 step_size = 0.3251 reward = -0.0000 fps = 88 mse_loss = 3.4116 
2022-07-08 15:24:40.632954 - gail/main.py:174 - [TRPO] iter = 595000 dist_mean = 0.1538 dist_std = 0.2418 vf_loss = 0.0362 grad_norm = 2.2619 nat_grad_norm = 0.2209 cg_residual = 0.8144 step_size = 0.3053 reward = 0.0000 fps = 80 mse_loss = 3.1173 
2022-07-08 15:24:40.681490 - gail/main.py:201 - [Discriminator] iter = 595000 loss = -2.8389 grad_norm = 3.0555 grad_penalty = 0.1975 regularization = 0.0000 true_logits = -1.0889 fake_logits = -4.1253 true_prob = 0.3402 fake_prob = 0.0485 
2022-07-08 15:24:46.562499 - gail/main.py:142 - [Evaluate] iter = 595000 episode={ returns = 1540.1535 lengths = 381 } discounted_episode={ returns = 1230.6354 lengths = 378 } 
2022-07-08 15:24:47.756969 - gail/main.py:174 - [TRPO] iter = 596000 dist_mean = 0.1439 dist_std = 0.2414 vf_loss = 0.1064 grad_norm = 3.0210 nat_grad_norm = 0.1959 cg_residual = 1.1811 step_size = 0.3427 reward = -0.0000 fps = 141 mse_loss = 3.4292 
2022-07-08 15:24:48.954479 - gail/main.py:174 - [TRPO] iter = 597000 dist_mean = 0.1426 dist_std = 0.2405 vf_loss = 0.0246 grad_norm = 2.3024 nat_grad_norm = 0.2382 cg_residual = 1.3438 step_size = 0.3048 reward = 0.0000 fps = 120 mse_loss = 3.2501 
2022-07-08 15:24:50.146193 - gail/main.py:174 - [TRPO] iter = 598000 dist_mean = 0.0910 dist_std = 0.2398 vf_loss = 0.0239 grad_norm = 2.7597 nat_grad_norm = 0.2013 cg_residual = 1.2941 step_size = 0.3207 reward = 0.0000 fps = 105 mse_loss = 3.3015 
2022-07-08 15:24:51.324346 - gail/main.py:174 - [TRPO] iter = 599000 dist_mean = 0.1136 dist_std = 0.2394 vf_loss = 0.0186 grad_norm = 2.0166 nat_grad_norm = 0.1954 cg_residual = 1.0570 step_size = 0.3438 reward = 0.0000 fps = 93 mse_loss = 3.1667 
2022-07-08 15:24:52.502504 - gail/main.py:174 - [TRPO] iter = 600000 dist_mean = 0.1483 dist_std = 0.2390 vf_loss = 0.0240 grad_norm = 2.5067 nat_grad_norm = 0.2566 cg_residual = 1.2760 step_size = 0.2917 reward = 0.0000 fps = 84 mse_loss = 3.3910 
2022-07-08 15:24:52.552123 - gail/main.py:201 - [Discriminator] iter = 600000 loss = -2.7816 grad_norm = 2.8070 grad_penalty = 0.1830 regularization = 0.0000 true_logits = -0.9778 fake_logits = -3.9425 true_prob = 0.3532 fake_prob = 0.0571 
2022-07-08 15:24:58.802547 - gail/main.py:142 - [Evaluate] iter = 600000 episode={ returns = 1636.5215 lengths = 403 } discounted_episode={ returns = 1285.1774 lengths = 397 } 
2022-07-08 15:25:00.003551 - gail/main.py:174 - [TRPO] iter = 601000 dist_mean = 0.1683 dist_std = 0.2384 vf_loss = 0.0161 grad_norm = 2.0108 nat_grad_norm = 0.1936 cg_residual = 0.7098 step_size = 0.3482 reward = -0.0000 fps = 134 mse_loss = 3.0943 
2022-07-08 15:25:01.213402 - gail/main.py:174 - [TRPO] iter = 602000 dist_mean = 0.1314 dist_std = 0.2385 vf_loss = 0.0258 grad_norm = 2.8829 nat_grad_norm = 0.2030 cg_residual = 1.2541 step_size = 0.3192 reward = 0.0000 fps = 115 mse_loss = 3.3381 
2022-07-08 15:25:02.394680 - gail/main.py:174 - [TRPO] iter = 603000 dist_mean = 0.1379 dist_std = 0.2378 vf_loss = 0.0306 grad_norm = 2.2261 nat_grad_norm = 0.2237 cg_residual = 1.0567 step_size = 0.3353 reward = -0.0000 fps = 101 mse_loss = 3.2883 
2022-07-08 15:25:03.585244 - gail/main.py:174 - [TRPO] iter = 604000 dist_mean = 0.1078 dist_std = 0.2378 vf_loss = 0.0282 grad_norm = 2.4730 nat_grad_norm = 0.2145 cg_residual = 1.3384 step_size = 0.3184 reward = 0.0000 fps = 90 mse_loss = 3.2028 
2022-07-08 15:25:04.799840 - gail/main.py:174 - [TRPO] iter = 605000 dist_mean = 0.1305 dist_std = 0.2362 vf_loss = 0.0388 grad_norm = 2.6247 nat_grad_norm = 0.2121 cg_residual = 0.7466 step_size = 0.3323 reward = -0.0000 fps = 81 mse_loss = 3.1997 
2022-07-08 15:25:04.862591 - gail/main.py:201 - [Discriminator] iter = 605000 loss = -2.7134 grad_norm = 2.4613 grad_penalty = 0.1903 regularization = 0.0000 true_logits = -0.9086 fake_logits = -3.8123 true_prob = 0.3703 fake_prob = 0.0580 
2022-07-08 15:25:11.248961 - gail/main.py:142 - [Evaluate] iter = 605000 episode={ returns = 1701.8427 lengths = 419 } discounted_episode={ returns = 1298.8673 lengths = 406 } 
2022-07-08 15:25:12.440762 - gail/main.py:174 - [TRPO] iter = 606000 dist_mean = 0.1447 dist_std = 0.2358 vf_loss = 0.0190 grad_norm = 2.2979 nat_grad_norm = 0.2349 cg_residual = 1.3653 step_size = 0.3163 reward = 0.0000 fps = 132 mse_loss = 3.2919 
2022-07-08 15:25:13.636789 - gail/main.py:174 - [TRPO] iter = 607000 dist_mean = 0.1413 dist_std = 0.2347 vf_loss = 0.0190 grad_norm = 2.5368 nat_grad_norm = 0.1936 cg_residual = 1.1405 step_size = 0.3181 reward = -0.0000 fps = 114 mse_loss = 3.2262 
2022-07-08 15:25:14.856963 - gail/main.py:174 - [TRPO] iter = 608000 dist_mean = 0.1182 dist_std = 0.2345 vf_loss = 0.0225 grad_norm = 2.8822 nat_grad_norm = 0.2452 cg_residual = 2.0911 step_size = 0.2541 reward = 0.0000 fps = 100 mse_loss = 3.2394 
2022-07-08 15:25:16.062026 - gail/main.py:174 - [TRPO] iter = 609000 dist_mean = 0.1115 dist_std = 0.2339 vf_loss = 0.0178 grad_norm = 2.4040 nat_grad_norm = 0.1805 cg_residual = 0.7253 step_size = 0.3144 reward = -0.0000 fps = 89 mse_loss = 3.3637 
2022-07-08 15:25:17.291702 - gail/main.py:174 - [TRPO] iter = 610000 dist_mean = 0.1022 dist_std = 0.2337 vf_loss = 0.0329 grad_norm = 2.9291 nat_grad_norm = 0.2004 cg_residual = 1.7054 step_size = 0.3042 reward = 0.0000 fps = 80 mse_loss = 3.2034 
2022-07-08 15:25:17.345399 - gail/main.py:201 - [Discriminator] iter = 610000 loss = -2.9430 grad_norm = 2.6942 grad_penalty = 0.2030 regularization = 0.0000 true_logits = -0.9445 fake_logits = -4.0905 true_prob = 0.3661 fake_prob = 0.0555 
2022-07-08 15:25:22.537627 - gail/main.py:142 - [Evaluate] iter = 610000 episode={ returns = 1329.7016 lengths = 343 } discounted_episode={ returns = 1042.1299 lengths = 330 } 
2022-07-08 15:25:23.731517 - gail/main.py:174 - [TRPO] iter = 611000 dist_mean = 0.1204 dist_std = 0.2331 vf_loss = 0.0180 grad_norm = 2.6175 nat_grad_norm = 0.2409 cg_residual = 1.4496 step_size = 0.3058 reward = 0.0000 fps = 156 mse_loss = 2.9927 
2022-07-08 15:25:24.924545 - gail/main.py:174 - [TRPO] iter = 612000 dist_mean = 0.1235 dist_std = 0.2328 vf_loss = 0.0281 grad_norm = 2.9312 nat_grad_norm = 0.1844 cg_residual = 1.3552 step_size = 0.3315 reward = -0.0000 fps = 132 mse_loss = 3.3927 
2022-07-08 15:25:26.097356 - gail/main.py:174 - [TRPO] iter = 613000 dist_mean = 0.1223 dist_std = 0.2325 vf_loss = 0.0242 grad_norm = 2.4540 nat_grad_norm = 0.1741 cg_residual = 1.2702 step_size = 0.3707 reward = -0.0000 fps = 114 mse_loss = 3.1508 
2022-07-08 15:25:27.299752 - gail/main.py:174 - [TRPO] iter = 614000 dist_mean = 0.1442 dist_std = 0.2323 vf_loss = 0.0282 grad_norm = 2.4990 nat_grad_norm = 0.2364 cg_residual = 1.6275 step_size = 0.2893 reward = -0.0000 fps = 100 mse_loss = 3.0657 
2022-07-08 15:25:28.495008 - gail/main.py:174 - [TRPO] iter = 615000 dist_mean = 0.1435 dist_std = 0.2330 vf_loss = 0.0451 grad_norm = 2.0169 nat_grad_norm = 0.1931 cg_residual = 1.0726 step_size = 0.3735 reward = -0.0000 fps = 89 mse_loss = 3.2038 
2022-07-08 15:25:28.543962 - gail/main.py:201 - [Discriminator] iter = 615000 loss = -2.9605 grad_norm = 2.9419 grad_penalty = 0.1984 regularization = 0.0000 true_logits = -0.8795 fake_logits = -4.0383 true_prob = 0.3711 fake_prob = 0.0507 
2022-07-08 15:25:33.676969 - gail/main.py:142 - [Evaluate] iter = 615000 episode={ returns = 1292.3247 lengths = 337 } discounted_episode={ returns = 1029.3927 lengths = 328 } 
2022-07-08 15:25:34.876525 - gail/main.py:174 - [TRPO] iter = 616000 dist_mean = 0.1470 dist_std = 0.2321 vf_loss = 0.0221 grad_norm = 3.1912 nat_grad_norm = 0.2063 cg_residual = 1.6498 step_size = 0.3143 reward = -0.0000 fps = 158 mse_loss = 3.3939 
2022-07-08 15:25:36.058419 - gail/main.py:174 - [TRPO] iter = 617000 dist_mean = 0.1403 dist_std = 0.2319 vf_loss = 0.0173 grad_norm = 2.9411 nat_grad_norm = 0.2094 cg_residual = 1.4443 step_size = 0.3037 reward = 0.0000 fps = 133 mse_loss = 3.0890 
2022-07-08 15:25:37.246138 - gail/main.py:174 - [TRPO] iter = 618000 dist_mean = 0.1618 dist_std = 0.2318 vf_loss = 0.0275 grad_norm = 2.2627 nat_grad_norm = 0.1995 cg_residual = 0.9934 step_size = 0.3416 reward = -0.0000 fps = 114 mse_loss = 3.2208 
2022-07-08 15:25:38.419179 - gail/main.py:174 - [TRPO] iter = 619000 dist_mean = 0.1140 dist_std = 0.2310 vf_loss = 0.0180 grad_norm = 2.1213 nat_grad_norm = 0.1925 cg_residual = 1.5283 step_size = 0.3414 reward = 0.0000 fps = 101 mse_loss = 3.1012 
2022-07-08 15:25:39.604331 - gail/main.py:174 - [TRPO] iter = 620000 dist_mean = 0.1587 dist_std = 0.2304 vf_loss = 0.0195 grad_norm = 3.1520 nat_grad_norm = 0.1824 cg_residual = 1.3359 step_size = 0.3136 reward = 0.0000 fps = 90 mse_loss = 3.1304 
2022-07-08 15:25:39.655240 - gail/main.py:201 - [Discriminator] iter = 620000 loss = -2.3090 grad_norm = 3.1351 grad_penalty = 0.1609 regularization = 0.0000 true_logits = -0.9093 fake_logits = -3.3792 true_prob = 0.3626 fake_prob = 0.0744 
2022-07-08 15:25:44.576379 - gail/main.py:142 - [Evaluate] iter = 620000 episode={ returns = 1190.6491 lengths = 320 } discounted_episode={ returns = 970.4777 lengths = 315 } 
2022-07-08 15:25:45.758256 - gail/main.py:174 - [TRPO] iter = 621000 dist_mean = 0.1975 dist_std = 0.2298 vf_loss = 0.0245 grad_norm = 2.3877 nat_grad_norm = 0.2016 cg_residual = 0.8423 step_size = 0.3203 reward = -0.0000 fps = 163 mse_loss = 3.2038 
2022-07-08 15:25:46.950820 - gail/main.py:174 - [TRPO] iter = 622000 dist_mean = 0.1485 dist_std = 0.2300 vf_loss = 0.0342 grad_norm = 3.1450 nat_grad_norm = 0.1965 cg_residual = 1.6050 step_size = 0.3056 reward = 0.0000 fps = 137 mse_loss = 3.1179 
2022-07-08 15:25:48.155849 - gail/main.py:174 - [TRPO] iter = 623000 dist_mean = 0.2127 dist_std = 0.2294 vf_loss = 0.0277 grad_norm = 2.4201 nat_grad_norm = 0.1829 cg_residual = 1.0762 step_size = 0.3490 reward = -0.0000 fps = 117 mse_loss = 3.0492 
2022-07-08 15:25:49.353304 - gail/main.py:174 - [TRPO] iter = 624000 dist_mean = 0.1718 dist_std = 0.2286 vf_loss = 0.0332 grad_norm = 2.7964 nat_grad_norm = 0.2021 cg_residual = 0.8952 step_size = 0.3199 reward = -0.0000 fps = 103 mse_loss = 3.1021 
2022-07-08 15:25:50.550015 - gail/main.py:174 - [TRPO] iter = 625000 dist_mean = 0.1642 dist_std = 0.2288 vf_loss = 0.0341 grad_norm = 3.0767 nat_grad_norm = 0.2043 cg_residual = 0.8738 step_size = 0.2995 reward = 0.0000 fps = 91 mse_loss = 3.0127 
2022-07-08 15:25:50.601158 - gail/main.py:201 - [Discriminator] iter = 625000 loss = -2.2877 grad_norm = 2.7436 grad_penalty = 0.1509 regularization = 0.0000 true_logits = -0.9822 fake_logits = -3.4208 true_prob = 0.3548 fake_prob = 0.0647 
2022-07-08 15:25:57.841509 - gail/main.py:142 - [Evaluate] iter = 625000 episode={ returns = 1419.1842 lengths = 364 } discounted_episode={ returns = 1192.9612 lengths = 376 } 
2022-07-08 15:25:59.455832 - gail/main.py:174 - [TRPO] iter = 626000 dist_mean = 0.1486 dist_std = 0.2285 vf_loss = 0.0187 grad_norm = 3.0470 nat_grad_norm = 0.1647 cg_residual = 1.5404 step_size = 0.3347 reward = 0.0000 fps = 113 mse_loss = 2.9660 
2022-07-08 15:26:01.083299 - gail/main.py:174 - [TRPO] iter = 627000 dist_mean = 0.1140 dist_std = 0.2286 vf_loss = 0.0200 grad_norm = 2.8040 nat_grad_norm = 0.2146 cg_residual = 1.8304 step_size = 0.2676 reward = 0.0000 fps = 95 mse_loss = 3.2284 
2022-07-08 15:26:02.677581 - gail/main.py:174 - [TRPO] iter = 628000 dist_mean = 0.1227 dist_std = 0.2281 vf_loss = 0.0187 grad_norm = 2.7203 nat_grad_norm = 0.2045 cg_residual = 1.5611 step_size = 0.3224 reward = -0.0000 fps = 82 mse_loss = 3.1661 
2022-07-08 15:26:04.114087 - gail/main.py:174 - [TRPO] iter = 629000 dist_mean = 0.1334 dist_std = 0.2279 vf_loss = 0.0258 grad_norm = 2.7315 nat_grad_norm = 0.2352 cg_residual = 1.6500 step_size = 0.3029 reward = 0.0000 fps = 74 mse_loss = 3.1856 
2022-07-08 15:26:05.318338 - gail/main.py:174 - [TRPO] iter = 630000 dist_mean = 0.2058 dist_std = 0.2278 vf_loss = 0.0159 grad_norm = 2.1132 nat_grad_norm = 0.1882 cg_residual = 1.7993 step_size = 0.3467 reward = 0.0000 fps = 67 mse_loss = 2.9393 
2022-07-08 15:26:05.369836 - gail/main.py:201 - [Discriminator] iter = 630000 loss = -2.5137 grad_norm = 2.6990 grad_penalty = 0.1766 regularization = 0.0000 true_logits = -0.7379 fake_logits = -3.4282 true_prob = 0.3934 fake_prob = 0.0617 
2022-07-08 15:26:11.339208 - gail/main.py:142 - [Evaluate] iter = 630000 episode={ returns = 1544.5011 lengths = 388 } discounted_episode={ returns = 1241.9652 lengths = 389 } 
2022-07-08 15:26:12.532698 - gail/main.py:174 - [TRPO] iter = 631000 dist_mean = 0.1695 dist_std = 0.2277 vf_loss = 0.0163 grad_norm = 3.2303 nat_grad_norm = 0.2284 cg_residual = 2.0701 step_size = 0.2867 reward = -0.0000 fps = 139 mse_loss = 3.1825 
2022-07-08 15:26:13.713176 - gail/main.py:174 - [TRPO] iter = 632000 dist_mean = 0.1569 dist_std = 0.2270 vf_loss = 0.0226 grad_norm = 2.3354 nat_grad_norm = 0.1963 cg_residual = 1.4740 step_size = 0.3217 reward = -0.0000 fps = 119 mse_loss = 3.1371 
2022-07-08 15:26:14.894471 - gail/main.py:174 - [TRPO] iter = 633000 dist_mean = 0.1879 dist_std = 0.2264 vf_loss = 0.0162 grad_norm = 3.2146 nat_grad_norm = 0.2458 cg_residual = 1.7052 step_size = 0.2612 reward = 0.0000 fps = 105 mse_loss = 3.1550 
2022-07-08 15:26:16.072146 - gail/main.py:174 - [TRPO] iter = 634000 dist_mean = 0.1655 dist_std = 0.2257 vf_loss = 0.0152 grad_norm = 3.0865 nat_grad_norm = 0.2266 cg_residual = 2.1022 step_size = 0.2993 reward = 0.0000 fps = 93 mse_loss = 3.2117 
2022-07-08 15:26:17.272363 - gail/main.py:174 - [TRPO] iter = 635000 dist_mean = 0.1037 dist_std = 0.2249 vf_loss = 0.0289 grad_norm = 2.5848 nat_grad_norm = 0.2436 cg_residual = 3.1318 step_size = 0.2621 reward = 0.0000 fps = 84 mse_loss = 3.0683 
2022-07-08 15:26:17.324279 - gail/main.py:201 - [Discriminator] iter = 635000 loss = -2.8583 grad_norm = 3.2761 grad_penalty = 0.1893 regularization = 0.0000 true_logits = -0.6464 fake_logits = -3.6940 true_prob = 0.4053 fake_prob = 0.0723 
2022-07-08 15:26:23.647431 - gail/main.py:142 - [Evaluate] iter = 635000 episode={ returns = 1581.5308 lengths = 399 } discounted_episode={ returns = 1352.4300 lengths = 423 } 
2022-07-08 15:26:24.852587 - gail/main.py:174 - [TRPO] iter = 636000 dist_mean = 0.1702 dist_std = 0.2249 vf_loss = 0.0180 grad_norm = 2.9926 nat_grad_norm = 0.2571 cg_residual = 1.9964 step_size = 0.2672 reward = 0.0000 fps = 132 mse_loss = 3.0126 
2022-07-08 15:26:26.035124 - gail/main.py:174 - [TRPO] iter = 637000 dist_mean = 0.1223 dist_std = 0.2248 vf_loss = 0.0178 grad_norm = 2.8050 nat_grad_norm = 0.1828 cg_residual = 1.9434 step_size = 0.3313 reward = 0.0000 fps = 114 mse_loss = 3.1925 
2022-07-08 15:26:27.229011 - gail/main.py:174 - [TRPO] iter = 638000 dist_mean = 0.1586 dist_std = 0.2246 vf_loss = 0.0229 grad_norm = 2.6635 nat_grad_norm = 0.1977 cg_residual = 1.2563 step_size = 0.3512 reward = -0.0000 fps = 100 mse_loss = 2.9247 
2022-07-08 15:26:28.414068 - gail/main.py:174 - [TRPO] iter = 639000 dist_mean = 0.1535 dist_std = 0.2238 vf_loss = 0.0215 grad_norm = 3.2026 nat_grad_norm = 0.2115 cg_residual = 1.5402 step_size = 0.2864 reward = -0.0000 fps = 90 mse_loss = 2.8282 
2022-07-08 15:26:29.624768 - gail/main.py:174 - [TRPO] iter = 640000 dist_mean = 0.1259 dist_std = 0.2233 vf_loss = 0.0168 grad_norm = 3.4020 nat_grad_norm = 0.2016 cg_residual = 1.6961 step_size = 0.3010 reward = 0.0000 fps = 81 mse_loss = 2.9119 
2022-07-08 15:26:29.675889 - gail/main.py:201 - [Discriminator] iter = 640000 loss = -2.6491 grad_norm = 3.0703 grad_penalty = 0.1746 regularization = 0.0000 true_logits = -0.6593 fake_logits = -3.4830 true_prob = 0.4004 fake_prob = 0.0731 
2022-07-08 15:26:35.029040 - gail/main.py:142 - [Evaluate] iter = 640000 episode={ returns = 1426.2452 lengths = 347 } discounted_episode={ returns = 1165.5625 lengths = 345 } 
2022-07-08 15:26:36.225332 - gail/main.py:174 - [TRPO] iter = 641000 dist_mean = 0.1375 dist_std = 0.2231 vf_loss = 0.0196 grad_norm = 2.9795 nat_grad_norm = 0.2009 cg_residual = 1.3856 step_size = 0.3051 reward = 0.0000 fps = 152 mse_loss = 2.9440 
2022-07-08 15:26:37.433553 - gail/main.py:174 - [TRPO] iter = 642000 dist_mean = 0.0837 dist_std = 0.2227 vf_loss = 0.0194 grad_norm = 2.7729 nat_grad_norm = 0.2845 cg_residual = 2.4579 step_size = 0.2378 reward = 0.0000 fps = 128 mse_loss = 2.9448 
2022-07-08 15:26:38.633828 - gail/main.py:174 - [TRPO] iter = 643000 dist_mean = 0.1133 dist_std = 0.2223 vf_loss = 0.0173 grad_norm = 2.2666 nat_grad_norm = 0.2714 cg_residual = 2.9886 step_size = 0.2734 reward = 0.0000 fps = 111 mse_loss = 2.9193 
2022-07-08 15:26:39.856254 - gail/main.py:174 - [TRPO] iter = 644000 dist_mean = 0.1082 dist_std = 0.2219 vf_loss = 0.0181 grad_norm = 2.4178 nat_grad_norm = 0.2737 cg_residual = 1.7806 step_size = 0.2541 reward = 0.0000 fps = 98 mse_loss = 2.9061 
2022-07-08 15:26:41.043909 - gail/main.py:174 - [TRPO] iter = 645000 dist_mean = 0.0935 dist_std = 0.2221 vf_loss = 0.0207 grad_norm = 2.5381 nat_grad_norm = 0.1784 cg_residual = 1.7187 step_size = 0.3419 reward = 0.0000 fps = 87 mse_loss = 3.0187 
2022-07-08 15:26:41.097155 - gail/main.py:201 - [Discriminator] iter = 645000 loss = -2.8300 grad_norm = 3.5606 grad_penalty = 0.1937 regularization = 0.0000 true_logits = -0.8530 fake_logits = -3.8767 true_prob = 0.3767 fake_prob = 0.0614 
2022-07-08 15:26:46.085630 - gail/main.py:142 - [Evaluate] iter = 645000 episode={ returns = 1341.3099 lengths = 332 } discounted_episode={ returns = 1077.8028 lengths = 321 } 
2022-07-08 15:26:47.252988 - gail/main.py:174 - [TRPO] iter = 646000 dist_mean = 0.0840 dist_std = 0.2215 vf_loss = 0.0227 grad_norm = 2.7474 nat_grad_norm = 0.1973 cg_residual = 2.2094 step_size = 0.3085 reward = -0.0000 fps = 162 mse_loss = 2.9907 
2022-07-08 15:26:48.421190 - gail/main.py:174 - [TRPO] iter = 647000 dist_mean = 0.1077 dist_std = 0.2208 vf_loss = 0.0427 grad_norm = 2.9192 nat_grad_norm = 0.2149 cg_residual = 1.4869 step_size = 0.3096 reward = 0.0000 fps = 136 mse_loss = 2.8883 
2022-07-08 15:26:49.641947 - gail/main.py:174 - [TRPO] iter = 648000 dist_mean = 0.1082 dist_std = 0.2211 vf_loss = 0.0411 grad_norm = 3.1037 nat_grad_norm = 0.2131 cg_residual = 2.2079 step_size = 0.2755 reward = -0.0000 fps = 117 mse_loss = 3.1119 
2022-07-08 15:26:50.835880 - gail/main.py:174 - [TRPO] iter = 649000 dist_mean = 0.1058 dist_std = 0.2213 vf_loss = 0.0586 grad_norm = 2.2204 nat_grad_norm = 0.1853 cg_residual = 0.9527 step_size = 0.3643 reward = -0.0000 fps = 102 mse_loss = 2.8747 
2022-07-08 15:26:52.048630 - gail/main.py:174 - [TRPO] iter = 650000 dist_mean = 0.1253 dist_std = 0.2208 vf_loss = 0.0221 grad_norm = 2.6304 nat_grad_norm = 0.2262 cg_residual = 1.6168 step_size = 0.3092 reward = -0.0000 fps = 91 mse_loss = 2.9733 
2022-07-08 15:26:52.101336 - gail/main.py:201 - [Discriminator] iter = 650000 loss = -2.5404 grad_norm = 2.9946 grad_penalty = 0.1711 regularization = 0.0000 true_logits = -0.7806 fake_logits = -3.4921 true_prob = 0.3793 fake_prob = 0.0683 
2022-07-08 15:26:56.732046 - gail/main.py:142 - [Evaluate] iter = 650000 episode={ returns = 1184.5933 lengths = 299 } discounted_episode={ returns = 1008.4141 lengths = 302 } 
2022-07-08 15:26:57.914950 - gail/main.py:174 - [TRPO] iter = 651000 dist_mean = 0.1132 dist_std = 0.2206 vf_loss = 0.0247 grad_norm = 2.9113 nat_grad_norm = 0.2181 cg_residual = 2.8334 step_size = 0.3030 reward = -0.0000 fps = 172 mse_loss = 3.0246 
2022-07-08 15:26:59.127997 - gail/main.py:174 - [TRPO] iter = 652000 dist_mean = 0.1052 dist_std = 0.2208 vf_loss = 0.0159 grad_norm = 2.2711 nat_grad_norm = 0.1951 cg_residual = 1.7678 step_size = 0.3402 reward = -0.0000 fps = 142 mse_loss = 2.9236 
2022-07-08 15:27:01.073181 - gail/main.py:174 - [TRPO] iter = 653000 dist_mean = 0.1111 dist_std = 0.2202 vf_loss = 0.0221 grad_norm = 2.6082 nat_grad_norm = 0.2536 cg_residual = 2.1193 step_size = 0.2779 reward = -0.0000 fps = 111 mse_loss = 3.0101 
2022-07-08 15:27:03.062686 - gail/main.py:174 - [TRPO] iter = 654000 dist_mean = 0.0953 dist_std = 0.2195 vf_loss = 0.0262 grad_norm = 3.2200 nat_grad_norm = 0.2230 cg_residual = 2.2061 step_size = 0.2852 reward = -0.0000 fps = 91 mse_loss = 2.8974 
2022-07-08 15:27:05.054687 - gail/main.py:174 - [TRPO] iter = 655000 dist_mean = 0.1317 dist_std = 0.2192 vf_loss = 0.0206 grad_norm = 2.4420 nat_grad_norm = 0.2212 cg_residual = 1.4523 step_size = 0.3138 reward = -0.0000 fps = 77 mse_loss = 2.9784 
2022-07-08 15:27:05.139435 - gail/main.py:201 - [Discriminator] iter = 655000 loss = -2.5026 grad_norm = 2.6830 grad_penalty = 0.1708 regularization = 0.0000 true_logits = -0.8907 fake_logits = -3.5641 true_prob = 0.3757 fake_prob = 0.0626 
2022-07-08 15:27:16.226531 - gail/main.py:142 - [Evaluate] iter = 655000 episode={ returns = 2013.6347 lengths = 490 } discounted_episode={ returns = 1552.7714 lengths = 494 } 
2022-07-08 15:27:18.198556 - gail/main.py:174 - [TRPO] iter = 656000 dist_mean = 0.1921 dist_std = 0.2188 vf_loss = 0.0176 grad_norm = 3.0609 nat_grad_norm = 0.1586 cg_residual = 1.8567 step_size = 0.3558 reward = -0.0000 fps = 76 mse_loss = 2.9491 
2022-07-08 15:27:19.989826 - gail/main.py:174 - [TRPO] iter = 657000 dist_mean = 0.1264 dist_std = 0.2179 vf_loss = 0.0197 grad_norm = 2.6378 nat_grad_norm = 0.1903 cg_residual = 1.4285 step_size = 0.3125 reward = 0.0000 fps = 67 mse_loss = 2.9094 
2022-07-08 15:27:21.725962 - gail/main.py:174 - [TRPO] iter = 658000 dist_mean = 0.1357 dist_std = 0.2183 vf_loss = 0.0159 grad_norm = 2.3742 nat_grad_norm = 0.2199 cg_residual = 1.9058 step_size = 0.2974 reward = -0.0000 fps = 60 mse_loss = 2.7754 
2022-07-08 15:27:23.500161 - gail/main.py:174 - [TRPO] iter = 659000 dist_mean = 0.1997 dist_std = 0.2186 vf_loss = 0.0197 grad_norm = 2.3175 nat_grad_norm = 0.2214 cg_residual = 1.4465 step_size = 0.3173 reward = -0.0000 fps = 54 mse_loss = 2.8329 
2022-07-08 15:27:25.224823 - gail/main.py:174 - [TRPO] iter = 660000 dist_mean = 0.1485 dist_std = 0.2188 vf_loss = 0.0152 grad_norm = 2.8632 nat_grad_norm = 0.2017 cg_residual = 1.5181 step_size = 0.3182 reward = 0.0000 fps = 49 mse_loss = 2.7827 
2022-07-08 15:27:25.303186 - gail/main.py:201 - [Discriminator] iter = 660000 loss = -2.6557 grad_norm = 2.6918 grad_penalty = 0.1805 regularization = 0.0000 true_logits = -0.7640 fake_logits = -3.6002 true_prob = 0.3833 fake_prob = 0.0606 
2022-07-08 15:27:36.893663 - gail/main.py:142 - [Evaluate] iter = 660000 episode={ returns = 2217.0347 lengths = 533 } discounted_episode={ returns = 1656.8293 lengths = 533 } 
2022-07-08 15:27:38.703532 - gail/main.py:174 - [TRPO] iter = 661000 dist_mean = 0.1278 dist_std = 0.2182 vf_loss = 0.0131 grad_norm = 3.3107 nat_grad_norm = 0.2364 cg_residual = 1.2630 step_size = 0.2815 reward = -0.0000 fps = 74 mse_loss = 2.9672 
2022-07-08 15:27:40.636530 - gail/main.py:174 - [TRPO] iter = 662000 dist_mean = 0.1358 dist_std = 0.2174 vf_loss = 0.0138 grad_norm = 2.5284 nat_grad_norm = 0.2527 cg_residual = 1.7052 step_size = 0.2744 reward = 0.0000 fps = 65 mse_loss = 2.9429 
2022-07-08 15:27:42.629306 - gail/main.py:174 - [TRPO] iter = 663000 dist_mean = 0.1525 dist_std = 0.2174 vf_loss = 0.0149 grad_norm = 3.1290 nat_grad_norm = 0.2491 cg_residual = 2.0260 step_size = 0.2586 reward = 0.0000 fps = 57 mse_loss = 2.9668 
2022-07-08 15:27:44.636653 - gail/main.py:174 - [TRPO] iter = 664000 dist_mean = 0.1281 dist_std = 0.2168 vf_loss = 0.0144 grad_norm = 2.7226 nat_grad_norm = 0.2201 cg_residual = 1.7787 step_size = 0.2522 reward = 0.0000 fps = 51 mse_loss = 2.6497 
2022-07-08 15:27:46.330775 - gail/main.py:174 - [TRPO] iter = 665000 dist_mean = 0.1261 dist_std = 0.2173 vf_loss = 0.0154 grad_norm = 2.9561 nat_grad_norm = 0.1998 cg_residual = 1.6699 step_size = 0.2982 reward = 0.0000 fps = 47 mse_loss = 2.8436 
2022-07-08 15:27:46.409241 - gail/main.py:201 - [Discriminator] iter = 665000 loss = -2.6079 grad_norm = 2.6310 grad_penalty = 0.1775 regularization = 0.0000 true_logits = -0.6808 fake_logits = -3.4662 true_prob = 0.4022 fake_prob = 0.0735 
2022-07-08 15:27:55.948832 - gail/main.py:142 - [Evaluate] iter = 665000 episode={ returns = 2272.4002 lengths = 549 } discounted_episode={ returns = 1682.3883 lengths = 543 } 
2022-07-08 15:27:57.174417 - gail/main.py:174 - [TRPO] iter = 666000 dist_mean = 0.1230 dist_std = 0.2171 vf_loss = 0.0138 grad_norm = 2.5144 nat_grad_norm = 0.2094 cg_residual = 1.1228 step_size = 0.3278 reward = -0.0000 fps = 92 mse_loss = 2.9994 
2022-07-08 15:27:58.380962 - gail/main.py:174 - [TRPO] iter = 667000 dist_mean = 0.1433 dist_std = 0.2166 vf_loss = 0.0185 grad_norm = 2.8223 nat_grad_norm = 0.2127 cg_residual = 1.6059 step_size = 0.3095 reward = 0.0000 fps = 83 mse_loss = 2.9107 
2022-07-08 15:27:59.582234 - gail/main.py:174 - [TRPO] iter = 668000 dist_mean = 0.1014 dist_std = 0.2162 vf_loss = 0.0112 grad_norm = 2.4259 nat_grad_norm = 0.1625 cg_residual = 1.4507 step_size = 0.3583 reward = 0.0000 fps = 75 mse_loss = 2.8544 
2022-07-08 15:28:00.780700 - gail/main.py:174 - [TRPO] iter = 669000 dist_mean = 0.0905 dist_std = 0.2161 vf_loss = 0.0223 grad_norm = 2.9343 nat_grad_norm = 0.2205 cg_residual = 2.3543 step_size = 0.2927 reward = 0.0000 fps = 69 mse_loss = 2.8378 
2022-07-08 15:28:01.982359 - gail/main.py:174 - [TRPO] iter = 670000 dist_mean = 0.1588 dist_std = 0.2163 vf_loss = 0.0138 grad_norm = 2.6366 nat_grad_norm = 0.1841 cg_residual = 1.5533 step_size = 0.2916 reward = -0.0000 fps = 64 mse_loss = 2.9511 
2022-07-08 15:28:02.038508 - gail/main.py:201 - [Discriminator] iter = 670000 loss = -2.4000 grad_norm = 2.6905 grad_penalty = 0.1529 regularization = 0.0000 true_logits = -0.6211 fake_logits = -3.1740 true_prob = 0.4086 fake_prob = 0.0779 
2022-07-08 15:28:08.438980 - gail/main.py:142 - [Evaluate] iter = 670000 episode={ returns = 1700.9572 lengths = 405 } discounted_episode={ returns = 1399.1144 lengths = 422 } 
2022-07-08 15:28:09.631904 - gail/main.py:174 - [TRPO] iter = 671000 dist_mean = 0.1199 dist_std = 0.2157 vf_loss = 0.0209 grad_norm = 2.5273 nat_grad_norm = 0.2177 cg_residual = 1.8072 step_size = 0.2967 reward = -0.0000 fps = 131 mse_loss = 2.9661 
2022-07-08 15:28:10.833428 - gail/main.py:174 - [TRPO] iter = 672000 dist_mean = 0.1286 dist_std = 0.2152 vf_loss = 0.0155 grad_norm = 1.9630 nat_grad_norm = 0.2082 cg_residual = 1.2261 step_size = 0.3517 reward = 0.0000 fps = 113 mse_loss = 2.8778 
2022-07-08 15:28:12.047542 - gail/main.py:174 - [TRPO] iter = 673000 dist_mean = 0.0765 dist_std = 0.2154 vf_loss = 0.0203 grad_norm = 3.1552 nat_grad_norm = 0.1971 cg_residual = 1.5371 step_size = 0.3077 reward = 0.0000 fps = 99 mse_loss = 2.8720 
2022-07-08 15:28:13.272222 - gail/main.py:174 - [TRPO] iter = 674000 dist_mean = 0.1407 dist_std = 0.2143 vf_loss = 0.0221 grad_norm = 3.0259 nat_grad_norm = 0.1786 cg_residual = 1.2673 step_size = 0.3186 reward = 0.0000 fps = 89 mse_loss = 2.8660 
2022-07-08 15:28:14.495978 - gail/main.py:174 - [TRPO] iter = 675000 dist_mean = 0.1435 dist_std = 0.2140 vf_loss = 0.0144 grad_norm = 2.7852 nat_grad_norm = 0.2092 cg_residual = 1.5017 step_size = 0.3077 reward = 0.0000 fps = 80 mse_loss = 2.8857 
2022-07-08 15:28:14.548775 - gail/main.py:201 - [Discriminator] iter = 675000 loss = -2.4633 grad_norm = 2.4039 grad_penalty = 0.1501 regularization = 0.0000 true_logits = -0.6602 fake_logits = -3.2735 true_prob = 0.4030 fake_prob = 0.0770 
2022-07-08 15:28:23.463161 - gail/main.py:142 - [Evaluate] iter = 675000 episode={ returns = 2559.8547 lengths = 588 } discounted_episode={ returns = 1742.1644 lengths = 546 } 
2022-07-08 15:28:24.670006 - gail/main.py:174 - [TRPO] iter = 676000 dist_mean = 0.1070 dist_std = 0.2132 vf_loss = 0.0266 grad_norm = 3.6730 nat_grad_norm = 0.2141 cg_residual = 2.4065 step_size = 0.2771 reward = -0.0000 fps = 98 mse_loss = 2.8091 
2022-07-08 15:28:25.894523 - gail/main.py:174 - [TRPO] iter = 677000 dist_mean = 0.1466 dist_std = 0.2129 vf_loss = 0.0144 grad_norm = 2.7748 nat_grad_norm = 0.2208 cg_residual = 2.1160 step_size = 0.3128 reward = 0.0000 fps = 88 mse_loss = 2.8649 
2022-07-08 15:28:27.093091 - gail/main.py:174 - [TRPO] iter = 678000 dist_mean = 0.1259 dist_std = 0.2127 vf_loss = 0.0186 grad_norm = 2.3875 nat_grad_norm = 0.1987 cg_residual = 1.3746 step_size = 0.3138 reward = -0.0000 fps = 79 mse_loss = 2.7533 
2022-07-08 15:28:28.295771 - gail/main.py:174 - [TRPO] iter = 679000 dist_mean = 0.0836 dist_std = 0.2120 vf_loss = 0.0168 grad_norm = 2.3540 nat_grad_norm = 0.1970 cg_residual = 1.3864 step_size = 0.3193 reward = 0.0000 fps = 72 mse_loss = 2.8649 
2022-07-08 15:28:29.504854 - gail/main.py:174 - [TRPO] iter = 680000 dist_mean = 0.1035 dist_std = 0.2127 vf_loss = 0.0200 grad_norm = 3.9690 nat_grad_norm = 0.2176 cg_residual = 1.8011 step_size = 0.2545 reward = 0.0000 fps = 66 mse_loss = 2.8978 
2022-07-08 15:28:29.554572 - gail/main.py:201 - [Discriminator] iter = 680000 loss = -2.6122 grad_norm = 2.6697 grad_penalty = 0.1935 regularization = 0.0000 true_logits = -0.6116 fake_logits = -3.4174 true_prob = 0.4018 fake_prob = 0.0738 
2022-07-08 15:28:39.160817 - gail/main.py:142 - [Evaluate] iter = 680000 episode={ returns = 2363.2356 lengths = 543 } discounted_episode={ returns = 1690.5738 lengths = 521 } 
2022-07-08 15:28:40.433159 - gail/main.py:174 - [TRPO] iter = 681000 dist_mean = 0.1251 dist_std = 0.2125 vf_loss = 0.0139 grad_norm = 3.2656 nat_grad_norm = 0.2399 cg_residual = 1.9133 step_size = 0.2606 reward = -0.0000 fps = 91 mse_loss = 2.9956 
2022-07-08 15:28:41.625013 - gail/main.py:174 - [TRPO] iter = 682000 dist_mean = 0.0963 dist_std = 0.2124 vf_loss = 0.0158 grad_norm = 2.6473 nat_grad_norm = 0.1804 cg_residual = 1.5674 step_size = 0.3293 reward = 0.0000 fps = 82 mse_loss = 2.9240 
2022-07-08 15:28:42.801199 - gail/main.py:174 - [TRPO] iter = 683000 dist_mean = 0.1040 dist_std = 0.2125 vf_loss = 0.0190 grad_norm = 2.6388 nat_grad_norm = 0.1764 cg_residual = 1.4632 step_size = 0.3038 reward = -0.0000 fps = 75 mse_loss = 2.9506 
2022-07-08 15:28:44.000827 - gail/main.py:174 - [TRPO] iter = 684000 dist_mean = 0.1123 dist_std = 0.2124 vf_loss = 0.0149 grad_norm = 2.2202 nat_grad_norm = 0.1804 cg_residual = 1.7026 step_size = 0.3528 reward = -0.0000 fps = 69 mse_loss = 2.7752 
2022-07-08 15:28:45.210641 - gail/main.py:174 - [TRPO] iter = 685000 dist_mean = 0.1475 dist_std = 0.2119 vf_loss = 0.0242 grad_norm = 3.1375 nat_grad_norm = 0.2435 cg_residual = 2.1741 step_size = 0.2561 reward = 0.0000 fps = 63 mse_loss = 2.9065 
2022-07-08 15:28:45.262877 - gail/main.py:201 - [Discriminator] iter = 685000 loss = -2.8008 grad_norm = 2.9734 grad_penalty = 0.2155 regularization = 0.0000 true_logits = -0.6007 fake_logits = -3.6171 true_prob = 0.4068 fake_prob = 0.0608 
2022-07-08 15:28:51.064199 - gail/main.py:142 - [Evaluate] iter = 685000 episode={ returns = 1235.2903 lengths = 303 } discounted_episode={ returns = 1370.3067 lengths = 434 } 
2022-07-08 15:28:52.254816 - gail/main.py:174 - [TRPO] iter = 686000 dist_mean = 0.0921 dist_std = 0.2120 vf_loss = 0.0213 grad_norm = 2.8593 nat_grad_norm = 0.2592 cg_residual = 2.6450 step_size = 0.2627 reward = -0.0000 fps = 143 mse_loss = 2.7933 
2022-07-08 15:28:53.467799 - gail/main.py:174 - [TRPO] iter = 687000 dist_mean = 0.1199 dist_std = 0.2126 vf_loss = 0.0280 grad_norm = 3.5683 nat_grad_norm = 0.2428 cg_residual = 2.8305 step_size = 0.2790 reward = 0.0000 fps = 121 mse_loss = 2.8523 
2022-07-08 15:28:54.704285 - gail/main.py:174 - [TRPO] iter = 688000 dist_mean = 0.1251 dist_std = 0.2127 vf_loss = 0.0533 grad_norm = 2.5987 nat_grad_norm = 0.2259 cg_residual = 2.6749 step_size = 0.3024 reward = -0.0000 fps = 105 mse_loss = 2.8438 
2022-07-08 15:28:56.016498 - gail/main.py:174 - [TRPO] iter = 689000 dist_mean = 0.0930 dist_std = 0.2128 vf_loss = 0.0575 grad_norm = 2.8472 nat_grad_norm = 0.2108 cg_residual = 2.2975 step_size = 0.2984 reward = 0.0000 fps = 93 mse_loss = 2.8038 
2022-07-08 15:28:57.245380 - gail/main.py:174 - [TRPO] iter = 690000 dist_mean = 0.1143 dist_std = 0.2126 vf_loss = 0.0296 grad_norm = 3.1586 nat_grad_norm = 0.2583 cg_residual = 2.0922 step_size = 0.2607 reward = -0.0000 fps = 83 mse_loss = 2.7724 
2022-07-08 15:28:57.297188 - gail/main.py:201 - [Discriminator] iter = 690000 loss = -2.8124 grad_norm = 2.8945 grad_penalty = 0.1985 regularization = 0.0000 true_logits = -0.7536 fake_logits = -3.7644 true_prob = 0.3812 fake_prob = 0.0665 
2022-07-08 15:29:04.329409 - gail/main.py:142 - [Evaluate] iter = 690000 episode={ returns = 1911.2252 lengths = 441 } discounted_episode={ returns = 1551.9573 lengths = 467 } 
2022-07-08 15:29:05.521504 - gail/main.py:174 - [TRPO] iter = 691000 dist_mean = 0.1030 dist_std = 0.2122 vf_loss = 0.0248 grad_norm = 2.5475 nat_grad_norm = 0.1894 cg_residual = 2.0346 step_size = 0.3011 reward = -0.0000 fps = 121 mse_loss = 2.7579 
2022-07-08 15:29:06.724435 - gail/main.py:174 - [TRPO] iter = 692000 dist_mean = 0.0884 dist_std = 0.2119 vf_loss = 0.0269 grad_norm = 3.7370 nat_grad_norm = 0.2384 cg_residual = 4.7076 step_size = 0.2602 reward = -0.0000 fps = 106 mse_loss = 2.8197 
2022-07-08 15:29:07.939159 - gail/main.py:174 - [TRPO] iter = 693000 dist_mean = 0.1366 dist_std = 0.2116 vf_loss = 0.0152 grad_norm = 2.9452 nat_grad_norm = 0.2319 cg_residual = 2.3894 step_size = 0.2671 reward = -0.0000 fps = 93 mse_loss = 2.7159 
2022-07-08 15:29:09.123171 - gail/main.py:174 - [TRPO] iter = 694000 dist_mean = 0.0589 dist_std = 0.2114 vf_loss = 0.0246 grad_norm = 3.0506 nat_grad_norm = 0.2254 cg_residual = 2.6688 step_size = 0.3086 reward = -0.0000 fps = 84 mse_loss = 2.6856 
2022-07-08 15:29:10.322808 - gail/main.py:174 - [TRPO] iter = 695000 dist_mean = 0.1202 dist_std = 0.2113 vf_loss = 0.0659 grad_norm = 3.5778 nat_grad_norm = 0.2898 cg_residual = 3.6014 step_size = 0.2371 reward = -0.0000 fps = 76 mse_loss = 2.5919 
2022-07-08 15:29:10.385545 - gail/main.py:201 - [Discriminator] iter = 695000 loss = -3.1266 grad_norm = 2.8940 grad_penalty = 0.2511 regularization = 0.0000 true_logits = -0.6799 fake_logits = -4.0577 true_prob = 0.3919 fake_prob = 0.0538 
2022-07-08 15:29:15.661929 - gail/main.py:142 - [Evaluate] iter = 695000 episode={ returns = 1451.0223 lengths = 343 } discounted_episode={ returns = 1171.7623 lengths = 343 } 
2022-07-08 15:29:16.856755 - gail/main.py:174 - [TRPO] iter = 696000 dist_mean = 0.1055 dist_std = 0.2112 vf_loss = 0.0273 grad_norm = 2.7290 nat_grad_norm = 0.1877 cg_residual = 2.6630 step_size = 0.3216 reward = 0.0000 fps = 154 mse_loss = 2.7466 
2022-07-08 15:29:18.043704 - gail/main.py:174 - [TRPO] iter = 697000 dist_mean = 0.1197 dist_std = 0.2109 vf_loss = 0.0264 grad_norm = 2.5618 nat_grad_norm = 0.2069 cg_residual = 1.7241 step_size = 0.3024 reward = 0.0000 fps = 130 mse_loss = 2.7104 
2022-07-08 15:29:19.248744 - gail/main.py:174 - [TRPO] iter = 698000 dist_mean = 0.0893 dist_std = 0.2104 vf_loss = 0.0176 grad_norm = 2.7694 nat_grad_norm = 0.1916 cg_residual = 1.2874 step_size = 0.2835 reward = -0.0000 fps = 112 mse_loss = 2.6767 
2022-07-08 15:29:20.461227 - gail/main.py:174 - [TRPO] iter = 699000 dist_mean = 0.1090 dist_std = 0.2102 vf_loss = 0.0347 grad_norm = 3.0086 nat_grad_norm = 0.1990 cg_residual = 1.5982 step_size = 0.2777 reward = -0.0000 fps = 99 mse_loss = 2.6208 
2022-07-08 15:29:21.642226 - gail/main.py:174 - [TRPO] iter = 700000 dist_mean = 0.1255 dist_std = 0.2099 vf_loss = 0.0272 grad_norm = 2.9406 nat_grad_norm = 0.2481 cg_residual = 2.9272 step_size = 0.2649 reward = -0.0000 fps = 88 mse_loss = 2.6557 
2022-07-08 15:29:21.691740 - gail/main.py:201 - [Discriminator] iter = 700000 loss = -2.4011 grad_norm = 2.7426 grad_penalty = 0.1531 regularization = 0.0000 true_logits = -0.5221 fake_logits = -3.0762 true_prob = 0.4249 fake_prob = 0.0897 
2022-07-08 15:29:27.994183 - gail/main.py:142 - [Evaluate] iter = 700000 episode={ returns = 1651.5727 lengths = 388 } discounted_episode={ returns = 1406.0926 lengths = 435 } 
2022-07-08 15:29:29.171285 - gail/main.py:174 - [TRPO] iter = 701000 dist_mean = 0.1604 dist_std = 0.2092 vf_loss = 0.0239 grad_norm = 3.1410 nat_grad_norm = 0.2160 cg_residual = 3.2865 step_size = 0.2515 reward = -0.0000 fps = 133 mse_loss = 2.8587 
2022-07-08 15:29:30.352816 - gail/main.py:174 - [TRPO] iter = 702000 dist_mean = 0.1828 dist_std = 0.2090 vf_loss = 0.0150 grad_norm = 2.9329 nat_grad_norm = 0.1962 cg_residual = 1.9895 step_size = 0.3314 reward = -0.0000 fps = 115 mse_loss = 2.6127 
2022-07-08 15:29:31.553504 - gail/main.py:174 - [TRPO] iter = 703000 dist_mean = 0.1100 dist_std = 0.2087 vf_loss = 0.0203 grad_norm = 2.7618 nat_grad_norm = 0.1779 cg_residual = 1.9469 step_size = 0.3427 reward = -0.0000 fps = 101 mse_loss = 2.6916 
2022-07-08 15:29:32.742120 - gail/main.py:174 - [TRPO] iter = 704000 dist_mean = 0.1116 dist_std = 0.2090 vf_loss = 0.0199 grad_norm = 2.6846 nat_grad_norm = 0.2015 cg_residual = 1.8606 step_size = 0.3169 reward = 0.0000 fps = 90 mse_loss = 2.6707 
2022-07-08 15:29:33.946179 - gail/main.py:174 - [TRPO] iter = 705000 dist_mean = 0.0888 dist_std = 0.2083 vf_loss = 0.0270 grad_norm = 2.6293 nat_grad_norm = 0.2618 cg_residual = 2.9815 step_size = 0.2943 reward = -0.0000 fps = 81 mse_loss = 2.7610 
2022-07-08 15:29:33.997863 - gail/main.py:201 - [Discriminator] iter = 705000 loss = -2.6925 grad_norm = 2.9446 grad_penalty = 0.1818 regularization = 0.0000 true_logits = -0.6189 fake_logits = -3.4933 true_prob = 0.4069 fake_prob = 0.0785 
2022-07-08 15:29:38.548990 - gail/main.py:142 - [Evaluate] iter = 705000 episode={ returns = 1174.4483 lengths = 294 } discounted_episode={ returns = 990.8473 lengths = 299 } 
2022-07-08 15:29:39.751312 - gail/main.py:174 - [TRPO] iter = 706000 dist_mean = 0.1011 dist_std = 0.2074 vf_loss = 0.0197 grad_norm = 2.8075 nat_grad_norm = 0.1714 cg_residual = 1.9008 step_size = 0.3195 reward = -0.0000 fps = 173 mse_loss = 2.6364 
2022-07-08 15:29:40.953268 - gail/main.py:174 - [TRPO] iter = 707000 dist_mean = 0.1217 dist_std = 0.2071 vf_loss = 0.0241 grad_norm = 2.6251 nat_grad_norm = 0.2059 cg_residual = 2.5514 step_size = 0.3043 reward = -0.0000 fps = 143 mse_loss = 2.6796 
2022-07-08 15:29:42.134849 - gail/main.py:174 - [TRPO] iter = 708000 dist_mean = 0.1064 dist_std = 0.2070 vf_loss = 0.0172 grad_norm = 2.8013 nat_grad_norm = 0.1618 cg_residual = 1.4623 step_size = 0.3383 reward = -0.0000 fps = 122 mse_loss = 2.6757 
2022-07-08 15:29:43.335169 - gail/main.py:174 - [TRPO] iter = 709000 dist_mean = 0.1203 dist_std = 0.2071 vf_loss = 0.0181 grad_norm = 3.0465 nat_grad_norm = 0.2003 cg_residual = 1.9496 step_size = 0.3117 reward = -0.0000 fps = 107 mse_loss = 2.6349 
2022-07-08 15:29:44.557498 - gail/main.py:174 - [TRPO] iter = 710000 dist_mean = 0.1056 dist_std = 0.2067 vf_loss = 0.0119 grad_norm = 3.5378 nat_grad_norm = 0.3068 cg_residual = 6.5247 step_size = 0.2015 reward = 0.0000 fps = 94 mse_loss = 2.6969 
2022-07-08 15:29:44.606754 - gail/main.py:201 - [Discriminator] iter = 710000 loss = -2.6212 grad_norm = 2.5399 grad_penalty = 0.1620 regularization = 0.0000 true_logits = -0.6612 fake_logits = -3.4444 true_prob = 0.3979 fake_prob = 0.0727 
2022-07-08 15:29:49.508986 - gail/main.py:142 - [Evaluate] iter = 710000 episode={ returns = 1267.9605 lengths = 315 } discounted_episode={ returns = 1073.3413 lengths = 320 } 
2022-07-08 15:29:50.694563 - gail/main.py:174 - [TRPO] iter = 711000 dist_mean = 0.1101 dist_std = 0.2062 vf_loss = 0.0143 grad_norm = 2.1871 nat_grad_norm = 0.1915 cg_residual = 1.6791 step_size = 0.3364 reward = 0.0000 fps = 164 mse_loss = 2.5338 
2022-07-08 15:29:51.875005 - gail/main.py:174 - [TRPO] iter = 712000 dist_mean = 0.1230 dist_std = 0.2059 vf_loss = 0.0123 grad_norm = 2.6081 nat_grad_norm = 0.1830 cg_residual = 1.2961 step_size = 0.3121 reward = -0.0000 fps = 137 mse_loss = 2.6563 
2022-07-08 15:29:53.061446 - gail/main.py:174 - [TRPO] iter = 713000 dist_mean = 0.2140 dist_std = 0.2058 vf_loss = 0.0149 grad_norm = 2.6508 nat_grad_norm = 0.1911 cg_residual = 2.5650 step_size = 0.2933 reward = -0.0000 fps = 118 mse_loss = 2.6594 
2022-07-08 15:29:54.250833 - gail/main.py:174 - [TRPO] iter = 714000 dist_mean = 0.1038 dist_std = 0.2056 vf_loss = 0.1008 grad_norm = 2.7865 nat_grad_norm = 0.1580 cg_residual = 0.9460 step_size = 0.3276 reward = -0.0000 fps = 103 mse_loss = 2.7076 
2022-07-08 15:29:55.441589 - gail/main.py:174 - [TRPO] iter = 715000 dist_mean = 0.1381 dist_std = 0.2058 vf_loss = 0.0117 grad_norm = 2.2629 nat_grad_norm = 0.1548 cg_residual = 1.2767 step_size = 0.3690 reward = 0.0000 fps = 92 mse_loss = 2.6585 
2022-07-08 15:29:55.491533 - gail/main.py:201 - [Discriminator] iter = 715000 loss = -2.3772 grad_norm = 2.6016 grad_penalty = 0.1520 regularization = 0.0000 true_logits = -0.6805 fake_logits = -3.2096 true_prob = 0.3974 fake_prob = 0.0810 
2022-07-08 15:30:00.265736 - gail/main.py:142 - [Evaluate] iter = 715000 episode={ returns = 1159.7733 lengths = 295 } discounted_episode={ returns = 1074.4453 lengths = 324 } 
2022-07-08 15:30:01.464530 - gail/main.py:174 - [TRPO] iter = 716000 dist_mean = 0.0944 dist_std = 0.2055 vf_loss = 0.0200 grad_norm = 2.9905 nat_grad_norm = 0.2200 cg_residual = 2.6901 step_size = 0.2802 reward = -0.0000 fps = 167 mse_loss = 2.6208 
2022-07-08 15:30:02.652940 - gail/main.py:174 - [TRPO] iter = 717000 dist_mean = 0.2143 dist_std = 0.2051 vf_loss = 0.0176 grad_norm = 2.5145 nat_grad_norm = 0.1489 cg_residual = 1.0266 step_size = 0.3727 reward = -0.0000 fps = 139 mse_loss = 2.6413 
2022-07-08 15:30:03.874736 - gail/main.py:174 - [TRPO] iter = 718000 dist_mean = 0.1129 dist_std = 0.2053 vf_loss = 0.0224 grad_norm = 2.3066 nat_grad_norm = 0.1906 cg_residual = 1.8142 step_size = 0.3449 reward = -0.0000 fps = 119 mse_loss = 2.6485 
2022-07-08 15:30:05.079370 - gail/main.py:174 - [TRPO] iter = 719000 dist_mean = 0.0827 dist_std = 0.2057 vf_loss = 0.0141 grad_norm = 2.8902 nat_grad_norm = 0.1741 cg_residual = 2.3873 step_size = 0.3250 reward = -0.0000 fps = 104 mse_loss = 2.5522 
2022-07-08 15:30:06.300013 - gail/main.py:174 - [TRPO] iter = 720000 dist_mean = 0.0751 dist_std = 0.2053 vf_loss = 0.0211 grad_norm = 2.9965 nat_grad_norm = 0.1974 cg_residual = 2.5771 step_size = 0.3080 reward = -0.0000 fps = 92 mse_loss = 2.6391 
2022-07-08 15:30:06.352932 - gail/main.py:201 - [Discriminator] iter = 720000 loss = -2.8988 grad_norm = 2.6710 grad_penalty = 0.1952 regularization = 0.0000 true_logits = -0.7102 fake_logits = -3.8042 true_prob = 0.3915 fake_prob = 0.0613 
