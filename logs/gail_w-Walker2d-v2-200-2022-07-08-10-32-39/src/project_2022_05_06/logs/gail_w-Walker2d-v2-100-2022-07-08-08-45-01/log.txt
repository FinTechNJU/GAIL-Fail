2022-07-08 08:45:01.701631 - utils/flags.py:257 - log_dir = logs/gail_w-Walker2d-v2-100-2022-07-08-08-45-01
2022-07-08 08:46:23.696458 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Walker2d-v2
2022-07-08 08:46:35.331246 - gail/main.py:80 - Expert Reward 5150.674112
2022-07-08 08:46:35.778747 - gail/main.py:84 - Original dataset size 3000
2022-07-08 08:46:35.812554 - gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 08:46:35.827328 - gail/main.py:87 - np random: 864 random : 786
2022-07-08 08:46:35.829919 - gail/main.py:91 - Sampled obs: 0.0531, acs: 0.2269
2022-07-08 08:46:36.776738 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 08:46:44.509915 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 08:46:44.514401 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.2194959e+00  2.4445076e-01 -7.8132987e-02 -2.6673764e-01
   1.8222688e-01 -9.5077172e-02 -3.3649772e-01  5.3370733e-02
   4.1614923e+00  4.1431887e-03  3.8142569e-02 -2.6013174e-03
  -1.0202496e-02  5.6982285e-01  2.9836079e-02 -1.5763690e-01
   1.7689442e-02]] 
 scale:[[0.06687175 0.23681822 0.23042987 0.33821535 0.664349   0.20301929
  0.42807332 0.7138035  0.986894   0.65049744 2.0363257  2.3816926
  3.7250905  6.026913   2.0511289  4.406521   6.1475325 ]]
2022-07-08 08:46:48.294990 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 08:46:48.298375 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(23, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 08:46:48.300739 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 08:46:49.414379 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 08:47:09.246588 - gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 154.4648 lengths = 185 } discounted_episode={ returns = 152.4866 lengths = 170 } 
2022-07-08 08:47:09.249342 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 08:47:19.428465 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 08:47:19.719746 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 08:47:20.386994 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 08:47:20.657063 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 08:47:22.251698 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 08:47:25.346768 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 08:47:25.719331 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 08:47:26.073915 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 08:47:26.702876 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 08:47:27.725802 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 08:47:28.076504 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 08:47:28.437446 - gail/main.py:174 - [TRPO] iter = 1000 dist_mean = -0.0000 dist_std = 1.0000 vf_loss = 0.6732 grad_norm = 0.3302 nat_grad_norm = 0.4330 cg_residual = 0.0000 step_size = 0.4424 reward = -0.0000 fps = 25 mse_loss = 0.3947 
2022-07-08 08:47:35.954651 - gail/main.py:174 - [TRPO] iter = 2000 dist_mean = -0.0054 dist_std = 0.9958 vf_loss = 0.6101 grad_norm = 0.4075 nat_grad_norm = 0.4600 cg_residual = 0.0000 step_size = 0.3874 reward = 0.0000 fps = 21 mse_loss = 0.4196 
2022-07-08 08:47:43.691093 - gail/main.py:174 - [TRPO] iter = 3000 dist_mean = -0.0084 dist_std = 0.9990 vf_loss = 0.8399 grad_norm = 0.4533 nat_grad_norm = 0.5118 cg_residual = 0.0000 step_size = 0.3425 reward = -0.0000 fps = 18 mse_loss = 0.4391 
2022-07-08 08:47:50.865723 - gail/main.py:174 - [TRPO] iter = 4000 dist_mean = -0.0088 dist_std = 0.9946 vf_loss = 0.6656 grad_norm = 0.4738 nat_grad_norm = 0.4880 cg_residual = 0.0001 step_size = 0.3526 reward = 0.0000 fps = 16 mse_loss = 0.4331 
2022-07-08 08:47:58.139462 - gail/main.py:174 - [TRPO] iter = 5000 dist_mean = -0.0022 dist_std = 0.9907 vf_loss = 0.7723 grad_norm = 0.5320 nat_grad_norm = 0.4963 cg_residual = 0.0001 step_size = 0.3217 reward = -0.0000 fps = 14 mse_loss = 0.4623 
2022-07-08 08:47:58.141007 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 08:48:00.353792 - gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.8659 grad_norm = 13.8695 grad_penalty = 1.5255 regularization = 0.0000 true_logits = -0.0193 fake_logits = 0.3212 true_prob = 0.4952 fake_prob = 0.5761 
2022-07-08 08:48:02.097457 - gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = -7.1408 lengths = 19 } discounted_episode={ returns = -7.0578 lengths = 19 } 
2022-07-08 08:48:08.832494 - gail/main.py:174 - [TRPO] iter = 6000 dist_mean = -0.0121 dist_std = 0.9852 vf_loss = 0.7109 grad_norm = 0.5759 nat_grad_norm = 0.5205 cg_residual = 0.0001 step_size = 0.3021 reward = 0.0000 fps = 118 mse_loss = 0.4968 
2022-07-08 08:48:16.260319 - gail/main.py:174 - [TRPO] iter = 7000 dist_mean = 0.0041 dist_std = 0.9777 vf_loss = 0.3959 grad_norm = 0.5019 nat_grad_norm = 0.4932 cg_residual = 0.0002 step_size = 0.3491 reward = -0.0000 fps = 62 mse_loss = 0.5500 
2022-07-08 08:48:23.506594 - gail/main.py:174 - [TRPO] iter = 8000 dist_mean = 0.0182 dist_std = 0.9747 vf_loss = 0.3301 grad_norm = 0.5295 nat_grad_norm = 0.5267 cg_residual = 0.0003 step_size = 0.3311 reward = 0.0000 fps = 43 mse_loss = 0.5573 
2022-07-08 08:48:30.876547 - gail/main.py:174 - [TRPO] iter = 9000 dist_mean = 0.0292 dist_std = 0.9685 vf_loss = 0.2379 grad_norm = 0.5613 nat_grad_norm = 0.4399 cg_residual = 0.0002 step_size = 0.3557 reward = 0.0000 fps = 32 mse_loss = 0.5984 
2022-07-08 08:48:38.412556 - gail/main.py:174 - [TRPO] iter = 10000 dist_mean = 0.0372 dist_std = 0.9627 vf_loss = 0.2773 grad_norm = 0.5062 nat_grad_norm = 0.4898 cg_residual = 0.0004 step_size = 0.3592 reward = -0.0000 fps = 26 mse_loss = 0.6384 
2022-07-08 08:48:38.655459 - gail/main.py:201 - [Discriminator] iter = 10000 loss = 0.8904 grad_norm = 10.2298 grad_penalty = 0.8741 regularization = 0.0000 true_logits = -0.0085 fake_logits = 0.0078 true_prob = 0.4981 fake_prob = 0.5024 
2022-07-08 08:48:40.117254 - gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = -11.6015 lengths = 15 } discounted_episode={ returns = -11.5358 lengths = 15 } 
2022-07-08 08:48:48.109139 - gail/main.py:174 - [TRPO] iter = 11000 dist_mean = 0.0402 dist_std = 0.9561 vf_loss = 0.2551 grad_norm = 0.5274 nat_grad_norm = 0.4791 cg_residual = 0.0004 step_size = 0.3638 reward = 0.0000 fps = 105 mse_loss = 0.5759 
2022-07-08 08:48:56.437339 - gail/main.py:174 - [TRPO] iter = 12000 dist_mean = 0.0639 dist_std = 0.9534 vf_loss = 0.2240 grad_norm = 0.6430 nat_grad_norm = 0.5001 cg_residual = 0.0007 step_size = 0.3312 reward = 0.0000 fps = 56 mse_loss = 0.6167 
2022-07-08 08:49:04.842886 - gail/main.py:174 - [TRPO] iter = 13000 dist_mean = 0.0898 dist_std = 0.9486 vf_loss = 0.1727 grad_norm = 0.5995 nat_grad_norm = 0.5065 cg_residual = 0.0007 step_size = 0.3228 reward = -0.0000 fps = 38 mse_loss = 0.6181 
2022-07-08 08:49:12.653012 - gail/main.py:174 - [TRPO] iter = 14000 dist_mean = 0.1051 dist_std = 0.9354 vf_loss = 0.1022 grad_norm = 0.5674 nat_grad_norm = 0.5401 cg_residual = 0.0008 step_size = 0.3413 reward = 0.0000 fps = 29 mse_loss = 0.6735 
2022-07-08 08:49:20.119763 - gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.1208 dist_std = 0.9252 vf_loss = 0.1410 grad_norm = 0.6225 nat_grad_norm = 0.5543 cg_residual = 0.0008 step_size = 0.3204 reward = -0.0000 fps = 24 mse_loss = 0.6972 
2022-07-08 08:49:20.371911 - gail/main.py:201 - [Discriminator] iter = 15000 loss = -0.0435 grad_norm = 9.8571 grad_penalty = 0.5803 regularization = 0.0000 true_logits = 0.0030 fake_logits = -0.6208 true_prob = 0.5012 fake_prob = 0.3543 
2022-07-08 08:49:21.906098 - gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = -11.1722 lengths = 15 } discounted_episode={ returns = -10.9988 lengths = 15 } 
2022-07-08 08:49:29.446644 - gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.1453 dist_std = 0.9156 vf_loss = 0.0961 grad_norm = 0.5960 nat_grad_norm = 0.4166 cg_residual = 0.0009 step_size = 0.3738 reward = -0.0000 fps = 110 mse_loss = 0.6643 
2022-07-08 08:49:36.883748 - gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.1552 dist_std = 0.9177 vf_loss = 0.1886 grad_norm = 0.6683 nat_grad_norm = 0.4832 cg_residual = 0.0007 step_size = 0.3162 reward = 0.0000 fps = 60 mse_loss = 0.6757 
2022-07-08 08:49:44.897112 - gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.1747 dist_std = 0.9134 vf_loss = 0.1913 grad_norm = 0.7476 nat_grad_norm = 0.5109 cg_residual = 0.0010 step_size = 0.2720 reward = -0.0000 fps = 40 mse_loss = 0.6239 
2022-07-08 08:49:52.289729 - gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.2023 dist_std = 0.9109 vf_loss = 0.2039 grad_norm = 0.7696 nat_grad_norm = 0.4972 cg_residual = 0.0008 step_size = 0.2813 reward = -0.0000 fps = 31 mse_loss = 0.5965 
2022-07-08 08:49:59.684084 - gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.2250 dist_std = 0.9122 vf_loss = 0.2915 grad_norm = 0.7985 nat_grad_norm = 0.4829 cg_residual = 0.0005 step_size = 0.2812 reward = 0.0000 fps = 25 mse_loss = 0.5884 
2022-07-08 08:49:59.894405 - gail/main.py:201 - [Discriminator] iter = 20000 loss = -0.8522 grad_norm = 8.3713 grad_penalty = 0.4744 regularization = 0.0000 true_logits = 0.0393 fake_logits = -1.2872 true_prob = 0.5105 fake_prob = 0.2318 
2022-07-08 08:50:04.019666 - gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = -2.0548 lengths = 24 } discounted_episode={ returns = -2.0434 lengths = 24 } 
2022-07-08 08:50:15.447385 - gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.2396 dist_std = 0.9070 vf_loss = 0.3936 grad_norm = 0.6827 nat_grad_norm = 0.5532 cg_residual = 0.0011 step_size = 0.3052 reward = 0.0000 fps = 64 mse_loss = 0.5812 
2022-07-08 08:50:23.561756 - gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.2644 dist_std = 0.9060 vf_loss = 0.8316 grad_norm = 0.7997 nat_grad_norm = 0.5036 cg_residual = 0.0006 step_size = 0.2974 reward = 0.0000 fps = 42 mse_loss = 0.5863 
2022-07-08 08:50:30.871495 - gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.2853 dist_std = 0.9025 vf_loss = 0.8804 grad_norm = 0.6642 nat_grad_norm = 0.4925 cg_residual = 0.0006 step_size = 0.3395 reward = -0.0000 fps = 32 mse_loss = 0.6140 
2022-07-08 08:50:38.558152 - gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.3323 dist_std = 0.8962 vf_loss = 1.1027 grad_norm = 0.5262 nat_grad_norm = 0.5396 cg_residual = 0.0015 step_size = 0.3989 reward = -0.0000 fps = 25 mse_loss = 0.6200 
2022-07-08 08:50:45.863295 - gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.3372 dist_std = 0.9002 vf_loss = 1.2830 grad_norm = 0.5969 nat_grad_norm = 0.4806 cg_residual = 0.0016 step_size = 0.4140 reward = 0.0000 fps = 21 mse_loss = 0.6009 
2022-07-08 08:50:46.097805 - gail/main.py:201 - [Discriminator] iter = 25000 loss = -0.9189 grad_norm = 6.9237 grad_penalty = 0.4582 regularization = 0.0000 true_logits = -0.0008 fake_logits = -1.3779 true_prob = 0.5037 fake_prob = 0.2251 
2022-07-08 08:51:15.995351 - gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = 356.3630 lengths = 278 } discounted_episode={ returns = 309.0623 lengths = 312 } 
2022-07-08 08:51:23.404308 - gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.3904 dist_std = 0.9010 vf_loss = 1.2270 grad_norm = 0.6293 nat_grad_norm = 0.5430 cg_residual = 0.0011 step_size = 0.3875 reward = -0.0000 fps = 26 mse_loss = 0.5930 
2022-07-08 08:51:30.666339 - gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.4234 dist_std = 0.8976 vf_loss = 2.2162 grad_norm = 0.6075 nat_grad_norm = 0.5051 cg_residual = 0.0014 step_size = 0.4172 reward = 0.0000 fps = 22 mse_loss = 0.5861 
2022-07-08 08:51:38.044594 - gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.4455 dist_std = 0.8995 vf_loss = 1.2191 grad_norm = 0.4596 nat_grad_norm = 0.4507 cg_residual = 0.0036 step_size = 0.4594 reward = 0.0000 fps = 19 mse_loss = 0.5880 
2022-07-08 08:51:45.448897 - gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.4327 dist_std = 0.8974 vf_loss = 1.4023 grad_norm = 0.5944 nat_grad_norm = 0.4829 cg_residual = 0.0019 step_size = 0.4078 reward = -0.0000 fps = 16 mse_loss = 0.6391 
2022-07-08 08:51:52.711282 - gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.5061 dist_std = 0.8915 vf_loss = 1.5225 grad_norm = 0.6181 nat_grad_norm = 0.4893 cg_residual = 0.0011 step_size = 0.4050 reward = -0.0000 fps = 15 mse_loss = 0.6539 
2022-07-08 08:51:52.975490 - gail/main.py:201 - [Discriminator] iter = 30000 loss = -0.7311 grad_norm = 5.6234 grad_penalty = 0.4035 regularization = 0.0000 true_logits = 0.0113 fake_logits = -1.1233 true_prob = 0.5076 fake_prob = 0.2685 
2022-07-08 08:52:14.919179 - gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = 345.6545 lengths = 221 } discounted_episode={ returns = 299.4411 lengths = 216 } 
2022-07-08 08:52:22.427836 - gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.4956 dist_std = 0.8945 vf_loss = 1.4681 grad_norm = 0.4431 nat_grad_norm = 0.5517 cg_residual = 0.0048 step_size = 0.3886 reward = 0.0000 fps = 33 mse_loss = 0.6564 
2022-07-08 08:52:29.624926 - gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.5008 dist_std = 0.8920 vf_loss = 0.7091 grad_norm = 0.4674 nat_grad_norm = 0.5449 cg_residual = 0.0050 step_size = 0.3870 reward = 0.0000 fps = 27 mse_loss = 0.6231 
2022-07-08 08:52:36.902723 - gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.4631 dist_std = 0.8877 vf_loss = 1.3014 grad_norm = 0.3681 nat_grad_norm = 0.4218 cg_residual = 0.0029 step_size = 0.5123 reward = 0.0000 fps = 22 mse_loss = 0.6776 
2022-07-08 08:52:43.924823 - gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.5168 dist_std = 0.8865 vf_loss = 1.1920 grad_norm = 0.4168 nat_grad_norm = 0.4866 cg_residual = 0.0017 step_size = 0.4344 reward = -0.0000 fps = 19 mse_loss = 0.6361 
2022-07-08 08:52:51.159612 - gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.5479 dist_std = 0.8825 vf_loss = 1.3578 grad_norm = 0.5746 nat_grad_norm = 0.3938 cg_residual = 0.0015 step_size = 0.4698 reward = 0.0000 fps = 17 mse_loss = 0.6673 
2022-07-08 08:52:51.391159 - gail/main.py:201 - [Discriminator] iter = 35000 loss = -1.1371 grad_norm = 5.3012 grad_penalty = 0.3370 regularization = 0.0000 true_logits = 0.0255 fake_logits = -1.4485 true_prob = 0.5119 fake_prob = 0.2057 
2022-07-08 08:53:16.258993 - gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 197.5802 lengths = 256 } discounted_episode={ returns = 153.7397 lengths = 227 } 
2022-07-08 08:53:23.861225 - gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.5523 dist_std = 0.8809 vf_loss = 1.1925 grad_norm = 0.3310 nat_grad_norm = 0.4971 cg_residual = 0.0024 step_size = 0.4593 reward = 0.0000 fps = 30 mse_loss = 0.6698 
2022-07-08 08:53:31.670849 - gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.5407 dist_std = 0.8797 vf_loss = 0.9599 grad_norm = 0.3667 nat_grad_norm = 0.5241 cg_residual = 0.0051 step_size = 0.4056 reward = -0.0000 fps = 24 mse_loss = 0.7549 
2022-07-08 08:53:39.514933 - gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.5243 dist_std = 0.8764 vf_loss = 1.1924 grad_norm = 0.3451 nat_grad_norm = 0.4073 cg_residual = 0.0010 step_size = 0.5005 reward = -0.0000 fps = 20 mse_loss = 0.7114 
2022-07-08 08:53:46.903441 - gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.5360 dist_std = 0.8758 vf_loss = 0.5598 grad_norm = 0.4667 nat_grad_norm = 0.5638 cg_residual = 0.0031 step_size = 0.3874 reward = 0.0000 fps = 18 mse_loss = 0.7654 
2022-07-08 08:53:54.312561 - gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.5408 dist_std = 0.8725 vf_loss = 0.5603 grad_norm = 0.4932 nat_grad_norm = 0.5147 cg_residual = 0.0056 step_size = 0.4248 reward = 0.0000 fps = 15 mse_loss = 0.7359 
2022-07-08 08:53:54.542476 - gail/main.py:201 - [Discriminator] iter = 40000 loss = -1.4575 grad_norm = 5.5958 grad_penalty = 0.3332 regularization = 0.0000 true_logits = 0.0472 fake_logits = -1.7434 true_prob = 0.5156 fake_prob = 0.1658 
2022-07-08 08:54:22.625990 - gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 376.5583 lengths = 263 } discounted_episode={ returns = 327.4839 lengths = 298 } 
2022-07-08 08:54:30.074458 - gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.5441 dist_std = 0.8696 vf_loss = 0.4442 grad_norm = 0.5550 nat_grad_norm = 0.5015 cg_residual = 0.0024 step_size = 0.4177 reward = -0.0000 fps = 28 mse_loss = 0.7796 
2022-07-08 08:54:37.350936 - gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.5322 dist_std = 0.8742 vf_loss = 0.7694 grad_norm = 0.3754 nat_grad_norm = 0.4664 cg_residual = 0.0037 step_size = 0.4565 reward = -0.0000 fps = 23 mse_loss = 0.7565 
2022-07-08 08:54:44.699612 - gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.5533 dist_std = 0.8749 vf_loss = 0.9244 grad_norm = 0.4676 nat_grad_norm = 0.4584 cg_residual = 0.0031 step_size = 0.4171 reward = -0.0000 fps = 19 mse_loss = 0.7778 
2022-07-08 08:54:52.452516 - gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.5395 dist_std = 0.8744 vf_loss = 0.5331 grad_norm = 0.3696 nat_grad_norm = 0.4801 cg_residual = 0.0045 step_size = 0.4248 reward = 0.0000 fps = 17 mse_loss = 0.7346 
2022-07-08 08:55:00.702287 - gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.5494 dist_std = 0.8778 vf_loss = 0.5165 grad_norm = 0.4287 nat_grad_norm = 0.5094 cg_residual = 0.0050 step_size = 0.3780 reward = -0.0000 fps = 15 mse_loss = 0.7646 
2022-07-08 08:55:00.955860 - gail/main.py:201 - [Discriminator] iter = 45000 loss = -2.1551 grad_norm = 6.0369 grad_penalty = 0.3110 regularization = 0.0000 true_logits = 0.0646 fake_logits = -2.4015 true_prob = 0.5271 fake_prob = 0.0994 
2022-07-08 08:55:27.911042 - gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 184.5824 lengths = 243 } discounted_episode={ returns = 215.0765 lengths = 251 } 
2022-07-08 08:55:34.982840 - gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.5543 dist_std = 0.8788 vf_loss = 0.8865 grad_norm = 0.4372 nat_grad_norm = 0.4532 cg_residual = 0.0040 step_size = 0.4335 reward = 0.0000 fps = 29 mse_loss = 0.8600 
2022-07-08 08:55:42.326178 - gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.5588 dist_std = 0.8773 vf_loss = 1.0516 grad_norm = 0.4372 nat_grad_norm = 0.4757 cg_residual = 0.0046 step_size = 0.4414 reward = 0.0000 fps = 24 mse_loss = 0.7574 
2022-07-08 08:55:49.683979 - gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.5352 dist_std = 0.8738 vf_loss = 1.0619 grad_norm = 0.3008 nat_grad_norm = 0.4572 cg_residual = 0.0020 step_size = 0.4727 reward = -0.0000 fps = 20 mse_loss = 0.7273 
2022-07-08 08:55:56.983972 - gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.5291 dist_std = 0.8761 vf_loss = 1.4219 grad_norm = 0.3256 nat_grad_norm = 0.5154 cg_residual = 0.0019 step_size = 0.4516 reward = -0.0000 fps = 17 mse_loss = 0.8115 
2022-07-08 08:56:04.500858 - gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.5277 dist_std = 0.8734 vf_loss = 0.8625 grad_norm = 0.3659 nat_grad_norm = 0.5064 cg_residual = 0.0023 step_size = 0.4731 reward = 0.0000 fps = 15 mse_loss = 0.7569 
2022-07-08 08:56:04.768420 - gail/main.py:201 - [Discriminator] iter = 50000 loss = -2.7009 grad_norm = 5.7393 grad_penalty = 0.3253 regularization = 0.0000 true_logits = 0.0924 fake_logits = -2.9339 true_prob = 0.5361 fake_prob = 0.0660 
2022-07-08 08:56:25.145876 - gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 354.1514 lengths = 202 } discounted_episode={ returns = 319.9417 lengths = 212 } 
2022-07-08 08:56:32.974537 - gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.4977 dist_std = 0.8745 vf_loss = 1.0924 grad_norm = 0.3565 nat_grad_norm = 0.5134 cg_residual = 0.0019 step_size = 0.4348 reward = -0.0000 fps = 35 mse_loss = 0.8384 
2022-07-08 08:56:40.634794 - gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.4706 dist_std = 0.8727 vf_loss = 0.4795 grad_norm = 0.4167 nat_grad_norm = 0.6957 cg_residual = 0.0037 step_size = 0.3558 reward = -0.0000 fps = 27 mse_loss = 0.7694 
2022-07-08 08:56:47.912683 - gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.4937 dist_std = 0.8795 vf_loss = 1.1385 grad_norm = 0.4277 nat_grad_norm = 0.5688 cg_residual = 0.0016 step_size = 0.4026 reward = 0.0000 fps = 23 mse_loss = 0.8234 
2022-07-08 08:56:55.447849 - gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.5019 dist_std = 0.8752 vf_loss = 0.8163 grad_norm = 0.4152 nat_grad_norm = 0.5503 cg_residual = 0.0023 step_size = 0.3944 reward = 0.0000 fps = 19 mse_loss = 0.8839 
2022-07-08 08:57:02.936118 - gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.4770 dist_std = 0.8719 vf_loss = 0.5707 grad_norm = 0.4645 nat_grad_norm = 0.6086 cg_residual = 0.0048 step_size = 0.3459 reward = -0.0000 fps = 17 mse_loss = 0.8885 
2022-07-08 08:57:03.196131 - gail/main.py:201 - [Discriminator] iter = 55000 loss = -3.0481 grad_norm = 5.7770 grad_penalty = 0.4309 regularization = 0.0000 true_logits = 0.1140 fake_logits = -3.3650 true_prob = 0.5391 fake_prob = 0.0506 
2022-07-08 08:57:18.737810 - gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 327.6200 lengths = 156 } discounted_episode={ returns = 305.8889 lengths = 163 } 
2022-07-08 08:57:26.160760 - gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.5051 dist_std = 0.8705 vf_loss = 0.5667 grad_norm = 0.3618 nat_grad_norm = 0.4875 cg_residual = 0.0026 step_size = 0.4625 reward = -0.0000 fps = 43 mse_loss = 0.9290 
2022-07-08 08:57:33.380949 - gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.4943 dist_std = 0.8735 vf_loss = 0.8267 grad_norm = 0.5136 nat_grad_norm = 0.5452 cg_residual = 0.0039 step_size = 0.3602 reward = -0.0000 fps = 33 mse_loss = 0.8969 
2022-07-08 08:57:40.487300 - gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.4931 dist_std = 0.8744 vf_loss = 0.9858 grad_norm = 0.4953 nat_grad_norm = 0.5514 cg_residual = 0.0023 step_size = 0.3860 reward = 0.0000 fps = 26 mse_loss = 0.9033 
2022-07-08 08:57:47.846685 - gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.4513 dist_std = 0.8729 vf_loss = 1.0255 grad_norm = 0.4754 nat_grad_norm = 0.6582 cg_residual = 0.0038 step_size = 0.3607 reward = 0.0000 fps = 22 mse_loss = 1.0043 
2022-07-08 08:57:55.197342 - gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.4769 dist_std = 0.8684 vf_loss = 0.5689 grad_norm = 0.5661 nat_grad_norm = 0.7743 cg_residual = 0.0078 step_size = 0.3256 reward = 0.0000 fps = 19 mse_loss = 0.9001 
2022-07-08 08:57:55.435611 - gail/main.py:201 - [Discriminator] iter = 60000 loss = -3.3062 grad_norm = 6.2913 grad_penalty = 0.4275 regularization = 0.0000 true_logits = 0.1760 fake_logits = -3.5577 true_prob = 0.5531 fake_prob = 0.0434 
2022-07-08 08:58:09.384479 - gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 322.4545 lengths = 148 } discounted_episode={ returns = 288.8502 lengths = 144 } 
2022-07-08 08:58:16.929548 - gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.4839 dist_std = 0.8712 vf_loss = 0.7346 grad_norm = 0.4935 nat_grad_norm = 0.5692 cg_residual = 0.0029 step_size = 0.3792 reward = -0.0000 fps = 46 mse_loss = 0.9061 
2022-07-08 08:58:24.287107 - gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.4693 dist_std = 0.8667 vf_loss = 0.8488 grad_norm = 0.4512 nat_grad_norm = 0.4867 cg_residual = 0.0024 step_size = 0.4168 reward = 0.0000 fps = 34 mse_loss = 0.9081 
2022-07-08 08:58:31.870659 - gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.4280 dist_std = 0.8690 vf_loss = 0.6738 grad_norm = 0.3356 nat_grad_norm = 0.5515 cg_residual = 0.0022 step_size = 0.4465 reward = 0.0000 fps = 27 mse_loss = 0.9893 
2022-07-08 08:58:39.028214 - gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.4558 dist_std = 0.8679 vf_loss = 0.4511 grad_norm = 0.4813 nat_grad_norm = 0.6695 cg_residual = 0.0058 step_size = 0.3386 reward = 0.0000 fps = 22 mse_loss = 1.0405 
2022-07-08 08:58:46.092665 - gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.4557 dist_std = 0.8594 vf_loss = 0.6763 grad_norm = 0.4467 nat_grad_norm = 0.5838 cg_residual = 0.0043 step_size = 0.3904 reward = -0.0000 fps = 19 mse_loss = 0.8817 
2022-07-08 08:58:46.349520 - gail/main.py:201 - [Discriminator] iter = 65000 loss = -3.5022 grad_norm = 5.1984 grad_penalty = 0.3992 regularization = 0.0000 true_logits = 0.0851 fake_logits = -3.8163 true_prob = 0.5393 fake_prob = 0.0381 
2022-07-08 08:59:00.006346 - gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 308.1736 lengths = 144 } discounted_episode={ returns = 283.0464 lengths = 144 } 
2022-07-08 08:59:07.360851 - gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.4535 dist_std = 0.8562 vf_loss = 0.8283 grad_norm = 0.5492 nat_grad_norm = 0.7310 cg_residual = 0.0037 step_size = 0.3361 reward = 0.0000 fps = 47 mse_loss = 0.8423 
2022-07-08 08:59:14.634133 - gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.4541 dist_std = 0.8560 vf_loss = 1.0429 grad_norm = 0.4522 nat_grad_norm = 0.6028 cg_residual = 0.0024 step_size = 0.3852 reward = -0.0000 fps = 35 mse_loss = 0.8897 
2022-07-08 08:59:21.857761 - gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.4498 dist_std = 0.8564 vf_loss = 1.1628 grad_norm = 0.4221 nat_grad_norm = 0.6344 cg_residual = 0.0031 step_size = 0.3906 reward = -0.0000 fps = 28 mse_loss = 0.8583 
2022-07-08 08:59:28.875454 - gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.4092 dist_std = 0.8567 vf_loss = 0.5591 grad_norm = 0.5262 nat_grad_norm = 0.6801 cg_residual = 0.0033 step_size = 0.3582 reward = 0.0000 fps = 23 mse_loss = 0.8277 
2022-07-08 08:59:36.753633 - gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.4281 dist_std = 0.8570 vf_loss = 0.8077 grad_norm = 0.4585 nat_grad_norm = 0.6082 cg_residual = 0.0045 step_size = 0.3888 reward = -0.0000 fps = 19 mse_loss = 0.7592 
2022-07-08 08:59:36.955754 - gail/main.py:201 - [Discriminator] iter = 70000 loss = -3.6418 grad_norm = 4.9246 grad_penalty = 0.4266 regularization = 0.0000 true_logits = 0.0416 fake_logits = -4.0269 true_prob = 0.5335 fake_prob = 0.0300 
2022-07-08 08:59:51.699814 - gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 319.4675 lengths = 148 } discounted_episode={ returns = 293.4766 lengths = 148 } 
2022-07-08 08:59:58.846750 - gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.3980 dist_std = 0.8544 vf_loss = 0.6524 grad_norm = 0.5850 nat_grad_norm = 0.7579 cg_residual = 0.0057 step_size = 0.3468 reward = -0.0000 fps = 45 mse_loss = 0.8429 
2022-07-08 09:00:07.100596 - gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.4065 dist_std = 0.8533 vf_loss = 0.5975 grad_norm = 0.5125 nat_grad_norm = 0.7410 cg_residual = 0.0041 step_size = 0.3303 reward = -0.0000 fps = 33 mse_loss = 0.8035 
2022-07-08 09:00:15.567685 - gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.3765 dist_std = 0.8555 vf_loss = 0.7057 grad_norm = 0.5045 nat_grad_norm = 0.6654 cg_residual = 0.0050 step_size = 0.3428 reward = -0.0000 fps = 25 mse_loss = 0.9594 
2022-07-08 09:00:23.568762 - gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.3615 dist_std = 0.8518 vf_loss = 0.3156 grad_norm = 0.5927 nat_grad_norm = 0.6723 cg_residual = 0.0098 step_size = 0.3365 reward = -0.0000 fps = 21 mse_loss = 0.8652 
2022-07-08 09:00:34.335518 - gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.3907 dist_std = 0.8526 vf_loss = 0.3904 grad_norm = 0.5053 nat_grad_norm = 0.5565 cg_residual = 0.0041 step_size = 0.4016 reward = -0.0000 fps = 17 mse_loss = 0.9356 
2022-07-08 09:00:34.745690 - gail/main.py:201 - [Discriminator] iter = 75000 loss = -3.4951 grad_norm = 4.6899 grad_penalty = 0.3954 regularization = 0.0000 true_logits = -0.0075 fake_logits = -3.8979 true_prob = 0.5218 fake_prob = 0.0320 
2022-07-08 09:00:50.690467 - gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 325.1748 lengths = 153 } discounted_episode={ returns = 297.2537 lengths = 152 } 
2022-07-08 09:00:58.036168 - gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.4051 dist_std = 0.8508 vf_loss = 0.4432 grad_norm = 0.4406 nat_grad_norm = 0.4660 cg_residual = 0.0028 step_size = 0.4443 reward = -0.0000 fps = 42 mse_loss = 0.9915 
2022-07-08 09:01:05.093397 - gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.3826 dist_std = 0.8545 vf_loss = 0.4325 grad_norm = 0.5145 nat_grad_norm = 0.7634 cg_residual = 0.0064 step_size = 0.3284 reward = 0.0000 fps = 32 mse_loss = 0.8590 
2022-07-08 09:01:12.695152 - gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.3717 dist_std = 0.8503 vf_loss = 0.4382 grad_norm = 0.5066 nat_grad_norm = 0.6218 cg_residual = 0.0035 step_size = 0.3892 reward = -0.0000 fps = 26 mse_loss = 0.9791 
2022-07-08 09:01:19.995443 - gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.3786 dist_std = 0.8531 vf_loss = 0.6530 grad_norm = 0.4654 nat_grad_norm = 0.6224 cg_residual = 0.0048 step_size = 0.3785 reward = 0.0000 fps = 22 mse_loss = 0.9663 
2022-07-08 09:01:27.428219 - gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.3822 dist_std = 0.8471 vf_loss = 0.4486 grad_norm = 0.6557 nat_grad_norm = 0.8528 cg_residual = 0.0121 step_size = 0.2907 reward = -0.0000 fps = 18 mse_loss = 1.0602 
2022-07-08 09:01:27.696493 - gail/main.py:201 - [Discriminator] iter = 80000 loss = -3.9395 grad_norm = 5.3941 grad_penalty = 0.3639 regularization = 0.0000 true_logits = -0.0706 fake_logits = -4.3739 true_prob = 0.5083 fake_prob = 0.0247 
2022-07-08 09:01:40.438096 - gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 288.9293 lengths = 136 } discounted_episode={ returns = 265.7132 lengths = 134 } 
2022-07-08 09:01:47.558389 - gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.4040 dist_std = 0.8444 vf_loss = 0.5422 grad_norm = 0.5127 nat_grad_norm = 0.7836 cg_residual = 0.0057 step_size = 0.3294 reward = 0.0000 fps = 50 mse_loss = 1.0387 
2022-07-08 09:01:54.700253 - gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.3984 dist_std = 0.8414 vf_loss = 0.6360 grad_norm = 0.4431 nat_grad_norm = 0.6006 cg_residual = 0.0041 step_size = 0.4255 reward = -0.0000 fps = 37 mse_loss = 0.9577 
2022-07-08 09:02:01.645278 - gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.3915 dist_std = 0.8398 vf_loss = 0.5421 grad_norm = 0.5083 nat_grad_norm = 0.6687 cg_residual = 0.0057 step_size = 0.3369 reward = -0.0000 fps = 29 mse_loss = 1.0125 
2022-07-08 09:02:08.684172 - gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.3741 dist_std = 0.8422 vf_loss = 0.5194 grad_norm = 0.5439 nat_grad_norm = 0.5787 cg_residual = 0.0058 step_size = 0.3651 reward = -0.0000 fps = 24 mse_loss = 1.1409 
2022-07-08 09:02:15.557308 - gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.3759 dist_std = 0.8390 vf_loss = 0.3797 grad_norm = 0.5963 nat_grad_norm = 0.6819 cg_residual = 0.0061 step_size = 0.3402 reward = 0.0000 fps = 20 mse_loss = 1.1723 
2022-07-08 09:02:15.763910 - gail/main.py:201 - [Discriminator] iter = 85000 loss = -3.6300 grad_norm = 4.7184 grad_penalty = 0.4326 regularization = 0.0000 true_logits = -0.2193 fake_logits = -4.2820 true_prob = 0.4790 fake_prob = 0.0240 
2022-07-08 09:02:27.970280 - gail/main.py:142 - [Evaluate] iter = 85000 episode={ returns = 282.1510 lengths = 129 } discounted_episode={ returns = 259.1484 lengths = 127 } 
2022-07-08 09:02:35.186084 - gail/main.py:174 - [TRPO] iter = 86000 dist_mean = 0.3949 dist_std = 0.8340 vf_loss = 0.2802 grad_norm = 0.5561 nat_grad_norm = 0.5640 cg_residual = 0.0062 step_size = 0.3728 reward = -0.0000 fps = 51 mse_loss = 1.0623 
2022-07-08 09:02:42.828618 - gail/main.py:174 - [TRPO] iter = 87000 dist_mean = 0.3343 dist_std = 0.8307 vf_loss = 0.3116 grad_norm = 0.5571 nat_grad_norm = 0.6498 cg_residual = 0.0082 step_size = 0.3691 reward = -0.0000 fps = 36 mse_loss = 1.0627 
2022-07-08 09:02:50.884505 - gail/main.py:174 - [TRPO] iter = 88000 dist_mean = 0.3663 dist_std = 0.8253 vf_loss = 0.2937 grad_norm = 0.5507 nat_grad_norm = 0.6803 cg_residual = 0.0146 step_size = 0.3512 reward = 0.0000 fps = 28 mse_loss = 1.0556 
2022-07-08 09:02:58.164011 - gail/main.py:174 - [TRPO] iter = 89000 dist_mean = 0.4074 dist_std = 0.8207 vf_loss = 0.4623 grad_norm = 0.4382 nat_grad_norm = 0.5160 cg_residual = 0.0094 step_size = 0.4316 reward = -0.0000 fps = 23 mse_loss = 1.0936 
2022-07-08 09:03:05.625427 - gail/main.py:174 - [TRPO] iter = 90000 dist_mean = 0.3710 dist_std = 0.8195 vf_loss = 0.2880 grad_norm = 0.5116 nat_grad_norm = 0.5607 cg_residual = 0.0071 step_size = 0.3806 reward = 0.0000 fps = 20 mse_loss = 1.1052 
2022-07-08 09:03:05.879609 - gail/main.py:201 - [Discriminator] iter = 90000 loss = -3.5486 grad_norm = 4.4431 grad_penalty = 0.3867 regularization = 0.0000 true_logits = -0.2341 fake_logits = -4.1694 true_prob = 0.4824 fake_prob = 0.0239 
2022-07-08 09:03:17.385403 - gail/main.py:142 - [Evaluate] iter = 90000 episode={ returns = 263.9015 lengths = 121 } discounted_episode={ returns = 249.6447 lengths = 121 } 
2022-07-08 09:03:24.959611 - gail/main.py:174 - [TRPO] iter = 91000 dist_mean = 0.4155 dist_std = 0.8172 vf_loss = 0.3260 grad_norm = 0.5654 nat_grad_norm = 0.6222 cg_residual = 0.0116 step_size = 0.3415 reward = 0.0000 fps = 52 mse_loss = 1.0892 
2022-07-08 09:03:32.767029 - gail/main.py:174 - [TRPO] iter = 92000 dist_mean = 0.3644 dist_std = 0.8120 vf_loss = 0.2981 grad_norm = 0.5024 nat_grad_norm = 0.6385 cg_residual = 0.0082 step_size = 0.3474 reward = 0.0000 fps = 37 mse_loss = 0.9732 
2022-07-08 09:03:40.110032 - gail/main.py:174 - [TRPO] iter = 93000 dist_mean = 0.4403 dist_std = 0.8088 vf_loss = 0.4913 grad_norm = 0.4402 nat_grad_norm = 0.5767 cg_residual = 0.0101 step_size = 0.4208 reward = 0.0000 fps = 29 mse_loss = 1.1400 
2022-07-08 09:03:47.706301 - gail/main.py:174 - [TRPO] iter = 94000 dist_mean = 0.3998 dist_std = 0.8051 vf_loss = 0.4249 grad_norm = 0.4701 nat_grad_norm = 0.5793 cg_residual = 0.0138 step_size = 0.3672 reward = -0.0000 fps = 23 mse_loss = 1.0146 
2022-07-08 09:03:55.317363 - gail/main.py:174 - [TRPO] iter = 95000 dist_mean = 0.3909 dist_std = 0.8033 vf_loss = 0.5157 grad_norm = 0.5560 nat_grad_norm = 0.7249 cg_residual = 0.0156 step_size = 0.3157 reward = 0.0000 fps = 20 mse_loss = 1.1111 
2022-07-08 09:03:55.562684 - gail/main.py:201 - [Discriminator] iter = 95000 loss = -3.6596 grad_norm = 3.7448 grad_penalty = 0.3556 regularization = 0.0000 true_logits = -0.1942 fake_logits = -4.2093 true_prob = 0.4851 fake_prob = 0.0250 
2022-07-08 09:04:07.164446 - gail/main.py:142 - [Evaluate] iter = 95000 episode={ returns = 279.9512 lengths = 122 } discounted_episode={ returns = 255.4356 lengths = 121 } 
2022-07-08 09:04:14.815506 - gail/main.py:174 - [TRPO] iter = 96000 dist_mean = 0.3598 dist_std = 0.8030 vf_loss = 0.3170 grad_norm = 0.4362 nat_grad_norm = 0.6227 cg_residual = 0.0099 step_size = 0.4115 reward = 0.0000 fps = 51 mse_loss = 0.9875 
2022-07-08 09:04:25.920602 - gail/main.py:174 - [TRPO] iter = 97000 dist_mean = 0.3800 dist_std = 0.8056 vf_loss = 0.3719 grad_norm = 0.5219 nat_grad_norm = 0.5984 cg_residual = 0.0152 step_size = 0.3512 reward = 0.0000 fps = 32 mse_loss = 1.0685 
2022-07-08 09:04:40.485437 - gail/main.py:174 - [TRPO] iter = 98000 dist_mean = 0.3888 dist_std = 0.7991 vf_loss = 0.5099 grad_norm = 0.6076 nat_grad_norm = 0.6038 cg_residual = 0.0137 step_size = 0.3856 reward = -0.0000 fps = 22 mse_loss = 0.9646 
2022-07-08 09:04:54.911976 - gail/main.py:174 - [TRPO] iter = 99000 dist_mean = 0.3842 dist_std = 0.7988 vf_loss = 0.6028 grad_norm = 0.4479 nat_grad_norm = 0.6067 cg_residual = 0.0108 step_size = 0.3910 reward = -0.0000 fps = 16 mse_loss = 0.9592 
2022-07-08 09:05:10.120176 - gail/main.py:174 - [TRPO] iter = 100000 dist_mean = 0.3828 dist_std = 0.7954 vf_loss = 0.4585 grad_norm = 0.4801 nat_grad_norm = 0.5617 cg_residual = 0.0101 step_size = 0.3999 reward = -0.0000 fps = 13 mse_loss = 0.8656 
2022-07-08 09:05:10.674847 - gail/main.py:201 - [Discriminator] iter = 100000 loss = -3.7043 grad_norm = 2.9938 grad_penalty = 0.3665 regularization = 0.0000 true_logits = -0.1722 fake_logits = -4.2429 true_prob = 0.4867 fake_prob = 0.0227 
2022-07-08 09:05:41.079329 - gail/main.py:142 - [Evaluate] iter = 100000 episode={ returns = 277.5413 lengths = 124 } discounted_episode={ returns = 256.1505 lengths = 124 } 
2022-07-08 09:05:58.453060 - gail/main.py:174 - [TRPO] iter = 101000 dist_mean = 0.3932 dist_std = 0.7972 vf_loss = 0.4475 grad_norm = 0.5065 nat_grad_norm = 0.6567 cg_residual = 0.0115 step_size = 0.3592 reward = 0.0000 fps = 20 mse_loss = 0.8962 
2022-07-08 09:06:15.402893 - gail/main.py:174 - [TRPO] iter = 102000 dist_mean = 0.4007 dist_std = 0.7954 vf_loss = 0.5827 grad_norm = 0.5572 nat_grad_norm = 0.6209 cg_residual = 0.0172 step_size = 0.3399 reward = -0.0000 fps = 15 mse_loss = 0.8459 
2022-07-08 09:06:32.586983 - gail/main.py:174 - [TRPO] iter = 103000 dist_mean = 0.3647 dist_std = 0.7948 vf_loss = 0.3772 grad_norm = 0.5004 nat_grad_norm = 0.5527 cg_residual = 0.0162 step_size = 0.3766 reward = -0.0000 fps = 12 mse_loss = 0.9704 
2022-07-08 09:06:51.802363 - gail/main.py:174 - [TRPO] iter = 104000 dist_mean = 0.3681 dist_std = 0.7933 vf_loss = 0.2565 grad_norm = 0.5325 nat_grad_norm = 0.5919 cg_residual = 0.0213 step_size = 0.3561 reward = -0.0000 fps = 9 mse_loss = 0.9322 
2022-07-08 09:07:09.889291 - gail/main.py:174 - [TRPO] iter = 105000 dist_mean = 0.3607 dist_std = 0.7912 vf_loss = 0.3027 grad_norm = 0.6102 nat_grad_norm = 0.6307 cg_residual = 0.0108 step_size = 0.3614 reward = -0.0000 fps = 8 mse_loss = 1.0290 
2022-07-08 09:07:10.459142 - gail/main.py:201 - [Discriminator] iter = 105000 loss = -3.8504 grad_norm = 3.9019 grad_penalty = 0.3683 regularization = 0.0000 true_logits = -0.1343 fake_logits = -4.3530 true_prob = 0.4997 fake_prob = 0.0197 
2022-07-08 09:07:37.620248 - gail/main.py:142 - [Evaluate] iter = 105000 episode={ returns = 273.7188 lengths = 123 } discounted_episode={ returns = 256.5482 lengths = 123 } 
2022-07-08 09:07:55.703043 - gail/main.py:174 - [TRPO] iter = 106000 dist_mean = 0.3645 dist_std = 0.7894 vf_loss = 0.3978 grad_norm = 0.5359 nat_grad_norm = 0.5611 cg_residual = 0.0129 step_size = 0.4047 reward = 0.0000 fps = 22 mse_loss = 1.0240 
2022-07-08 09:08:13.129105 - gail/main.py:174 - [TRPO] iter = 107000 dist_mean = 0.3998 dist_std = 0.7887 vf_loss = 0.4013 grad_norm = 0.5380 nat_grad_norm = 0.5906 cg_residual = 0.0126 step_size = 0.3835 reward = 0.0000 fps = 15 mse_loss = 0.9889 
2022-07-08 09:08:31.669570 - gail/main.py:174 - [TRPO] iter = 108000 dist_mean = 0.3699 dist_std = 0.7891 vf_loss = 0.2961 grad_norm = 0.6253 nat_grad_norm = 0.6726 cg_residual = 0.0190 step_size = 0.3350 reward = 0.0000 fps = 12 mse_loss = 0.9441 
2022-07-08 09:08:49.340660 - gail/main.py:174 - [TRPO] iter = 109000 dist_mean = 0.3471 dist_std = 0.7866 vf_loss = 0.2992 grad_norm = 0.4743 nat_grad_norm = 0.6514 cg_residual = 0.0190 step_size = 0.3674 reward = -0.0000 fps = 10 mse_loss = 0.9298 
2022-07-08 09:09:10.141080 - gail/main.py:174 - [TRPO] iter = 110000 dist_mean = 0.3533 dist_std = 0.7853 vf_loss = 0.2101 grad_norm = 0.4220 nat_grad_norm = 0.5384 cg_residual = 0.0154 step_size = 0.4296 reward = -0.0000 fps = 8 mse_loss = 0.9576 
2022-07-08 09:09:10.918019 - gail/main.py:201 - [Discriminator] iter = 110000 loss = -3.7392 grad_norm = 2.9893 grad_penalty = 0.3612 regularization = 0.0000 true_logits = -0.0683 fake_logits = -4.1687 true_prob = 0.5043 fake_prob = 0.0234 
2022-07-08 09:09:50.726224 - gail/main.py:142 - [Evaluate] iter = 110000 episode={ returns = 302.2715 lengths = 123 } discounted_episode={ returns = 281.6681 lengths = 123 } 
2022-07-08 09:10:14.115561 - gail/main.py:174 - [TRPO] iter = 111000 dist_mean = 0.3610 dist_std = 0.7880 vf_loss = 0.4796 grad_norm = 0.6177 nat_grad_norm = 0.4732 cg_residual = 0.0135 step_size = 0.4090 reward = 0.0000 fps = 15 mse_loss = 0.9339 
2022-07-08 09:10:42.744583 - gail/main.py:174 - [TRPO] iter = 112000 dist_mean = 0.3671 dist_std = 0.7848 vf_loss = 0.6359 grad_norm = 0.5827 nat_grad_norm = 0.5773 cg_residual = 0.0128 step_size = 0.3951 reward = 0.0000 fps = 10 mse_loss = 0.9412 
2022-07-08 09:11:17.757326 - gail/main.py:174 - [TRPO] iter = 113000 dist_mean = 0.3337 dist_std = 0.7867 vf_loss = 0.2995 grad_norm = 0.6671 nat_grad_norm = 0.5601 cg_residual = 0.0172 step_size = 0.3422 reward = -0.0000 fps = 7 mse_loss = 0.9780 
2022-07-08 09:11:46.310246 - gail/main.py:174 - [TRPO] iter = 114000 dist_mean = 0.3524 dist_std = 0.7867 vf_loss = 0.2808 grad_norm = 0.6072 nat_grad_norm = 0.5344 cg_residual = 0.0176 step_size = 0.3793 reward = -0.0000 fps = 6 mse_loss = 1.1750 
2022-07-08 09:12:15.863386 - gail/main.py:174 - [TRPO] iter = 115000 dist_mean = 0.3044 dist_std = 0.7837 vf_loss = 0.2490 grad_norm = 0.4879 nat_grad_norm = 0.4987 cg_residual = 0.0149 step_size = 0.4254 reward = -0.0000 fps = 5 mse_loss = 1.0038 
2022-07-08 09:12:16.699941 - gail/main.py:201 - [Discriminator] iter = 115000 loss = -3.7081 grad_norm = 3.0084 grad_penalty = 0.3379 regularization = 0.0000 true_logits = -0.0430 fake_logits = -4.0889 true_prob = 0.5123 fake_prob = 0.0261 
2022-07-08 09:13:09.113175 - gail/main.py:142 - [Evaluate] iter = 115000 episode={ returns = 312.8352 lengths = 123 } discounted_episode={ returns = 289.0721 lengths = 123 } 
2022-07-08 09:13:39.738658 - gail/main.py:174 - [TRPO] iter = 116000 dist_mean = 0.4144 dist_std = 0.7827 vf_loss = 0.6487 grad_norm = 0.5815 nat_grad_norm = 0.7204 cg_residual = 0.0232 step_size = 0.3333 reward = -0.0000 fps = 12 mse_loss = 1.1099 
2022-07-08 09:14:09.331739 - gail/main.py:174 - [TRPO] iter = 117000 dist_mean = 0.3356 dist_std = 0.7829 vf_loss = 0.2853 grad_norm = 0.6045 nat_grad_norm = 0.5287 cg_residual = 0.0329 step_size = 0.3518 reward = -0.0000 fps = 8 mse_loss = 1.0327 
2022-07-08 09:14:39.701526 - gail/main.py:174 - [TRPO] iter = 118000 dist_mean = 0.3177 dist_std = 0.7843 vf_loss = 0.3298 grad_norm = 0.4958 nat_grad_norm = 0.5126 cg_residual = 0.0140 step_size = 0.3952 reward = -0.0000 fps = 6 mse_loss = 1.0043 
2022-07-08 09:15:12.336130 - gail/main.py:174 - [TRPO] iter = 119000 dist_mean = 0.3512 dist_std = 0.7844 vf_loss = 0.3870 grad_norm = 0.6867 nat_grad_norm = 0.7193 cg_residual = 0.0277 step_size = 0.3192 reward = -0.0000 fps = 5 mse_loss = 0.9754 
2022-07-08 09:15:42.315197 - gail/main.py:174 - [TRPO] iter = 120000 dist_mean = 0.3725 dist_std = 0.7837 vf_loss = 0.4328 grad_norm = 0.5185 nat_grad_norm = 0.6190 cg_residual = 0.0202 step_size = 0.3681 reward = -0.0000 fps = 4 mse_loss = 1.0229 
2022-07-08 09:15:43.076553 - gail/main.py:201 - [Discriminator] iter = 120000 loss = -3.8652 grad_norm = 3.0519 grad_penalty = 0.3635 regularization = 0.0000 true_logits = -0.0433 fake_logits = -4.2719 true_prob = 0.5139 fake_prob = 0.0206 
2022-07-08 09:16:32.796135 - gail/main.py:142 - [Evaluate] iter = 120000 episode={ returns = 301.6089 lengths = 123 } discounted_episode={ returns = 278.8715 lengths = 123 } 
2022-07-08 09:17:04.115028 - gail/main.py:174 - [TRPO] iter = 121000 dist_mean = 0.3292 dist_std = 0.7830 vf_loss = 0.3711 grad_norm = 0.6015 nat_grad_norm = 0.6222 cg_residual = 0.0279 step_size = 0.3502 reward = -0.0000 fps = 12 mse_loss = 0.9485 
2022-07-08 09:17:34.400328 - gail/main.py:174 - [TRPO] iter = 122000 dist_mean = 0.3442 dist_std = 0.7782 vf_loss = 0.4004 grad_norm = 0.7874 nat_grad_norm = 0.5388 cg_residual = 0.0209 step_size = 0.3547 reward = -0.0000 fps = 8 mse_loss = 1.0933 
2022-07-08 09:18:03.116308 - gail/main.py:174 - [TRPO] iter = 123000 dist_mean = 0.3619 dist_std = 0.7733 vf_loss = 0.4348 grad_norm = 0.5814 nat_grad_norm = 0.6659 cg_residual = 0.0360 step_size = 0.3359 reward = -0.0000 fps = 7 mse_loss = 0.9582 
2022-07-08 09:18:31.971934 - gail/main.py:174 - [TRPO] iter = 124000 dist_mean = 0.3449 dist_std = 0.7731 vf_loss = 0.4424 grad_norm = 0.5418 nat_grad_norm = 0.6609 cg_residual = 0.0533 step_size = 0.3298 reward = 0.0000 fps = 5 mse_loss = 1.0246 
2022-07-08 09:19:02.111222 - gail/main.py:174 - [TRPO] iter = 125000 dist_mean = 0.3250 dist_std = 0.7704 vf_loss = 0.3376 grad_norm = 0.5471 nat_grad_norm = 0.5692 cg_residual = 0.0258 step_size = 0.3694 reward = -0.0000 fps = 5 mse_loss = 1.0524 
2022-07-08 09:19:02.916678 - gail/main.py:201 - [Discriminator] iter = 125000 loss = -3.7185 grad_norm = 4.0510 grad_penalty = 0.3438 regularization = 0.0000 true_logits = -0.0096 fake_logits = -4.0718 true_prob = 0.5155 fake_prob = 0.0291 
2022-07-08 09:19:54.902959 - gail/main.py:142 - [Evaluate] iter = 125000 episode={ returns = 347.5227 lengths = 130 } discounted_episode={ returns = 324.1180 lengths = 130 } 
2022-07-08 09:20:25.444531 - gail/main.py:174 - [TRPO] iter = 126000 dist_mean = 0.3317 dist_std = 0.7666 vf_loss = 0.2446 grad_norm = 0.6361 nat_grad_norm = 0.5433 cg_residual = 0.0254 step_size = 0.3553 reward = 0.0000 fps = 12 mse_loss = 1.0808 
2022-07-08 09:20:54.809560 - gail/main.py:174 - [TRPO] iter = 127000 dist_mean = 0.3236 dist_std = 0.7658 vf_loss = 0.2390 grad_norm = 0.8049 nat_grad_norm = 0.5506 cg_residual = 0.0421 step_size = 0.3195 reward = 0.0000 fps = 8 mse_loss = 1.0646 
2022-07-08 09:21:23.086842 - gail/main.py:174 - [TRPO] iter = 128000 dist_mean = 0.3403 dist_std = 0.7662 vf_loss = 0.2394 grad_norm = 0.4475 nat_grad_norm = 0.4895 cg_residual = 0.0213 step_size = 0.4085 reward = 0.0000 fps = 7 mse_loss = 1.0435 
2022-07-08 09:21:56.156399 - gail/main.py:174 - [TRPO] iter = 129000 dist_mean = 0.3475 dist_std = 0.7666 vf_loss = 0.3309 grad_norm = 0.6984 nat_grad_norm = 0.5310 cg_residual = 0.0294 step_size = 0.3668 reward = 0.0000 fps = 5 mse_loss = 0.9500 
2022-07-08 09:22:27.054461 - gail/main.py:174 - [TRPO] iter = 130000 dist_mean = 0.3164 dist_std = 0.7625 vf_loss = 0.3161 grad_norm = 0.6234 nat_grad_norm = 0.4996 cg_residual = 0.0180 step_size = 0.3856 reward = -0.0000 fps = 4 mse_loss = 0.9613 
2022-07-08 09:22:27.897569 - gail/main.py:201 - [Discriminator] iter = 130000 loss = -3.5965 grad_norm = 3.6001 grad_penalty = 0.3353 regularization = 0.0000 true_logits = -0.0264 fake_logits = -3.9582 true_prob = 0.5164 fake_prob = 0.0302 
2022-07-08 09:23:18.970321 - gail/main.py:142 - [Evaluate] iter = 130000 episode={ returns = 310.9466 lengths = 126 } discounted_episode={ returns = 288.8319 lengths = 126 } 
2022-07-08 09:23:47.730532 - gail/main.py:174 - [TRPO] iter = 131000 dist_mean = 0.3458 dist_std = 0.7623 vf_loss = 0.3860 grad_norm = 0.7721 nat_grad_norm = 0.5110 cg_residual = 0.0218 step_size = 0.3510 reward = -0.0000 fps = 12 mse_loss = 1.0013 
2022-07-08 09:24:16.527449 - gail/main.py:174 - [TRPO] iter = 132000 dist_mean = 0.3850 dist_std = 0.7582 vf_loss = 0.3542 grad_norm = 0.5571 nat_grad_norm = 0.4897 cg_residual = 0.0278 step_size = 0.3983 reward = 0.0000 fps = 9 mse_loss = 1.0539 
2022-07-08 09:24:43.677880 - gail/main.py:174 - [TRPO] iter = 133000 dist_mean = 0.3273 dist_std = 0.7572 vf_loss = 0.3287 grad_norm = 0.6538 nat_grad_norm = 0.5229 cg_residual = 0.0368 step_size = 0.3492 reward = 0.0000 fps = 7 mse_loss = 1.0881 
2022-07-08 09:25:10.453968 - gail/main.py:174 - [TRPO] iter = 134000 dist_mean = 0.4310 dist_std = 0.7516 vf_loss = 0.4265 grad_norm = 0.5136 nat_grad_norm = 0.5231 cg_residual = 0.0151 step_size = 0.4188 reward = 0.0000 fps = 6 mse_loss = 1.0964 
2022-07-08 09:25:38.323861 - gail/main.py:174 - [TRPO] iter = 135000 dist_mean = 0.3307 dist_std = 0.7500 vf_loss = 0.2444 grad_norm = 0.5695 nat_grad_norm = 0.5054 cg_residual = 0.0328 step_size = 0.3898 reward = -0.0000 fps = 5 mse_loss = 1.0078 
2022-07-08 09:25:39.111376 - gail/main.py:201 - [Discriminator] iter = 135000 loss = -3.7398 grad_norm = 3.5089 grad_penalty = 0.3279 regularization = 0.0000 true_logits = 0.0160 fake_logits = -4.0517 true_prob = 0.5292 fake_prob = 0.0265 
2022-07-08 09:26:30.676719 - gail/main.py:142 - [Evaluate] iter = 135000 episode={ returns = 325.2529 lengths = 130 } discounted_episode={ returns = 301.8091 lengths = 130 } 
2022-07-08 09:26:58.658998 - gail/main.py:174 - [TRPO] iter = 136000 dist_mean = 0.4387 dist_std = 0.7489 vf_loss = 0.3477 grad_norm = 0.7446 nat_grad_norm = 0.8250 cg_residual = 0.0483 step_size = 0.2661 reward = -0.0000 fps = 12 mse_loss = 1.1025 
2022-07-08 09:27:26.215597 - gail/main.py:174 - [TRPO] iter = 137000 dist_mean = 0.3566 dist_std = 0.7481 vf_loss = 0.3508 grad_norm = 0.5344 nat_grad_norm = 0.5869 cg_residual = 0.0264 step_size = 0.3648 reward = 0.0000 fps = 9 mse_loss = 1.0597 
2022-07-08 09:27:53.428562 - gail/main.py:174 - [TRPO] iter = 138000 dist_mean = 0.3557 dist_std = 0.7492 vf_loss = 0.2388 grad_norm = 0.6275 nat_grad_norm = 0.4652 cg_residual = 0.0284 step_size = 0.4075 reward = -0.0000 fps = 7 mse_loss = 1.0639 
2022-07-08 09:28:20.313397 - gail/main.py:174 - [TRPO] iter = 139000 dist_mean = 0.3631 dist_std = 0.7484 vf_loss = 0.5342 grad_norm = 0.6360 nat_grad_norm = 0.4347 cg_residual = 0.0397 step_size = 0.4136 reward = 0.0000 fps = 6 mse_loss = 1.0276 
2022-07-08 09:28:48.758719 - gail/main.py:174 - [TRPO] iter = 140000 dist_mean = 0.3609 dist_std = 0.7512 vf_loss = 0.3451 grad_norm = 0.5375 nat_grad_norm = 0.5248 cg_residual = 0.0298 step_size = 0.3845 reward = 0.0000 fps = 5 mse_loss = 1.0832 
2022-07-08 09:28:49.572159 - gail/main.py:201 - [Discriminator] iter = 140000 loss = -3.7545 grad_norm = 3.4343 grad_penalty = 0.3331 regularization = 0.0000 true_logits = 0.0679 fake_logits = -4.0197 true_prob = 0.5359 fake_prob = 0.0283 
2022-07-08 09:29:36.879409 - gail/main.py:142 - [Evaluate] iter = 140000 episode={ returns = 321.2962 lengths = 125 } discounted_episode={ returns = 297.5526 lengths = 125 } 
2022-07-08 09:30:04.124604 - gail/main.py:174 - [TRPO] iter = 141000 dist_mean = 0.3762 dist_std = 0.7495 vf_loss = 0.8716 grad_norm = 0.8225 nat_grad_norm = 0.5560 cg_residual = 0.0274 step_size = 0.3209 reward = 0.0000 fps = 13 mse_loss = 1.0912 
2022-07-08 09:30:31.555973 - gail/main.py:174 - [TRPO] iter = 142000 dist_mean = 0.3337 dist_std = 0.7470 vf_loss = 0.4243 grad_norm = 0.7596 nat_grad_norm = 0.5613 cg_residual = 0.0409 step_size = 0.3577 reward = 0.0000 fps = 9 mse_loss = 1.1384 
2022-07-08 09:30:58.459368 - gail/main.py:174 - [TRPO] iter = 143000 dist_mean = 0.3599 dist_std = 0.7451 vf_loss = 0.5328 grad_norm = 0.6828 nat_grad_norm = 0.5084 cg_residual = 0.0452 step_size = 0.3562 reward = -0.0000 fps = 7 mse_loss = 1.2213 
2022-07-08 09:31:26.968072 - gail/main.py:174 - [TRPO] iter = 144000 dist_mean = 0.3555 dist_std = 0.7420 vf_loss = 0.3872 grad_norm = 0.6637 nat_grad_norm = 0.5214 cg_residual = 0.0337 step_size = 0.3935 reward = 0.0000 fps = 6 mse_loss = 1.1985 
2022-07-08 09:31:54.226926 - gail/main.py:174 - [TRPO] iter = 145000 dist_mean = 0.3391 dist_std = 0.7399 vf_loss = 0.2870 grad_norm = 0.6023 nat_grad_norm = 0.5423 cg_residual = 0.0555 step_size = 0.3528 reward = 0.0000 fps = 5 mse_loss = 1.2029 
2022-07-08 09:31:55.020811 - gail/main.py:201 - [Discriminator] iter = 145000 loss = -3.7358 grad_norm = 2.9682 grad_penalty = 0.3221 regularization = 0.0000 true_logits = 0.0022 fake_logits = -4.0557 true_prob = 0.5264 fake_prob = 0.0282 
2022-07-08 09:32:51.301068 - gail/main.py:142 - [Evaluate] iter = 145000 episode={ returns = 335.4589 lengths = 135 } discounted_episode={ returns = 309.8475 lengths = 135 } 
2022-07-08 09:33:19.192426 - gail/main.py:174 - [TRPO] iter = 146000 dist_mean = 0.3456 dist_std = 0.7387 vf_loss = 0.2723 grad_norm = 0.7382 nat_grad_norm = 0.5289 cg_residual = 0.0441 step_size = 0.3374 reward = 0.0000 fps = 11 mse_loss = 1.2221 
2022-07-08 09:33:47.296585 - gail/main.py:174 - [TRPO] iter = 147000 dist_mean = 0.3606 dist_std = 0.7390 vf_loss = 0.3632 grad_norm = 0.6050 nat_grad_norm = 0.6250 cg_residual = 0.0584 step_size = 0.3321 reward = 0.0000 fps = 8 mse_loss = 1.2336 
2022-07-08 09:34:13.727222 - gail/main.py:174 - [TRPO] iter = 148000 dist_mean = 0.3376 dist_std = 0.7380 vf_loss = 0.3708 grad_norm = 0.6352 nat_grad_norm = 0.5662 cg_residual = 0.0373 step_size = 0.3404 reward = 0.0000 fps = 7 mse_loss = 1.2959 
2022-07-08 09:34:40.107765 - gail/main.py:174 - [TRPO] iter = 149000 dist_mean = 0.3374 dist_std = 0.7371 vf_loss = 0.4211 grad_norm = 0.4975 nat_grad_norm = 0.4665 cg_residual = 0.0302 step_size = 0.4146 reward = -0.0000 fps = 6 mse_loss = 1.2509 
2022-07-08 09:35:07.489559 - gail/main.py:174 - [TRPO] iter = 150000 dist_mean = 0.2997 dist_std = 0.7355 vf_loss = 0.3084 grad_norm = 0.7108 nat_grad_norm = 0.6120 cg_residual = 0.0772 step_size = 0.3102 reward = 0.0000 fps = 5 mse_loss = 1.1978 
2022-07-08 09:35:08.242042 - gail/main.py:201 - [Discriminator] iter = 150000 loss = -3.6993 grad_norm = 3.4007 grad_penalty = 0.3126 regularization = 0.0000 true_logits = 0.1492 fake_logits = -3.8627 true_prob = 0.5537 fake_prob = 0.0368 
2022-07-08 09:35:57.140194 - gail/main.py:142 - [Evaluate] iter = 150000 episode={ returns = 361.7669 lengths = 139 } discounted_episode={ returns = 331.6641 lengths = 138 } 
2022-07-08 09:36:24.042253 - gail/main.py:174 - [TRPO] iter = 151000 dist_mean = 0.3306 dist_std = 0.7360 vf_loss = 0.2802 grad_norm = 0.7472 nat_grad_norm = 0.6136 cg_residual = 0.0426 step_size = 0.3254 reward = 0.0000 fps = 13 mse_loss = 1.2968 
2022-07-08 09:36:51.071403 - gail/main.py:174 - [TRPO] iter = 152000 dist_mean = 0.3790 dist_std = 0.7354 vf_loss = 0.3825 grad_norm = 0.7216 nat_grad_norm = 0.5432 cg_residual = 0.0530 step_size = 0.3271 reward = -0.0000 fps = 9 mse_loss = 1.2585 
2022-07-08 09:37:17.111396 - gail/main.py:174 - [TRPO] iter = 153000 dist_mean = 0.3450 dist_std = 0.7301 vf_loss = 0.4167 grad_norm = 0.6896 nat_grad_norm = 0.6118 cg_residual = 0.0365 step_size = 0.3271 reward = -0.0000 fps = 7 mse_loss = 1.3699 
2022-07-08 09:37:44.073670 - gail/main.py:174 - [TRPO] iter = 154000 dist_mean = 0.3369 dist_std = 0.7268 vf_loss = 0.3907 grad_norm = 0.9138 nat_grad_norm = 0.6311 cg_residual = 0.0421 step_size = 0.3021 reward = -0.0000 fps = 6 mse_loss = 1.3220 
2022-07-08 09:38:10.390260 - gail/main.py:174 - [TRPO] iter = 155000 dist_mean = 0.3534 dist_std = 0.7226 vf_loss = 0.2813 grad_norm = 0.7928 nat_grad_norm = 0.6013 cg_residual = 0.0855 step_size = 0.3052 reward = -0.0000 fps = 5 mse_loss = 1.2852 
2022-07-08 09:38:11.151380 - gail/main.py:201 - [Discriminator] iter = 155000 loss = -3.8955 grad_norm = 3.4999 grad_penalty = 0.3331 regularization = 0.0000 true_logits = 0.0943 fake_logits = -4.1343 true_prob = 0.5434 fake_prob = 0.0276 
2022-07-08 09:39:04.140043 - gail/main.py:142 - [Evaluate] iter = 155000 episode={ returns = 389.1972 lengths = 148 } discounted_episode={ returns = 354.0227 lengths = 147 } 
2022-07-08 09:39:29.960650 - gail/main.py:174 - [TRPO] iter = 156000 dist_mean = 0.3325 dist_std = 0.7204 vf_loss = 0.3181 grad_norm = 0.6841 nat_grad_norm = 0.5570 cg_residual = 0.0730 step_size = 0.3410 reward = 0.0000 fps = 12 mse_loss = 1.3071 
2022-07-08 09:39:57.578501 - gail/main.py:174 - [TRPO] iter = 157000 dist_mean = 0.3451 dist_std = 0.7200 vf_loss = 0.3671 grad_norm = 0.8743 nat_grad_norm = 0.5519 cg_residual = 0.1076 step_size = 0.3213 reward = 0.0000 fps = 9 mse_loss = 1.4381 
2022-07-08 09:40:25.839733 - gail/main.py:174 - [TRPO] iter = 158000 dist_mean = 0.2842 dist_std = 0.7181 vf_loss = 0.4699 grad_norm = 0.8760 nat_grad_norm = 0.4925 cg_residual = 0.0542 step_size = 0.3579 reward = 0.0000 fps = 7 mse_loss = 1.3824 
2022-07-08 09:40:52.174874 - gail/main.py:174 - [TRPO] iter = 159000 dist_mean = 0.3196 dist_std = 0.7180 vf_loss = 0.3168 grad_norm = 0.8354 nat_grad_norm = 0.5741 cg_residual = 0.0741 step_size = 0.3328 reward = -0.0000 fps = 6 mse_loss = 1.3602 
2022-07-08 09:41:18.197834 - gail/main.py:174 - [TRPO] iter = 160000 dist_mean = 0.3158 dist_std = 0.7132 vf_loss = 0.4004 grad_norm = 0.7389 nat_grad_norm = 0.6778 cg_residual = 0.0764 step_size = 0.2913 reward = 0.0000 fps = 5 mse_loss = 1.4275 
2022-07-08 09:41:19.027242 - gail/main.py:201 - [Discriminator] iter = 160000 loss = -3.7789 grad_norm = 2.5762 grad_penalty = 0.3206 regularization = 0.0000 true_logits = 0.0765 fake_logits = -4.0230 true_prob = 0.5429 fake_prob = 0.0335 
2022-07-08 09:42:20.837080 - gail/main.py:142 - [Evaluate] iter = 160000 episode={ returns = 428.9723 lengths = 154 } discounted_episode={ returns = 391.1822 lengths = 155 } 
2022-07-08 09:42:46.861991 - gail/main.py:174 - [TRPO] iter = 161000 dist_mean = 0.3066 dist_std = 0.7132 vf_loss = 0.3586 grad_norm = 0.7151 nat_grad_norm = 0.5915 cg_residual = 0.0425 step_size = 0.3259 reward = -0.0000 fps = 11 mse_loss = 1.3792 
2022-07-08 09:43:11.792468 - gail/main.py:174 - [TRPO] iter = 162000 dist_mean = 0.3226 dist_std = 0.7087 vf_loss = 0.2712 grad_norm = 0.8052 nat_grad_norm = 0.8045 cg_residual = 0.0631 step_size = 0.2805 reward = 0.0000 fps = 8 mse_loss = 1.3052 
2022-07-08 09:43:36.509526 - gail/main.py:174 - [TRPO] iter = 163000 dist_mean = 0.3001 dist_std = 0.7068 vf_loss = 0.2305 grad_norm = 0.8940 nat_grad_norm = 0.4838 cg_residual = 0.0522 step_size = 0.3588 reward = -0.0000 fps = 7 mse_loss = 1.2959 
2022-07-08 09:44:02.424507 - gail/main.py:174 - [TRPO] iter = 164000 dist_mean = 0.3314 dist_std = 0.7036 vf_loss = 0.1872 grad_norm = 0.7131 nat_grad_norm = 0.6051 cg_residual = 0.0682 step_size = 0.3212 reward = 0.0000 fps = 6 mse_loss = 1.3428 
2022-07-08 09:44:28.232886 - gail/main.py:174 - [TRPO] iter = 165000 dist_mean = 0.3865 dist_std = 0.7040 vf_loss = 0.4271 grad_norm = 0.7711 nat_grad_norm = 0.5845 cg_residual = 0.0577 step_size = 0.3217 reward = 0.0000 fps = 5 mse_loss = 1.2976 
2022-07-08 09:44:28.885698 - gail/main.py:201 - [Discriminator] iter = 165000 loss = -3.8733 grad_norm = 2.8394 grad_penalty = 0.3287 regularization = 0.0000 true_logits = 0.1186 fake_logits = -4.0834 true_prob = 0.5486 fake_prob = 0.0329 
2022-07-08 09:45:32.576060 - gail/main.py:142 - [Evaluate] iter = 165000 episode={ returns = 605.9404 lengths = 189 } discounted_episode={ returns = 543.7471 lengths = 190 } 
2022-07-08 09:45:58.163981 - gail/main.py:174 - [TRPO] iter = 166000 dist_mean = 0.3465 dist_std = 0.7042 vf_loss = 0.2851 grad_norm = 0.7261 nat_grad_norm = 0.5922 cg_residual = 0.0991 step_size = 0.3082 reward = 0.0000 fps = 11 mse_loss = 1.3682 
2022-07-08 09:46:23.157656 - gail/main.py:174 - [TRPO] iter = 167000 dist_mean = 0.3088 dist_std = 0.7019 vf_loss = 0.4124 grad_norm = 0.6987 nat_grad_norm = 0.6380 cg_residual = 0.0564 step_size = 0.3149 reward = 0.0000 fps = 8 mse_loss = 1.3180 
2022-07-08 09:46:49.464204 - gail/main.py:174 - [TRPO] iter = 168000 dist_mean = 0.3120 dist_std = 0.7006 vf_loss = 0.2149 grad_norm = 0.8539 nat_grad_norm = 0.7371 cg_residual = 0.1010 step_size = 0.2667 reward = 0.0000 fps = 7 mse_loss = 1.2730 
2022-07-08 09:47:15.783737 - gail/main.py:174 - [TRPO] iter = 169000 dist_mean = 0.3361 dist_std = 0.7006 vf_loss = 0.4064 grad_norm = 0.8708 nat_grad_norm = 0.6594 cg_residual = 0.0612 step_size = 0.2980 reward = 0.0000 fps = 5 mse_loss = 1.3598 
2022-07-08 09:47:41.860036 - gail/main.py:174 - [TRPO] iter = 170000 dist_mean = 0.3144 dist_std = 0.6984 vf_loss = 0.2461 grad_norm = 1.1603 nat_grad_norm = 0.6155 cg_residual = 0.0660 step_size = 0.2667 reward = 0.0000 fps = 5 mse_loss = 1.3450 
2022-07-08 09:47:42.552904 - gail/main.py:201 - [Discriminator] iter = 170000 loss = -3.5718 grad_norm = 3.0476 grad_penalty = 0.3107 regularization = 0.0000 true_logits = 0.1250 fake_logits = -3.7576 true_prob = 0.5488 fake_prob = 0.0429 
2022-07-08 09:48:43.800820 - gail/main.py:142 - [Evaluate] iter = 170000 episode={ returns = 547.7294 lengths = 179 } discounted_episode={ returns = 494.1011 lengths = 179 } 
2022-07-08 09:49:10.014411 - gail/main.py:174 - [TRPO] iter = 171000 dist_mean = 0.3543 dist_std = 0.6979 vf_loss = 0.3957 grad_norm = 0.6963 nat_grad_norm = 0.5065 cg_residual = 0.0501 step_size = 0.3497 reward = -0.0000 fps = 11 mse_loss = 1.3234 
2022-07-08 09:49:35.960315 - gail/main.py:174 - [TRPO] iter = 172000 dist_mean = 0.3065 dist_std = 0.6961 vf_loss = 0.3421 grad_norm = 0.8163 nat_grad_norm = 0.6795 cg_residual = 0.1075 step_size = 0.2912 reward = 0.0000 fps = 8 mse_loss = 1.2631 
2022-07-08 09:50:05.262018 - gail/main.py:174 - [TRPO] iter = 173000 dist_mean = 0.3280 dist_std = 0.6913 vf_loss = 0.4252 grad_norm = 0.7677 nat_grad_norm = 0.6539 cg_residual = 0.0695 step_size = 0.2954 reward = 0.0000 fps = 7 mse_loss = 1.2247 
2022-07-08 09:50:33.185954 - gail/main.py:174 - [TRPO] iter = 174000 dist_mean = 0.3157 dist_std = 0.6885 vf_loss = 0.3178 grad_norm = 0.9352 nat_grad_norm = 0.5666 cg_residual = 0.0776 step_size = 0.3210 reward = 0.0000 fps = 5 mse_loss = 1.2987 
2022-07-08 09:50:58.496982 - gail/main.py:174 - [TRPO] iter = 175000 dist_mean = 0.2773 dist_std = 0.6843 vf_loss = 0.2835 grad_norm = 0.8296 nat_grad_norm = 0.5706 cg_residual = 0.0817 step_size = 0.3170 reward = 0.0000 fps = 5 mse_loss = 1.2718 
2022-07-08 09:50:59.316785 - gail/main.py:201 - [Discriminator] iter = 175000 loss = -3.7817 grad_norm = 3.0335 grad_penalty = 0.2849 regularization = 0.0000 true_logits = 0.2216 fake_logits = -3.8449 true_prob = 0.5612 fake_prob = 0.0392 
2022-07-08 09:52:02.863358 - gail/main.py:142 - [Evaluate] iter = 175000 episode={ returns = 548.3042 lengths = 176 } discounted_episode={ returns = 508.2648 lengths = 179 } 
2022-07-08 09:52:32.399391 - gail/main.py:174 - [TRPO] iter = 176000 dist_mean = 0.3125 dist_std = 0.6808 vf_loss = 0.1824 grad_norm = 0.8437 nat_grad_norm = 0.5824 cg_residual = 0.0733 step_size = 0.3120 reward = 0.0000 fps = 10 mse_loss = 1.3186 
2022-07-08 09:52:58.808140 - gail/main.py:174 - [TRPO] iter = 177000 dist_mean = 0.3028 dist_std = 0.6792 vf_loss = 0.3744 grad_norm = 0.9102 nat_grad_norm = 0.6126 cg_residual = 0.0756 step_size = 0.2990 reward = -0.0000 fps = 8 mse_loss = 1.2944 
2022-07-08 09:53:25.745692 - gail/main.py:174 - [TRPO] iter = 178000 dist_mean = 0.3128 dist_std = 0.6772 vf_loss = 0.2988 grad_norm = 0.8233 nat_grad_norm = 0.7008 cg_residual = 0.1240 step_size = 0.2845 reward = 0.0000 fps = 6 mse_loss = 1.2876 
2022-07-08 09:53:53.183614 - gail/main.py:174 - [TRPO] iter = 179000 dist_mean = 0.3096 dist_std = 0.6759 vf_loss = 0.3013 grad_norm = 0.8226 nat_grad_norm = 0.5576 cg_residual = 0.0775 step_size = 0.3308 reward = -0.0000 fps = 5 mse_loss = 1.2759 
2022-07-08 09:54:21.495754 - gail/main.py:174 - [TRPO] iter = 180000 dist_mean = 0.2891 dist_std = 0.6777 vf_loss = 0.3335 grad_norm = 0.8232 nat_grad_norm = 0.6248 cg_residual = 0.0699 step_size = 0.2913 reward = -0.0000 fps = 4 mse_loss = 1.2834 
2022-07-08 09:54:22.295248 - gail/main.py:201 - [Discriminator] iter = 180000 loss = -3.5478 grad_norm = 2.9943 grad_penalty = 0.2997 regularization = 0.0000 true_logits = 0.2030 fake_logits = -3.6445 true_prob = 0.5604 fake_prob = 0.0506 
2022-07-08 09:55:21.652695 - gail/main.py:142 - [Evaluate] iter = 180000 episode={ returns = 516.6112 lengths = 172 } discounted_episode={ returns = 463.8055 lengths = 172 } 
2022-07-08 09:55:46.598107 - gail/main.py:174 - [TRPO] iter = 181000 dist_mean = 0.3262 dist_std = 0.6748 vf_loss = 0.4666 grad_norm = 0.6988 nat_grad_norm = 0.5465 cg_residual = 0.0351 step_size = 0.3523 reward = 0.0000 fps = 11 mse_loss = 1.1853 
2022-07-08 09:56:11.472863 - gail/main.py:174 - [TRPO] iter = 182000 dist_mean = 0.3088 dist_std = 0.6742 vf_loss = 0.6162 grad_norm = 0.7140 nat_grad_norm = 0.5836 cg_residual = 0.0592 step_size = 0.3284 reward = -0.0000 fps = 9 mse_loss = 1.2502 
2022-07-08 09:56:36.294827 - gail/main.py:174 - [TRPO] iter = 183000 dist_mean = 0.3227 dist_std = 0.6728 vf_loss = 0.3796 grad_norm = 0.7788 nat_grad_norm = 0.6502 cg_residual = 0.0745 step_size = 0.3176 reward = -0.0000 fps = 7 mse_loss = 1.2513 
2022-07-08 09:57:00.903348 - gail/main.py:174 - [TRPO] iter = 184000 dist_mean = 0.3098 dist_std = 0.6674 vf_loss = 0.4094 grad_norm = 0.9183 nat_grad_norm = 0.6079 cg_residual = 0.0709 step_size = 0.3213 reward = 0.0000 fps = 6 mse_loss = 1.2610 
2022-07-08 09:57:25.737650 - gail/main.py:174 - [TRPO] iter = 185000 dist_mean = 0.3006 dist_std = 0.6636 vf_loss = 0.4090 grad_norm = 0.7873 nat_grad_norm = 0.6492 cg_residual = 0.0726 step_size = 0.3143 reward = -0.0000 fps = 5 mse_loss = 1.3267 
2022-07-08 09:57:26.465164 - gail/main.py:201 - [Discriminator] iter = 185000 loss = -3.7182 grad_norm = 2.8593 grad_penalty = 0.2975 regularization = 0.0000 true_logits = 0.2201 fake_logits = -3.7956 true_prob = 0.5641 fake_prob = 0.0437 
2022-07-08 09:58:27.601076 - gail/main.py:142 - [Evaluate] iter = 185000 episode={ returns = 566.6185 lengths = 184 } discounted_episode={ returns = 506.2656 lengths = 184 } 
2022-07-08 09:58:54.157889 - gail/main.py:174 - [TRPO] iter = 186000 dist_mean = 0.3111 dist_std = 0.6590 vf_loss = 0.3727 grad_norm = 0.7113 nat_grad_norm = 0.5552 cg_residual = 0.0630 step_size = 0.3377 reward = -0.0000 fps = 11 mse_loss = 1.3401 
2022-07-08 09:59:19.003891 - gail/main.py:174 - [TRPO] iter = 187000 dist_mean = 0.3045 dist_std = 0.6618 vf_loss = 0.2881 grad_norm = 0.8277 nat_grad_norm = 0.5829 cg_residual = 0.0691 step_size = 0.3185 reward = 0.0000 fps = 8 mse_loss = 1.3544 
2022-07-08 09:59:46.394155 - gail/main.py:174 - [TRPO] iter = 188000 dist_mean = 0.3082 dist_std = 0.6603 vf_loss = 0.3004 grad_norm = 0.7622 nat_grad_norm = 0.6318 cg_residual = 0.0796 step_size = 0.3063 reward = 0.0000 fps = 7 mse_loss = 1.3612 
2022-07-08 10:00:13.508459 - gail/main.py:174 - [TRPO] iter = 189000 dist_mean = 0.3006 dist_std = 0.6582 vf_loss = 0.2824 grad_norm = 0.9391 nat_grad_norm = 0.5874 cg_residual = 0.0723 step_size = 0.2967 reward = 0.0000 fps = 5 mse_loss = 1.2833 
2022-07-08 10:00:40.426934 - gail/main.py:174 - [TRPO] iter = 190000 dist_mean = 0.3144 dist_std = 0.6532 vf_loss = 0.5771 grad_norm = 0.7504 nat_grad_norm = 0.5344 cg_residual = 0.0985 step_size = 0.3453 reward = -0.0000 fps = 5 mse_loss = 1.4450 
2022-07-08 10:00:41.254404 - gail/main.py:201 - [Discriminator] iter = 190000 loss = -3.8321 grad_norm = 3.4611 grad_penalty = 0.3140 regularization = 0.0000 true_logits = 0.2347 fake_logits = -3.9114 true_prob = 0.5658 fake_prob = 0.0393 
2022-07-08 10:01:48.982513 - gail/main.py:142 - [Evaluate] iter = 190000 episode={ returns = 543.3948 lengths = 181 } discounted_episode={ returns = 486.7111 lengths = 181 } 
2022-07-08 10:02:25.254162 - gail/main.py:174 - [TRPO] iter = 191000 dist_mean = 0.3204 dist_std = 0.6530 vf_loss = 0.3853 grad_norm = 0.6272 nat_grad_norm = 0.6696 cg_residual = 0.0941 step_size = 0.3092 reward = -0.0000 fps = 9 mse_loss = 1.3707 
2022-07-08 10:02:55.054376 - gail/main.py:174 - [TRPO] iter = 192000 dist_mean = 0.3484 dist_std = 0.6517 vf_loss = 0.4376 grad_norm = 0.8473 nat_grad_norm = 0.6674 cg_residual = 0.1225 step_size = 0.2792 reward = -0.0000 fps = 7 mse_loss = 1.2868 
2022-07-08 10:03:24.960716 - gail/main.py:174 - [TRPO] iter = 193000 dist_mean = 0.3036 dist_std = 0.6482 vf_loss = 0.3286 grad_norm = 0.9222 nat_grad_norm = 0.6446 cg_residual = 0.1105 step_size = 0.2767 reward = -0.0000 fps = 6 mse_loss = 1.3027 
2022-07-08 10:03:55.016398 - gail/main.py:174 - [TRPO] iter = 194000 dist_mean = 0.2941 dist_std = 0.6451 vf_loss = 0.4291 grad_norm = 0.8212 nat_grad_norm = 0.5128 cg_residual = 0.0827 step_size = 0.3210 reward = 0.0000 fps = 5 mse_loss = 1.3984 
2022-07-08 10:04:24.289096 - gail/main.py:174 - [TRPO] iter = 195000 dist_mean = 0.3297 dist_std = 0.6467 vf_loss = 0.5269 grad_norm = 0.7725 nat_grad_norm = 0.6172 cg_residual = 0.1024 step_size = 0.3333 reward = 0.0000 fps = 4 mse_loss = 1.3418 
2022-07-08 10:04:25.140785 - gail/main.py:201 - [Discriminator] iter = 195000 loss = -3.7563 grad_norm = 3.6655 grad_penalty = 0.3155 regularization = 0.0000 true_logits = 0.2063 fake_logits = -3.8655 true_prob = 0.5546 fake_prob = 0.0434 
2022-07-08 10:05:37.004379 - gail/main.py:142 - [Evaluate] iter = 195000 episode={ returns = 529.1492 lengths = 178 } discounted_episode={ returns = 476.4032 lengths = 179 } 
2022-07-08 10:06:07.149896 - gail/main.py:174 - [TRPO] iter = 196000 dist_mean = 0.3345 dist_std = 0.6444 vf_loss = 0.4501 grad_norm = 0.7390 nat_grad_norm = 0.6909 cg_residual = 0.0762 step_size = 0.3008 reward = -0.0000 fps = 9 mse_loss = 1.3539 
2022-07-08 10:06:36.834274 - gail/main.py:174 - [TRPO] iter = 197000 dist_mean = 0.3494 dist_std = 0.6443 vf_loss = 0.4483 grad_norm = 1.0158 nat_grad_norm = 0.6352 cg_residual = 0.1063 step_size = 0.2919 reward = -0.0000 fps = 7 mse_loss = 1.3395 
2022-07-08 10:07:07.193130 - gail/main.py:174 - [TRPO] iter = 198000 dist_mean = 0.3023 dist_std = 0.6421 vf_loss = 0.3658 grad_norm = 1.0487 nat_grad_norm = 0.5898 cg_residual = 0.0975 step_size = 0.3120 reward = -0.0000 fps = 6 mse_loss = 1.3426 
2022-07-08 10:07:36.396034 - gail/main.py:174 - [TRPO] iter = 199000 dist_mean = 0.3314 dist_std = 0.6400 vf_loss = 0.3255 grad_norm = 1.0173 nat_grad_norm = 0.6479 cg_residual = 0.1400 step_size = 0.2746 reward = 0.0000 fps = 5 mse_loss = 1.2705 
2022-07-08 10:08:04.609190 - gail/main.py:174 - [TRPO] iter = 200000 dist_mean = 0.3072 dist_std = 0.6326 vf_loss = 0.2832 grad_norm = 0.8687 nat_grad_norm = 0.6182 cg_residual = 0.1121 step_size = 0.3042 reward = 0.0000 fps = 4 mse_loss = 1.2686 
2022-07-08 10:08:05.432412 - gail/main.py:201 - [Discriminator] iter = 200000 loss = -3.6799 grad_norm = 2.8540 grad_penalty = 0.2962 regularization = 0.0000 true_logits = 0.2174 fake_logits = -3.7588 true_prob = 0.5587 fake_prob = 0.0495 
2022-07-08 10:09:18.061370 - gail/main.py:142 - [Evaluate] iter = 200000 episode={ returns = 559.6869 lengths = 182 } discounted_episode={ returns = 501.1074 lengths = 182 } 
2022-07-08 10:09:48.660272 - gail/main.py:174 - [TRPO] iter = 201000 dist_mean = 0.3427 dist_std = 0.6306 vf_loss = 0.2210 grad_norm = 0.7240 nat_grad_norm = 0.6743 cg_residual = 0.1114 step_size = 0.3139 reward = -0.0000 fps = 9 mse_loss = 1.3515 
2022-07-08 10:10:17.311267 - gail/main.py:174 - [TRPO] iter = 202000 dist_mean = 0.3084 dist_std = 0.6298 vf_loss = 0.3708 grad_norm = 0.9428 nat_grad_norm = 0.5355 cg_residual = 0.0978 step_size = 0.3103 reward = 0.0000 fps = 7 mse_loss = 1.4355 
2022-07-08 10:10:45.820373 - gail/main.py:174 - [TRPO] iter = 203000 dist_mean = 0.3338 dist_std = 0.6285 vf_loss = 0.2448 grad_norm = 0.7601 nat_grad_norm = 0.5542 cg_residual = 0.1043 step_size = 0.3369 reward = -0.0000 fps = 6 mse_loss = 1.3400 
2022-07-08 10:11:15.360129 - gail/main.py:174 - [TRPO] iter = 204000 dist_mean = 0.3213 dist_std = 0.6282 vf_loss = 0.4753 grad_norm = 0.8696 nat_grad_norm = 0.6527 cg_residual = 0.1418 step_size = 0.2932 reward = -0.0000 fps = 5 mse_loss = 1.5192 
2022-07-08 10:11:46.923848 - gail/main.py:174 - [TRPO] iter = 205000 dist_mean = 0.3243 dist_std = 0.6244 vf_loss = 0.2923 grad_norm = 1.1930 nat_grad_norm = 0.7599 cg_residual = 0.1256 step_size = 0.2598 reward = -0.0000 fps = 4 mse_loss = 1.3889 
2022-07-08 10:11:48.219692 - gail/main.py:201 - [Discriminator] iter = 205000 loss = -3.7230 grad_norm = 2.7668 grad_penalty = 0.2959 regularization = 0.0000 true_logits = 0.1303 fake_logits = -3.8886 true_prob = 0.5466 fake_prob = 0.0403 
2022-07-08 10:13:05.726872 - gail/main.py:142 - [Evaluate] iter = 205000 episode={ returns = 531.2262 lengths = 177 } discounted_episode={ returns = 479.5469 lengths = 178 } 
2022-07-08 10:13:34.480055 - gail/main.py:174 - [TRPO] iter = 206000 dist_mean = 0.3378 dist_std = 0.6212 vf_loss = 0.2844 grad_norm = 0.8199 nat_grad_norm = 0.6589 cg_residual = 0.1491 step_size = 0.2907 reward = 0.0000 fps = 9 mse_loss = 1.4798 
2022-07-08 10:14:03.134129 - gail/main.py:174 - [TRPO] iter = 207000 dist_mean = 0.3432 dist_std = 0.6200 vf_loss = 0.2318 grad_norm = 1.0028 nat_grad_norm = 0.6709 cg_residual = 0.2091 step_size = 0.2695 reward = -0.0000 fps = 7 mse_loss = 1.5023 
2022-07-08 10:14:33.132556 - gail/main.py:174 - [TRPO] iter = 208000 dist_mean = 0.3547 dist_std = 0.6194 vf_loss = 0.4031 grad_norm = 0.7397 nat_grad_norm = 0.5415 cg_residual = 0.0896 step_size = 0.3387 reward = -0.0000 fps = 6 mse_loss = 1.4895 
2022-07-08 10:15:02.055042 - gail/main.py:174 - [TRPO] iter = 209000 dist_mean = 0.3331 dist_std = 0.6176 vf_loss = 0.2675 grad_norm = 0.9211 nat_grad_norm = 0.6429 cg_residual = 0.1244 step_size = 0.2941 reward = 0.0000 fps = 5 mse_loss = 1.4491 
2022-07-08 10:15:31.851451 - gail/main.py:174 - [TRPO] iter = 210000 dist_mean = 0.3268 dist_std = 0.6193 vf_loss = 0.3135 grad_norm = 0.8820 nat_grad_norm = 0.5863 cg_residual = 0.1438 step_size = 0.2975 reward = 0.0000 fps = 4 mse_loss = 1.4441 
2022-07-08 10:15:32.782157 - gail/main.py:201 - [Discriminator] iter = 210000 loss = -3.6973 grad_norm = 3.0129 grad_penalty = 0.2896 regularization = 0.0000 true_logits = 0.1962 fake_logits = -3.7907 true_prob = 0.5537 fake_prob = 0.0457 
2022-07-08 10:16:42.045728 - gail/main.py:142 - [Evaluate] iter = 210000 episode={ returns = 534.5118 lengths = 177 } discounted_episode={ returns = 480.2000 lengths = 177 } 
2022-07-08 10:17:11.295416 - gail/main.py:174 - [TRPO] iter = 211000 dist_mean = 0.3757 dist_std = 0.6181 vf_loss = 0.2467 grad_norm = 0.8333 nat_grad_norm = 0.6195 cg_residual = 0.1221 step_size = 0.2823 reward = 0.0000 fps = 10 mse_loss = 1.4171 
2022-07-08 10:17:40.372305 - gail/main.py:174 - [TRPO] iter = 212000 dist_mean = 0.3980 dist_std = 0.6188 vf_loss = 0.3257 grad_norm = 0.6124 nat_grad_norm = 0.5442 cg_residual = 0.0910 step_size = 0.3549 reward = 0.0000 fps = 7 mse_loss = 1.4036 
2022-07-08 10:18:08.927586 - gail/main.py:174 - [TRPO] iter = 213000 dist_mean = 0.3729 dist_std = 0.6183 vf_loss = 0.2659 grad_norm = 1.1500 nat_grad_norm = 0.6104 cg_residual = 0.1266 step_size = 0.2781 reward = 0.0000 fps = 6 mse_loss = 1.3366 
2022-07-08 10:18:37.655134 - gail/main.py:174 - [TRPO] iter = 214000 dist_mean = 0.3472 dist_std = 0.6181 vf_loss = 0.3311 grad_norm = 0.8356 nat_grad_norm = 0.5796 cg_residual = 0.1176 step_size = 0.2970 reward = 0.0000 fps = 5 mse_loss = 1.3566 
2022-07-08 10:19:04.675920 - gail/main.py:174 - [TRPO] iter = 215000 dist_mean = 0.4100 dist_std = 0.6167 vf_loss = 0.5524 grad_norm = 0.7256 nat_grad_norm = 0.6231 cg_residual = 0.1035 step_size = 0.3182 reward = -0.0000 fps = 4 mse_loss = 1.3297 
2022-07-08 10:19:05.475416 - gail/main.py:201 - [Discriminator] iter = 215000 loss = -3.5232 grad_norm = 2.8082 grad_penalty = 0.2804 regularization = 0.0000 true_logits = 0.1266 fake_logits = -3.6771 true_prob = 0.5447 fake_prob = 0.0569 
2022-07-08 10:20:30.957023 - gail/main.py:142 - [Evaluate] iter = 215000 episode={ returns = 735.0114 lengths = 220 } discounted_episode={ returns = 644.5044 lengths = 219 } 
2022-07-08 10:21:00.865520 - gail/main.py:174 - [TRPO] iter = 216000 dist_mean = 0.3437 dist_std = 0.6160 vf_loss = 0.2563 grad_norm = 1.0896 nat_grad_norm = 0.6844 cg_residual = 0.1375 step_size = 0.2519 reward = -0.0000 fps = 8 mse_loss = 1.2514 
2022-07-08 10:21:30.202669 - gail/main.py:174 - [TRPO] iter = 217000 dist_mean = 0.3352 dist_std = 0.6106 vf_loss = 0.2454 grad_norm = 0.8591 nat_grad_norm = 0.5998 cg_residual = 0.1497 step_size = 0.2888 reward = -0.0000 fps = 6 mse_loss = 1.2757 
2022-07-08 10:22:04.883703 - gail/main.py:174 - [TRPO] iter = 218000 dist_mean = 0.3108 dist_std = 0.6115 vf_loss = 0.2164 grad_norm = 0.8460 nat_grad_norm = 0.5947 cg_residual = 0.1358 step_size = 0.3157 reward = 0.0000 fps = 5 mse_loss = 1.3269 
2022-07-08 10:22:32.547902 - gail/main.py:174 - [TRPO] iter = 219000 dist_mean = 0.3483 dist_std = 0.6103 vf_loss = 0.2046 grad_norm = 0.7414 nat_grad_norm = 0.6365 cg_residual = 0.1266 step_size = 0.3002 reward = -0.0000 fps = 4 mse_loss = 1.3774 
2022-07-08 10:23:01.272056 - gail/main.py:174 - [TRPO] iter = 220000 dist_mean = 0.3660 dist_std = 0.6094 vf_loss = 0.3306 grad_norm = 0.9162 nat_grad_norm = 0.5677 cg_residual = 0.0964 step_size = 0.2880 reward = -0.0000 fps = 4 mse_loss = 1.3767 
2022-07-08 10:23:02.052948 - gail/main.py:201 - [Discriminator] iter = 220000 loss = -3.6775 grad_norm = 3.1590 grad_penalty = 0.2709 regularization = 0.0000 true_logits = 0.1400 fake_logits = -3.8083 true_prob = 0.5473 fake_prob = 0.0474 
2022-07-08 10:24:32.709124 - gail/main.py:142 - [Evaluate] iter = 220000 episode={ returns = 805.9864 lengths = 237 } discounted_episode={ returns = 675.2814 lengths = 232 } 
2022-07-08 10:25:02.662585 - gail/main.py:174 - [TRPO] iter = 221000 dist_mean = 0.2810 dist_std = 0.6108 vf_loss = 0.2172 grad_norm = 1.2519 nat_grad_norm = 0.5619 cg_residual = 0.1588 step_size = 0.3101 reward = 0.0000 fps = 8 mse_loss = 1.2977 
2022-07-08 10:25:30.807478 - gail/main.py:174 - [TRPO] iter = 222000 dist_mean = 0.3725 dist_std = 0.6076 vf_loss = 0.2123 grad_norm = 0.8456 nat_grad_norm = 0.6600 cg_residual = 0.1669 step_size = 0.2768 reward = 0.0000 fps = 6 mse_loss = 1.3001 
2022-07-08 10:25:59.345091 - gail/main.py:174 - [TRPO] iter = 223000 dist_mean = 0.3275 dist_std = 0.6031 vf_loss = 0.2552 grad_norm = 1.1561 nat_grad_norm = 0.5900 cg_residual = 0.1635 step_size = 0.2697 reward = -0.0000 fps = 5 mse_loss = 1.3625 
2022-07-08 10:26:29.459649 - gail/main.py:174 - [TRPO] iter = 224000 dist_mean = 0.3347 dist_std = 0.5960 vf_loss = 0.2647 grad_norm = 0.9273 nat_grad_norm = 0.6267 cg_residual = 0.1695 step_size = 0.2789 reward = -0.0000 fps = 4 mse_loss = 1.3377 
2022-07-08 10:26:59.478366 - gail/main.py:174 - [TRPO] iter = 225000 dist_mean = 0.3982 dist_std = 0.5952 vf_loss = 0.2985 grad_norm = 0.9893 nat_grad_norm = 0.5890 cg_residual = 0.1866 step_size = 0.2848 reward = 0.0000 fps = 4 mse_loss = 1.3611 
2022-07-08 10:27:00.374180 - gail/main.py:201 - [Discriminator] iter = 225000 loss = -3.7804 grad_norm = 2.8087 grad_penalty = 0.2924 regularization = 0.0000 true_logits = 0.1843 fake_logits = -3.8884 true_prob = 0.5538 fake_prob = 0.0434 
2022-07-08 10:28:33.253777 - gail/main.py:142 - [Evaluate] iter = 225000 episode={ returns = 759.9583 lengths = 229 } discounted_episode={ returns = 663.7640 lengths = 230 } 
2022-07-08 10:29:02.887102 - gail/main.py:174 - [TRPO] iter = 226000 dist_mean = 0.4067 dist_std = 0.5965 vf_loss = 0.3002 grad_norm = 0.9086 nat_grad_norm = 0.7070 cg_residual = 0.1536 step_size = 0.2645 reward = -0.0000 fps = 8 mse_loss = 1.2701 
2022-07-08 10:29:32.485976 - gail/main.py:174 - [TRPO] iter = 227000 dist_mean = 0.3531 dist_std = 0.5951 vf_loss = 0.3511 grad_norm = 1.1478 nat_grad_norm = 0.6443 cg_residual = 0.1491 step_size = 0.2691 reward = -0.0000 fps = 6 mse_loss = 1.3303 
2022-07-08 10:30:03.174560 - gail/main.py:174 - [TRPO] iter = 228000 dist_mean = 0.3531 dist_std = 0.5921 vf_loss = 0.3124 grad_norm = 0.8703 nat_grad_norm = 0.5357 cg_residual = 0.1428 step_size = 0.3218 reward = -0.0000 fps = 5 mse_loss = 1.3850 
2022-07-08 10:30:33.672923 - gail/main.py:174 - [TRPO] iter = 229000 dist_mean = 0.4119 dist_std = 0.5907 vf_loss = 0.1686 grad_norm = 0.9394 nat_grad_norm = 0.6253 cg_residual = 0.1738 step_size = 0.2880 reward = -0.0000 fps = 4 mse_loss = 1.2851 
2022-07-08 10:31:04.408606 - gail/main.py:174 - [TRPO] iter = 230000 dist_mean = 0.3876 dist_std = 0.5870 vf_loss = 0.3264 grad_norm = 0.8048 nat_grad_norm = 0.5549 cg_residual = 0.1977 step_size = 0.3111 reward = -0.0000 fps = 4 mse_loss = 1.3029 
2022-07-08 10:31:05.357462 - gail/main.py:201 - [Discriminator] iter = 230000 loss = -3.8198 grad_norm = 2.9230 grad_penalty = 0.2948 regularization = 0.0000 true_logits = 0.2196 fake_logits = -3.8951 true_prob = 0.5597 fake_prob = 0.0460 
2022-07-08 10:32:16.833932 - gail/main.py:142 - [Evaluate] iter = 230000 episode={ returns = 793.1180 lengths = 253 } discounted_episode={ returns = 661.5232 lengths = 248 } 
2022-07-08 10:32:26.623559 - gail/main.py:174 - [TRPO] iter = 231000 dist_mean = 0.3729 dist_std = 0.5872 vf_loss = 0.2152 grad_norm = 0.9864 nat_grad_norm = 0.5559 cg_residual = 0.1343 step_size = 0.3003 reward = 0.0000 fps = 12 mse_loss = 1.3341 
2022-07-08 10:32:36.206166 - gail/main.py:174 - [TRPO] iter = 232000 dist_mean = 0.3842 dist_std = 0.5842 vf_loss = 0.2411 grad_norm = 1.1262 nat_grad_norm = 0.6787 cg_residual = 0.2210 step_size = 0.2630 reward = 0.0000 fps = 11 mse_loss = 1.2520 
2022-07-08 10:32:46.862804 - gail/main.py:174 - [TRPO] iter = 233000 dist_mean = 0.3638 dist_std = 0.5827 vf_loss = 0.2234 grad_norm = 0.9463 nat_grad_norm = 0.5667 cg_residual = 0.1568 step_size = 0.2992 reward = -0.0000 fps = 9 mse_loss = 1.2946 
