2022-07-08 10:34:22.216416 - project_2022_05_06/utils/flags.py:257 - log_dir = logs/gail_w-Walker2d-v2-200-2022-07-08-10-32-39
2022-07-08 10:34:23.565850 - project_2022_05_06/gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Walker2d-v2
2022-07-08 10:34:24.814380 - project_2022_05_06/gail/main.py:80 - Expert Reward 5150.674112
2022-07-08 10:34:24.864952 - project_2022_05_06/gail/main.py:84 - Original dataset size 3000
2022-07-08 10:34:24.875224 - project_2022_05_06/gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 10:34:24.875853 - project_2022_05_06/gail/main.py:87 - np random: 864 random : 786
2022-07-08 10:34:24.878955 - project_2022_05_06/gail/main.py:91 - Sampled obs: 0.0531, acs: 0.2269
2022-07-08 10:34:25.020264 - project_2022_05_06/lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 10:34:26.050410 - project_2022_05_06/gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 10:34:26.052019 - project_2022_05_06/gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.2194959e+00  2.4445076e-01 -7.8132987e-02 -2.6673764e-01
   1.8222688e-01 -9.5077172e-02 -3.3649772e-01  5.3370733e-02
   4.1614923e+00  4.1431887e-03  3.8142569e-02 -2.6013174e-03
  -1.0202496e-02  5.6982285e-01  2.9836079e-02 -1.5763690e-01
   1.7689442e-02]] 
 scale:[[0.06687175 0.23681822 0.23042987 0.33821535 0.664349   0.20301929
  0.42807332 0.7138035  0.986894   0.65049744 2.0363257  2.3816926
  3.7250905  6.026913   2.0511289  4.406521   6.1475325 ]]
2022-07-08 10:34:26.577140 - project_2022_05_06/gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 10:34:26.578059 - project_2022_05_06/gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(23, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 10:34:26.578864 - project_2022_05_06/gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 10:34:26.683646 - project_2022_05_06/lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 10:34:29.098419 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 113.4058 lengths = 135 } discounted_episode={ returns = 135.8490 lengths = 156 } 
2022-07-08 10:34:29.099331 - project_2022_05_06/lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 10:34:30.276803 - project_2022_05_06/lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 10:34:30.307689 - project_2022_05_06/lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 10:34:30.361103 - project_2022_05_06/lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 10:34:30.385578 - project_2022_05_06/lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 10:34:30.524045 - project_2022_05_06/lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 10:34:30.818248 - project_2022_05_06/lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 10:34:30.855454 - project_2022_05_06/lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 10:34:30.885813 - project_2022_05_06/lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 10:34:30.935265 - project_2022_05_06/lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 10:34:31.052501 - project_2022_05_06/lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 10:34:31.081031 - project_2022_05_06/lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 10:34:31.108672 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 1000 dist_mean = 0.0000 dist_std = 1.0000 vf_loss = 0.2127 grad_norm = 0.3176 nat_grad_norm = 0.3986 cg_residual = 0.0000 step_size = 0.5038 reward = 0.0000 fps = 227 mse_loss = 0.4380 
2022-07-08 10:34:32.172750 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 2000 dist_mean = -0.0148 dist_std = 1.0010 vf_loss = 0.3019 grad_norm = 0.5345 nat_grad_norm = 0.4888 cg_residual = 0.0000 step_size = 0.3417 reward = -0.0000 fps = 182 mse_loss = 0.4759 
2022-07-08 10:34:33.294723 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 3000 dist_mean = -0.0348 dist_std = 1.0057 vf_loss = 0.1878 grad_norm = 0.5650 nat_grad_norm = 0.4909 cg_residual = 0.0000 step_size = 0.3328 reward = -0.0000 fps = 151 mse_loss = 0.5481 
2022-07-08 10:34:34.420779 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 4000 dist_mean = -0.0429 dist_std = 1.0060 vf_loss = 0.1870 grad_norm = 0.4669 nat_grad_norm = 0.5075 cg_residual = 0.0000 step_size = 0.3714 reward = 0.0000 fps = 129 mse_loss = 0.6285 
2022-07-08 10:34:35.482926 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 5000 dist_mean = -0.0506 dist_std = 1.0078 vf_loss = 0.1613 grad_norm = 0.5281 nat_grad_norm = 0.4704 cg_residual = 0.0001 step_size = 0.3728 reward = -0.0000 fps = 113 mse_loss = 0.6875 
2022-07-08 10:34:35.483962 - project_2022_05_06/lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 10:34:35.698237 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.4121 grad_norm = 9.8276 grad_penalty = 1.0169 regularization = 0.0000 true_logits = 0.3014 fake_logits = 0.6966 true_prob = 0.5739 fake_prob = 0.6630 
2022-07-08 10:34:36.115438 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = 0.5522 lengths = 26 } discounted_episode={ returns = 0.2826 lengths = 26 } 
2022-07-08 10:34:37.233254 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 6000 dist_mean = -0.0595 dist_std = 1.0085 vf_loss = 0.3100 grad_norm = 0.4358 nat_grad_norm = 0.4758 cg_residual = 0.0001 step_size = 0.4007 reward = 0.0000 fps = 652 mse_loss = 0.6795 
2022-07-08 10:34:38.282800 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 7000 dist_mean = -0.0571 dist_std = 1.0104 vf_loss = 0.4002 grad_norm = 0.4682 nat_grad_norm = 0.4719 cg_residual = 0.0001 step_size = 0.3677 reward = -0.0000 fps = 387 mse_loss = 0.6821 
2022-07-08 10:34:39.343436 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 8000 dist_mean = -0.0578 dist_std = 1.0098 vf_loss = 0.3454 grad_norm = 0.4779 nat_grad_norm = 0.4845 cg_residual = 0.0002 step_size = 0.3702 reward = 0.0000 fps = 274 mse_loss = 0.6815 
2022-07-08 10:34:40.415602 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 9000 dist_mean = -0.0432 dist_std = 1.0079 vf_loss = 0.3692 grad_norm = 0.4299 nat_grad_norm = 0.4747 cg_residual = 0.0002 step_size = 0.4066 reward = 0.0000 fps = 212 mse_loss = 0.6830 
2022-07-08 10:34:41.507839 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 10000 dist_mean = -0.0477 dist_std = 1.0020 vf_loss = 0.3104 grad_norm = 0.5218 nat_grad_norm = 0.4771 cg_residual = 0.0001 step_size = 0.3738 reward = -0.0000 fps = 172 mse_loss = 0.7671 
2022-07-08 10:34:41.547200 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 10000 loss = 0.7476 grad_norm = 7.4934 grad_penalty = 0.6376 regularization = 0.0000 true_logits = 0.3380 fake_logits = 0.4480 true_prob = 0.5823 fake_prob = 0.6059 
2022-07-08 10:34:41.965503 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = -0.5345 lengths = 24 } discounted_episode={ returns = -0.7446 lengths = 24 } 
2022-07-08 10:34:43.054891 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 11000 dist_mean = -0.0247 dist_std = 1.0060 vf_loss = 0.6413 grad_norm = 0.4589 nat_grad_norm = 0.5094 cg_residual = 0.0001 step_size = 0.3757 reward = -0.0000 fps = 664 mse_loss = 0.7846 
2022-07-08 10:34:44.175731 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 12000 dist_mean = -0.0201 dist_std = 1.0071 vf_loss = 0.6034 grad_norm = 0.4672 nat_grad_norm = 0.5023 cg_residual = 0.0002 step_size = 0.3789 reward = -0.0000 fps = 380 mse_loss = 0.8191 
2022-07-08 10:34:45.292426 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 13000 dist_mean = -0.0128 dist_std = 1.0010 vf_loss = 0.4867 grad_norm = 0.4440 nat_grad_norm = 0.5169 cg_residual = 0.0001 step_size = 0.3828 reward = -0.0000 fps = 267 mse_loss = 0.8075 
2022-07-08 10:34:46.581628 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 14000 dist_mean = 0.0193 dist_std = 0.9993 vf_loss = 0.5215 grad_norm = 0.4364 nat_grad_norm = 0.5285 cg_residual = 0.0002 step_size = 0.4072 reward = 0.0000 fps = 198 mse_loss = 0.7674 
2022-07-08 10:34:47.683663 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.0343 dist_std = 0.9990 vf_loss = 0.4964 grad_norm = 0.3391 nat_grad_norm = 0.6331 cg_residual = 0.0004 step_size = 0.3883 reward = 0.0000 fps = 163 mse_loss = 0.7814 
2022-07-08 10:34:47.725023 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 15000 loss = 0.4732 grad_norm = 6.6826 grad_penalty = 0.5586 regularization = 0.0000 true_logits = 0.3724 fake_logits = 0.2870 true_prob = 0.5901 fake_prob = 0.5679 
2022-07-08 10:34:48.537150 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = -6.3059 lengths = 53 } discounted_episode={ returns = -6.1579 lengths = 53 } 
2022-07-08 10:34:50.195033 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.0207 dist_std = 0.9953 vf_loss = 0.5158 grad_norm = 0.4636 nat_grad_norm = 0.6354 cg_residual = 0.0003 step_size = 0.3420 reward = 0.0000 fps = 405 mse_loss = 0.8440 
2022-07-08 10:34:51.306266 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.0293 dist_std = 0.9932 vf_loss = 0.4927 grad_norm = 0.4326 nat_grad_norm = 0.5414 cg_residual = 0.0003 step_size = 0.4098 reward = 0.0000 fps = 279 mse_loss = 0.8344 
2022-07-08 10:34:52.395878 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.0529 dist_std = 0.9890 vf_loss = 0.5382 grad_norm = 0.4347 nat_grad_norm = 0.5970 cg_residual = 0.0004 step_size = 0.3815 reward = -0.0000 fps = 214 mse_loss = 0.8124 
2022-07-08 10:34:53.495722 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.0611 dist_std = 0.9899 vf_loss = 0.3538 grad_norm = 0.3922 nat_grad_norm = 0.5491 cg_residual = 0.0003 step_size = 0.4062 reward = -0.0000 fps = 173 mse_loss = 0.8226 
2022-07-08 10:34:54.583428 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.0638 dist_std = 0.9921 vf_loss = 0.3143 grad_norm = 0.4093 nat_grad_norm = 0.6924 cg_residual = 0.0009 step_size = 0.3587 reward = 0.0000 fps = 145 mse_loss = 0.8542 
2022-07-08 10:34:54.634489 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 20000 loss = -0.0558 grad_norm = 6.1154 grad_penalty = 0.4229 regularization = 0.0000 true_logits = 0.4090 fake_logits = -0.0698 true_prob = 0.5979 fake_prob = 0.4851 
2022-07-08 10:34:55.467224 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = -4.0447 lengths = 45 } discounted_episode={ returns = -4.3344 lengths = 46 } 
2022-07-08 10:34:56.836453 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.0607 dist_std = 0.9961 vf_loss = 0.5308 grad_norm = 0.3524 nat_grad_norm = 0.5610 cg_residual = 0.0004 step_size = 0.4229 reward = 0.0000 fps = 454 mse_loss = 0.8047 
2022-07-08 10:34:58.073375 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.0775 dist_std = 0.9976 vf_loss = 0.3949 grad_norm = 0.3932 nat_grad_norm = 0.8176 cg_residual = 0.0008 step_size = 0.3378 reward = -0.0000 fps = 291 mse_loss = 0.8143 
2022-07-08 10:34:59.126045 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.0764 dist_std = 0.9965 vf_loss = 0.3121 grad_norm = 0.4510 nat_grad_norm = 0.6182 cg_residual = 0.0007 step_size = 0.3569 reward = -0.0000 fps = 222 mse_loss = 0.7806 
2022-07-08 10:35:00.179475 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.0641 dist_std = 1.0050 vf_loss = 0.2684 grad_norm = 0.3781 nat_grad_norm = 0.5631 cg_residual = 0.0005 step_size = 0.4362 reward = 0.0000 fps = 180 mse_loss = 0.7748 
2022-07-08 10:35:01.290759 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.0575 dist_std = 1.0038 vf_loss = 0.3993 grad_norm = 0.4084 nat_grad_norm = 0.5325 cg_residual = 0.0003 step_size = 0.4159 reward = 0.0000 fps = 150 mse_loss = 0.7954 
2022-07-08 10:35:01.332026 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 25000 loss = -0.6814 grad_norm = 6.0971 grad_penalty = 0.4262 regularization = 0.0000 true_logits = 0.4051 fake_logits = -0.7025 true_prob = 0.5973 fake_prob = 0.3458 
2022-07-08 10:35:01.988237 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = -4.1848 lengths = 46 } discounted_episode={ returns = -4.0676 lengths = 46 } 
2022-07-08 10:35:03.006363 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.0708 dist_std = 0.9952 vf_loss = 0.2992 grad_norm = 0.3350 nat_grad_norm = 0.5684 cg_residual = 0.0006 step_size = 0.4386 reward = -0.0000 fps = 598 mse_loss = 0.8095 
2022-07-08 10:35:04.070154 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.0808 dist_std = 0.9876 vf_loss = 0.6416 grad_norm = 0.5263 nat_grad_norm = 0.6126 cg_residual = 0.0004 step_size = 0.3557 reward = 0.0000 fps = 365 mse_loss = 0.8210 
2022-07-08 10:35:05.123082 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.0750 dist_std = 0.9846 vf_loss = 0.4300 grad_norm = 0.4662 nat_grad_norm = 0.5532 cg_residual = 0.0005 step_size = 0.3959 reward = 0.0000 fps = 263 mse_loss = 0.8766 
2022-07-08 10:35:06.202393 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.0496 dist_std = 0.9820 vf_loss = 0.2634 grad_norm = 0.3508 nat_grad_norm = 0.5377 cg_residual = 0.0004 step_size = 0.4324 reward = -0.0000 fps = 205 mse_loss = 0.8969 
2022-07-08 10:35:07.284846 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.0837 dist_std = 0.9816 vf_loss = 0.6232 grad_norm = 0.4092 nat_grad_norm = 0.5376 cg_residual = 0.0006 step_size = 0.4242 reward = -0.0000 fps = 168 mse_loss = 0.9464 
2022-07-08 10:35:07.323469 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 30000 loss = -1.2253 grad_norm = 6.1716 grad_penalty = 0.3971 regularization = 0.0000 true_logits = 0.4149 fake_logits = -1.2074 true_prob = 0.5997 fake_prob = 0.2488 
2022-07-08 10:35:08.067824 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = -5.3251 lengths = 43 } discounted_episode={ returns = -4.8255 lengths = 43 } 
2022-07-08 10:35:09.147104 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.0808 dist_std = 0.9832 vf_loss = 0.4438 grad_norm = 0.4137 nat_grad_norm = 0.6252 cg_residual = 0.0008 step_size = 0.3814 reward = -0.0000 fps = 549 mse_loss = 1.0183 
2022-07-08 10:35:10.215960 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.0765 dist_std = 0.9853 vf_loss = 1.2024 grad_norm = 0.4307 nat_grad_norm = 0.6430 cg_residual = 0.0011 step_size = 0.3620 reward = -0.0000 fps = 346 mse_loss = 0.9503 
2022-07-08 10:35:11.232761 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.0851 dist_std = 0.9777 vf_loss = 0.3926 grad_norm = 0.3696 nat_grad_norm = 0.5513 cg_residual = 0.0006 step_size = 0.4381 reward = -0.0000 fps = 255 mse_loss = 0.9473 
2022-07-08 10:35:12.277213 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.0902 dist_std = 0.9760 vf_loss = 0.7552 grad_norm = 0.4280 nat_grad_norm = 0.5816 cg_residual = 0.0012 step_size = 0.3750 reward = 0.0000 fps = 201 mse_loss = 1.0080 
2022-07-08 10:35:13.331513 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.0716 dist_std = 0.9777 vf_loss = 0.5485 grad_norm = 0.3812 nat_grad_norm = 0.6887 cg_residual = 0.0008 step_size = 0.3734 reward = -0.0000 fps = 166 mse_loss = 0.9314 
2022-07-08 10:35:13.369754 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 35000 loss = -1.9746 grad_norm = 6.8495 grad_penalty = 0.4146 regularization = 0.0000 true_logits = 0.4951 fake_logits = -1.8941 true_prob = 0.6183 fake_prob = 0.1569 
2022-07-08 10:35:14.377827 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 1.0737 lengths = 75 } discounted_episode={ returns = 0.4192 lengths = 76 } 
2022-07-08 10:35:16.605826 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.0841 dist_std = 0.9776 vf_loss = 0.5749 grad_norm = 0.4295 nat_grad_norm = 0.5811 cg_residual = 0.0007 step_size = 0.3955 reward = -0.0000 fps = 309 mse_loss = 0.9696 
2022-07-08 10:35:18.342513 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.0804 dist_std = 0.9828 vf_loss = 0.4274 grad_norm = 0.3948 nat_grad_norm = 0.5591 cg_residual = 0.0012 step_size = 0.4050 reward = -0.0000 fps = 201 mse_loss = 1.0068 
2022-07-08 10:35:19.473324 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.1322 dist_std = 0.9731 vf_loss = 0.9000 grad_norm = 0.3682 nat_grad_norm = 0.5828 cg_residual = 0.0012 step_size = 0.4010 reward = -0.0000 fps = 164 mse_loss = 0.9440 
2022-07-08 10:35:20.584531 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.1124 dist_std = 0.9731 vf_loss = 0.7508 grad_norm = 0.3424 nat_grad_norm = 0.6417 cg_residual = 0.0012 step_size = 0.4292 reward = -0.0000 fps = 138 mse_loss = 0.9167 
2022-07-08 10:35:21.734348 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.0933 dist_std = 0.9726 vf_loss = 0.4449 grad_norm = 0.4652 nat_grad_norm = 0.6734 cg_residual = 0.0010 step_size = 0.3512 reward = -0.0000 fps = 119 mse_loss = 0.8471 
2022-07-08 10:35:21.777779 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 40000 loss = -2.5910 grad_norm = 7.0262 grad_penalty = 0.4180 regularization = 0.0000 true_logits = 0.5172 fake_logits = -2.4918 true_prob = 0.6239 fake_prob = 0.1018 
2022-07-08 10:35:23.749431 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 13.6172 lengths = 103 } discounted_episode={ returns = 10.1206 lengths = 116 } 
2022-07-08 10:35:25.555819 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.0945 dist_std = 0.9731 vf_loss = 0.3788 grad_norm = 0.3621 nat_grad_norm = 0.5873 cg_residual = 0.0005 step_size = 0.4280 reward = 0.0000 fps = 265 mse_loss = 0.8816 
2022-07-08 10:35:26.952202 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.1059 dist_std = 0.9704 vf_loss = 0.6891 grad_norm = 0.4261 nat_grad_norm = 0.5634 cg_residual = 0.0013 step_size = 0.3911 reward = 0.0000 fps = 193 mse_loss = 0.8912 
2022-07-08 10:35:28.018614 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.1876 dist_std = 0.9687 vf_loss = 0.4119 grad_norm = 0.4199 nat_grad_norm = 0.5722 cg_residual = 0.0041 step_size = 0.4090 reward = 0.0000 fps = 160 mse_loss = 0.8855 
2022-07-08 10:35:29.614845 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.1457 dist_std = 0.9708 vf_loss = 0.6276 grad_norm = 0.4092 nat_grad_norm = 0.6689 cg_residual = 0.0035 step_size = 0.3674 reward = 0.0000 fps = 127 mse_loss = 0.8967 
2022-07-08 10:35:30.830304 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.2067 dist_std = 0.9714 vf_loss = 0.2892 grad_norm = 0.5024 nat_grad_norm = 0.6049 cg_residual = 0.0069 step_size = 0.3422 reward = -0.0000 fps = 110 mse_loss = 0.8880 
2022-07-08 10:35:30.872470 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 45000 loss = -2.9693 grad_norm = 6.8531 grad_penalty = 0.4071 regularization = 0.0000 true_logits = 0.5964 fake_logits = -2.7800 true_prob = 0.6416 fake_prob = 0.0801 
2022-07-08 10:35:33.462376 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 209.4827 lengths = 120 } discounted_episode={ returns = 194.7423 lengths = 122 } 
2022-07-08 10:35:34.510069 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.1635 dist_std = 0.9728 vf_loss = 0.8451 grad_norm = 0.5590 nat_grad_norm = 0.5555 cg_residual = 0.0027 step_size = 0.3676 reward = -0.0000 fps = 275 mse_loss = 0.8987 
2022-07-08 10:35:35.526150 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.1606 dist_std = 0.9724 vf_loss = 0.5208 grad_norm = 0.4000 nat_grad_norm = 0.6898 cg_residual = 0.0033 step_size = 0.3670 reward = 0.0000 fps = 215 mse_loss = 0.8770 
2022-07-08 10:35:36.579245 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.1537 dist_std = 0.9699 vf_loss = 0.4611 grad_norm = 0.4212 nat_grad_norm = 0.5260 cg_residual = 0.0029 step_size = 0.4189 reward = 0.0000 fps = 175 mse_loss = 0.9336 
2022-07-08 10:35:37.593675 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.1795 dist_std = 0.9704 vf_loss = 0.3398 grad_norm = 0.4876 nat_grad_norm = 0.5540 cg_residual = 0.0050 step_size = 0.3738 reward = 0.0000 fps = 148 mse_loss = 0.9282 
2022-07-08 10:35:38.636409 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.1712 dist_std = 0.9718 vf_loss = 0.3391 grad_norm = 0.5145 nat_grad_norm = 0.6019 cg_residual = 0.0042 step_size = 0.3648 reward = 0.0000 fps = 128 mse_loss = 0.8871 
2022-07-08 10:35:38.676291 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 50000 loss = -3.3414 grad_norm = 7.1683 grad_penalty = 0.4685 regularization = 0.0000 true_logits = 0.5944 fake_logits = -3.2155 true_prob = 0.6391 fake_prob = 0.0590 
2022-07-08 10:35:41.838024 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 301.5934 lengths = 205 } discounted_episode={ returns = 261.6042 lengths = 201 } 
2022-07-08 10:35:43.347811 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.1593 dist_std = 0.9666 vf_loss = 0.3671 grad_norm = 0.4422 nat_grad_norm = 0.6572 cg_residual = 0.0031 step_size = 0.3754 reward = 0.0000 fps = 214 mse_loss = 0.9385 
2022-07-08 10:35:44.647370 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.2076 dist_std = 0.9737 vf_loss = 0.3936 grad_norm = 0.4636 nat_grad_norm = 0.6035 cg_residual = 0.0039 step_size = 0.3853 reward = 0.0000 fps = 167 mse_loss = 0.9047 
2022-07-08 10:35:45.704565 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.1928 dist_std = 0.9747 vf_loss = 0.2557 grad_norm = 0.4766 nat_grad_norm = 0.5652 cg_residual = 0.0040 step_size = 0.3880 reward = -0.0000 fps = 142 mse_loss = 0.8822 
2022-07-08 10:35:46.791065 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.1745 dist_std = 0.9800 vf_loss = 0.4214 grad_norm = 0.4095 nat_grad_norm = 0.6188 cg_residual = 0.0025 step_size = 0.4011 reward = 0.0000 fps = 123 mse_loss = 0.9565 
2022-07-08 10:35:47.817834 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.1637 dist_std = 0.9765 vf_loss = 0.4069 grad_norm = 0.4406 nat_grad_norm = 0.5961 cg_residual = 0.0020 step_size = 0.4192 reward = -0.0000 fps = 109 mse_loss = 0.8732 
2022-07-08 10:35:47.858314 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 55000 loss = -3.8434 grad_norm = 7.2907 grad_penalty = 0.4936 regularization = 0.0000 true_logits = 0.6312 fake_logits = -3.7058 true_prob = 0.6472 fake_prob = 0.0401 
2022-07-08 10:35:58.991204 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 633.8180 lengths = 583 } discounted_episode={ returns = 493.0809 lengths = 696 } 
2022-07-08 10:36:00.031793 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.2100 dist_std = 0.9743 vf_loss = 0.3729 grad_norm = 0.4018 nat_grad_norm = 0.6548 cg_residual = 0.0026 step_size = 0.3804 reward = 0.0000 fps = 82 mse_loss = 0.9255 
2022-07-08 10:36:01.079624 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.1941 dist_std = 0.9739 vf_loss = 0.6683 grad_norm = 0.4424 nat_grad_norm = 0.6956 cg_residual = 0.0058 step_size = 0.3824 reward = -0.0000 fps = 75 mse_loss = 0.9132 
2022-07-08 10:36:02.142077 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.1752 dist_std = 0.9751 vf_loss = 0.3971 grad_norm = 0.4321 nat_grad_norm = 0.5468 cg_residual = 0.0022 step_size = 0.4521 reward = -0.0000 fps = 70 mse_loss = 0.9371 
2022-07-08 10:36:03.200977 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.2000 dist_std = 0.9722 vf_loss = 0.4621 grad_norm = 0.4532 nat_grad_norm = 0.6619 cg_residual = 0.0046 step_size = 0.3718 reward = 0.0000 fps = 65 mse_loss = 0.8718 
2022-07-08 10:36:04.229077 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.2191 dist_std = 0.9682 vf_loss = 0.4348 grad_norm = 0.3654 nat_grad_norm = 0.5664 cg_residual = 0.0030 step_size = 0.4346 reward = -0.0000 fps = 61 mse_loss = 0.9349 
2022-07-08 10:36:04.268767 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 60000 loss = -4.0519 grad_norm = 6.5735 grad_penalty = 0.5249 regularization = 0.0000 true_logits = 0.5748 fake_logits = -4.0020 true_prob = 0.6346 fake_prob = 0.0343 
2022-07-08 10:36:19.713906 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 979.3089 lengths = 1000 } discounted_episode={ returns = 610.1385 lengths = 1000 } 
2022-07-08 10:36:21.316327 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.1761 dist_std = 0.9647 vf_loss = 0.5222 grad_norm = 0.5043 nat_grad_norm = 0.6761 cg_residual = 0.0035 step_size = 0.3571 reward = -0.0000 fps = 58 mse_loss = 0.9076 
2022-07-08 10:36:22.582199 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.2361 dist_std = 0.9679 vf_loss = 0.5194 grad_norm = 0.5148 nat_grad_norm = 0.6267 cg_residual = 0.0051 step_size = 0.3622 reward = -0.0000 fps = 54 mse_loss = 0.8254 
2022-07-08 10:36:23.633184 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.2137 dist_std = 0.9624 vf_loss = 0.4210 grad_norm = 0.5061 nat_grad_norm = 0.6520 cg_residual = 0.0065 step_size = 0.3649 reward = 0.0000 fps = 51 mse_loss = 0.8544 
2022-07-08 10:36:24.798769 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.2148 dist_std = 0.9613 vf_loss = 0.3843 grad_norm = 0.5410 nat_grad_norm = 0.6142 cg_residual = 0.0064 step_size = 0.3455 reward = -0.0000 fps = 48 mse_loss = 0.7693 
2022-07-08 10:36:25.934168 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.2037 dist_std = 0.9628 vf_loss = 0.2969 grad_norm = 0.4342 nat_grad_norm = 0.6171 cg_residual = 0.0048 step_size = 0.4027 reward = 0.0000 fps = 46 mse_loss = 0.8961 
2022-07-08 10:36:25.974848 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 65000 loss = -4.0902 grad_norm = 9.3328 grad_penalty = 0.5762 regularization = 0.0000 true_logits = 0.4626 fake_logits = -4.2038 true_prob = 0.6126 fake_prob = 0.0317 
2022-07-08 10:36:33.430055 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 525.1393 lengths = 441 } discounted_episode={ returns = 373.0434 lengths = 379 } 
2022-07-08 10:36:34.587319 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.2132 dist_std = 0.9567 vf_loss = 0.3874 grad_norm = 0.4576 nat_grad_norm = 0.5785 cg_residual = 0.0056 step_size = 0.3939 reward = 0.0000 fps = 116 mse_loss = 0.8303 
2022-07-08 10:36:35.864348 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.1999 dist_std = 0.9551 vf_loss = 0.2728 grad_norm = 0.4993 nat_grad_norm = 0.6640 cg_residual = 0.0055 step_size = 0.3528 reward = 0.0000 fps = 101 mse_loss = 0.7501 
2022-07-08 10:36:36.990545 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.1889 dist_std = 0.9544 vf_loss = 0.2162 grad_norm = 0.4592 nat_grad_norm = 0.7452 cg_residual = 0.0044 step_size = 0.3546 reward = -0.0000 fps = 90 mse_loss = 0.6964 
2022-07-08 10:36:38.047796 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.1716 dist_std = 0.9499 vf_loss = 0.3977 grad_norm = 0.4715 nat_grad_norm = 0.5468 cg_residual = 0.0059 step_size = 0.3992 reward = 0.0000 fps = 82 mse_loss = 0.6751 
2022-07-08 10:36:39.127242 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.2031 dist_std = 0.9488 vf_loss = 0.3125 grad_norm = 0.4906 nat_grad_norm = 0.6069 cg_residual = 0.0056 step_size = 0.3886 reward = 0.0000 fps = 76 mse_loss = 0.7365 
2022-07-08 10:36:39.166057 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 70000 loss = -4.4120 grad_norm = 6.7568 grad_penalty = 0.5008 regularization = 0.0000 true_logits = 0.3385 fake_logits = -4.5744 true_prob = 0.5859 fake_prob = 0.0239 
2022-07-08 10:36:41.915394 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 250.9397 lengths = 163 } discounted_episode={ returns = 243.8782 lengths = 182 } 
2022-07-08 10:36:43.671776 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.1927 dist_std = 0.9423 vf_loss = 0.2177 grad_norm = 0.4573 nat_grad_norm = 0.6651 cg_residual = 0.0070 step_size = 0.3751 reward = -0.0000 fps = 222 mse_loss = 0.7699 
2022-07-08 10:36:44.888771 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.1739 dist_std = 0.9455 vf_loss = 0.4405 grad_norm = 0.4642 nat_grad_norm = 0.6649 cg_residual = 0.0047 step_size = 0.3534 reward = -0.0000 fps = 174 mse_loss = 0.7685 
2022-07-08 10:36:46.341502 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.1555 dist_std = 0.9472 vf_loss = 0.4347 grad_norm = 0.4727 nat_grad_norm = 0.6425 cg_residual = 0.0043 step_size = 0.3737 reward = 0.0000 fps = 139 mse_loss = 0.7094 
2022-07-08 10:36:47.362128 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.1991 dist_std = 0.9428 vf_loss = 0.4380 grad_norm = 0.4853 nat_grad_norm = 0.6254 cg_residual = 0.0064 step_size = 0.3615 reward = 0.0000 fps = 122 mse_loss = 0.8192 
2022-07-08 10:36:48.398016 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.1780 dist_std = 0.9450 vf_loss = 0.2840 grad_norm = 0.5192 nat_grad_norm = 0.6730 cg_residual = 0.0072 step_size = 0.3445 reward = 0.0000 fps = 108 mse_loss = 0.8180 
2022-07-08 10:36:48.437378 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 75000 loss = -4.8045 grad_norm = 5.3498 grad_penalty = 0.4941 regularization = 0.0000 true_logits = 0.2715 fake_logits = -5.0271 true_prob = 0.5718 fake_prob = 0.0175 
2022-07-08 10:36:55.139026 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 553.9214 lengths = 449 } discounted_episode={ returns = 417.8958 lengths = 477 } 
2022-07-08 10:36:56.205623 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.1979 dist_std = 0.9407 vf_loss = 0.2521 grad_norm = 0.5584 nat_grad_norm = 0.6514 cg_residual = 0.0062 step_size = 0.3342 reward = 0.0000 fps = 128 mse_loss = 0.8586 
2022-07-08 10:36:57.245911 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.1781 dist_std = 0.9406 vf_loss = 0.3151 grad_norm = 0.5862 nat_grad_norm = 0.6565 cg_residual = 0.0082 step_size = 0.3398 reward = -0.0000 fps = 113 mse_loss = 0.7765 
2022-07-08 10:36:58.279887 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.2102 dist_std = 0.9366 vf_loss = 0.1778 grad_norm = 0.4645 nat_grad_norm = 0.6504 cg_residual = 0.0064 step_size = 0.3522 reward = -0.0000 fps = 101 mse_loss = 0.8000 
2022-07-08 10:36:59.292931 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.2086 dist_std = 0.9337 vf_loss = 0.2037 grad_norm = 0.5338 nat_grad_norm = 0.6206 cg_residual = 0.0099 step_size = 0.3810 reward = -0.0000 fps = 92 mse_loss = 0.8078 
2022-07-08 10:37:00.314854 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.2211 dist_std = 0.9318 vf_loss = 0.2600 grad_norm = 0.4715 nat_grad_norm = 0.6631 cg_residual = 0.0042 step_size = 0.3966 reward = -0.0000 fps = 84 mse_loss = 0.7453 
2022-07-08 10:37:00.354462 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 80000 loss = -4.8310 grad_norm = 6.7165 grad_penalty = 0.5316 regularization = 0.0000 true_logits = 0.0964 fake_logits = -5.2662 true_prob = 0.5397 fake_prob = 0.0148 
2022-07-08 10:37:06.041188 - project_2022_05_06/gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 435.2746 lengths = 320 } discounted_episode={ returns = 424.8347 lengths = 501 } 
2022-07-08 10:37:07.083966 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.2519 dist_std = 0.9349 vf_loss = 0.4089 grad_norm = 0.5868 nat_grad_norm = 0.6152 cg_residual = 0.0149 step_size = 0.3375 reward = -0.0000 fps = 148 mse_loss = 0.7763 
2022-07-08 10:37:08.111579 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.2213 dist_std = 0.9356 vf_loss = 0.3020 grad_norm = 0.5476 nat_grad_norm = 0.6586 cg_residual = 0.0088 step_size = 0.3461 reward = -0.0000 fps = 128 mse_loss = 0.7142 
2022-07-08 10:37:09.165293 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.2233 dist_std = 0.9302 vf_loss = 0.2157 grad_norm = 0.4910 nat_grad_norm = 0.6464 cg_residual = 0.0107 step_size = 0.3708 reward = -0.0000 fps = 113 mse_loss = 0.8093 
2022-07-08 10:37:10.225906 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.2102 dist_std = 0.9230 vf_loss = 0.3436 grad_norm = 0.4723 nat_grad_norm = 0.6516 cg_residual = 0.0054 step_size = 0.3710 reward = 0.0000 fps = 101 mse_loss = 0.7759 
2022-07-08 10:37:11.271732 - project_2022_05_06/gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.2200 dist_std = 0.9186 vf_loss = 0.5861 grad_norm = 0.3913 nat_grad_norm = 0.5731 cg_residual = 0.0049 step_size = 0.4188 reward = 0.0000 fps = 91 mse_loss = 0.7747 
2022-07-08 10:37:11.312704 - project_2022_05_06/gail/main.py:201 - [Discriminator] iter = 85000 loss = -5.0019 grad_norm = 6.3925 grad_penalty = 0.5884 regularization = 0.0000 true_logits = 0.0131 fake_logits = -5.5773 true_prob = 0.5265 fake_prob = 0.0115 
