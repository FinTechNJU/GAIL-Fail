2022-07-08 09:04:58.303803 - utils/flags.py:257 - log_dir = logs/gail_w-Hopper-v2-100-2022-07-08-09-04-57
2022-07-08 09:05:16.632856 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Hopper-v2
2022-07-08 09:05:36.642847 - gail/main.py:80 - Expert Reward 3582.436530
2022-07-08 09:05:37.624377 - gail/main.py:84 - Original dataset size 3000
2022-07-08 09:05:37.723033 - gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 09:05:37.732725 - gail/main.py:87 - np random: 864 random : 786
2022-07-08 09:05:37.738735 - gail/main.py:91 - Sampled obs: 0.4652, acs: 0.0749
2022-07-08 09:05:40.387418 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 09:06:02.531061 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 09:06:02.551676 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.3966653  -0.06165453 -0.19472611 -0.4584401   0.18350822  2.5732448
   0.00400542 -0.00549955 -0.04755233 -0.02386179  0.00759995]] 
 scale:[[0.16755195 0.05883223 0.15990146 0.34682125 0.5992658  0.6461788
  1.5187451  0.8811966  2.0685835  3.6282625  5.862049  ]]
2022-07-08 09:06:13.392521 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 09:06:13.409603 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(14, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 09:06:13.417255 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 09:06:15.985180 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 09:07:04.342965 - gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 240.1615 lengths = 229 } discounted_episode={ returns = 182.4166 lengths = 192 } 
2022-07-08 09:07:04.349703 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 09:07:26.872270 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 09:07:27.567201 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 09:07:28.837231 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 09:07:29.394205 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 09:07:33.053178 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 09:07:39.666591 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 09:07:40.286417 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 09:07:40.979701 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 09:07:42.166272 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 09:07:44.118111 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 09:07:44.815849 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 09:07:45.495381 - gail/main.py:174 - [TRPO] iter = 1000 dist_mean = -0.0000 dist_std = 1.0000 vf_loss = 0.3574 grad_norm = 0.2691 nat_grad_norm = 0.3367 cg_residual = 0.0000 step_size = 0.5255 reward = 0.0000 fps = 11 mse_loss = 0.3189 
2022-07-08 09:08:02.562590 - gail/main.py:174 - [TRPO] iter = 2000 dist_mean = -0.0418 dist_std = 0.9919 vf_loss = 0.2640 grad_norm = 0.3809 nat_grad_norm = 0.3659 cg_residual = 0.0000 step_size = 0.4041 reward = -0.0000 fps = 9 mse_loss = 0.3278 
2022-07-08 09:08:19.461250 - gail/main.py:174 - [TRPO] iter = 3000 dist_mean = -0.0849 dist_std = 0.9892 vf_loss = 0.4147 grad_norm = 0.4320 nat_grad_norm = 0.3771 cg_residual = 0.0000 step_size = 0.3703 reward = -0.0000 fps = 8 mse_loss = 0.3524 
2022-07-08 09:08:36.728359 - gail/main.py:174 - [TRPO] iter = 4000 dist_mean = -0.1135 dist_std = 0.9857 vf_loss = 0.3278 grad_norm = 0.5239 nat_grad_norm = 0.3955 cg_residual = 0.0000 step_size = 0.3332 reward = 0.0000 fps = 7 mse_loss = 0.3733 
2022-07-08 09:08:53.604431 - gail/main.py:174 - [TRPO] iter = 5000 dist_mean = -0.1550 dist_std = 0.9854 vf_loss = 0.1677 grad_norm = 0.5997 nat_grad_norm = 0.3996 cg_residual = 0.0000 step_size = 0.3147 reward = -0.0000 fps = 6 mse_loss = 0.4267 
2022-07-08 09:08:53.606019 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 09:08:59.944911 - gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.8033 grad_norm = 14.1450 grad_penalty = 1.6640 regularization = 0.0000 true_logits = 0.1373 fake_logits = 0.2766 true_prob = 0.5342 fake_prob = 0.5681 
2022-07-08 09:09:02.414510 - gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = 6.3892 lengths = 8 } discounted_episode={ returns = 6.3658 lengths = 8 } 
2022-07-08 09:09:27.509285 - gail/main.py:174 - [TRPO] iter = 6000 dist_mean = -0.1886 dist_std = 0.9808 vf_loss = 0.1538 grad_norm = 0.6919 nat_grad_norm = 0.4945 cg_residual = 0.0000 step_size = 0.2684 reward = -0.0000 fps = 36 mse_loss = 0.4764 
2022-07-08 09:09:50.389949 - gail/main.py:174 - [TRPO] iter = 7000 dist_mean = -0.2040 dist_std = 0.9784 vf_loss = 0.1224 grad_norm = 0.6576 nat_grad_norm = 0.4556 cg_residual = 0.0000 step_size = 0.2908 reward = -0.0000 fps = 19 mse_loss = 0.5055 
2022-07-08 09:10:15.213644 - gail/main.py:174 - [TRPO] iter = 8000 dist_mean = -0.2119 dist_std = 0.9686 vf_loss = 0.0941 grad_norm = 0.6527 nat_grad_norm = 0.4851 cg_residual = 0.0000 step_size = 0.2902 reward = -0.0000 fps = 13 mse_loss = 0.6055 
2022-07-08 09:10:42.695510 - gail/main.py:174 - [TRPO] iter = 9000 dist_mean = -0.2275 dist_std = 0.9663 vf_loss = 0.0433 grad_norm = 0.6643 nat_grad_norm = 0.3796 cg_residual = 0.0000 step_size = 0.3156 reward = -0.0000 fps = 9 mse_loss = 0.5589 
2022-07-08 09:11:17.155285 - gail/main.py:174 - [TRPO] iter = 10000 dist_mean = -0.2371 dist_std = 0.9523 vf_loss = 0.0697 grad_norm = 0.9271 nat_grad_norm = 0.5174 cg_residual = 0.0000 step_size = 0.2397 reward = 0.0000 fps = 7 mse_loss = 0.6872 
2022-07-08 09:11:17.960135 - gail/main.py:201 - [Discriminator] iter = 10000 loss = 0.7527 grad_norm = 10.2307 grad_penalty = 0.9303 regularization = 0.0000 true_logits = 0.1793 fake_logits = 0.0016 true_prob = 0.5444 fake_prob = 0.5004 
2022-07-08 09:11:20.796731 - gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = 5.1844 lengths = 7 } discounted_episode={ returns = 5.1619 lengths = 7 } 
2022-07-08 09:11:49.320878 - gail/main.py:174 - [TRPO] iter = 11000 dist_mean = -0.2417 dist_std = 0.9433 vf_loss = 0.0765 grad_norm = 0.4937 nat_grad_norm = 0.4567 cg_residual = 0.0000 step_size = 0.3915 reward = 0.0000 fps = 31 mse_loss = 0.6568 
2022-07-08 09:12:18.982541 - gail/main.py:174 - [TRPO] iter = 12000 dist_mean = -0.1846 dist_std = 0.9488 vf_loss = 0.0802 grad_norm = 0.8081 nat_grad_norm = 0.4370 cg_residual = 0.0000 step_size = 0.2797 reward = -0.0000 fps = 16 mse_loss = 0.7678 
2022-07-08 09:12:51.161298 - gail/main.py:174 - [TRPO] iter = 13000 dist_mean = -0.1087 dist_std = 0.9544 vf_loss = 0.1944 grad_norm = 0.8456 nat_grad_norm = 0.4429 cg_residual = 0.0000 step_size = 0.2699 reward = 0.0000 fps = 10 mse_loss = 0.7624 
2022-07-08 09:13:21.057198 - gail/main.py:174 - [TRPO] iter = 14000 dist_mean = -0.0262 dist_std = 0.9598 vf_loss = 0.1499 grad_norm = 0.9175 nat_grad_norm = 0.4038 cg_residual = 0.0001 step_size = 0.2737 reward = 0.0000 fps = 8 mse_loss = 0.7241 
2022-07-08 09:13:52.042501 - gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.0650 dist_std = 0.9696 vf_loss = 0.3418 grad_norm = 0.7095 nat_grad_norm = 0.3949 cg_residual = 0.0001 step_size = 0.3453 reward = -0.0000 fps = 6 mse_loss = 0.7734 
2022-07-08 09:13:52.805622 - gail/main.py:201 - [Discriminator] iter = 15000 loss = 0.2675 grad_norm = 9.3622 grad_penalty = 0.8053 regularization = 0.0000 true_logits = 0.1699 fake_logits = -0.3679 true_prob = 0.5421 fake_prob = 0.4098 
2022-07-08 09:13:55.948202 - gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = 7.0108 lengths = 8 } discounted_episode={ returns = 6.9283 lengths = 8 } 
2022-07-08 09:14:24.497933 - gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.1152 dist_std = 0.9731 vf_loss = 0.7711 grad_norm = 0.6561 nat_grad_norm = 0.4857 cg_residual = 0.0002 step_size = 0.3495 reward = 0.0000 fps = 31 mse_loss = 0.7549 
2022-07-08 09:14:55.011156 - gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.2029 dist_std = 0.9789 vf_loss = 1.0896 grad_norm = 0.9064 nat_grad_norm = 0.4460 cg_residual = 0.0002 step_size = 0.3226 reward = 0.0000 fps = 16 mse_loss = 0.6663 
2022-07-08 09:15:24.494305 - gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.2949 dist_std = 0.9795 vf_loss = 1.1573 grad_norm = 0.6880 nat_grad_norm = 0.3413 cg_residual = 0.0001 step_size = 0.4171 reward = -0.0000 fps = 10 mse_loss = 0.6356 
2022-07-08 09:15:54.079039 - gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.3943 dist_std = 0.9769 vf_loss = 0.9078 grad_norm = 0.6216 nat_grad_norm = 0.4148 cg_residual = 0.0003 step_size = 0.4246 reward = 0.0000 fps = 8 mse_loss = 0.6088 
2022-07-08 09:16:22.807858 - gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.4521 dist_std = 0.9696 vf_loss = 0.6548 grad_norm = 0.5477 nat_grad_norm = 0.4194 cg_residual = 0.0005 step_size = 0.4512 reward = 0.0000 fps = 6 mse_loss = 0.6332 
2022-07-08 09:16:23.562984 - gail/main.py:201 - [Discriminator] iter = 20000 loss = 0.1210 grad_norm = 7.5911 grad_penalty = 0.7161 regularization = 0.0000 true_logits = 0.1708 fake_logits = -0.4243 true_prob = 0.5423 fake_prob = 0.3992 
2022-07-08 09:16:33.565176 - gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = 42.8747 lengths = 26 } discounted_episode={ returns = 42.4595 lengths = 26 } 
2022-07-08 09:17:02.669454 - gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.5415 dist_std = 0.9672 vf_loss = 0.5183 grad_norm = 0.5880 nat_grad_norm = 0.4213 cg_residual = 0.0004 step_size = 0.4887 reward = 0.0000 fps = 25 mse_loss = 0.6711 
2022-07-08 09:17:31.024802 - gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.5634 dist_std = 0.9626 vf_loss = 0.6609 grad_norm = 0.5888 nat_grad_norm = 0.3654 cg_residual = 0.0002 step_size = 0.5419 reward = -0.0000 fps = 14 mse_loss = 0.5915 
2022-07-08 09:17:58.820113 - gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.6269 dist_std = 0.9774 vf_loss = 0.6671 grad_norm = 0.5416 nat_grad_norm = 0.3692 cg_residual = 0.0004 step_size = 0.5371 reward = -0.0000 fps = 10 mse_loss = 0.7073 
2022-07-08 09:18:25.972264 - gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.6573 dist_std = 0.9738 vf_loss = 0.7807 grad_norm = 0.5731 nat_grad_norm = 0.3741 cg_residual = 0.0004 step_size = 0.4858 reward = -0.0000 fps = 8 mse_loss = 0.6677 
2022-07-08 09:18:54.840055 - gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.7123 dist_std = 0.9778 vf_loss = 0.4616 grad_norm = 0.2867 nat_grad_norm = 0.3990 cg_residual = 0.0002 step_size = 0.5736 reward = -0.0000 fps = 6 mse_loss = 0.6863 
2022-07-08 09:18:55.622569 - gail/main.py:201 - [Discriminator] iter = 25000 loss = -0.0958 grad_norm = 7.0769 grad_penalty = 0.5709 regularization = 0.0000 true_logits = 0.1609 fake_logits = -0.5058 true_prob = 0.5400 fake_prob = 0.3805 
2022-07-08 09:19:07.575457 - gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = 58.1177 lengths = 32 } discounted_episode={ returns = 55.9372 lengths = 32 } 
2022-07-08 09:19:35.852594 - gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.7209 dist_std = 0.9708 vf_loss = 0.4822 grad_norm = 0.4500 nat_grad_norm = 0.5168 cg_residual = 0.0008 step_size = 0.4318 reward = 0.0000 fps = 24 mse_loss = 0.6766 
2022-07-08 09:20:03.497898 - gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.7876 dist_std = 0.9630 vf_loss = 0.2973 grad_norm = 0.3041 nat_grad_norm = 0.4988 cg_residual = 0.0003 step_size = 0.5218 reward = 0.0000 fps = 14 mse_loss = 0.9345 
2022-07-08 09:20:31.840330 - gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.8056 dist_std = 0.9527 vf_loss = 0.0968 grad_norm = 0.4463 nat_grad_norm = 0.8827 cg_residual = 0.0031 step_size = 0.3198 reward = 0.0000 fps = 10 mse_loss = 0.9025 
2022-07-08 09:20:58.975442 - gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.8140 dist_std = 0.9474 vf_loss = 0.0384 grad_norm = 0.6375 nat_grad_norm = 0.3497 cg_residual = 0.0009 step_size = 0.4928 reward = 0.0000 fps = 8 mse_loss = 0.9494 
2022-07-08 09:21:25.469757 - gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.7770 dist_std = 0.9419 vf_loss = 0.4743 grad_norm = 0.6228 nat_grad_norm = 0.4241 cg_residual = 0.0004 step_size = 0.4214 reward = -0.0000 fps = 6 mse_loss = 1.0505 
2022-07-08 09:21:26.212697 - gail/main.py:201 - [Discriminator] iter = 30000 loss = -0.4463 grad_norm = 5.7779 grad_penalty = 0.4365 regularization = 0.0000 true_logits = 0.1872 fake_logits = -0.6956 true_prob = 0.5465 fake_prob = 0.3369 
2022-07-08 09:21:36.726837 - gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = 51.6469 lengths = 28 } discounted_episode={ returns = 51.7192 lengths = 29 } 
2022-07-08 09:22:10.584141 - gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.8377 dist_std = 0.9461 vf_loss = 0.0927 grad_norm = 0.3548 nat_grad_norm = 0.5218 cg_residual = 0.0003 step_size = 0.4612 reward = -0.0000 fps = 22 mse_loss = 1.0872 
2022-07-08 09:22:37.618804 - gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.7896 dist_std = 0.9454 vf_loss = 0.3697 grad_norm = 0.4464 nat_grad_norm = 0.4199 cg_residual = 0.0004 step_size = 0.5709 reward = -0.0000 fps = 14 mse_loss = 1.0838 
2022-07-08 09:23:06.071569 - gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.7411 dist_std = 0.9415 vf_loss = 0.3741 grad_norm = 0.4630 nat_grad_norm = 0.6322 cg_residual = 0.0006 step_size = 0.3914 reward = -0.0000 fps = 10 mse_loss = 1.1672 
2022-07-08 09:23:33.610735 - gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.7547 dist_std = 0.9288 vf_loss = 0.4857 grad_norm = 0.3495 nat_grad_norm = 0.5340 cg_residual = 0.0016 step_size = 0.4376 reward = -0.0000 fps = 7 mse_loss = 1.2405 
2022-07-08 09:24:00.503530 - gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.7295 dist_std = 0.9284 vf_loss = 0.3742 grad_norm = 0.5956 nat_grad_norm = 0.3946 cg_residual = 0.0014 step_size = 0.4965 reward = -0.0000 fps = 6 mse_loss = 1.1892 
2022-07-08 09:24:01.278139 - gail/main.py:201 - [Discriminator] iter = 35000 loss = -0.5368 grad_norm = 6.5702 grad_penalty = 0.4853 regularization = 0.0000 true_logits = 0.2125 fake_logits = -0.8096 true_prob = 0.5525 fake_prob = 0.3130 
2022-07-08 09:24:29.415766 - gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 163.0135 lengths = 82 } discounted_episode={ returns = 156.9647 lengths = 82 } 
2022-07-08 09:24:54.646119 - gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.6776 dist_std = 0.9316 vf_loss = 0.9834 grad_norm = 0.4905 nat_grad_norm = 0.4160 cg_residual = 0.0017 step_size = 0.5207 reward = 0.0000 fps = 18 mse_loss = 1.1556 
2022-07-08 09:25:19.726979 - gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.6672 dist_std = 0.9254 vf_loss = 0.8459 grad_norm = 0.4990 nat_grad_norm = 0.4375 cg_residual = 0.0019 step_size = 0.4593 reward = 0.0000 fps = 12 mse_loss = 1.1309 
2022-07-08 09:25:45.820298 - gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.5651 dist_std = 0.9228 vf_loss = 0.7592 grad_norm = 0.6071 nat_grad_norm = 0.3827 cg_residual = 0.0007 step_size = 0.5143 reward = -0.0000 fps = 9 mse_loss = 1.4162 
2022-07-08 09:26:13.628033 - gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.5351 dist_std = 0.9288 vf_loss = 0.2841 grad_norm = 0.2969 nat_grad_norm = 0.5160 cg_residual = 0.0009 step_size = 0.5063 reward = -0.0000 fps = 7 mse_loss = 1.2868 
2022-07-08 09:26:40.112857 - gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.5679 dist_std = 0.9194 vf_loss = 1.2305 grad_norm = 0.7006 nat_grad_norm = 0.4145 cg_residual = 0.0011 step_size = 0.5140 reward = 0.0000 fps = 6 mse_loss = 1.3432 
2022-07-08 09:26:40.806106 - gail/main.py:201 - [Discriminator] iter = 40000 loss = -0.6865 grad_norm = 5.4451 grad_penalty = 0.4159 regularization = 0.0000 true_logits = 0.2434 fake_logits = -0.8589 true_prob = 0.5598 fake_prob = 0.3056 
2022-07-08 09:27:10.584075 - gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 168.2817 lengths = 86 } discounted_episode={ returns = 159.7298 lengths = 85 } 
2022-07-08 09:27:36.869863 - gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.5769 dist_std = 0.9088 vf_loss = 0.4685 grad_norm = 0.5993 nat_grad_norm = 0.4945 cg_residual = 0.0020 step_size = 0.4217 reward = -0.0000 fps = 17 mse_loss = 1.3647 
2022-07-08 09:28:02.153242 - gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.5473 dist_std = 0.8964 vf_loss = 0.2064 grad_norm = 0.4519 nat_grad_norm = 0.4190 cg_residual = 0.0010 step_size = 0.5287 reward = -0.0000 fps = 12 mse_loss = 1.4639 
2022-07-08 09:28:27.909184 - gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.5404 dist_std = 0.8962 vf_loss = 0.1299 grad_norm = 0.4854 nat_grad_norm = 0.3794 cg_residual = 0.0008 step_size = 0.5880 reward = -0.0000 fps = 9 mse_loss = 1.4822 
2022-07-08 09:28:54.412249 - gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.5292 dist_std = 0.8873 vf_loss = 0.0935 grad_norm = 0.7211 nat_grad_norm = 0.3524 cg_residual = 0.0021 step_size = 0.5868 reward = -0.0000 fps = 7 mse_loss = 1.6774 
2022-07-08 09:29:20.280338 - gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.5173 dist_std = 0.8917 vf_loss = 0.0871 grad_norm = 0.3734 nat_grad_norm = 0.3750 cg_residual = 0.0039 step_size = 0.5331 reward = 0.0000 fps = 6 mse_loss = 1.7029 
2022-07-08 09:29:21.000367 - gail/main.py:201 - [Discriminator] iter = 45000 loss = -0.9852 grad_norm = 5.4907 grad_penalty = 0.3566 regularization = 0.0000 true_logits = 0.2534 fake_logits = -1.0884 true_prob = 0.5628 fake_prob = 0.2630 
2022-07-08 09:29:50.778870 - gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 170.5472 lengths = 86 } discounted_episode={ returns = 163.8191 lengths = 86 } 
2022-07-08 09:30:17.713247 - gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.5092 dist_std = 0.8876 vf_loss = 0.1011 grad_norm = 0.4509 nat_grad_norm = 0.3416 cg_residual = 0.0041 step_size = 0.6083 reward = 0.0000 fps = 17 mse_loss = 1.9560 
2022-07-08 09:30:42.642525 - gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.4968 dist_std = 0.8894 vf_loss = 0.0999 grad_norm = 0.9281 nat_grad_norm = 0.3419 cg_residual = 0.0023 step_size = 0.5472 reward = -0.0000 fps = 12 mse_loss = 2.0934 
2022-07-08 09:31:09.024703 - gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.4934 dist_std = 0.8897 vf_loss = 0.0656 grad_norm = 0.5337 nat_grad_norm = 0.2786 cg_residual = 0.0022 step_size = 0.6237 reward = -0.0000 fps = 9 mse_loss = 1.9838 
2022-07-08 09:31:35.432889 - gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.4584 dist_std = 0.8914 vf_loss = 0.1338 grad_norm = 0.5772 nat_grad_norm = 0.4218 cg_residual = 0.0011 step_size = 0.4829 reward = 0.0000 fps = 7 mse_loss = 1.9014 
2022-07-08 09:32:01.525538 - gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.4384 dist_std = 0.8984 vf_loss = 0.2332 grad_norm = 0.4594 nat_grad_norm = 0.3777 cg_residual = 0.0015 step_size = 0.5775 reward = 0.0000 fps = 6 mse_loss = 1.9332 
2022-07-08 09:32:02.291692 - gail/main.py:201 - [Discriminator] iter = 50000 loss = -1.3182 grad_norm = 5.9404 grad_penalty = 0.3510 regularization = 0.0000 true_logits = 0.2834 fake_logits = -1.3857 true_prob = 0.5703 fake_prob = 0.2116 
2022-07-08 09:32:37.245081 - gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 176.0997 lengths = 87 } discounted_episode={ returns = 168.2833 lengths = 87 } 
2022-07-08 09:33:03.469418 - gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.3933 dist_std = 0.9140 vf_loss = 0.7275 grad_norm = 0.8694 nat_grad_norm = 0.4526 cg_residual = 0.0069 step_size = 0.4377 reward = -0.0000 fps = 16 mse_loss = 1.6682 
2022-07-08 09:33:29.015837 - gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.3754 dist_std = 0.9057 vf_loss = 0.7750 grad_norm = 0.6964 nat_grad_norm = 0.3580 cg_residual = 0.0022 step_size = 0.5337 reward = -0.0000 fps = 11 mse_loss = 2.0820 
2022-07-08 09:33:54.019433 - gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.3621 dist_std = 0.9042 vf_loss = 0.4576 grad_norm = 0.7426 nat_grad_norm = 0.4180 cg_residual = 0.0026 step_size = 0.4876 reward = 0.0000 fps = 8 mse_loss = 2.1630 
2022-07-08 09:34:18.878878 - gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.3679 dist_std = 0.9054 vf_loss = 0.5284 grad_norm = 0.9583 nat_grad_norm = 0.4327 cg_residual = 0.0026 step_size = 0.4651 reward = -0.0000 fps = 7 mse_loss = 2.1887 
2022-07-08 09:34:43.438908 - gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.2603 dist_std = 0.9111 vf_loss = 0.8399 grad_norm = 0.6902 nat_grad_norm = 0.3766 cg_residual = 0.0039 step_size = 0.4860 reward = 0.0000 fps = 6 mse_loss = 2.1801 
2022-07-08 09:34:44.151898 - gail/main.py:201 - [Discriminator] iter = 55000 loss = -1.1817 grad_norm = 5.9638 grad_penalty = 0.3965 regularization = 0.0000 true_logits = 0.2650 fake_logits = -1.3132 true_prob = 0.5657 fake_prob = 0.2400 
2022-07-08 09:35:26.554362 - gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 356.5532 lengths = 132 } discounted_episode={ returns = 328.3238 lengths = 131 } 
2022-07-08 09:35:51.532176 - gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.2316 dist_std = 0.9124 vf_loss = 1.4375 grad_norm = 0.4441 nat_grad_norm = 0.5232 cg_residual = 0.0087 step_size = 0.4640 reward = 0.0000 fps = 14 mse_loss = 2.2865 
2022-07-08 09:36:15.987365 - gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.2538 dist_std = 0.9088 vf_loss = 0.6714 grad_norm = 0.4708 nat_grad_norm = 0.4552 cg_residual = 0.0040 step_size = 0.5474 reward = -0.0000 fps = 10 mse_loss = 2.3254 
2022-07-08 09:36:40.360896 - gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.2417 dist_std = 0.9047 vf_loss = 0.6122 grad_norm = 0.5712 nat_grad_norm = 0.3768 cg_residual = 0.0252 step_size = 0.5539 reward = 0.0000 fps = 8 mse_loss = 1.8674 
2022-07-08 09:37:05.874474 - gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.1907 dist_std = 0.9040 vf_loss = 0.3965 grad_norm = 0.8715 nat_grad_norm = 0.3661 cg_residual = 0.0058 step_size = 0.4872 reward = 0.0000 fps = 7 mse_loss = 1.6482 
2022-07-08 09:37:29.989828 - gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.2082 dist_std = 0.9004 vf_loss = 0.5181 grad_norm = 0.5867 nat_grad_norm = 0.4825 cg_residual = 0.0097 step_size = 0.4791 reward = -0.0000 fps = 6 mse_loss = 2.0913 
2022-07-08 09:37:30.745564 - gail/main.py:201 - [Discriminator] iter = 60000 loss = -1.2082 grad_norm = 4.1893 grad_penalty = 0.3212 regularization = 0.0000 true_logits = 0.2855 fake_logits = -1.2439 true_prob = 0.5700 fake_prob = 0.2594 
2022-07-08 09:38:13.453107 - gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 361.5098 lengths = 133 } discounted_episode={ returns = 336.6801 lengths = 134 } 
2022-07-08 09:38:38.208710 - gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.1827 dist_std = 0.9003 vf_loss = 0.2488 grad_norm = 0.7036 nat_grad_norm = 0.4701 cg_residual = 0.0236 step_size = 0.4611 reward = -0.0000 fps = 14 mse_loss = 2.1821 
2022-07-08 09:39:02.674904 - gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.2008 dist_std = 0.8984 vf_loss = 0.8491 grad_norm = 0.7639 nat_grad_norm = 0.4179 cg_residual = 0.0064 step_size = 0.4888 reward = 0.0000 fps = 10 mse_loss = 1.8931 
2022-07-08 09:39:26.781653 - gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.1576 dist_std = 0.8907 vf_loss = 0.3278 grad_norm = 0.4739 nat_grad_norm = 0.4952 cg_residual = 0.0054 step_size = 0.4961 reward = 0.0000 fps = 8 mse_loss = 1.8793 
2022-07-08 09:39:51.768549 - gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.1326 dist_std = 0.8907 vf_loss = 0.1538 grad_norm = 0.5786 nat_grad_norm = 0.3239 cg_residual = 0.0145 step_size = 0.5741 reward = -0.0000 fps = 7 mse_loss = 1.8274 
2022-07-08 09:40:17.804021 - gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.1232 dist_std = 0.8898 vf_loss = 0.2242 grad_norm = 0.3853 nat_grad_norm = 0.4221 cg_residual = 0.0072 step_size = 0.5819 reward = -0.0000 fps = 5 mse_loss = 1.8265 
2022-07-08 09:40:18.556565 - gail/main.py:201 - [Discriminator] iter = 65000 loss = -1.2111 grad_norm = 3.9685 grad_penalty = 0.2584 regularization = 0.0000 true_logits = 0.2646 fake_logits = -1.2050 true_prob = 0.5661 fake_prob = 0.2636 
2022-07-08 09:41:02.882807 - gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 367.9163 lengths = 134 } discounted_episode={ returns = 339.1315 lengths = 134 } 
2022-07-08 09:41:27.481709 - gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.1507 dist_std = 0.8791 vf_loss = 0.4105 grad_norm = 0.4977 nat_grad_norm = 0.4865 cg_residual = 0.0200 step_size = 0.4943 reward = -0.0000 fps = 14 mse_loss = 2.1266 
2022-07-08 09:41:51.215397 - gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.0900 dist_std = 0.8796 vf_loss = 0.1316 grad_norm = 0.6765 nat_grad_norm = 0.3990 cg_residual = 0.0080 step_size = 0.4809 reward = -0.0000 fps = 10 mse_loss = 2.1442 
2022-07-08 09:42:21.140212 - gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.1242 dist_std = 0.8753 vf_loss = 0.2533 grad_norm = 0.5203 nat_grad_norm = 0.4411 cg_residual = 0.0210 step_size = 0.4585 reward = 0.0000 fps = 8 mse_loss = 2.2570 
2022-07-08 09:42:44.876578 - gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.0802 dist_std = 0.8675 vf_loss = 0.2473 grad_norm = 0.5411 nat_grad_norm = 0.4504 cg_residual = 0.0074 step_size = 0.5357 reward = -0.0000 fps = 6 mse_loss = 2.1206 
2022-07-08 09:43:08.320301 - gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.0763 dist_std = 0.8600 vf_loss = 0.4136 grad_norm = 0.4340 nat_grad_norm = 0.4471 cg_residual = 0.0045 step_size = 0.5363 reward = -0.0000 fps = 5 mse_loss = 2.1090 
2022-07-08 09:43:09.038482 - gail/main.py:201 - [Discriminator] iter = 70000 loss = -1.1361 grad_norm = 4.1502 grad_penalty = 0.2577 regularization = 0.0000 true_logits = 0.2368 fake_logits = -1.1570 true_prob = 0.5593 fake_prob = 0.2681 
2022-07-08 09:43:49.579783 - gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 368.7367 lengths = 133 } discounted_episode={ returns = 341.6655 lengths = 133 } 
2022-07-08 09:44:14.058242 - gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.1020 dist_std = 0.8531 vf_loss = 0.5181 grad_norm = 0.6046 nat_grad_norm = 0.5351 cg_residual = 0.0345 step_size = 0.4413 reward = -0.0000 fps = 15 mse_loss = 2.3122 
2022-07-08 09:44:38.097882 - gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.0702 dist_std = 0.8503 vf_loss = 0.4171 grad_norm = 0.7913 nat_grad_norm = 0.4486 cg_residual = 0.0044 step_size = 0.4551 reward = 0.0000 fps = 11 mse_loss = 2.5385 
2022-07-08 09:45:01.463731 - gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.1008 dist_std = 0.8374 vf_loss = 0.2934 grad_norm = 0.4907 nat_grad_norm = 0.4426 cg_residual = 0.0083 step_size = 0.5097 reward = 0.0000 fps = 8 mse_loss = 2.5867 
2022-07-08 09:45:25.143214 - gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.0685 dist_std = 0.8427 vf_loss = 0.2148 grad_norm = 0.5664 nat_grad_norm = 0.5562 cg_residual = 0.0056 step_size = 0.4389 reward = 0.0000 fps = 7 mse_loss = 2.9007 
2022-07-08 09:45:47.780172 - gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.1487 dist_std = 0.8380 vf_loss = 0.9815 grad_norm = 0.4018 nat_grad_norm = 0.4334 cg_residual = 0.0081 step_size = 0.5006 reward = -0.0000 fps = 6 mse_loss = 3.0840 
2022-07-08 09:45:48.517149 - gail/main.py:201 - [Discriminator] iter = 75000 loss = -1.2195 grad_norm = 3.5920 grad_penalty = 0.2277 regularization = 0.0000 true_logits = 0.2578 fake_logits = -1.1895 true_prob = 0.5638 fake_prob = 0.2617 
2022-07-08 09:46:28.535151 - gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 372.1138 lengths = 132 } discounted_episode={ returns = 345.6081 lengths = 132 } 
2022-07-08 09:46:52.628012 - gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.1144 dist_std = 0.8384 vf_loss = 0.8335 grad_norm = 0.6104 nat_grad_norm = 0.4854 cg_residual = 0.0095 step_size = 0.4273 reward = -0.0000 fps = 15 mse_loss = 2.9822 
2022-07-08 09:47:16.219800 - gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.0962 dist_std = 0.8358 vf_loss = 0.3069 grad_norm = 0.4504 nat_grad_norm = 0.4008 cg_residual = 0.0057 step_size = 0.5356 reward = -0.0000 fps = 11 mse_loss = 2.6065 
2022-07-08 09:47:40.643491 - gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.0761 dist_std = 0.8438 vf_loss = 0.4224 grad_norm = 0.5614 nat_grad_norm = 0.4573 cg_residual = 0.0065 step_size = 0.4935 reward = -0.0000 fps = 8 mse_loss = 2.9169 
2022-07-08 09:48:04.582599 - gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.0237 dist_std = 0.8464 vf_loss = 0.3076 grad_norm = 0.9428 nat_grad_norm = 0.4041 cg_residual = 0.0306 step_size = 0.4326 reward = -0.0000 fps = 7 mse_loss = 3.0375 
2022-07-08 09:48:27.525365 - gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.0922 dist_std = 0.8457 vf_loss = 0.3097 grad_norm = 0.6210 nat_grad_norm = 0.4697 cg_residual = 0.0052 step_size = 0.4676 reward = 0.0000 fps = 6 mse_loss = 3.4385 
2022-07-08 09:48:28.300759 - gail/main.py:201 - [Discriminator] iter = 80000 loss = -1.2556 grad_norm = 3.2026 grad_penalty = 0.2100 regularization = 0.0000 true_logits = 0.2659 fake_logits = -1.1996 true_prob = 0.5648 fake_prob = 0.2584 
2022-07-08 09:49:18.142258 - gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 538.4054 lengths = 163 } discounted_episode={ returns = 496.1930 lengths = 164 } 
2022-07-08 09:49:42.943070 - gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.0807 dist_std = 0.8376 vf_loss = 0.5825 grad_norm = 0.4656 nat_grad_norm = 0.4550 cg_residual = 0.0080 step_size = 0.4971 reward = 0.0000 fps = 13 mse_loss = 3.1830 
2022-07-08 09:50:09.107064 - gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.0950 dist_std = 0.8308 vf_loss = 0.2855 grad_norm = 0.6459 nat_grad_norm = 0.4278 cg_residual = 0.0067 step_size = 0.4782 reward = -0.0000 fps = 9 mse_loss = 2.5232 
2022-07-08 09:50:34.010663 - gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.0452 dist_std = 0.8321 vf_loss = 0.4082 grad_norm = 0.3958 nat_grad_norm = 0.4710 cg_residual = 0.0076 step_size = 0.5117 reward = -0.0000 fps = 7 mse_loss = 2.3774 
2022-07-08 09:50:56.946995 - gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.0307 dist_std = 0.8244 vf_loss = 0.2257 grad_norm = 0.5369 nat_grad_norm = 0.3935 cg_residual = 0.0101 step_size = 0.5321 reward = 0.0000 fps = 6 mse_loss = 2.2745 
2022-07-08 09:51:19.328135 - gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.1094 dist_std = 0.8273 vf_loss = 0.5351 grad_norm = 0.3473 nat_grad_norm = 0.3724 cg_residual = 0.0067 step_size = 0.5913 reward = 0.0000 fps = 5 mse_loss = 2.7244 
2022-07-08 09:51:20.084901 - gail/main.py:201 - [Discriminator] iter = 85000 loss = -1.1206 grad_norm = 3.0256 grad_penalty = 0.2185 regularization = 0.0000 true_logits = 0.2625 fake_logits = -1.0767 true_prob = 0.5641 fake_prob = 0.2786 
2022-07-08 09:52:26.643808 - gail/main.py:142 - [Evaluate] iter = 85000 episode={ returns = 634.2728 lengths = 196 } discounted_episode={ returns = 571.0632 lengths = 198 } 
2022-07-08 09:52:50.978415 - gail/main.py:174 - [TRPO] iter = 86000 dist_mean = 0.0855 dist_std = 0.8258 vf_loss = 0.3083 grad_norm = 0.7959 nat_grad_norm = 0.5326 cg_residual = 0.0104 step_size = 0.4105 reward = 0.0000 fps = 11 mse_loss = 3.0095 
2022-07-08 09:53:15.651552 - gail/main.py:174 - [TRPO] iter = 87000 dist_mean = 0.0486 dist_std = 0.8199 vf_loss = 0.1784 grad_norm = 0.4004 nat_grad_norm = 0.3275 cg_residual = 0.0075 step_size = 0.6153 reward = 0.0000 fps = 8 mse_loss = 2.9775 
2022-07-08 09:53:40.922557 - gail/main.py:174 - [TRPO] iter = 88000 dist_mean = 0.0314 dist_std = 0.8084 vf_loss = 0.1910 grad_norm = 0.7179 nat_grad_norm = 0.3255 cg_residual = 0.0050 step_size = 0.5111 reward = 0.0000 fps = 7 mse_loss = 2.7618 
2022-07-08 09:54:05.825510 - gail/main.py:174 - [TRPO] iter = 89000 dist_mean = 0.0701 dist_std = 0.8008 vf_loss = 0.3850 grad_norm = 0.4671 nat_grad_norm = 0.3681 cg_residual = 0.0089 step_size = 0.5871 reward = -0.0000 fps = 6 mse_loss = 2.8423 
2022-07-08 09:54:31.442489 - gail/main.py:174 - [TRPO] iter = 90000 dist_mean = 0.1348 dist_std = 0.7879 vf_loss = 0.2708 grad_norm = 0.3719 nat_grad_norm = 0.3947 cg_residual = 0.0058 step_size = 0.5487 reward = -0.0000 fps = 5 mse_loss = 2.8077 
2022-07-08 09:54:32.206146 - gail/main.py:201 - [Discriminator] iter = 90000 loss = -1.0707 grad_norm = 3.6936 grad_penalty = 0.1944 regularization = 0.0000 true_logits = 0.2815 fake_logits = -0.9835 true_prob = 0.5676 fake_prob = 0.2989 
2022-07-08 09:55:43.060976 - gail/main.py:142 - [Evaluate] iter = 90000 episode={ returns = 743.1623 lengths = 236 } discounted_episode={ returns = 651.1291 lengths = 233 } 
2022-07-08 09:56:05.552603 - gail/main.py:174 - [TRPO] iter = 91000 dist_mean = 0.0475 dist_std = 0.7807 vf_loss = 0.3834 grad_norm = 0.4952 nat_grad_norm = 0.4243 cg_residual = 0.0101 step_size = 0.5058 reward = -0.0000 fps = 10 mse_loss = 3.2945 
2022-07-08 09:56:27.580989 - gail/main.py:174 - [TRPO] iter = 92000 dist_mean = 0.0922 dist_std = 0.7713 vf_loss = 0.2254 grad_norm = 0.5571 nat_grad_norm = 0.4236 cg_residual = 0.0086 step_size = 0.4926 reward = 0.0000 fps = 8 mse_loss = 3.0645 
2022-07-08 09:56:49.781778 - gail/main.py:174 - [TRPO] iter = 93000 dist_mean = 0.1363 dist_std = 0.7740 vf_loss = 0.3540 grad_norm = 0.6232 nat_grad_norm = 0.3831 cg_residual = 0.0136 step_size = 0.4916 reward = 0.0000 fps = 7 mse_loss = 3.3094 
2022-07-08 09:57:12.539751 - gail/main.py:174 - [TRPO] iter = 94000 dist_mean = 0.0633 dist_std = 0.7672 vf_loss = 0.1656 grad_norm = 0.4585 nat_grad_norm = 0.4103 cg_residual = 0.0077 step_size = 0.5503 reward = -0.0000 fps = 6 mse_loss = 3.4096 
2022-07-08 09:57:36.110075 - gail/main.py:174 - [TRPO] iter = 95000 dist_mean = 0.0180 dist_std = 0.7554 vf_loss = 0.1012 grad_norm = 0.5788 nat_grad_norm = 0.4186 cg_residual = 0.0215 step_size = 0.4909 reward = -0.0000 fps = 5 mse_loss = 3.5430 
2022-07-08 09:57:36.819099 - gail/main.py:201 - [Discriminator] iter = 95000 loss = -1.0215 grad_norm = 3.1959 grad_penalty = 0.2238 regularization = 0.0000 true_logits = 0.3303 fake_logits = -0.9149 true_prob = 0.5767 fake_prob = 0.3108 
2022-07-08 09:58:58.931393 - gail/main.py:142 - [Evaluate] iter = 95000 episode={ returns = 822.9413 lengths = 271 } discounted_episode={ returns = 704.5733 lengths = 269 } 
2022-07-08 09:59:22.044685 - gail/main.py:174 - [TRPO] iter = 96000 dist_mean = 0.0811 dist_std = 0.7509 vf_loss = 0.2690 grad_norm = 0.6588 nat_grad_norm = 0.3101 cg_residual = 0.0148 step_size = 0.5385 reward = -0.0000 fps = 9 mse_loss = 3.9468 
2022-07-08 09:59:46.839631 - gail/main.py:174 - [TRPO] iter = 97000 dist_mean = 0.1202 dist_std = 0.7534 vf_loss = 0.1472 grad_norm = 0.4373 nat_grad_norm = 0.4103 cg_residual = 0.0163 step_size = 0.5246 reward = -0.0000 fps = 7 mse_loss = 3.7057 
2022-07-08 10:00:11.226337 - gail/main.py:174 - [TRPO] iter = 98000 dist_mean = 0.1115 dist_std = 0.7476 vf_loss = 0.1173 grad_norm = 0.6929 nat_grad_norm = 0.3586 cg_residual = 0.0142 step_size = 0.5159 reward = 0.0000 fps = 6 mse_loss = 3.5583 
2022-07-08 10:00:35.626955 - gail/main.py:174 - [TRPO] iter = 99000 dist_mean = 0.1585 dist_std = 0.7434 vf_loss = 0.2130 grad_norm = 0.4864 nat_grad_norm = 0.3849 cg_residual = 0.0094 step_size = 0.5299 reward = -0.0000 fps = 5 mse_loss = 3.6496 
2022-07-08 10:01:00.869245 - gail/main.py:174 - [TRPO] iter = 100000 dist_mean = 0.1611 dist_std = 0.7376 vf_loss = 0.1107 grad_norm = 0.5484 nat_grad_norm = 0.3920 cg_residual = 0.0111 step_size = 0.5053 reward = 0.0000 fps = 4 mse_loss = 3.5361 
2022-07-08 10:01:01.516403 - gail/main.py:201 - [Discriminator] iter = 100000 loss = -0.9982 grad_norm = 3.0784 grad_penalty = 0.1814 regularization = 0.0000 true_logits = 0.3529 fake_logits = -0.8266 true_prob = 0.5798 fake_prob = 0.3265 
2022-07-08 10:02:44.326056 - gail/main.py:142 - [Evaluate] iter = 100000 episode={ returns = 499.0815 lengths = 201 } discounted_episode={ returns = 789.8160 lengths = 357 } 
2022-07-08 10:03:11.311909 - gail/main.py:174 - [TRPO] iter = 101000 dist_mean = 0.0622 dist_std = 0.7337 vf_loss = 0.2180 grad_norm = 0.4519 nat_grad_norm = 0.3465 cg_residual = 0.0092 step_size = 0.5853 reward = 0.0000 fps = 7 mse_loss = 3.8340 
2022-07-08 10:03:36.293919 - gail/main.py:174 - [TRPO] iter = 102000 dist_mean = 0.1728 dist_std = 0.7442 vf_loss = 0.2445 grad_norm = 0.3970 nat_grad_norm = 0.3419 cg_residual = 0.0145 step_size = 0.5800 reward = 0.0000 fps = 6 mse_loss = 4.0588 
2022-07-08 10:04:04.846855 - gail/main.py:174 - [TRPO] iter = 103000 dist_mean = 0.1348 dist_std = 0.7488 vf_loss = 0.1566 grad_norm = 0.5123 nat_grad_norm = 0.4240 cg_residual = 0.0166 step_size = 0.5011 reward = -0.0000 fps = 5 mse_loss = 4.1464 
2022-07-08 10:04:31.334637 - gail/main.py:174 - [TRPO] iter = 104000 dist_mean = 0.1455 dist_std = 0.7382 vf_loss = 0.1670 grad_norm = 0.5619 nat_grad_norm = 0.4638 cg_residual = 0.0272 step_size = 0.4939 reward = 0.0000 fps = 4 mse_loss = 4.1245 
2022-07-08 10:04:57.972808 - gail/main.py:174 - [TRPO] iter = 105000 dist_mean = 0.0768 dist_std = 0.7386 vf_loss = 0.1863 grad_norm = 0.7327 nat_grad_norm = 0.5078 cg_residual = 0.0208 step_size = 0.4566 reward = 0.0000 fps = 4 mse_loss = 4.6211 
2022-07-08 10:04:58.742452 - gail/main.py:201 - [Discriminator] iter = 105000 loss = -1.1928 grad_norm = 2.8368 grad_penalty = 0.1707 regularization = 0.0000 true_logits = 0.4077 fake_logits = -0.9559 true_prob = 0.5905 fake_prob = 0.2999 
2022-07-08 10:06:56.807636 - gail/main.py:142 - [Evaluate] iter = 105000 episode={ returns = 991.5684 lengths = 334 } discounted_episode={ returns = 773.4851 lengths = 319 } 
2022-07-08 10:07:24.332869 - gail/main.py:174 - [TRPO] iter = 106000 dist_mean = 0.1352 dist_std = 0.7345 vf_loss = 0.1859 grad_norm = 0.4660 nat_grad_norm = 0.4181 cg_residual = 0.0160 step_size = 0.5243 reward = -0.0000 fps = 6 mse_loss = 4.3937 
2022-07-08 10:07:50.519687 - gail/main.py:174 - [TRPO] iter = 107000 dist_mean = 0.1093 dist_std = 0.7251 vf_loss = 0.1138 grad_norm = 0.5496 nat_grad_norm = 0.5720 cg_residual = 0.0226 step_size = 0.4378 reward = 0.0000 fps = 5 mse_loss = 4.3686 
2022-07-08 10:08:16.634763 - gail/main.py:174 - [TRPO] iter = 108000 dist_mean = 0.1665 dist_std = 0.7257 vf_loss = 0.1784 grad_norm = 0.6250 nat_grad_norm = 0.3937 cg_residual = 0.0155 step_size = 0.4952 reward = 0.0000 fps = 5 mse_loss = 4.2026 
2022-07-08 10:08:43.425604 - gail/main.py:174 - [TRPO] iter = 109000 dist_mean = 0.1401 dist_std = 0.7223 vf_loss = 0.2025 grad_norm = 0.5370 nat_grad_norm = 0.3806 cg_residual = 0.0121 step_size = 0.5214 reward = -0.0000 fps = 4 mse_loss = 4.4035 
2022-07-08 10:09:11.717048 - gail/main.py:174 - [TRPO] iter = 110000 dist_mean = 0.0878 dist_std = 0.7235 vf_loss = 0.2712 grad_norm = 0.5218 nat_grad_norm = 0.3634 cg_residual = 0.0106 step_size = 0.6043 reward = 0.0000 fps = 3 mse_loss = 4.9788 
2022-07-08 10:09:12.556693 - gail/main.py:201 - [Discriminator] iter = 110000 loss = -1.2255 grad_norm = 3.1814 grad_penalty = 0.1587 regularization = 0.0000 true_logits = 0.4022 fake_logits = -0.9820 true_prob = 0.5878 fake_prob = 0.2956 
2022-07-08 10:10:55.750683 - gail/main.py:142 - [Evaluate] iter = 110000 episode={ returns = 879.3837 lengths = 290 } discounted_episode={ returns = 745.5616 lengths = 291 } 
2022-07-08 10:11:23.364985 - gail/main.py:174 - [TRPO] iter = 111000 dist_mean = 0.0918 dist_std = 0.7198 vf_loss = 0.1457 grad_norm = 0.5817 nat_grad_norm = 0.4236 cg_residual = 0.0093 step_size = 0.5025 reward = -0.0000 fps = 7 mse_loss = 4.6888 
2022-07-08 10:11:53.933478 - gail/main.py:174 - [TRPO] iter = 112000 dist_mean = 0.1399 dist_std = 0.7176 vf_loss = 0.1908 grad_norm = 0.5658 nat_grad_norm = 0.4084 cg_residual = 0.0117 step_size = 0.4757 reward = -0.0000 fps = 6 mse_loss = 4.6333 
2022-07-08 10:12:25.941915 - gail/main.py:174 - [TRPO] iter = 113000 dist_mean = 0.0659 dist_std = 0.7190 vf_loss = 0.2092 grad_norm = 0.3994 nat_grad_norm = 0.4101 cg_residual = 0.0163 step_size = 0.5590 reward = -0.0000 fps = 5 mse_loss = 4.6934 
2022-07-08 10:12:53.632350 - gail/main.py:174 - [TRPO] iter = 114000 dist_mean = -0.0447 dist_std = 0.7138 vf_loss = 0.1639 grad_norm = 0.3827 nat_grad_norm = 0.3518 cg_residual = 0.0177 step_size = 0.6225 reward = -0.0000 fps = 4 mse_loss = 4.6102 
2022-07-08 10:13:19.567000 - gail/main.py:174 - [TRPO] iter = 115000 dist_mean = 0.0661 dist_std = 0.7085 vf_loss = 0.1046 grad_norm = 0.5692 nat_grad_norm = 0.4022 cg_residual = 0.0232 step_size = 0.4617 reward = 0.0000 fps = 4 mse_loss = 4.6395 
2022-07-08 10:13:20.333722 - gail/main.py:201 - [Discriminator] iter = 115000 loss = -1.1305 grad_norm = 2.7520 grad_penalty = 0.1554 regularization = 0.0000 true_logits = 0.4174 fake_logits = -0.8685 true_prob = 0.5890 fake_prob = 0.3197 
2022-07-08 10:14:51.904517 - gail/main.py:142 - [Evaluate] iter = 115000 episode={ returns = 857.2916 lengths = 264 } discounted_episode={ returns = 738.6013 lengths = 264 } 
2022-07-08 10:15:19.121745 - gail/main.py:174 - [TRPO] iter = 116000 dist_mean = 0.0536 dist_std = 0.7102 vf_loss = 0.1435 grad_norm = 0.4882 nat_grad_norm = 0.4116 cg_residual = 0.0239 step_size = 0.5192 reward = 0.0000 fps = 8 mse_loss = 4.4441 
2022-07-08 10:15:45.657759 - gail/main.py:174 - [TRPO] iter = 117000 dist_mean = -0.0399 dist_std = 0.7112 vf_loss = 0.3138 grad_norm = 0.5879 nat_grad_norm = 0.4100 cg_residual = 0.0284 step_size = 0.5004 reward = 0.0000 fps = 6 mse_loss = 4.5916 
2022-07-08 10:16:12.191387 - gail/main.py:174 - [TRPO] iter = 118000 dist_mean = 0.0378 dist_std = 0.7099 vf_loss = 0.1391 grad_norm = 0.7174 nat_grad_norm = 0.4187 cg_residual = 0.0352 step_size = 0.4346 reward = -0.0000 fps = 5 mse_loss = 4.5133 
2022-07-08 10:16:38.922312 - gail/main.py:174 - [TRPO] iter = 119000 dist_mean = 0.0537 dist_std = 0.6991 vf_loss = 0.0836 grad_norm = 0.5793 nat_grad_norm = 0.3811 cg_residual = 0.0181 step_size = 0.4997 reward = -0.0000 fps = 5 mse_loss = 4.6971 
2022-07-08 10:17:05.124148 - gail/main.py:174 - [TRPO] iter = 120000 dist_mean = 0.0444 dist_std = 0.6907 vf_loss = 0.1277 grad_norm = 0.7131 nat_grad_norm = 0.4421 cg_residual = 0.0312 step_size = 0.4700 reward = -0.0000 fps = 4 mse_loss = 4.7416 
2022-07-08 10:17:05.941870 - gail/main.py:201 - [Discriminator] iter = 120000 loss = -1.1891 grad_norm = 3.6835 grad_penalty = 0.1654 regularization = 0.0000 true_logits = 0.4664 fake_logits = -0.8881 true_prob = 0.5980 fake_prob = 0.3178 
2022-07-08 10:18:26.234145 - gail/main.py:142 - [Evaluate] iter = 120000 episode={ returns = 627.9279 lengths = 221 } discounted_episode={ returns = 617.8286 lengths = 248 } 
2022-07-08 10:18:52.157112 - gail/main.py:174 - [TRPO] iter = 121000 dist_mean = 0.0511 dist_std = 0.6978 vf_loss = 0.0855 grad_norm = 0.5688 nat_grad_norm = 0.3030 cg_residual = 0.0186 step_size = 0.5996 reward = 0.0000 fps = 9 mse_loss = 5.0881 
2022-07-08 10:19:17.290588 - gail/main.py:174 - [TRPO] iter = 122000 dist_mean = 0.0414 dist_std = 0.6950 vf_loss = 0.1294 grad_norm = 0.6501 nat_grad_norm = 0.4242 cg_residual = 0.0442 step_size = 0.4186 reward = -0.0000 fps = 7 mse_loss = 4.9663 
2022-07-08 10:19:44.296592 - gail/main.py:174 - [TRPO] iter = 123000 dist_mean = 0.0222 dist_std = 0.6911 vf_loss = 0.1239 grad_norm = 0.6644 nat_grad_norm = 0.3587 cg_residual = 0.0175 step_size = 0.5376 reward = -0.0000 fps = 6 mse_loss = 5.1141 
2022-07-08 10:20:11.432191 - gail/main.py:174 - [TRPO] iter = 124000 dist_mean = 0.0818 dist_std = 0.6886 vf_loss = 0.0857 grad_norm = 0.9252 nat_grad_norm = 0.3840 cg_residual = 0.0246 step_size = 0.4185 reward = 0.0000 fps = 5 mse_loss = 5.5966 
2022-07-08 10:20:38.400442 - gail/main.py:174 - [TRPO] iter = 125000 dist_mean = 0.0279 dist_std = 0.6932 vf_loss = 0.0860 grad_norm = 0.6641 nat_grad_norm = 0.4926 cg_residual = 0.0574 step_size = 0.3998 reward = 0.0000 fps = 4 mse_loss = 5.2920 
2022-07-08 10:20:39.180267 - gail/main.py:201 - [Discriminator] iter = 125000 loss = -1.1966 grad_norm = 3.1415 grad_penalty = 0.1570 regularization = 0.0000 true_logits = 0.4793 fake_logits = -0.8743 true_prob = 0.5985 fake_prob = 0.3181 
2022-07-08 10:22:15.898260 - gail/main.py:142 - [Evaluate] iter = 125000 episode={ returns = 845.8787 lengths = 264 } discounted_episode={ returns = 725.3609 lengths = 264 } 
2022-07-08 10:22:41.920471 - gail/main.py:174 - [TRPO] iter = 126000 dist_mean = 0.0115 dist_std = 0.6835 vf_loss = 0.5643 grad_norm = 0.8780 nat_grad_norm = 0.5519 cg_residual = 0.0691 step_size = 0.3398 reward = -0.0000 fps = 8 mse_loss = 5.1077 
2022-07-08 10:23:08.289718 - gail/main.py:174 - [TRPO] iter = 127000 dist_mean = 0.1206 dist_std = 0.6713 vf_loss = 0.1230 grad_norm = 0.6926 nat_grad_norm = 0.4122 cg_residual = 0.0402 step_size = 0.4872 reward = 0.0000 fps = 6 mse_loss = 4.9109 
2022-07-08 10:23:34.553699 - gail/main.py:174 - [TRPO] iter = 128000 dist_mean = 0.0755 dist_std = 0.6712 vf_loss = 0.0885 grad_norm = 0.6113 nat_grad_norm = 0.4946 cg_residual = 0.0364 step_size = 0.4247 reward = -0.0000 fps = 5 mse_loss = 5.1420 
2022-07-08 10:24:00.380532 - gail/main.py:174 - [TRPO] iter = 129000 dist_mean = 0.1010 dist_std = 0.6716 vf_loss = 0.1038 grad_norm = 0.7060 nat_grad_norm = 0.3462 cg_residual = 0.0312 step_size = 0.4885 reward = -0.0000 fps = 4 mse_loss = 5.2429 
2022-07-08 10:24:26.932990 - gail/main.py:174 - [TRPO] iter = 130000 dist_mean = 0.0666 dist_std = 0.6681 vf_loss = 0.1483 grad_norm = 0.8801 nat_grad_norm = 0.4404 cg_residual = 0.0588 step_size = 0.3831 reward = -0.0000 fps = 4 mse_loss = 4.4254 
2022-07-08 10:24:27.801749 - gail/main.py:201 - [Discriminator] iter = 130000 loss = -1.2200 grad_norm = 3.5187 grad_penalty = 0.1450 regularization = 0.0000 true_logits = 0.5131 fake_logits = -0.8519 true_prob = 0.6053 fake_prob = 0.3215 
2022-07-08 10:25:58.638073 - gail/main.py:142 - [Evaluate] iter = 130000 episode={ returns = 835.8429 lengths = 264 } discounted_episode={ returns = 717.2675 lengths = 263 } 
2022-07-08 10:26:25.970780 - gail/main.py:174 - [TRPO] iter = 131000 dist_mean = 0.1217 dist_std = 0.6551 vf_loss = 0.1091 grad_norm = 0.8376 nat_grad_norm = 0.5064 cg_residual = 0.0281 step_size = 0.3761 reward = 0.0000 fps = 8 mse_loss = 4.3832 
2022-07-08 10:26:53.591125 - gail/main.py:174 - [TRPO] iter = 132000 dist_mean = 0.0842 dist_std = 0.6538 vf_loss = 0.0972 grad_norm = 0.7289 nat_grad_norm = 0.3627 cg_residual = 0.0627 step_size = 0.4439 reward = 0.0000 fps = 6 mse_loss = 4.7463 
2022-07-08 10:27:21.100716 - gail/main.py:174 - [TRPO] iter = 133000 dist_mean = 0.1673 dist_std = 0.6496 vf_loss = 0.2760 grad_norm = 0.6006 nat_grad_norm = 0.3634 cg_residual = 0.0364 step_size = 0.4500 reward = -0.0000 fps = 5 mse_loss = 4.9406 
2022-07-08 10:27:48.844726 - gail/main.py:174 - [TRPO] iter = 134000 dist_mean = 0.1250 dist_std = 0.6450 vf_loss = 0.1037 grad_norm = 0.5736 nat_grad_norm = 0.4011 cg_residual = 0.0812 step_size = 0.4632 reward = 0.0000 fps = 4 mse_loss = 4.4741 
2022-07-08 10:28:16.448716 - gail/main.py:174 - [TRPO] iter = 135000 dist_mean = 0.0191 dist_std = 0.6348 vf_loss = 0.1173 grad_norm = 0.9626 nat_grad_norm = 0.3332 cg_residual = 0.0317 step_size = 0.4350 reward = 0.0000 fps = 4 mse_loss = 4.3268 
2022-07-08 10:28:17.323494 - gail/main.py:201 - [Discriminator] iter = 135000 loss = -1.3375 grad_norm = 3.3831 grad_penalty = 0.1450 regularization = 0.0000 true_logits = 0.5477 fake_logits = -0.9348 true_prob = 0.6096 fake_prob = 0.3085 
2022-07-08 10:29:50.466274 - gail/main.py:142 - [Evaluate] iter = 135000 episode={ returns = 833.9434 lengths = 256 } discounted_episode={ returns = 720.8450 lengths = 256 } 
2022-07-08 10:30:18.596635 - gail/main.py:174 - [TRPO] iter = 136000 dist_mean = 0.1096 dist_std = 0.6287 vf_loss = 1.2936 grad_norm = 0.8895 nat_grad_norm = 0.3747 cg_residual = 0.0326 step_size = 0.4561 reward = -0.0000 fps = 8 mse_loss = 4.4208 
2022-07-08 10:30:47.106595 - gail/main.py:174 - [TRPO] iter = 137000 dist_mean = 0.0292 dist_std = 0.6250 vf_loss = 1.1962 grad_norm = 1.1389 nat_grad_norm = 0.4644 cg_residual = 0.0441 step_size = 0.3956 reward = -0.0000 fps = 6 mse_loss = 4.4841 
2022-07-08 10:31:14.973909 - gail/main.py:174 - [TRPO] iter = 138000 dist_mean = 0.0421 dist_std = 0.6266 vf_loss = 1.2255 grad_norm = 0.7413 nat_grad_norm = 0.4014 cg_residual = 0.0937 step_size = 0.4144 reward = 0.0000 fps = 5 mse_loss = 4.5486 
2022-07-08 10:31:49.707958 - gail/main.py:174 - [TRPO] iter = 139000 dist_mean = 0.0196 dist_std = 0.6135 vf_loss = 0.3038 grad_norm = 0.6578 nat_grad_norm = 0.2928 cg_residual = 0.0337 step_size = 0.5317 reward = 0.0000 fps = 4 mse_loss = 4.2980 
