2022-07-08 08:45:11.678324 - utils/flags.py:257 - log_dir = logs/gail_w-Walker2d-v2-300-2022-07-08-08-45-11
2022-07-08 08:46:24.944291 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Walker2d-v2
2022-07-08 08:46:33.264134 - gail/main.py:80 - Expert Reward 5150.674112
2022-07-08 08:46:33.633832 - gail/main.py:84 - Original dataset size 3000
2022-07-08 08:46:33.684116 - gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 08:46:33.684796 - gail/main.py:87 - np random: 864 random : 786
2022-07-08 08:46:33.685912 - gail/main.py:91 - Sampled obs: 0.0531, acs: 0.2269
2022-07-08 08:46:34.750192 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 08:46:41.899895 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 08:46:41.911215 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.2194959e+00  2.4445076e-01 -7.8132987e-02 -2.6673764e-01
   1.8222688e-01 -9.5077172e-02 -3.3649772e-01  5.3370733e-02
   4.1614923e+00  4.1431887e-03  3.8142569e-02 -2.6013174e-03
  -1.0202496e-02  5.6982285e-01  2.9836079e-02 -1.5763690e-01
   1.7689442e-02]] 
 scale:[[0.06687175 0.23681822 0.23042987 0.33821535 0.664349   0.20301929
  0.42807332 0.7138035  0.986894   0.65049744 2.0363257  2.3816926
  3.7250905  6.026913   2.0511289  4.406521   6.1475325 ]]
2022-07-08 08:46:45.400943 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 08:46:45.403211 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(23, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 08:46:45.404176 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 08:46:46.255529 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 08:46:54.787382 - gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 70.4326 lengths = 87 } discounted_episode={ returns = 68.4323 lengths = 86 } 
2022-07-08 08:46:54.788919 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 08:47:05.419812 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 08:47:05.837580 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 08:47:06.486208 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 08:47:06.827526 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 08:47:08.632685 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 08:47:11.530923 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 08:47:11.812306 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 08:47:12.089716 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 08:47:12.580539 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 08:47:13.417502 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 08:47:13.672326 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 08:47:13.985343 - gail/main.py:174 - [TRPO] iter = 1000 dist_mean = 0.0001 dist_std = 1.0000 vf_loss = 0.2010 grad_norm = 0.3681 nat_grad_norm = 0.5166 cg_residual = 0.0000 step_size = 0.3969 reward = -0.0000 fps = 36 mse_loss = 0.4353 
2022-07-08 08:47:21.270018 - gail/main.py:174 - [TRPO] iter = 2000 dist_mean = -0.0136 dist_std = 1.0050 vf_loss = 0.2367 grad_norm = 0.4137 nat_grad_norm = 0.5294 cg_residual = 0.0000 step_size = 0.3510 reward = 0.0000 fps = 28 mse_loss = 0.4500 
2022-07-08 08:47:28.884826 - gail/main.py:174 - [TRPO] iter = 3000 dist_mean = -0.0347 dist_std = 1.0003 vf_loss = 0.2748 grad_norm = 0.4021 nat_grad_norm = 0.5523 cg_residual = 0.0000 step_size = 0.3446 reward = 0.0000 fps = 23 mse_loss = 0.4777 
2022-07-08 08:47:36.133910 - gail/main.py:174 - [TRPO] iter = 4000 dist_mean = -0.0571 dist_std = 0.9992 vf_loss = 0.3172 grad_norm = 0.4847 nat_grad_norm = 0.5268 cg_residual = 0.0000 step_size = 0.3402 reward = -0.0000 fps = 20 mse_loss = 0.5019 
2022-07-08 08:47:43.698355 - gail/main.py:174 - [TRPO] iter = 5000 dist_mean = -0.0731 dist_std = 0.9978 vf_loss = 0.2435 grad_norm = 0.4364 nat_grad_norm = 0.4939 cg_residual = 0.0001 step_size = 0.3658 reward = 0.0000 fps = 17 mse_loss = 0.5351 
2022-07-08 08:47:43.699428 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 08:47:46.131311 - gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.0945 grad_norm = 12.5178 grad_penalty = 1.4682 regularization = 0.0000 true_logits = 0.0199 fake_logits = -0.3538 true_prob = 0.5051 fake_prob = 0.4135 
2022-07-08 08:47:47.565593 - gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = -0.5671 lengths = 14 } discounted_episode={ returns = -0.5516 lengths = 14 } 
2022-07-08 08:47:54.862722 - gail/main.py:174 - [TRPO] iter = 6000 dist_mean = -0.0906 dist_std = 0.9921 vf_loss = 0.2433 grad_norm = 0.4037 nat_grad_norm = 0.5582 cg_residual = 0.0001 step_size = 0.3564 reward = -0.0000 fps = 114 mse_loss = 0.5707 
2022-07-08 08:48:01.880372 - gail/main.py:174 - [TRPO] iter = 7000 dist_mean = -0.0971 dist_std = 0.9881 vf_loss = 0.2158 grad_norm = 0.5261 nat_grad_norm = 0.5300 cg_residual = 0.0001 step_size = 0.3186 reward = -0.0000 fps = 63 mse_loss = 0.6026 
2022-07-08 08:48:08.815376 - gail/main.py:174 - [TRPO] iter = 8000 dist_mean = -0.0925 dist_std = 0.9873 vf_loss = 0.1910 grad_norm = 0.5658 nat_grad_norm = 0.4657 cg_residual = 0.0001 step_size = 0.3512 reward = 0.0000 fps = 44 mse_loss = 0.5898 
2022-07-08 08:48:16.344575 - gail/main.py:174 - [TRPO] iter = 9000 dist_mean = -0.0862 dist_std = 0.9851 vf_loss = 0.1513 grad_norm = 0.5103 nat_grad_norm = 0.5467 cg_residual = 0.0002 step_size = 0.3423 reward = -0.0000 fps = 33 mse_loss = 0.5874 
2022-07-08 08:48:23.793967 - gail/main.py:174 - [TRPO] iter = 10000 dist_mean = -0.0759 dist_std = 0.9834 vf_loss = 0.1626 grad_norm = 0.4182 nat_grad_norm = 0.4988 cg_residual = 0.0002 step_size = 0.3925 reward = 0.0000 fps = 26 mse_loss = 0.5784 
2022-07-08 08:48:24.036108 - gail/main.py:201 - [Discriminator] iter = 10000 loss = -0.0570 grad_norm = 10.2298 grad_penalty = 0.7629 regularization = 0.0000 true_logits = 0.0693 fake_logits = -0.7506 true_prob = 0.5175 fake_prob = 0.3231 
2022-07-08 08:48:26.054973 - gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = -6.1994 lengths = 19 } discounted_episode={ returns = -5.9969 lengths = 19 } 
2022-07-08 08:48:33.291147 - gail/main.py:174 - [TRPO] iter = 11000 dist_mean = -0.0770 dist_std = 0.9791 vf_loss = 0.1842 grad_norm = 0.5616 nat_grad_norm = 0.4952 cg_residual = 0.0003 step_size = 0.3470 reward = 0.0000 fps = 108 mse_loss = 0.5736 
2022-07-08 08:48:40.828262 - gail/main.py:174 - [TRPO] iter = 12000 dist_mean = -0.0512 dist_std = 0.9734 vf_loss = 0.1647 grad_norm = 0.6783 nat_grad_norm = 0.5140 cg_residual = 0.0003 step_size = 0.3139 reward = -0.0000 fps = 59 mse_loss = 0.5450 
2022-07-08 08:48:48.916044 - gail/main.py:174 - [TRPO] iter = 13000 dist_mean = -0.0205 dist_std = 0.9743 vf_loss = 0.2575 grad_norm = 0.5948 nat_grad_norm = 0.4629 cg_residual = 0.0004 step_size = 0.3750 reward = 0.0000 fps = 40 mse_loss = 0.5528 
2022-07-08 08:48:57.349182 - gail/main.py:174 - [TRPO] iter = 14000 dist_mean = 0.0182 dist_std = 0.9704 vf_loss = 0.2109 grad_norm = 0.6776 nat_grad_norm = 0.4841 cg_residual = 0.0005 step_size = 0.3499 reward = -0.0000 fps = 30 mse_loss = 0.5004 
2022-07-08 08:49:05.520645 - gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.0482 dist_std = 0.9685 vf_loss = 0.1603 grad_norm = 0.4470 nat_grad_norm = 0.5387 cg_residual = 0.0008 step_size = 0.4014 reward = 0.0000 fps = 24 mse_loss = 0.5178 
2022-07-08 08:49:05.815970 - gail/main.py:201 - [Discriminator] iter = 15000 loss = -0.7841 grad_norm = 6.8347 grad_penalty = 0.4714 regularization = 0.0000 true_logits = 0.1413 fake_logits = -1.1141 true_prob = 0.5358 fake_prob = 0.2544 
2022-07-08 08:49:12.787979 - gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = -19.3789 lengths = 72 } discounted_episode={ returns = -18.2623 lengths = 72 } 
2022-07-08 08:49:20.203466 - gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.0549 dist_std = 0.9703 vf_loss = 0.1552 grad_norm = 0.5514 nat_grad_norm = 0.5207 cg_residual = 0.0004 step_size = 0.3732 reward = -0.0000 fps = 69 mse_loss = 0.5612 
2022-07-08 08:49:27.421439 - gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.0922 dist_std = 0.9710 vf_loss = 0.1164 grad_norm = 0.4994 nat_grad_norm = 0.4943 cg_residual = 0.0006 step_size = 0.4093 reward = 0.0000 fps = 46 mse_loss = 0.5737 
2022-07-08 08:49:34.925764 - gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.1107 dist_std = 0.9665 vf_loss = 0.1664 grad_norm = 0.4362 nat_grad_norm = 0.4632 cg_residual = 0.0004 step_size = 0.4384 reward = -0.0000 fps = 34 mse_loss = 0.5612 
2022-07-08 08:49:42.451954 - gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.1319 dist_std = 0.9634 vf_loss = 0.0944 grad_norm = 0.5515 nat_grad_norm = 0.6018 cg_residual = 0.0010 step_size = 0.3501 reward = 0.0000 fps = 27 mse_loss = 0.6418 
2022-07-08 08:49:50.200541 - gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.1498 dist_std = 0.9619 vf_loss = 0.1741 grad_norm = 0.5041 nat_grad_norm = 0.4881 cg_residual = 0.0006 step_size = 0.4128 reward = 0.0000 fps = 22 mse_loss = 0.7263 
2022-07-08 08:49:50.403286 - gail/main.py:201 - [Discriminator] iter = 20000 loss = -1.2548 grad_norm = 6.7575 grad_penalty = 0.4616 regularization = 0.0000 true_logits = 0.1910 fake_logits = -1.5253 true_prob = 0.5483 fake_prob = 0.1903 
2022-07-08 08:49:55.479566 - gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = -8.0259 lengths = 55 } discounted_episode={ returns = -6.8165 lengths = 49 } 
2022-07-08 08:50:04.947968 - gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.1712 dist_std = 0.9609 vf_loss = 0.1330 grad_norm = 0.4769 nat_grad_norm = 0.4800 cg_residual = 0.0006 step_size = 0.4453 reward = -0.0000 fps = 68 mse_loss = 0.7436 
2022-07-08 08:50:15.894343 - gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.1970 dist_std = 0.9619 vf_loss = 0.1244 grad_norm = 0.6710 nat_grad_norm = 0.5022 cg_residual = 0.0008 step_size = 0.3608 reward = -0.0000 fps = 39 mse_loss = 0.8306 
2022-07-08 08:50:23.309833 - gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.2170 dist_std = 0.9576 vf_loss = 0.2515 grad_norm = 0.7846 nat_grad_norm = 0.4655 cg_residual = 0.0008 step_size = 0.3362 reward = 0.0000 fps = 30 mse_loss = 0.8819 
2022-07-08 08:50:30.771187 - gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.2446 dist_std = 0.9506 vf_loss = 0.1608 grad_norm = 0.6016 nat_grad_norm = 0.5013 cg_residual = 0.0008 step_size = 0.3591 reward = -0.0000 fps = 24 mse_loss = 1.0401 
2022-07-08 08:50:38.521718 - gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.3028 dist_std = 0.9521 vf_loss = 0.3759 grad_norm = 0.4558 nat_grad_norm = 0.3943 cg_residual = 0.0006 step_size = 0.5044 reward = 0.0000 fps = 20 mse_loss = 0.9699 
2022-07-08 08:50:38.764177 - gail/main.py:201 - [Discriminator] iter = 25000 loss = -1.7051 grad_norm = 6.1630 grad_penalty = 0.3433 regularization = 0.0000 true_logits = 0.1819 fake_logits = -1.8665 true_prob = 0.5469 fake_prob = 0.1477 
2022-07-08 08:50:49.588936 - gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = 28.3291 lengths = 105 } discounted_episode={ returns = 28.2561 lengths = 104 } 
2022-07-08 08:50:57.180246 - gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.3239 dist_std = 0.9516 vf_loss = 0.5443 grad_norm = 0.6160 nat_grad_norm = 0.4184 cg_residual = 0.0005 step_size = 0.4124 reward = 0.0000 fps = 54 mse_loss = 1.0390 
2022-07-08 08:51:04.767854 - gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.4078 dist_std = 0.9513 vf_loss = 0.7579 grad_norm = 0.3325 nat_grad_norm = 0.4940 cg_residual = 0.0038 step_size = 0.4848 reward = 0.0000 fps = 38 mse_loss = 0.9761 
2022-07-08 08:51:12.125436 - gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.3372 dist_std = 0.9504 vf_loss = 0.5919 grad_norm = 0.5256 nat_grad_norm = 0.4937 cg_residual = 0.0009 step_size = 0.4122 reward = -0.0000 fps = 29 mse_loss = 1.1166 
2022-07-08 08:51:19.249217 - gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.3266 dist_std = 0.9441 vf_loss = 0.4702 grad_norm = 0.5705 nat_grad_norm = 0.4617 cg_residual = 0.0007 step_size = 0.4143 reward = -0.0000 fps = 24 mse_loss = 1.1905 
2022-07-08 08:51:26.573365 - gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.5308 dist_std = 0.9373 vf_loss = 0.8212 grad_norm = 0.6709 nat_grad_norm = 0.4318 cg_residual = 0.0014 step_size = 0.4728 reward = -0.0000 fps = 20 mse_loss = 1.2254 
2022-07-08 08:51:26.791365 - gail/main.py:201 - [Discriminator] iter = 30000 loss = -1.8010 grad_norm = 5.8737 grad_penalty = 0.3305 regularization = 0.0000 true_logits = 0.2371 fake_logits = -1.8944 true_prob = 0.5604 fake_prob = 0.1507 
2022-07-08 08:51:40.326207 - gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = 254.7125 lengths = 138 } discounted_episode={ returns = 233.9096 lengths = 138 } 
2022-07-08 08:51:47.147639 - gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.5480 dist_std = 0.9413 vf_loss = 1.0898 grad_norm = 0.5074 nat_grad_norm = 0.4945 cg_residual = 0.0035 step_size = 0.3845 reward = 0.0000 fps = 49 mse_loss = 1.2904 
2022-07-08 08:51:54.569594 - gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.6210 dist_std = 0.9377 vf_loss = 1.0347 grad_norm = 0.4522 nat_grad_norm = 0.3818 cg_residual = 0.0019 step_size = 0.5525 reward = 0.0000 fps = 36 mse_loss = 1.3196 
2022-07-08 08:52:01.799950 - gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.6403 dist_std = 0.9369 vf_loss = 0.9889 grad_norm = 0.5022 nat_grad_norm = 0.4454 cg_residual = 0.0068 step_size = 0.4332 reward = 0.0000 fps = 28 mse_loss = 1.4259 
2022-07-08 08:52:09.282452 - gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.4351 dist_std = 0.9352 vf_loss = 1.3910 grad_norm = 0.4856 nat_grad_norm = 0.4196 cg_residual = 0.0033 step_size = 0.4525 reward = 0.0000 fps = 23 mse_loss = 1.5087 
2022-07-08 08:52:16.345810 - gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.5969 dist_std = 0.9328 vf_loss = 1.6288 grad_norm = 0.3255 nat_grad_norm = 0.4548 cg_residual = 0.0018 step_size = 0.4563 reward = 0.0000 fps = 20 mse_loss = 1.5279 
2022-07-08 08:52:16.573677 - gail/main.py:201 - [Discriminator] iter = 35000 loss = -2.1083 grad_norm = 5.9056 grad_penalty = 0.2593 regularization = 0.0000 true_logits = 0.1977 fake_logits = -2.1699 true_prob = 0.5531 fake_prob = 0.1165 
2022-07-08 08:52:30.394528 - gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 253.2754 lengths = 136 } discounted_episode={ returns = 230.3078 lengths = 134 } 
2022-07-08 08:52:37.663519 - gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.6404 dist_std = 0.9230 vf_loss = 1.5652 grad_norm = 0.3823 nat_grad_norm = 0.4967 cg_residual = 0.0022 step_size = 0.4330 reward = -0.0000 fps = 47 mse_loss = 1.5583 
2022-07-08 08:52:44.874756 - gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.5410 dist_std = 0.9294 vf_loss = 0.8179 grad_norm = 0.3289 nat_grad_norm = 0.4535 cg_residual = 0.0050 step_size = 0.5081 reward = -0.0000 fps = 35 mse_loss = 1.6333 
2022-07-08 08:52:52.200056 - gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.4945 dist_std = 0.9286 vf_loss = 1.4161 grad_norm = 0.3238 nat_grad_norm = 0.4787 cg_residual = 0.0029 step_size = 0.4756 reward = 0.0000 fps = 28 mse_loss = 1.8016 
2022-07-08 08:52:59.314097 - gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.4799 dist_std = 0.9238 vf_loss = 1.4031 grad_norm = 0.4510 nat_grad_norm = 0.5028 cg_residual = 0.0043 step_size = 0.3893 reward = 0.0000 fps = 23 mse_loss = 1.6507 
2022-07-08 08:53:06.481731 - gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.5300 dist_std = 0.9142 vf_loss = 1.1524 grad_norm = 0.3842 nat_grad_norm = 0.4908 cg_residual = 0.0048 step_size = 0.4533 reward = 0.0000 fps = 20 mse_loss = 1.6172 
2022-07-08 08:53:06.710809 - gail/main.py:201 - [Discriminator] iter = 40000 loss = -2.6377 grad_norm = 6.1191 grad_penalty = 0.2952 regularization = 0.0000 true_logits = 0.2303 fake_logits = -2.7026 true_prob = 0.5598 fake_prob = 0.0739 
2022-07-08 08:53:19.829910 - gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 250.4188 lengths = 134 } discounted_episode={ returns = 230.2201 lengths = 133 } 
2022-07-08 08:53:27.602607 - gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.5501 dist_std = 0.9031 vf_loss = 1.0504 grad_norm = 0.3716 nat_grad_norm = 0.4948 cg_residual = 0.0041 step_size = 0.4379 reward = 0.0000 fps = 47 mse_loss = 1.7126 
2022-07-08 08:53:35.280941 - gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.5619 dist_std = 0.9066 vf_loss = 0.9332 grad_norm = 0.3522 nat_grad_norm = 0.3779 cg_residual = 0.0018 step_size = 0.5135 reward = 0.0000 fps = 35 mse_loss = 1.6973 
2022-07-08 08:53:42.672954 - gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.5328 dist_std = 0.9081 vf_loss = 1.3794 grad_norm = 0.4198 nat_grad_norm = 0.4382 cg_residual = 0.0045 step_size = 0.4462 reward = -0.0000 fps = 27 mse_loss = 1.6167 
2022-07-08 08:53:49.986479 - gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.6144 dist_std = 0.9029 vf_loss = 0.6040 grad_norm = 0.3186 nat_grad_norm = 0.4723 cg_residual = 0.0035 step_size = 0.4437 reward = 0.0000 fps = 23 mse_loss = 1.6931 
2022-07-08 08:53:57.180621 - gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.5694 dist_std = 0.8995 vf_loss = 0.7297 grad_norm = 0.5190 nat_grad_norm = 0.5932 cg_residual = 0.0071 step_size = 0.3601 reward = 0.0000 fps = 19 mse_loss = 1.7629 
2022-07-08 08:53:57.441584 - gail/main.py:201 - [Discriminator] iter = 45000 loss = -3.0449 grad_norm = 6.4021 grad_penalty = 0.3321 regularization = 0.0000 true_logits = 0.2484 fake_logits = -3.1287 true_prob = 0.5649 fake_prob = 0.0485 
2022-07-08 08:54:10.369066 - gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 243.1046 lengths = 129 } discounted_episode={ returns = 226.9982 lengths = 130 } 
2022-07-08 08:54:17.746035 - gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.5559 dist_std = 0.8880 vf_loss = 0.7622 grad_norm = 0.3655 nat_grad_norm = 0.4507 cg_residual = 0.0035 step_size = 0.4432 reward = 0.0000 fps = 49 mse_loss = 1.8356 
2022-07-08 08:54:25.298352 - gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.5518 dist_std = 0.8836 vf_loss = 0.7803 grad_norm = 0.4393 nat_grad_norm = 0.5134 cg_residual = 0.0044 step_size = 0.3927 reward = 0.0000 fps = 35 mse_loss = 1.7566 
2022-07-08 08:54:32.577499 - gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.5760 dist_std = 0.8867 vf_loss = 0.5026 grad_norm = 0.4339 nat_grad_norm = 0.5158 cg_residual = 0.0060 step_size = 0.3907 reward = 0.0000 fps = 28 mse_loss = 1.8524 
2022-07-08 08:54:40.012655 - gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.5442 dist_std = 0.8823 vf_loss = 0.4593 grad_norm = 0.4196 nat_grad_norm = 0.4615 cg_residual = 0.0056 step_size = 0.4170 reward = 0.0000 fps = 23 mse_loss = 1.7358 
2022-07-08 08:54:47.187027 - gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.5534 dist_std = 0.8813 vf_loss = 0.5494 grad_norm = 0.4639 nat_grad_norm = 0.4865 cg_residual = 0.0072 step_size = 0.4009 reward = -0.0000 fps = 20 mse_loss = 1.9055 
2022-07-08 08:54:47.452729 - gail/main.py:201 - [Discriminator] iter = 50000 loss = -3.3762 grad_norm = 7.5605 grad_penalty = 0.3834 regularization = 0.0000 true_logits = 0.1957 fake_logits = -3.5640 true_prob = 0.5548 fake_prob = 0.0328 
2022-07-08 08:54:59.216651 - gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 214.2635 lengths = 109 } discounted_episode={ returns = 197.7473 lengths = 107 } 
2022-07-08 08:55:07.901036 - gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.5347 dist_std = 0.8773 vf_loss = 0.5880 grad_norm = 0.4004 nat_grad_norm = 0.4834 cg_residual = 0.0131 step_size = 0.4360 reward = 0.0000 fps = 48 mse_loss = 1.8307 
2022-07-08 08:55:15.628692 - gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.5781 dist_std = 0.8766 vf_loss = 0.3203 grad_norm = 0.4989 nat_grad_norm = 0.5311 cg_residual = 0.0050 step_size = 0.3869 reward = 0.0000 fps = 35 mse_loss = 1.9857 
2022-07-08 08:55:22.953930 - gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.6064 dist_std = 0.8758 vf_loss = 0.1776 grad_norm = 0.6175 nat_grad_norm = 0.4202 cg_residual = 0.0046 step_size = 0.4468 reward = -0.0000 fps = 28 mse_loss = 1.9704 
2022-07-08 08:55:29.911307 - gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.5639 dist_std = 0.8794 vf_loss = 0.2977 grad_norm = 0.4808 nat_grad_norm = 0.4494 cg_residual = 0.0053 step_size = 0.4360 reward = 0.0000 fps = 23 mse_loss = 1.9946 
2022-07-08 08:55:37.225790 - gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.5606 dist_std = 0.8761 vf_loss = 0.2280 grad_norm = 0.5505 nat_grad_norm = 0.4431 cg_residual = 0.0064 step_size = 0.4339 reward = 0.0000 fps = 20 mse_loss = 2.0029 
2022-07-08 08:55:37.478588 - gail/main.py:201 - [Discriminator] iter = 55000 loss = -3.5174 grad_norm = 6.2295 grad_penalty = 0.4267 regularization = 0.0000 true_logits = 0.1773 fake_logits = -3.7668 true_prob = 0.5570 fake_prob = 0.0257 
2022-07-08 08:55:46.649734 - gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 189.1634 lengths = 95 } discounted_episode={ returns = 180.5252 lengths = 96 } 
2022-07-08 08:55:53.933814 - gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.5516 dist_std = 0.8751 vf_loss = 0.3763 grad_norm = 0.4721 nat_grad_norm = 0.4363 cg_residual = 0.0056 step_size = 0.4483 reward = 0.0000 fps = 60 mse_loss = 2.2809 
2022-07-08 08:56:01.136669 - gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.5161 dist_std = 0.8778 vf_loss = 0.3892 grad_norm = 0.4546 nat_grad_norm = 0.4558 cg_residual = 0.0099 step_size = 0.4028 reward = -0.0000 fps = 42 mse_loss = 2.2288 
2022-07-08 08:56:08.274911 - gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.5011 dist_std = 0.8746 vf_loss = 0.6423 grad_norm = 0.4399 nat_grad_norm = 0.4828 cg_residual = 0.0052 step_size = 0.4073 reward = -0.0000 fps = 32 mse_loss = 2.1972 
2022-07-08 08:56:15.271385 - gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.5294 dist_std = 0.8745 vf_loss = 0.4081 grad_norm = 0.5146 nat_grad_norm = 0.5840 cg_residual = 0.0175 step_size = 0.3786 reward = 0.0000 fps = 26 mse_loss = 1.9832 
2022-07-08 08:56:22.322409 - gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.5209 dist_std = 0.8710 vf_loss = 0.2710 grad_norm = 0.5567 nat_grad_norm = 0.4683 cg_residual = 0.0070 step_size = 0.3987 reward = 0.0000 fps = 22 mse_loss = 2.1380 
2022-07-08 08:56:22.558873 - gail/main.py:201 - [Discriminator] iter = 60000 loss = -3.6183 grad_norm = 4.4114 grad_penalty = 0.4245 regularization = 0.0000 true_logits = 0.1736 fake_logits = -3.8692 true_prob = 0.5523 fake_prob = 0.0240 
2022-07-08 08:56:32.095453 - gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 186.4059 lengths = 95 } discounted_episode={ returns = 177.9951 lengths = 95 } 
2022-07-08 08:56:39.717074 - gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.4991 dist_std = 0.8672 vf_loss = 0.3182 grad_norm = 0.5930 nat_grad_norm = 0.5445 cg_residual = 0.0169 step_size = 0.3575 reward = -0.0000 fps = 58 mse_loss = 2.2574 
2022-07-08 08:56:46.982952 - gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.4997 dist_std = 0.8642 vf_loss = 0.3056 grad_norm = 0.6281 nat_grad_norm = 0.4128 cg_residual = 0.0071 step_size = 0.4062 reward = -0.0000 fps = 40 mse_loss = 2.2662 
2022-07-08 08:56:54.370664 - gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.4993 dist_std = 0.8655 vf_loss = 0.3041 grad_norm = 0.3921 nat_grad_norm = 0.5189 cg_residual = 0.0107 step_size = 0.4171 reward = 0.0000 fps = 31 mse_loss = 2.2965 
2022-07-08 08:57:01.678889 - gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.4660 dist_std = 0.8646 vf_loss = 0.4630 grad_norm = 0.6048 nat_grad_norm = 0.4817 cg_residual = 0.0097 step_size = 0.3946 reward = -0.0000 fps = 25 mse_loss = 2.3835 
2022-07-08 08:57:08.966797 - gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.4608 dist_std = 0.8624 vf_loss = 0.2944 grad_norm = 0.5998 nat_grad_norm = 0.5032 cg_residual = 0.0147 step_size = 0.3900 reward = -0.0000 fps = 21 mse_loss = 2.5106 
2022-07-08 08:57:09.175076 - gail/main.py:201 - [Discriminator] iter = 65000 loss = -3.7844 grad_norm = 5.3798 grad_penalty = 0.4376 regularization = 0.0000 true_logits = 0.2135 fake_logits = -4.0086 true_prob = 0.5638 fake_prob = 0.0202 
2022-07-08 08:57:16.354407 - gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 141.8145 lengths = 75 } discounted_episode={ returns = 138.4724 lengths = 76 } 
2022-07-08 08:57:23.640950 - gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.4513 dist_std = 0.8625 vf_loss = 0.2475 grad_norm = 0.5307 nat_grad_norm = 0.5368 cg_residual = 0.0161 step_size = 0.3795 reward = -0.0000 fps = 69 mse_loss = 2.6168 
2022-07-08 08:57:30.757176 - gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.4581 dist_std = 0.8634 vf_loss = 0.2635 grad_norm = 0.6299 nat_grad_norm = 0.5561 cg_residual = 0.0142 step_size = 0.3597 reward = 0.0000 fps = 46 mse_loss = 2.4911 
2022-07-08 08:57:37.943266 - gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.4496 dist_std = 0.8630 vf_loss = 0.3004 grad_norm = 0.5716 nat_grad_norm = 0.5711 cg_residual = 0.0182 step_size = 0.3833 reward = 0.0000 fps = 34 mse_loss = 2.6944 
2022-07-08 08:57:44.994200 - gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.4067 dist_std = 0.8636 vf_loss = 0.3055 grad_norm = 0.5505 nat_grad_norm = 0.5253 cg_residual = 0.0134 step_size = 0.3984 reward = -0.0000 fps = 27 mse_loss = 2.8342 
2022-07-08 08:57:51.956017 - gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.4242 dist_std = 0.8574 vf_loss = 0.1783 grad_norm = 0.6409 nat_grad_norm = 0.6867 cg_residual = 0.0231 step_size = 0.2938 reward = 0.0000 fps = 23 mse_loss = 2.8935 
2022-07-08 08:57:52.158592 - gail/main.py:201 - [Discriminator] iter = 70000 loss = -3.8944 grad_norm = 5.8287 grad_penalty = 0.4184 regularization = 0.0000 true_logits = 0.1967 fake_logits = -4.1161 true_prob = 0.5581 fake_prob = 0.0181 
2022-07-08 08:57:58.465867 - gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 123.7740 lengths = 67 } discounted_episode={ returns = 119.1177 lengths = 67 } 
2022-07-08 08:58:05.589168 - gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.4051 dist_std = 0.8578 vf_loss = 0.3408 grad_norm = 0.5553 nat_grad_norm = 0.6601 cg_residual = 0.0083 step_size = 0.3629 reward = -0.0000 fps = 74 mse_loss = 2.9463 
2022-07-08 08:58:12.480320 - gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.3953 dist_std = 0.8628 vf_loss = 0.3040 grad_norm = 0.4352 nat_grad_norm = 0.6024 cg_residual = 0.0167 step_size = 0.3812 reward = 0.0000 fps = 49 mse_loss = 2.9702 
2022-07-08 08:58:19.552173 - gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.4461 dist_std = 0.8647 vf_loss = 0.2882 grad_norm = 0.6088 nat_grad_norm = 0.6544 cg_residual = 0.0185 step_size = 0.3480 reward = 0.0000 fps = 36 mse_loss = 2.6759 
2022-07-08 08:58:26.958531 - gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.4195 dist_std = 0.8656 vf_loss = 0.2562 grad_norm = 0.5627 nat_grad_norm = 0.6314 cg_residual = 0.0269 step_size = 0.3383 reward = 0.0000 fps = 28 mse_loss = 2.7704 
2022-07-08 08:58:34.150032 - gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.4187 dist_std = 0.8649 vf_loss = 0.2774 grad_norm = 0.4309 nat_grad_norm = 0.6733 cg_residual = 0.0184 step_size = 0.3755 reward = 0.0000 fps = 23 mse_loss = 2.8410 
2022-07-08 08:58:34.390965 - gail/main.py:201 - [Discriminator] iter = 75000 loss = -3.9919 grad_norm = 3.7920 grad_penalty = 0.3829 regularization = 0.0000 true_logits = 0.1629 fake_logits = -4.2118 true_prob = 0.5498 fake_prob = 0.0173 
2022-07-08 08:58:41.216584 - gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 136.8061 lengths = 72 } discounted_episode={ returns = 135.3354 lengths = 74 } 
2022-07-08 08:58:48.231865 - gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.3823 dist_std = 0.8675 vf_loss = 0.3474 grad_norm = 0.4586 nat_grad_norm = 0.5148 cg_residual = 0.0130 step_size = 0.4147 reward = 0.0000 fps = 72 mse_loss = 2.7629 
2022-07-08 08:58:55.321614 - gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.3996 dist_std = 0.8676 vf_loss = 0.3020 grad_norm = 0.6971 nat_grad_norm = 0.7249 cg_residual = 0.0170 step_size = 0.3138 reward = -0.0000 fps = 47 mse_loss = 2.7879 
2022-07-08 08:59:02.146386 - gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.3885 dist_std = 0.8654 vf_loss = 0.3387 grad_norm = 0.5437 nat_grad_norm = 0.5695 cg_residual = 0.0152 step_size = 0.3784 reward = -0.0000 fps = 36 mse_loss = 2.5379 
2022-07-08 08:59:09.466971 - gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.3959 dist_std = 0.8639 vf_loss = 0.3204 grad_norm = 0.6549 nat_grad_norm = 0.5985 cg_residual = 0.0195 step_size = 0.3496 reward = -0.0000 fps = 28 mse_loss = 2.6074 
2022-07-08 08:59:16.778315 - gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.3778 dist_std = 0.8605 vf_loss = 0.3614 grad_norm = 0.5861 nat_grad_norm = 0.6286 cg_residual = 0.0210 step_size = 0.3452 reward = 0.0000 fps = 23 mse_loss = 2.6136 
2022-07-08 08:59:17.015200 - gail/main.py:201 - [Discriminator] iter = 80000 loss = -4.0601 grad_norm = 3.4636 grad_penalty = 0.4341 regularization = 0.0000 true_logits = 0.1737 fake_logits = -4.3205 true_prob = 0.5527 fake_prob = 0.0155 
2022-07-08 08:59:24.612539 - gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 165.0998 lengths = 82 } discounted_episode={ returns = 153.8501 lengths = 81 } 
2022-07-08 08:59:31.897812 - gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.3943 dist_std = 0.8616 vf_loss = 0.3204 grad_norm = 0.5836 nat_grad_norm = 0.5104 cg_residual = 0.0143 step_size = 0.3796 reward = -0.0000 fps = 67 mse_loss = 2.8213 
2022-07-08 08:59:39.498681 - gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.3649 dist_std = 0.8602 vf_loss = 0.2410 grad_norm = 0.5690 nat_grad_norm = 0.5801 cg_residual = 0.0206 step_size = 0.3519 reward = 0.0000 fps = 44 mse_loss = 2.6465 
2022-07-08 08:59:46.881416 - gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.3682 dist_std = 0.8570 vf_loss = 0.2366 grad_norm = 0.4920 nat_grad_norm = 0.5763 cg_residual = 0.0172 step_size = 0.3676 reward = -0.0000 fps = 33 mse_loss = 3.0122 
2022-07-08 08:59:54.047255 - gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.3536 dist_std = 0.8544 vf_loss = 0.3800 grad_norm = 0.5665 nat_grad_norm = 0.6331 cg_residual = 0.0207 step_size = 0.3610 reward = -0.0000 fps = 27 mse_loss = 2.6551 
2022-07-08 09:00:01.730158 - gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.3861 dist_std = 0.8550 vf_loss = 0.2803 grad_norm = 0.6356 nat_grad_norm = 0.6278 cg_residual = 0.0243 step_size = 0.3327 reward = -0.0000 fps = 22 mse_loss = 2.5486 
2022-07-08 09:00:01.996855 - gail/main.py:201 - [Discriminator] iter = 85000 loss = -4.0153 grad_norm = 3.6276 grad_penalty = 0.3792 regularization = 0.0000 true_logits = 0.0864 fake_logits = -4.3081 true_prob = 0.5398 fake_prob = 0.0159 
2022-07-08 09:00:11.493091 - gail/main.py:142 - [Evaluate] iter = 85000 episode={ returns = 171.0220 lengths = 84 } discounted_episode={ returns = 161.7468 lengths = 83 } 
2022-07-08 09:00:19.607497 - gail/main.py:174 - [TRPO] iter = 86000 dist_mean = 0.3957 dist_std = 0.8504 vf_loss = 0.4676 grad_norm = 0.4496 nat_grad_norm = 0.6331 cg_residual = 0.0156 step_size = 0.3888 reward = -0.0000 fps = 56 mse_loss = 2.5307 
2022-07-08 09:00:27.200109 - gail/main.py:174 - [TRPO] iter = 87000 dist_mean = 0.3721 dist_std = 0.8471 vf_loss = 0.4274 grad_norm = 0.6691 nat_grad_norm = 0.5247 cg_residual = 0.0202 step_size = 0.3745 reward = 0.0000 fps = 39 mse_loss = 2.6618 
2022-07-08 09:00:39.486270 - gail/main.py:174 - [TRPO] iter = 88000 dist_mean = 0.3682 dist_std = 0.8450 vf_loss = 0.2797 grad_norm = 0.6061 nat_grad_norm = 0.5385 cg_residual = 0.0261 step_size = 0.3800 reward = -0.0000 fps = 26 mse_loss = 3.0665 
2022-07-08 09:00:46.695112 - gail/main.py:174 - [TRPO] iter = 89000 dist_mean = 0.3651 dist_std = 0.8443 vf_loss = 0.3348 grad_norm = 0.5241 nat_grad_norm = 0.5050 cg_residual = 0.0195 step_size = 0.4318 reward = 0.0000 fps = 22 mse_loss = 3.1133 
2022-07-08 09:00:53.881253 - gail/main.py:174 - [TRPO] iter = 90000 dist_mean = 0.3631 dist_std = 0.8404 vf_loss = 0.3198 grad_norm = 0.5399 nat_grad_norm = 0.5427 cg_residual = 0.0204 step_size = 0.3867 reward = -0.0000 fps = 19 mse_loss = 2.8650 
2022-07-08 09:00:54.110999 - gail/main.py:201 - [Discriminator] iter = 90000 loss = -4.1728 grad_norm = 3.6897 grad_penalty = 0.3930 regularization = 0.0000 true_logits = 0.0721 fake_logits = -4.4937 true_prob = 0.5366 fake_prob = 0.0133 
2022-07-08 09:01:02.096360 - gail/main.py:142 - [Evaluate] iter = 90000 episode={ returns = 175.8957 lengths = 85 } discounted_episode={ returns = 165.2300 lengths = 84 } 
2022-07-08 09:01:09.816402 - gail/main.py:174 - [TRPO] iter = 91000 dist_mean = 0.3674 dist_std = 0.8416 vf_loss = 0.3754 grad_norm = 0.5339 nat_grad_norm = 0.5424 cg_residual = 0.0122 step_size = 0.3652 reward = 0.0000 fps = 63 mse_loss = 2.8435 
2022-07-08 09:01:17.417983 - gail/main.py:174 - [TRPO] iter = 92000 dist_mean = 0.3613 dist_std = 0.8354 vf_loss = 0.3730 grad_norm = 0.4825 nat_grad_norm = 0.5527 cg_residual = 0.0261 step_size = 0.3782 reward = 0.0000 fps = 42 mse_loss = 3.1695 
2022-07-08 09:01:24.301387 - gail/main.py:174 - [TRPO] iter = 93000 dist_mean = 0.3627 dist_std = 0.8358 vf_loss = 0.2190 grad_norm = 0.4718 nat_grad_norm = 0.6300 cg_residual = 0.0193 step_size = 0.3581 reward = -0.0000 fps = 33 mse_loss = 3.2938 
2022-07-08 09:01:31.442120 - gail/main.py:174 - [TRPO] iter = 94000 dist_mean = 0.3697 dist_std = 0.8340 vf_loss = 0.3431 grad_norm = 0.5761 nat_grad_norm = 0.6295 cg_residual = 0.0173 step_size = 0.3514 reward = -0.0000 fps = 26 mse_loss = 3.5817 
2022-07-08 09:01:38.296130 - gail/main.py:174 - [TRPO] iter = 95000 dist_mean = 0.3507 dist_std = 0.8327 vf_loss = 0.3317 grad_norm = 0.5692 nat_grad_norm = 0.5461 cg_residual = 0.0101 step_size = 0.3892 reward = -0.0000 fps = 22 mse_loss = 3.4560 
2022-07-08 09:01:38.528291 - gail/main.py:201 - [Discriminator] iter = 95000 loss = -4.1630 grad_norm = 3.3876 grad_penalty = 0.4383 regularization = 0.0000 true_logits = 0.0837 fake_logits = -4.5175 true_prob = 0.5405 fake_prob = 0.0129 
2022-07-08 09:01:46.230645 - gail/main.py:142 - [Evaluate] iter = 95000 episode={ returns = 163.7360 lengths = 82 } discounted_episode={ returns = 153.3929 lengths = 81 } 
2022-07-08 09:01:53.111117 - gail/main.py:174 - [TRPO] iter = 96000 dist_mean = 0.3828 dist_std = 0.8345 vf_loss = 0.2852 grad_norm = 0.5771 nat_grad_norm = 0.5837 cg_residual = 0.0258 step_size = 0.3515 reward = -0.0000 fps = 68 mse_loss = 3.4387 
2022-07-08 09:02:00.259117 - gail/main.py:174 - [TRPO] iter = 97000 dist_mean = 0.3885 dist_std = 0.8365 vf_loss = 0.2468 grad_norm = 0.5762 nat_grad_norm = 0.5267 cg_residual = 0.0186 step_size = 0.3594 reward = -0.0000 fps = 46 mse_loss = 3.2878 
2022-07-08 09:02:07.312357 - gail/main.py:174 - [TRPO] iter = 98000 dist_mean = 0.3666 dist_std = 0.8332 vf_loss = 0.1999 grad_norm = 0.6019 nat_grad_norm = 0.6281 cg_residual = 0.0310 step_size = 0.3549 reward = 0.0000 fps = 34 mse_loss = 3.1300 
2022-07-08 09:02:14.260027 - gail/main.py:174 - [TRPO] iter = 99000 dist_mean = 0.3836 dist_std = 0.8313 vf_loss = 0.2585 grad_norm = 0.5014 nat_grad_norm = 0.6031 cg_residual = 0.0279 step_size = 0.3597 reward = 0.0000 fps = 27 mse_loss = 3.1972 
2022-07-08 09:02:21.389416 - gail/main.py:174 - [TRPO] iter = 100000 dist_mean = 0.3851 dist_std = 0.8291 vf_loss = 0.2069 grad_norm = 0.4602 nat_grad_norm = 0.5958 cg_residual = 0.0262 step_size = 0.3783 reward = 0.0000 fps = 23 mse_loss = 3.1580 
2022-07-08 09:02:21.629577 - gail/main.py:201 - [Discriminator] iter = 100000 loss = -4.2180 grad_norm = 3.4774 grad_penalty = 0.4027 regularization = 0.0000 true_logits = 0.0412 fake_logits = -4.5795 true_prob = 0.5310 fake_prob = 0.0123 
2022-07-08 09:02:30.879958 - gail/main.py:142 - [Evaluate] iter = 100000 episode={ returns = 203.7957 lengths = 98 } discounted_episode={ returns = 193.5462 lengths = 99 } 
2022-07-08 09:02:38.319605 - gail/main.py:174 - [TRPO] iter = 101000 dist_mean = 0.3897 dist_std = 0.8274 vf_loss = 0.2235 grad_norm = 0.6096 nat_grad_norm = 0.5604 cg_residual = 0.0157 step_size = 0.3707 reward = -0.0000 fps = 59 mse_loss = 3.0515 
2022-07-08 09:02:45.655742 - gail/main.py:174 - [TRPO] iter = 102000 dist_mean = 0.3697 dist_std = 0.8242 vf_loss = 0.2162 grad_norm = 0.6242 nat_grad_norm = 0.5187 cg_residual = 0.0200 step_size = 0.3563 reward = 0.0000 fps = 41 mse_loss = 3.0187 
2022-07-08 09:02:53.296917 - gail/main.py:174 - [TRPO] iter = 103000 dist_mean = 0.3866 dist_std = 0.8247 vf_loss = 0.3550 grad_norm = 0.6392 nat_grad_norm = 0.6393 cg_residual = 0.0253 step_size = 0.3266 reward = 0.0000 fps = 31 mse_loss = 3.0201 
2022-07-08 09:03:00.821785 - gail/main.py:174 - [TRPO] iter = 104000 dist_mean = 0.3824 dist_std = 0.8203 vf_loss = 0.2669 grad_norm = 0.5069 nat_grad_norm = 0.5231 cg_residual = 0.0185 step_size = 0.3995 reward = 0.0000 fps = 25 mse_loss = 2.8890 
2022-07-08 09:03:08.404501 - gail/main.py:174 - [TRPO] iter = 105000 dist_mean = 0.3749 dist_std = 0.8186 vf_loss = 0.2051 grad_norm = 0.6377 nat_grad_norm = 0.4761 cg_residual = 0.0184 step_size = 0.3803 reward = -0.0000 fps = 21 mse_loss = 2.7526 
2022-07-08 09:03:08.677743 - gail/main.py:201 - [Discriminator] iter = 105000 loss = -4.2203 grad_norm = 3.0321 grad_penalty = 0.4167 regularization = 0.0000 true_logits = 0.0536 fake_logits = -4.5834 true_prob = 0.5284 fake_prob = 0.0119 
2022-07-08 09:03:18.839630 - gail/main.py:142 - [Evaluate] iter = 105000 episode={ returns = 217.5452 lengths = 104 } discounted_episode={ returns = 207.8049 lengths = 106 } 
2022-07-08 09:03:26.196612 - gail/main.py:174 - [TRPO] iter = 106000 dist_mean = 0.3839 dist_std = 0.8153 vf_loss = 0.1963 grad_norm = 0.6097 nat_grad_norm = 0.5466 cg_residual = 0.0162 step_size = 0.3576 reward = 0.0000 fps = 57 mse_loss = 3.0136 
2022-07-08 09:03:33.993445 - gail/main.py:174 - [TRPO] iter = 107000 dist_mean = 0.3762 dist_std = 0.8112 vf_loss = 0.2606 grad_norm = 0.5647 nat_grad_norm = 0.4821 cg_residual = 0.0154 step_size = 0.3664 reward = 0.0000 fps = 39 mse_loss = 3.0520 
2022-07-08 09:03:41.404596 - gail/main.py:174 - [TRPO] iter = 108000 dist_mean = 0.3723 dist_std = 0.8070 vf_loss = 0.1971 grad_norm = 0.6167 nat_grad_norm = 0.5104 cg_residual = 0.0270 step_size = 0.3639 reward = -0.0000 fps = 30 mse_loss = 2.8441 
2022-07-08 09:03:48.820929 - gail/main.py:174 - [TRPO] iter = 109000 dist_mean = 0.3832 dist_std = 0.8076 vf_loss = 0.2157 grad_norm = 0.6007 nat_grad_norm = 0.4751 cg_residual = 0.0171 step_size = 0.3884 reward = 0.0000 fps = 24 mse_loss = 2.6979 
2022-07-08 09:03:56.443941 - gail/main.py:174 - [TRPO] iter = 110000 dist_mean = 0.3747 dist_std = 0.8044 vf_loss = 0.1642 grad_norm = 0.5643 nat_grad_norm = 0.4738 cg_residual = 0.0225 step_size = 0.3923 reward = 0.0000 fps = 20 mse_loss = 2.7511 
2022-07-08 09:03:56.681090 - gail/main.py:201 - [Discriminator] iter = 110000 loss = -4.2562 grad_norm = 3.0385 grad_penalty = 0.4175 regularization = 0.0000 true_logits = 0.1123 fake_logits = -4.5614 true_prob = 0.5420 fake_prob = 0.0124 
2022-07-08 09:04:06.479321 - gail/main.py:142 - [Evaluate] iter = 110000 episode={ returns = 213.4301 lengths = 101 } discounted_episode={ returns = 203.5067 lengths = 103 } 
2022-07-08 09:04:14.166693 - gail/main.py:174 - [TRPO] iter = 111000 dist_mean = 0.3971 dist_std = 0.7994 vf_loss = 0.2384 grad_norm = 0.5755 nat_grad_norm = 0.5060 cg_residual = 0.0313 step_size = 0.3602 reward = 0.0000 fps = 57 mse_loss = 2.9280 
2022-07-08 09:04:24.421187 - gail/main.py:174 - [TRPO] iter = 112000 dist_mean = 0.4060 dist_std = 0.8010 vf_loss = 0.2287 grad_norm = 0.5319 nat_grad_norm = 0.5322 cg_residual = 0.0267 step_size = 0.3897 reward = 0.0000 fps = 36 mse_loss = 2.9872 
2022-07-08 09:04:37.705152 - gail/main.py:174 - [TRPO] iter = 113000 dist_mean = 0.3932 dist_std = 0.7951 vf_loss = 0.1682 grad_norm = 0.3902 nat_grad_norm = 0.4213 cg_residual = 0.0153 step_size = 0.4647 reward = 0.0000 fps = 24 mse_loss = 3.0019 
2022-07-08 09:04:51.341582 - gail/main.py:174 - [TRPO] iter = 114000 dist_mean = 0.3878 dist_std = 0.7922 vf_loss = 0.1897 grad_norm = 0.5890 nat_grad_norm = 0.5406 cg_residual = 0.0342 step_size = 0.3726 reward = -0.0000 fps = 18 mse_loss = 3.0248 
2022-07-08 09:05:06.565699 - gail/main.py:174 - [TRPO] iter = 115000 dist_mean = 0.3856 dist_std = 0.7894 vf_loss = 0.2516 grad_norm = 0.6271 nat_grad_norm = 0.5653 cg_residual = 0.0362 step_size = 0.3659 reward = 0.0000 fps = 14 mse_loss = 3.1340 
2022-07-08 09:05:07.111798 - gail/main.py:201 - [Discriminator] iter = 115000 loss = -4.2242 grad_norm = 2.6463 grad_penalty = 0.4013 regularization = 0.0000 true_logits = 0.1034 fake_logits = -4.5222 true_prob = 0.5453 fake_prob = 0.0130 
2022-07-08 09:05:35.600467 - gail/main.py:142 - [Evaluate] iter = 115000 episode={ returns = 237.6382 lengths = 112 } discounted_episode={ returns = 223.7269 lengths = 113 } 
2022-07-08 09:05:53.280256 - gail/main.py:174 - [TRPO] iter = 116000 dist_mean = 0.3947 dist_std = 0.7897 vf_loss = 0.2501 grad_norm = 0.5286 nat_grad_norm = 0.4760 cg_residual = 0.0205 step_size = 0.3844 reward = -0.0000 fps = 21 mse_loss = 3.1660 
2022-07-08 09:06:09.690822 - gail/main.py:174 - [TRPO] iter = 117000 dist_mean = 0.3863 dist_std = 0.7834 vf_loss = 0.1981 grad_norm = 0.5628 nat_grad_norm = 0.5122 cg_residual = 0.0313 step_size = 0.3844 reward = 0.0000 fps = 15 mse_loss = 3.1780 
2022-07-08 09:06:25.654742 - gail/main.py:174 - [TRPO] iter = 118000 dist_mean = 0.3844 dist_std = 0.7821 vf_loss = 0.2198 grad_norm = 0.6464 nat_grad_norm = 0.4857 cg_residual = 0.0214 step_size = 0.4081 reward = 0.0000 fps = 12 mse_loss = 3.0939 
2022-07-08 09:06:44.136709 - gail/main.py:174 - [TRPO] iter = 119000 dist_mean = 0.3975 dist_std = 0.7772 vf_loss = 0.2008 grad_norm = 0.6614 nat_grad_norm = 0.4507 cg_residual = 0.0285 step_size = 0.3635 reward = -0.0000 fps = 10 mse_loss = 3.1450 
2022-07-08 09:07:01.366982 - gail/main.py:174 - [TRPO] iter = 120000 dist_mean = 0.3874 dist_std = 0.7757 vf_loss = 0.2024 grad_norm = 0.5508 nat_grad_norm = 0.5169 cg_residual = 0.0199 step_size = 0.3902 reward = -0.0000 fps = 8 mse_loss = 3.2894 
2022-07-08 09:07:01.911607 - gail/main.py:201 - [Discriminator] iter = 120000 loss = -4.2696 grad_norm = 3.4501 grad_penalty = 0.4135 regularization = 0.0000 true_logits = 0.1453 fake_logits = -4.5378 true_prob = 0.5500 fake_prob = 0.0125 
2022-07-08 09:07:26.757975 - gail/main.py:142 - [Evaluate] iter = 120000 episode={ returns = 231.4398 lengths = 109 } discounted_episode={ returns = 220.2825 lengths = 110 } 
2022-07-08 09:07:43.818238 - gail/main.py:174 - [TRPO] iter = 121000 dist_mean = 0.4101 dist_std = 0.7753 vf_loss = 0.2555 grad_norm = 0.6486 nat_grad_norm = 0.4826 cg_residual = 0.0174 step_size = 0.3756 reward = -0.0000 fps = 23 mse_loss = 3.0848 
2022-07-08 09:08:01.631583 - gail/main.py:174 - [TRPO] iter = 122000 dist_mean = 0.4107 dist_std = 0.7696 vf_loss = 0.2040 grad_norm = 0.6191 nat_grad_norm = 0.4967 cg_residual = 0.0288 step_size = 0.3769 reward = 0.0000 fps = 16 mse_loss = 3.3645 
2022-07-08 09:08:19.805609 - gail/main.py:174 - [TRPO] iter = 123000 dist_mean = 0.4114 dist_std = 0.7667 vf_loss = 0.2871 grad_norm = 0.5715 nat_grad_norm = 0.5005 cg_residual = 0.0216 step_size = 0.3608 reward = -0.0000 fps = 12 mse_loss = 3.2863 
2022-07-08 09:08:37.333128 - gail/main.py:174 - [TRPO] iter = 124000 dist_mean = 0.3958 dist_std = 0.7641 vf_loss = 0.1801 grad_norm = 0.6470 nat_grad_norm = 0.4740 cg_residual = 0.0248 step_size = 0.4050 reward = -0.0000 fps = 10 mse_loss = 3.3426 
2022-07-08 09:08:54.337619 - gail/main.py:174 - [TRPO] iter = 125000 dist_mean = 0.3935 dist_std = 0.7576 vf_loss = 0.2563 grad_norm = 0.6306 nat_grad_norm = 0.4622 cg_residual = 0.0326 step_size = 0.3658 reward = -0.0000 fps = 8 mse_loss = 3.5860 
2022-07-08 09:08:54.978246 - gail/main.py:201 - [Discriminator] iter = 125000 loss = -4.1877 grad_norm = 2.9040 grad_penalty = 0.3872 regularization = 0.0000 true_logits = 0.1209 fake_logits = -4.4540 true_prob = 0.5433 fake_prob = 0.0138 
2022-07-08 09:09:30.862833 - gail/main.py:142 - [Evaluate] iter = 125000 episode={ returns = 241.8627 lengths = 113 } discounted_episode={ returns = 225.9562 lengths = 113 } 
2022-07-08 09:09:53.271982 - gail/main.py:174 - [TRPO] iter = 126000 dist_mean = 0.3932 dist_std = 0.7566 vf_loss = 0.2366 grad_norm = 0.5980 nat_grad_norm = 0.4798 cg_residual = 0.0258 step_size = 0.4076 reward = -0.0000 fps = 17 mse_loss = 3.5301 
2022-07-08 09:10:18.129192 - gail/main.py:174 - [TRPO] iter = 127000 dist_mean = 0.3850 dist_std = 0.7566 vf_loss = 0.2691 grad_norm = 0.4998 nat_grad_norm = 0.4630 cg_residual = 0.0267 step_size = 0.3797 reward = -0.0000 fps = 12 mse_loss = 3.2707 
2022-07-08 09:10:46.353235 - gail/main.py:174 - [TRPO] iter = 128000 dist_mean = 0.3885 dist_std = 0.7558 vf_loss = 0.2319 grad_norm = 0.7492 nat_grad_norm = 0.4310 cg_residual = 0.0259 step_size = 0.3991 reward = -0.0000 fps = 8 mse_loss = 3.4096 
2022-07-08 09:11:20.631904 - gail/main.py:174 - [TRPO] iter = 129000 dist_mean = 0.3960 dist_std = 0.7509 vf_loss = 0.2192 grad_norm = 0.6852 nat_grad_norm = 0.4717 cg_residual = 0.0213 step_size = 0.3877 reward = -0.0000 fps = 6 mse_loss = 3.1741 
2022-07-08 09:11:48.459086 - gail/main.py:174 - [TRPO] iter = 130000 dist_mean = 0.4065 dist_std = 0.7517 vf_loss = 0.4089 grad_norm = 0.4807 nat_grad_norm = 0.5813 cg_residual = 0.0590 step_size = 0.4073 reward = -0.0000 fps = 5 mse_loss = 3.5435 
2022-07-08 09:11:49.231274 - gail/main.py:201 - [Discriminator] iter = 130000 loss = -4.1987 grad_norm = 3.5065 grad_penalty = 0.3920 regularization = 0.0000 true_logits = 0.1274 fake_logits = -4.4634 true_prob = 0.5482 fake_prob = 0.0142 
2022-07-08 09:12:35.628643 - gail/main.py:142 - [Evaluate] iter = 130000 episode={ returns = 254.1378 lengths = 116 } discounted_episode={ returns = 226.3574 lengths = 110 } 
2022-07-08 09:13:06.880198 - gail/main.py:174 - [TRPO] iter = 131000 dist_mean = 0.4024 dist_std = 0.7503 vf_loss = 0.3485 grad_norm = 0.5962 nat_grad_norm = 0.4686 cg_residual = 0.0503 step_size = 0.4011 reward = 0.0000 fps = 12 mse_loss = 3.3403 
2022-07-08 09:13:37.532445 - gail/main.py:174 - [TRPO] iter = 132000 dist_mean = 0.3855 dist_std = 0.7480 vf_loss = 0.2211 grad_norm = 0.7497 nat_grad_norm = 0.5594 cg_residual = 0.0569 step_size = 0.3417 reward = -0.0000 fps = 9 mse_loss = 3.6713 
2022-07-08 09:14:05.569858 - gail/main.py:174 - [TRPO] iter = 133000 dist_mean = 0.3869 dist_std = 0.7459 vf_loss = 0.2190 grad_norm = 0.7524 nat_grad_norm = 0.4758 cg_residual = 0.0647 step_size = 0.3865 reward = 0.0000 fps = 7 mse_loss = 3.5379 
2022-07-08 09:14:35.253743 - gail/main.py:174 - [TRPO] iter = 134000 dist_mean = 0.4166 dist_std = 0.7423 vf_loss = 0.3473 grad_norm = 0.6990 nat_grad_norm = 0.5194 cg_residual = 0.0363 step_size = 0.3618 reward = 0.0000 fps = 6 mse_loss = 3.7105 
2022-07-08 09:15:06.515224 - gail/main.py:174 - [TRPO] iter = 135000 dist_mean = 0.3920 dist_std = 0.7391 vf_loss = 0.3888 grad_norm = 0.8435 nat_grad_norm = 0.5646 cg_residual = 0.0386 step_size = 0.3161 reward = 0.0000 fps = 5 mse_loss = 3.1896 
2022-07-08 09:15:07.310544 - gail/main.py:201 - [Discriminator] iter = 135000 loss = -4.2781 grad_norm = 3.5165 grad_penalty = 0.3906 regularization = 0.0000 true_logits = 0.1379 fake_logits = -4.5307 true_prob = 0.5501 fake_prob = 0.0129 
2022-07-08 09:15:54.304830 - gail/main.py:142 - [Evaluate] iter = 135000 episode={ returns = 247.2162 lengths = 114 } discounted_episode={ returns = 239.0235 lengths = 118 } 
2022-07-08 09:16:23.902128 - gail/main.py:174 - [TRPO] iter = 136000 dist_mean = 0.4041 dist_std = 0.7383 vf_loss = 0.3407 grad_norm = 0.7769 nat_grad_norm = 0.5934 cg_residual = 0.0618 step_size = 0.3264 reward = 0.0000 fps = 13 mse_loss = 3.5093 
2022-07-08 09:16:53.090966 - gail/main.py:174 - [TRPO] iter = 137000 dist_mean = 0.4036 dist_std = 0.7361 vf_loss = 0.2958 grad_norm = 0.6507 nat_grad_norm = 0.4903 cg_residual = 0.0385 step_size = 0.3789 reward = 0.0000 fps = 9 mse_loss = 3.4832 
2022-07-08 09:17:22.719769 - gail/main.py:174 - [TRPO] iter = 138000 dist_mean = 0.3978 dist_std = 0.7346 vf_loss = 0.3234 grad_norm = 0.6149 nat_grad_norm = 0.5273 cg_residual = 0.0545 step_size = 0.3544 reward = -0.0000 fps = 7 mse_loss = 3.4946 
2022-07-08 09:17:52.349327 - gail/main.py:174 - [TRPO] iter = 139000 dist_mean = 0.3900 dist_std = 0.7294 vf_loss = 0.2751 grad_norm = 0.7663 nat_grad_norm = 0.4320 cg_residual = 0.0405 step_size = 0.3714 reward = -0.0000 fps = 6 mse_loss = 3.4100 
2022-07-08 09:18:20.573201 - gail/main.py:174 - [TRPO] iter = 140000 dist_mean = 0.4102 dist_std = 0.7311 vf_loss = 0.4347 grad_norm = 0.8092 nat_grad_norm = 0.5406 cg_residual = 0.0415 step_size = 0.3170 reward = -0.0000 fps = 5 mse_loss = 3.3797 
2022-07-08 09:18:21.338206 - gail/main.py:201 - [Discriminator] iter = 140000 loss = -4.3168 grad_norm = 2.8953 grad_penalty = 0.4125 regularization = 0.0000 true_logits = 0.1486 fake_logits = -4.5807 true_prob = 0.5481 fake_prob = 0.0125 
2022-07-08 09:19:08.054801 - gail/main.py:142 - [Evaluate] iter = 140000 episode={ returns = 265.0081 lengths = 119 } discounted_episode={ returns = 240.5729 lengths = 116 } 
2022-07-08 09:19:37.076297 - gail/main.py:174 - [TRPO] iter = 141000 dist_mean = 0.3942 dist_std = 0.7324 vf_loss = 0.5038 grad_norm = 0.7941 nat_grad_norm = 0.5449 cg_residual = 0.0577 step_size = 0.3236 reward = -0.0000 fps = 13 mse_loss = 3.1873 
2022-07-08 09:20:05.905600 - gail/main.py:174 - [TRPO] iter = 142000 dist_mean = 0.3999 dist_std = 0.7302 vf_loss = 0.3353 grad_norm = 0.8008 nat_grad_norm = 0.4720 cg_residual = 0.0662 step_size = 0.3828 reward = -0.0000 fps = 9 mse_loss = 3.3712 
2022-07-08 09:20:34.715254 - gail/main.py:174 - [TRPO] iter = 143000 dist_mean = 0.4027 dist_std = 0.7258 vf_loss = 0.3406 grad_norm = 0.6720 nat_grad_norm = 0.4392 cg_residual = 0.0633 step_size = 0.3773 reward = -0.0000 fps = 7 mse_loss = 3.4605 
2022-07-08 09:21:03.140478 - gail/main.py:174 - [TRPO] iter = 144000 dist_mean = 0.3800 dist_std = 0.7228 vf_loss = 0.3535 grad_norm = 0.8026 nat_grad_norm = 0.4971 cg_residual = 0.0581 step_size = 0.3387 reward = 0.0000 fps = 6 mse_loss = 3.4743 
2022-07-08 09:21:31.277964 - gail/main.py:174 - [TRPO] iter = 145000 dist_mean = 0.4002 dist_std = 0.7207 vf_loss = 0.3699 grad_norm = 0.6419 nat_grad_norm = 0.5187 cg_residual = 0.0369 step_size = 0.3678 reward = 0.0000 fps = 5 mse_loss = 3.5405 
2022-07-08 09:21:32.111920 - gail/main.py:201 - [Discriminator] iter = 145000 loss = -4.2023 grad_norm = 3.5261 grad_penalty = 0.3986 regularization = 0.0000 true_logits = 0.1619 fake_logits = -4.4390 true_prob = 0.5539 fake_prob = 0.0145 
2022-07-08 09:22:21.096936 - gail/main.py:142 - [Evaluate] iter = 145000 episode={ returns = 258.3394 lengths = 115 } discounted_episode={ returns = 232.9598 lengths = 112 } 
2022-07-08 09:22:50.732044 - gail/main.py:174 - [TRPO] iter = 146000 dist_mean = 0.3993 dist_std = 0.7199 vf_loss = 0.2587 grad_norm = 0.6647 nat_grad_norm = 0.4691 cg_residual = 0.0722 step_size = 0.3751 reward = -0.0000 fps = 12 mse_loss = 3.6716 
2022-07-08 09:23:19.256239 - gail/main.py:174 - [TRPO] iter = 147000 dist_mean = 0.4148 dist_std = 0.7189 vf_loss = 0.3424 grad_norm = 0.6625 nat_grad_norm = 0.4796 cg_residual = 0.0599 step_size = 0.3921 reward = -0.0000 fps = 9 mse_loss = 3.7590 
2022-07-08 09:23:47.736150 - gail/main.py:174 - [TRPO] iter = 148000 dist_mean = 0.4103 dist_std = 0.7210 vf_loss = 0.2717 grad_norm = 0.7945 nat_grad_norm = 0.4912 cg_residual = 0.0470 step_size = 0.3597 reward = -0.0000 fps = 7 mse_loss = 3.7234 
2022-07-08 09:24:15.779987 - gail/main.py:174 - [TRPO] iter = 149000 dist_mean = 0.4226 dist_std = 0.7210 vf_loss = 0.2915 grad_norm = 0.6551 nat_grad_norm = 0.4676 cg_residual = 0.0237 step_size = 0.3661 reward = -0.0000 fps = 6 mse_loss = 3.7298 
2022-07-08 09:24:42.754227 - gail/main.py:174 - [TRPO] iter = 150000 dist_mean = 0.4201 dist_std = 0.7180 vf_loss = 0.3699 grad_norm = 0.8838 nat_grad_norm = 0.5318 cg_residual = 0.0497 step_size = 0.3134 reward = -0.0000 fps = 5 mse_loss = 3.5230 
2022-07-08 09:24:43.408755 - gail/main.py:201 - [Discriminator] iter = 150000 loss = -4.2409 grad_norm = 3.3568 grad_penalty = 0.3865 regularization = 0.0000 true_logits = 0.1411 fake_logits = -4.4863 true_prob = 0.5506 fake_prob = 0.0140 
2022-07-08 09:25:23.663673 - gail/main.py:142 - [Evaluate] iter = 150000 episode={ returns = 256.8559 lengths = 113 } discounted_episode={ returns = 238.7743 lengths = 112 } 
2022-07-08 09:25:50.991895 - gail/main.py:174 - [TRPO] iter = 151000 dist_mean = 0.4034 dist_std = 0.7092 vf_loss = 0.2160 grad_norm = 0.7026 nat_grad_norm = 0.5920 cg_residual = 0.1072 step_size = 0.3224 reward = -0.0000 fps = 14 mse_loss = 3.9055 
2022-07-08 09:26:20.707485 - gail/main.py:174 - [TRPO] iter = 152000 dist_mean = 0.4363 dist_std = 0.7093 vf_loss = 0.4097 grad_norm = 0.7564 nat_grad_norm = 0.5667 cg_residual = 0.0672 step_size = 0.3564 reward = 0.0000 fps = 10 mse_loss = 3.4660 
2022-07-08 09:26:49.150976 - gail/main.py:174 - [TRPO] iter = 153000 dist_mean = 0.4135 dist_std = 0.7104 vf_loss = 0.3537 grad_norm = 0.8090 nat_grad_norm = 0.5895 cg_residual = 0.1427 step_size = 0.3084 reward = -0.0000 fps = 7 mse_loss = 3.7027 
2022-07-08 09:27:16.205922 - gail/main.py:174 - [TRPO] iter = 154000 dist_mean = 0.4002 dist_std = 0.7125 vf_loss = 0.2607 grad_norm = 0.8440 nat_grad_norm = 0.5576 cg_residual = 0.0862 step_size = 0.3245 reward = 0.0000 fps = 6 mse_loss = 3.3643 
2022-07-08 09:27:43.219577 - gail/main.py:174 - [TRPO] iter = 155000 dist_mean = 0.4144 dist_std = 0.7099 vf_loss = 0.2415 grad_norm = 0.7794 nat_grad_norm = 0.5757 cg_residual = 0.1247 step_size = 0.3344 reward = 0.0000 fps = 5 mse_loss = 3.5131 
2022-07-08 09:27:43.995660 - gail/main.py:201 - [Discriminator] iter = 155000 loss = -4.3281 grad_norm = 3.3572 grad_penalty = 0.4033 regularization = 0.0000 true_logits = 0.1117 fake_logits = -4.6197 true_prob = 0.5414 fake_prob = 0.0124 
2022-07-08 09:28:25.855109 - gail/main.py:142 - [Evaluate] iter = 155000 episode={ returns = 263.8202 lengths = 116 } discounted_episode={ returns = 245.3494 lengths = 116 } 
2022-07-08 09:28:54.244791 - gail/main.py:174 - [TRPO] iter = 156000 dist_mean = 0.4133 dist_std = 0.7064 vf_loss = 0.3208 grad_norm = 0.8618 nat_grad_norm = 0.6228 cg_residual = 0.0612 step_size = 0.2994 reward = 0.0000 fps = 14 mse_loss = 3.6110 
2022-07-08 09:29:22.005337 - gail/main.py:174 - [TRPO] iter = 157000 dist_mean = 0.3979 dist_std = 0.7037 vf_loss = 0.2141 grad_norm = 0.8096 nat_grad_norm = 0.5230 cg_residual = 0.0454 step_size = 0.3249 reward = -0.0000 fps = 10 mse_loss = 3.6707 
2022-07-08 09:29:48.926084 - gail/main.py:174 - [TRPO] iter = 158000 dist_mean = 0.4289 dist_std = 0.7004 vf_loss = 0.2413 grad_norm = 0.7485 nat_grad_norm = 0.5263 cg_residual = 0.0674 step_size = 0.3477 reward = 0.0000 fps = 8 mse_loss = 3.5224 
2022-07-08 09:30:16.635938 - gail/main.py:174 - [TRPO] iter = 159000 dist_mean = 0.4018 dist_std = 0.6982 vf_loss = 0.2352 grad_norm = 0.8328 nat_grad_norm = 0.4828 cg_residual = 0.0704 step_size = 0.3581 reward = -0.0000 fps = 6 mse_loss = 3.4410 
2022-07-08 09:30:43.547408 - gail/main.py:174 - [TRPO] iter = 160000 dist_mean = 0.4308 dist_std = 0.6946 vf_loss = 0.2090 grad_norm = 1.3410 nat_grad_norm = 0.5688 cg_residual = 0.1259 step_size = 0.3100 reward = -0.0000 fps = 5 mse_loss = 3.4053 
2022-07-08 09:30:44.298105 - gail/main.py:201 - [Discriminator] iter = 160000 loss = -4.0758 grad_norm = 3.0802 grad_penalty = 0.3774 regularization = 0.0000 true_logits = 0.1164 fake_logits = -4.3368 true_prob = 0.5434 fake_prob = 0.0172 
2022-07-08 09:31:28.470441 - gail/main.py:142 - [Evaluate] iter = 160000 episode={ returns = 270.1767 lengths = 117 } discounted_episode={ returns = 256.6415 lengths = 120 } 
2022-07-08 09:31:55.836384 - gail/main.py:174 - [TRPO] iter = 161000 dist_mean = 0.4552 dist_std = 0.6970 vf_loss = 0.4088 grad_norm = 0.7400 nat_grad_norm = 0.5108 cg_residual = 0.0495 step_size = 0.3663 reward = -0.0000 fps = 13 mse_loss = 3.5188 
2022-07-08 09:32:29.111433 - gail/main.py:174 - [TRPO] iter = 162000 dist_mean = 0.4174 dist_std = 0.6890 vf_loss = 0.3159 grad_norm = 1.0084 nat_grad_norm = 0.4727 cg_residual = 0.0800 step_size = 0.3318 reward = 0.0000 fps = 9 mse_loss = 3.5412 
2022-07-08 09:32:56.176797 - gail/main.py:174 - [TRPO] iter = 163000 dist_mean = 0.4210 dist_std = 0.6856 vf_loss = 0.2651 grad_norm = 0.9288 nat_grad_norm = 0.5574 cg_residual = 0.0981 step_size = 0.3165 reward = -0.0000 fps = 7 mse_loss = 3.4074 
2022-07-08 09:33:23.386035 - gail/main.py:174 - [TRPO] iter = 164000 dist_mean = 0.4219 dist_std = 0.6800 vf_loss = 0.2359 grad_norm = 0.7269 nat_grad_norm = 0.6087 cg_residual = 0.0722 step_size = 0.3320 reward = 0.0000 fps = 6 mse_loss = 3.6983 
2022-07-08 09:33:49.789030 - gail/main.py:174 - [TRPO] iter = 165000 dist_mean = 0.4598 dist_std = 0.6782 vf_loss = 0.2636 grad_norm = 0.7742 nat_grad_norm = 0.5646 cg_residual = 0.0815 step_size = 0.3241 reward = 0.0000 fps = 5 mse_loss = 3.3331 
2022-07-08 09:33:50.512600 - gail/main.py:201 - [Discriminator] iter = 165000 loss = -4.3480 grad_norm = 3.0433 grad_penalty = 0.3763 regularization = 0.0000 true_logits = 0.1091 fake_logits = -4.6152 true_prob = 0.5426 fake_prob = 0.0130 
2022-07-08 09:34:33.739056 - gail/main.py:142 - [Evaluate] iter = 165000 episode={ returns = 284.7855 lengths = 124 } discounted_episode={ returns = 259.3567 lengths = 122 } 
2022-07-08 09:35:00.822787 - gail/main.py:174 - [TRPO] iter = 166000 dist_mean = 0.4174 dist_std = 0.6745 vf_loss = 0.3514 grad_norm = 0.6891 nat_grad_norm = 0.5230 cg_residual = 0.1296 step_size = 0.3579 reward = -0.0000 fps = 14 mse_loss = 3.2762 
2022-07-08 09:35:27.021408 - gail/main.py:174 - [TRPO] iter = 167000 dist_mean = 0.4437 dist_std = 0.6662 vf_loss = 0.3806 grad_norm = 1.1060 nat_grad_norm = 0.4661 cg_residual = 0.1306 step_size = 0.3319 reward = -0.0000 fps = 10 mse_loss = 3.2003 
2022-07-08 09:35:53.558046 - gail/main.py:174 - [TRPO] iter = 168000 dist_mean = 0.4578 dist_std = 0.6666 vf_loss = 0.4539 grad_norm = 0.9253 nat_grad_norm = 0.5161 cg_residual = 0.1190 step_size = 0.3332 reward = 0.0000 fps = 8 mse_loss = 3.4052 
2022-07-08 09:36:19.661772 - gail/main.py:174 - [TRPO] iter = 169000 dist_mean = 0.4502 dist_std = 0.6638 vf_loss = 0.4314 grad_norm = 1.0159 nat_grad_norm = 0.5608 cg_residual = 0.1593 step_size = 0.3022 reward = -0.0000 fps = 6 mse_loss = 3.4338 
2022-07-08 09:36:45.773567 - gail/main.py:174 - [TRPO] iter = 170000 dist_mean = 0.4651 dist_std = 0.6629 vf_loss = 0.3260 grad_norm = 0.7642 nat_grad_norm = 0.5062 cg_residual = 0.1154 step_size = 0.3278 reward = 0.0000 fps = 5 mse_loss = 3.3078 
2022-07-08 09:36:46.491665 - gail/main.py:201 - [Discriminator] iter = 170000 loss = -4.1422 grad_norm = 2.6585 grad_penalty = 0.3878 regularization = 0.0000 true_logits = 0.1250 fake_logits = -4.4050 true_prob = 0.5437 fake_prob = 0.0169 
2022-07-08 09:37:30.347717 - gail/main.py:142 - [Evaluate] iter = 170000 episode={ returns = 290.7076 lengths = 125 } discounted_episode={ returns = 267.3089 lengths = 125 } 
2022-07-08 09:37:56.349419 - gail/main.py:174 - [TRPO] iter = 171000 dist_mean = 0.4158 dist_std = 0.6621 vf_loss = 0.2573 grad_norm = 0.7688 nat_grad_norm = 0.5687 cg_residual = 0.0973 step_size = 0.3234 reward = -0.0000 fps = 14 mse_loss = 3.6301 
2022-07-08 09:38:22.410180 - gail/main.py:174 - [TRPO] iter = 172000 dist_mean = 0.4258 dist_std = 0.6637 vf_loss = 0.3323 grad_norm = 0.7366 nat_grad_norm = 0.5448 cg_residual = 0.0918 step_size = 0.3307 reward = 0.0000 fps = 10 mse_loss = 3.8113 
2022-07-08 09:38:48.329631 - gail/main.py:174 - [TRPO] iter = 173000 dist_mean = 0.4573 dist_std = 0.6595 vf_loss = 0.4909 grad_norm = 0.9653 nat_grad_norm = 0.4718 cg_residual = 0.1074 step_size = 0.3385 reward = 0.0000 fps = 8 mse_loss = 3.4817 
2022-07-08 09:39:14.308875 - gail/main.py:174 - [TRPO] iter = 174000 dist_mean = 0.4791 dist_std = 0.6603 vf_loss = 0.2166 grad_norm = 1.1447 nat_grad_norm = 0.5314 cg_residual = 0.1575 step_size = 0.3085 reward = 0.0000 fps = 6 mse_loss = 3.4313 
2022-07-08 09:39:41.171769 - gail/main.py:174 - [TRPO] iter = 175000 dist_mean = 0.4435 dist_std = 0.6541 vf_loss = 0.2858 grad_norm = 0.7273 nat_grad_norm = 0.5711 cg_residual = 0.1291 step_size = 0.3244 reward = 0.0000 fps = 5 mse_loss = 3.4058 
2022-07-08 09:39:42.022567 - gail/main.py:201 - [Discriminator] iter = 175000 loss = -4.3546 grad_norm = 2.2609 grad_penalty = 0.3732 regularization = 0.0000 true_logits = 0.1591 fake_logits = -4.5688 true_prob = 0.5489 fake_prob = 0.0138 
2022-07-08 09:40:30.134720 - gail/main.py:142 - [Evaluate] iter = 175000 episode={ returns = 319.2347 lengths = 133 } discounted_episode={ returns = 288.5470 lengths = 131 } 
2022-07-08 09:40:56.213977 - gail/main.py:174 - [TRPO] iter = 176000 dist_mean = 0.4141 dist_std = 0.6522 vf_loss = 0.2444 grad_norm = 1.0821 nat_grad_norm = 0.5251 cg_residual = 0.0920 step_size = 0.3302 reward = 0.0000 fps = 13 mse_loss = 3.2882 
2022-07-08 09:41:22.062194 - gail/main.py:174 - [TRPO] iter = 177000 dist_mean = 0.4659 dist_std = 0.6523 vf_loss = 0.3827 grad_norm = 1.0683 nat_grad_norm = 0.5081 cg_residual = 0.1449 step_size = 0.3145 reward = 0.0000 fps = 9 mse_loss = 3.2612 
2022-07-08 09:41:48.887493 - gail/main.py:174 - [TRPO] iter = 178000 dist_mean = 0.4329 dist_std = 0.6554 vf_loss = 0.3602 grad_norm = 0.8711 nat_grad_norm = 0.4957 cg_residual = 0.1208 step_size = 0.3312 reward = 0.0000 fps = 7 mse_loss = 3.4648 
2022-07-08 09:42:21.391675 - gail/main.py:174 - [TRPO] iter = 179000 dist_mean = 0.4511 dist_std = 0.6540 vf_loss = 0.4122 grad_norm = 0.9176 nat_grad_norm = 0.5308 cg_residual = 0.1023 step_size = 0.3140 reward = 0.0000 fps = 6 mse_loss = 3.2620 
2022-07-08 09:42:46.841889 - gail/main.py:174 - [TRPO] iter = 180000 dist_mean = 0.4317 dist_std = 0.6550 vf_loss = 0.1881 grad_norm = 1.0141 nat_grad_norm = 0.4308 cg_residual = 0.1260 step_size = 0.3514 reward = -0.0000 fps = 5 mse_loss = 3.4691 
2022-07-08 09:42:47.552741 - gail/main.py:201 - [Discriminator] iter = 180000 loss = -4.2508 grad_norm = 2.9775 grad_penalty = 0.3859 regularization = 0.0000 true_logits = 0.1477 fake_logits = -4.4891 true_prob = 0.5451 fake_prob = 0.0148 
2022-07-08 09:43:30.851990 - gail/main.py:142 - [Evaluate] iter = 180000 episode={ returns = 302.6289 lengths = 131 } discounted_episode={ returns = 279.1437 lengths = 130 } 
2022-07-08 09:43:55.698665 - gail/main.py:174 - [TRPO] iter = 181000 dist_mean = 0.4280 dist_std = 0.6536 vf_loss = 0.2519 grad_norm = 1.2787 nat_grad_norm = 0.4865 cg_residual = 0.0761 step_size = 0.3407 reward = 0.0000 fps = 14 mse_loss = 3.2983 
2022-07-08 09:44:22.176288 - gail/main.py:174 - [TRPO] iter = 182000 dist_mean = 0.4273 dist_std = 0.6483 vf_loss = 0.2351 grad_norm = 0.8800 nat_grad_norm = 0.5905 cg_residual = 0.1064 step_size = 0.3218 reward = 0.0000 fps = 10 mse_loss = 3.4120 
2022-07-08 09:44:48.135874 - gail/main.py:174 - [TRPO] iter = 183000 dist_mean = 0.4066 dist_std = 0.6438 vf_loss = 0.2690 grad_norm = 0.7901 nat_grad_norm = 0.4593 cg_residual = 0.0980 step_size = 0.3233 reward = 0.0000 fps = 8 mse_loss = 3.2674 
2022-07-08 09:45:13.398173 - gail/main.py:174 - [TRPO] iter = 184000 dist_mean = 0.4392 dist_std = 0.6453 vf_loss = 0.2779 grad_norm = 0.8314 nat_grad_norm = 0.6330 cg_residual = 0.1854 step_size = 0.2939 reward = 0.0000 fps = 6 mse_loss = 3.5680 
2022-07-08 09:45:38.447319 - gail/main.py:174 - [TRPO] iter = 185000 dist_mean = 0.4463 dist_std = 0.6428 vf_loss = 0.3945 grad_norm = 0.9053 nat_grad_norm = 0.3977 cg_residual = 0.0666 step_size = 0.3485 reward = -0.0000 fps = 5 mse_loss = 3.4168 
2022-07-08 09:45:39.170000 - gail/main.py:201 - [Discriminator] iter = 185000 loss = -4.1902 grad_norm = 2.6261 grad_penalty = 0.3706 regularization = 0.0000 true_logits = 0.2089 fake_logits = -4.3519 true_prob = 0.5565 fake_prob = 0.0185 
2022-07-08 09:46:20.460633 - gail/main.py:142 - [Evaluate] iter = 185000 episode={ returns = 285.9654 lengths = 124 } discounted_episode={ returns = 263.4782 lengths = 124 } 
2022-07-08 09:46:46.603667 - gail/main.py:174 - [TRPO] iter = 186000 dist_mean = 0.4208 dist_std = 0.6405 vf_loss = 0.4471 grad_norm = 0.8099 nat_grad_norm = 0.5572 cg_residual = 0.1219 step_size = 0.2993 reward = 0.0000 fps = 14 mse_loss = 3.3500 
2022-07-08 09:47:12.267694 - gail/main.py:174 - [TRPO] iter = 187000 dist_mean = 0.4206 dist_std = 0.6371 vf_loss = 0.3909 grad_norm = 0.9025 nat_grad_norm = 0.4868 cg_residual = 0.0936 step_size = 0.3590 reward = -0.0000 fps = 10 mse_loss = 3.4450 
2022-07-08 09:47:38.173870 - gail/main.py:174 - [TRPO] iter = 188000 dist_mean = 0.3974 dist_std = 0.6330 vf_loss = 0.7081 grad_norm = 0.7164 nat_grad_norm = 0.4981 cg_residual = 0.0996 step_size = 0.3492 reward = -0.0000 fps = 8 mse_loss = 3.3782 
2022-07-08 09:48:03.897984 - gail/main.py:174 - [TRPO] iter = 189000 dist_mean = 0.4326 dist_std = 0.6325 vf_loss = 0.3468 grad_norm = 0.7460 nat_grad_norm = 0.3851 cg_residual = 0.0831 step_size = 0.3988 reward = 0.0000 fps = 6 mse_loss = 3.3132 
2022-07-08 09:48:28.839829 - gail/main.py:174 - [TRPO] iter = 190000 dist_mean = 0.4572 dist_std = 0.6283 vf_loss = 0.2672 grad_norm = 1.0711 nat_grad_norm = 0.5204 cg_residual = 0.0787 step_size = 0.3273 reward = 0.0000 fps = 5 mse_loss = 3.2703 
2022-07-08 09:48:29.533372 - gail/main.py:201 - [Discriminator] iter = 190000 loss = -4.1886 grad_norm = 3.0842 grad_penalty = 0.3535 regularization = 0.0000 true_logits = 0.2900 fake_logits = -4.2521 true_prob = 0.5703 fake_prob = 0.0201 
2022-07-08 09:49:17.377050 - gail/main.py:142 - [Evaluate] iter = 190000 episode={ returns = 340.6352 lengths = 142 } discounted_episode={ returns = 316.5057 lengths = 143 } 
2022-07-08 09:49:44.901838 - gail/main.py:174 - [TRPO] iter = 191000 dist_mean = 0.4385 dist_std = 0.6224 vf_loss = 0.5696 grad_norm = 0.8240 nat_grad_norm = 0.4732 cg_residual = 0.2137 step_size = 0.3188 reward = -0.0000 fps = 13 mse_loss = 3.5135 
2022-07-08 09:50:13.155835 - gail/main.py:174 - [TRPO] iter = 192000 dist_mean = 0.4399 dist_std = 0.6214 vf_loss = 0.2430 grad_norm = 1.1119 nat_grad_norm = 0.5317 cg_residual = 0.2002 step_size = 0.3015 reward = -0.0000 fps = 9 mse_loss = 3.3546 
2022-07-08 09:50:39.885761 - gail/main.py:174 - [TRPO] iter = 193000 dist_mean = 0.4255 dist_std = 0.6176 vf_loss = 0.4354 grad_norm = 1.2650 nat_grad_norm = 0.4898 cg_residual = 0.2197 step_size = 0.3265 reward = 0.0000 fps = 7 mse_loss = 3.4886 
2022-07-08 09:51:05.175186 - gail/main.py:174 - [TRPO] iter = 194000 dist_mean = 0.4459 dist_std = 0.6155 vf_loss = 0.5146 grad_norm = 0.9189 nat_grad_norm = 0.4655 cg_residual = 0.1459 step_size = 0.3597 reward = -0.0000 fps = 6 mse_loss = 3.1809 
2022-07-08 09:51:29.986011 - gail/main.py:174 - [TRPO] iter = 195000 dist_mean = 0.4248 dist_std = 0.6160 vf_loss = 0.4403 grad_norm = 0.7598 nat_grad_norm = 0.5012 cg_residual = 0.2398 step_size = 0.3312 reward = -0.0000 fps = 5 mse_loss = 3.3028 
2022-07-08 09:51:30.755394 - gail/main.py:201 - [Discriminator] iter = 195000 loss = -4.2323 grad_norm = 2.7545 grad_penalty = 0.3874 regularization = 0.0000 true_logits = 0.3311 fake_logits = -4.2886 true_prob = 0.5785 fake_prob = 0.0192 
2022-07-08 09:52:27.831173 - gail/main.py:142 - [Evaluate] iter = 195000 episode={ returns = 364.3569 lengths = 146 } discounted_episode={ returns = 336.3952 lengths = 147 } 
2022-07-08 09:52:53.034330 - gail/main.py:174 - [TRPO] iter = 196000 dist_mean = 0.4279 dist_std = 0.6125 vf_loss = 0.3752 grad_norm = 0.8014 nat_grad_norm = 0.3949 cg_residual = 0.0946 step_size = 0.3696 reward = -0.0000 fps = 12 mse_loss = 3.7170 
2022-07-08 09:53:19.481769 - gail/main.py:174 - [TRPO] iter = 197000 dist_mean = 0.4293 dist_std = 0.6134 vf_loss = 0.1466 grad_norm = 0.9645 nat_grad_norm = 0.5002 cg_residual = 0.1607 step_size = 0.3371 reward = -0.0000 fps = 9 mse_loss = 3.3710 
2022-07-08 09:53:46.392037 - gail/main.py:174 - [TRPO] iter = 198000 dist_mean = 0.4097 dist_std = 0.6152 vf_loss = 0.2187 grad_norm = 0.9411 nat_grad_norm = 0.4391 cg_residual = 0.0846 step_size = 0.3348 reward = 0.0000 fps = 7 mse_loss = 3.4879 
2022-07-08 09:54:13.621551 - gail/main.py:174 - [TRPO] iter = 199000 dist_mean = 0.4147 dist_std = 0.6129 vf_loss = 0.2548 grad_norm = 1.0941 nat_grad_norm = 0.4317 cg_residual = 0.1286 step_size = 0.3372 reward = 0.0000 fps = 6 mse_loss = 3.5116 
2022-07-08 09:54:40.207265 - gail/main.py:174 - [TRPO] iter = 200000 dist_mean = 0.4304 dist_std = 0.6109 vf_loss = 0.3757 grad_norm = 0.9022 nat_grad_norm = 0.5973 cg_residual = 0.1085 step_size = 0.3127 reward = -0.0000 fps = 5 mse_loss = 3.3310 
2022-07-08 09:54:40.977622 - gail/main.py:201 - [Discriminator] iter = 200000 loss = -4.1727 grad_norm = 3.1044 grad_penalty = 0.3556 regularization = 0.0000 true_logits = 0.3452 fake_logits = -4.1831 true_prob = 0.5845 fake_prob = 0.0231 
2022-07-08 09:55:26.958603 - gail/main.py:142 - [Evaluate] iter = 200000 episode={ returns = 337.4887 lengths = 138 } discounted_episode={ returns = 311.8965 lengths = 139 } 
2022-07-08 09:55:51.845433 - gail/main.py:174 - [TRPO] iter = 201000 dist_mean = 0.4265 dist_std = 0.6074 vf_loss = 0.1778 grad_norm = 0.9449 nat_grad_norm = 0.5332 cg_residual = 0.1503 step_size = 0.2973 reward = -0.0000 fps = 14 mse_loss = 3.5027 
2022-07-08 09:56:16.348435 - gail/main.py:174 - [TRPO] iter = 202000 dist_mean = 0.3926 dist_std = 0.6040 vf_loss = 0.3033 grad_norm = 1.3414 nat_grad_norm = 0.4860 cg_residual = 0.1540 step_size = 0.3147 reward = -0.0000 fps = 10 mse_loss = 3.4563 
2022-07-08 09:56:40.314120 - gail/main.py:174 - [TRPO] iter = 203000 dist_mean = 0.4136 dist_std = 0.6019 vf_loss = 0.2345 grad_norm = 1.1036 nat_grad_norm = 0.4569 cg_residual = 0.2101 step_size = 0.3389 reward = 0.0000 fps = 8 mse_loss = 3.5375 
2022-07-08 09:57:04.982299 - gail/main.py:174 - [TRPO] iter = 204000 dist_mean = 0.4178 dist_std = 0.5988 vf_loss = 0.1874 grad_norm = 1.0337 nat_grad_norm = 0.5099 cg_residual = 0.1693 step_size = 0.3256 reward = 0.0000 fps = 6 mse_loss = 3.5614 
2022-07-08 09:57:29.977136 - gail/main.py:174 - [TRPO] iter = 205000 dist_mean = 0.4267 dist_std = 0.5981 vf_loss = 0.2655 grad_norm = 1.1104 nat_grad_norm = 0.4976 cg_residual = 0.1531 step_size = 0.3074 reward = -0.0000 fps = 5 mse_loss = 3.3123 
2022-07-08 09:57:30.756045 - gail/main.py:201 - [Discriminator] iter = 205000 loss = -4.3237 grad_norm = 3.0025 grad_penalty = 0.3717 regularization = 0.0000 true_logits = 0.4237 fake_logits = -4.2717 true_prob = 0.5968 fake_prob = 0.0199 
2022-07-08 09:58:14.507381 - gail/main.py:142 - [Evaluate] iter = 205000 episode={ returns = 319.3887 lengths = 131 } discounted_episode={ returns = 300.4406 lengths = 137 } 
2022-07-08 09:58:40.893798 - gail/main.py:174 - [TRPO] iter = 206000 dist_mean = 0.4296 dist_std = 0.5997 vf_loss = 0.3564 grad_norm = 1.0463 nat_grad_norm = 0.4494 cg_residual = 0.3305 step_size = 0.3014 reward = 0.0000 fps = 14 mse_loss = 3.5495 
2022-07-08 09:59:06.472700 - gail/main.py:174 - [TRPO] iter = 207000 dist_mean = 0.4427 dist_std = 0.5956 vf_loss = 0.2201 grad_norm = 1.0431 nat_grad_norm = 0.4341 cg_residual = 0.1119 step_size = 0.3442 reward = 0.0000 fps = 10 mse_loss = 3.6446 
2022-07-08 09:59:32.738599 - gail/main.py:174 - [TRPO] iter = 208000 dist_mean = 0.4402 dist_std = 0.5952 vf_loss = 0.3139 grad_norm = 1.0133 nat_grad_norm = 0.5096 cg_residual = 0.3084 step_size = 0.3271 reward = -0.0000 fps = 8 mse_loss = 3.7631 
2022-07-08 09:59:59.462125 - gail/main.py:174 - [TRPO] iter = 209000 dist_mean = 0.4261 dist_std = 0.5952 vf_loss = 0.1835 grad_norm = 1.0019 nat_grad_norm = 0.4097 cg_residual = 0.0885 step_size = 0.3406 reward = -0.0000 fps = 6 mse_loss = 3.6586 
2022-07-08 10:00:25.710874 - gail/main.py:174 - [TRPO] iter = 210000 dist_mean = 0.4636 dist_std = 0.5913 vf_loss = 0.3411 grad_norm = 1.0165 nat_grad_norm = 0.4342 cg_residual = 0.2431 step_size = 0.3296 reward = -0.0000 fps = 5 mse_loss = 3.9783 
2022-07-08 10:00:26.537245 - gail/main.py:201 - [Discriminator] iter = 210000 loss = -4.2414 grad_norm = 3.6153 grad_penalty = 0.3850 regularization = 0.0000 true_logits = 0.4346 fake_logits = -4.1917 true_prob = 0.5960 fake_prob = 0.0242 
2022-07-08 10:01:10.498798 - gail/main.py:142 - [Evaluate] iter = 210000 episode={ returns = 295.5836 lengths = 121 } discounted_episode={ returns = 283.6532 lengths = 126 } 
2022-07-08 10:01:38.355094 - gail/main.py:174 - [TRPO] iter = 211000 dist_mean = 0.4248 dist_std = 0.5908 vf_loss = 0.4753 grad_norm = 0.9757 nat_grad_norm = 0.4322 cg_residual = 0.1812 step_size = 0.3299 reward = -0.0000 fps = 13 mse_loss = 3.9806 
2022-07-08 10:02:14.453762 - gail/main.py:174 - [TRPO] iter = 212000 dist_mean = 0.3853 dist_std = 0.5901 vf_loss = 0.2021 grad_norm = 1.1842 nat_grad_norm = 0.4201 cg_residual = 0.1380 step_size = 0.3231 reward = 0.0000 fps = 9 mse_loss = 4.0174 
2022-07-08 10:02:42.759492 - gail/main.py:174 - [TRPO] iter = 213000 dist_mean = 0.4191 dist_std = 0.5909 vf_loss = 0.4113 grad_norm = 1.1633 nat_grad_norm = 0.4827 cg_residual = 0.2146 step_size = 0.3177 reward = 0.0000 fps = 7 mse_loss = 3.8780 
2022-07-08 10:03:11.865075 - gail/main.py:174 - [TRPO] iter = 214000 dist_mean = 0.4133 dist_std = 0.5873 vf_loss = 0.1934 grad_norm = 1.0045 nat_grad_norm = 0.4304 cg_residual = 0.1485 step_size = 0.3199 reward = 0.0000 fps = 6 mse_loss = 3.7361 
2022-07-08 10:03:39.738242 - gail/main.py:174 - [TRPO] iter = 215000 dist_mean = 0.4458 dist_std = 0.5885 vf_loss = 0.3335 grad_norm = 0.9647 nat_grad_norm = 0.5109 cg_residual = 0.2906 step_size = 0.3075 reward = 0.0000 fps = 5 mse_loss = 3.5347 
2022-07-08 10:03:40.605562 - gail/main.py:201 - [Discriminator] iter = 215000 loss = -4.3480 grad_norm = 3.4295 grad_penalty = 0.3830 regularization = 0.0000 true_logits = 0.4597 fake_logits = -4.2713 true_prob = 0.6010 fake_prob = 0.0216 
2022-07-08 10:04:32.365124 - gail/main.py:142 - [Evaluate] iter = 215000 episode={ returns = 314.1994 lengths = 128 } discounted_episode={ returns = 292.1028 lengths = 129 } 
2022-07-08 10:05:01.253055 - gail/main.py:174 - [TRPO] iter = 216000 dist_mean = 0.4129 dist_std = 0.5875 vf_loss = 0.1810 grad_norm = 1.1650 nat_grad_norm = 0.3850 cg_residual = 0.1099 step_size = 0.3680 reward = 0.0000 fps = 12 mse_loss = 3.4771 
2022-07-08 10:05:30.907227 - gail/main.py:174 - [TRPO] iter = 217000 dist_mean = 0.4485 dist_std = 0.5831 vf_loss = 0.4584 grad_norm = 0.8696 nat_grad_norm = 0.4871 cg_residual = 0.2738 step_size = 0.3269 reward = 0.0000 fps = 9 mse_loss = 3.3586 
2022-07-08 10:05:59.828400 - gail/main.py:174 - [TRPO] iter = 218000 dist_mean = 0.4292 dist_std = 0.5783 vf_loss = 0.1904 grad_norm = 0.9409 nat_grad_norm = 0.4199 cg_residual = 0.2050 step_size = 0.3266 reward = 0.0000 fps = 7 mse_loss = 3.3346 
2022-07-08 10:06:29.200399 - gail/main.py:174 - [TRPO] iter = 219000 dist_mean = 0.4243 dist_std = 0.5774 vf_loss = 0.2845 grad_norm = 1.0184 nat_grad_norm = 0.4580 cg_residual = 0.1546 step_size = 0.3061 reward = -0.0000 fps = 5 mse_loss = 3.2915 
2022-07-08 10:06:57.885329 - gail/main.py:174 - [TRPO] iter = 220000 dist_mean = 0.4216 dist_std = 0.5778 vf_loss = 0.1580 grad_norm = 0.9974 nat_grad_norm = 0.3795 cg_residual = 0.1318 step_size = 0.3462 reward = -0.0000 fps = 5 mse_loss = 3.2172 
2022-07-08 10:06:58.788118 - gail/main.py:201 - [Discriminator] iter = 220000 loss = -4.2215 grad_norm = 3.2105 grad_penalty = 0.3606 regularization = 0.0000 true_logits = 0.4642 fake_logits = -4.1179 true_prob = 0.5994 fake_prob = 0.0256 
2022-07-08 10:07:48.651060 - gail/main.py:142 - [Evaluate] iter = 220000 episode={ returns = 327.5204 lengths = 131 } discounted_episode={ returns = 303.4323 lengths = 130 } 
2022-07-08 10:08:17.006672 - gail/main.py:174 - [TRPO] iter = 221000 dist_mean = 0.4193 dist_std = 0.5713 vf_loss = 0.1950 grad_norm = 0.9854 nat_grad_norm = 0.5134 cg_residual = 0.2163 step_size = 0.3089 reward = -0.0000 fps = 12 mse_loss = 3.3031 
2022-07-08 10:08:45.091091 - gail/main.py:174 - [TRPO] iter = 222000 dist_mean = 0.4180 dist_std = 0.5672 vf_loss = 0.1559 grad_norm = 1.1726 nat_grad_norm = 0.3940 cg_residual = 0.1532 step_size = 0.3280 reward = 0.0000 fps = 9 mse_loss = 3.1048 
2022-07-08 10:09:15.162422 - gail/main.py:174 - [TRPO] iter = 223000 dist_mean = 0.4528 dist_std = 0.5606 vf_loss = 0.1552 grad_norm = 0.9991 nat_grad_norm = 0.3927 cg_residual = 0.1855 step_size = 0.3377 reward = 0.0000 fps = 7 mse_loss = 2.9576 
2022-07-08 10:09:44.954815 - gail/main.py:174 - [TRPO] iter = 224000 dist_mean = 0.4199 dist_std = 0.5574 vf_loss = 0.2190 grad_norm = 1.4218 nat_grad_norm = 0.3941 cg_residual = 0.1499 step_size = 0.3302 reward = 0.0000 fps = 6 mse_loss = 2.9840 
2022-07-08 10:10:14.094162 - gail/main.py:174 - [TRPO] iter = 225000 dist_mean = 0.4334 dist_std = 0.5570 vf_loss = 0.2430 grad_norm = 1.3215 nat_grad_norm = 0.3983 cg_residual = 0.2256 step_size = 0.3539 reward = 0.0000 fps = 5 mse_loss = 2.9675 
2022-07-08 10:10:14.909285 - gail/main.py:201 - [Discriminator] iter = 225000 loss = -4.3204 grad_norm = 2.9958 grad_penalty = 0.3799 regularization = 0.0000 true_logits = 0.4849 fake_logits = -4.2155 true_prob = 0.6024 fake_prob = 0.0238 
2022-07-08 10:11:07.105024 - gail/main.py:142 - [Evaluate] iter = 225000 episode={ returns = 361.0373 lengths = 136 } discounted_episode={ returns = 333.1745 lengths = 136 } 
2022-07-08 10:11:37.688437 - gail/main.py:174 - [TRPO] iter = 226000 dist_mean = 0.4441 dist_std = 0.5539 vf_loss = 0.1778 grad_norm = 1.3996 nat_grad_norm = 0.4262 cg_residual = 0.1907 step_size = 0.3146 reward = -0.0000 fps = 12 mse_loss = 2.9756 
2022-07-08 10:12:14.551771 - gail/main.py:174 - [TRPO] iter = 227000 dist_mean = 0.4367 dist_std = 0.5509 vf_loss = 0.2146 grad_norm = 1.2731 nat_grad_norm = 0.3547 cg_residual = 0.1913 step_size = 0.3615 reward = 0.0000 fps = 8 mse_loss = 2.8960 
2022-07-08 10:12:44.152477 - gail/main.py:174 - [TRPO] iter = 228000 dist_mean = 0.4234 dist_std = 0.5512 vf_loss = 0.2087 grad_norm = 1.2514 nat_grad_norm = 0.4359 cg_residual = 0.2524 step_size = 0.3162 reward = 0.0000 fps = 6 mse_loss = 3.2301 
2022-07-08 10:13:13.052387 - gail/main.py:174 - [TRPO] iter = 229000 dist_mean = 0.4135 dist_std = 0.5469 vf_loss = 0.1335 grad_norm = 1.0722 nat_grad_norm = 0.4154 cg_residual = 0.2088 step_size = 0.3231 reward = -0.0000 fps = 5 mse_loss = 3.1659 
2022-07-08 10:13:40.981965 - gail/main.py:174 - [TRPO] iter = 230000 dist_mean = 0.4410 dist_std = 0.5440 vf_loss = 0.1938 grad_norm = 1.3051 nat_grad_norm = 0.4524 cg_residual = 0.2367 step_size = 0.2733 reward = -0.0000 fps = 4 mse_loss = 2.9919 
2022-07-08 10:13:41.712665 - gail/main.py:201 - [Discriminator] iter = 230000 loss = -4.1068 grad_norm = 2.6515 grad_penalty = 0.3547 regularization = 0.0000 true_logits = 0.4829 fake_logits = -3.9786 true_prob = 0.6007 fake_prob = 0.0323 
2022-07-08 10:14:33.373183 - gail/main.py:142 - [Evaluate] iter = 230000 episode={ returns = 356.6477 lengths = 134 } discounted_episode={ returns = 331.0021 lengths = 136 } 
2022-07-08 10:15:02.443990 - gail/main.py:174 - [TRPO] iter = 231000 dist_mean = 0.4328 dist_std = 0.5409 vf_loss = 0.1322 grad_norm = 1.1684 nat_grad_norm = 0.4025 cg_residual = 0.2028 step_size = 0.3167 reward = 0.0000 fps = 12 mse_loss = 3.0299 
2022-07-08 10:15:31.300357 - gail/main.py:174 - [TRPO] iter = 232000 dist_mean = 0.4293 dist_std = 0.5391 vf_loss = 0.1141 grad_norm = 0.8315 nat_grad_norm = 0.3430 cg_residual = 0.1563 step_size = 0.3886 reward = -0.0000 fps = 9 mse_loss = 2.8441 
2022-07-08 10:16:00.269675 - gail/main.py:174 - [TRPO] iter = 233000 dist_mean = 0.4363 dist_std = 0.5325 vf_loss = 0.2071 grad_norm = 1.1738 nat_grad_norm = 0.4173 cg_residual = 0.1943 step_size = 0.3151 reward = -0.0000 fps = 7 mse_loss = 3.2146 
2022-07-08 10:16:28.567477 - gail/main.py:174 - [TRPO] iter = 234000 dist_mean = 0.4123 dist_std = 0.5367 vf_loss = 0.2175 grad_norm = 1.2547 nat_grad_norm = 0.3967 cg_residual = 0.1710 step_size = 0.3170 reward = 0.0000 fps = 5 mse_loss = 3.2460 
2022-07-08 10:16:56.789347 - gail/main.py:174 - [TRPO] iter = 235000 dist_mean = 0.4554 dist_std = 0.5323 vf_loss = 0.1630 grad_norm = 1.1517 nat_grad_norm = 0.4063 cg_residual = 0.2879 step_size = 0.3278 reward = 0.0000 fps = 5 mse_loss = 3.0969 
2022-07-08 10:16:57.615656 - gail/main.py:201 - [Discriminator] iter = 235000 loss = -4.2260 grad_norm = 2.6150 grad_penalty = 0.3498 regularization = 0.0000 true_logits = 0.5484 fake_logits = -4.0275 true_prob = 0.6104 fake_prob = 0.0281 
2022-07-08 10:17:48.202806 - gail/main.py:142 - [Evaluate] iter = 235000 episode={ returns = 349.9564 lengths = 135 } discounted_episode={ returns = 322.0155 lengths = 135 } 
2022-07-08 10:18:16.402537 - gail/main.py:174 - [TRPO] iter = 236000 dist_mean = 0.4699 dist_std = 0.5310 vf_loss = 0.1394 grad_norm = 1.2083 nat_grad_norm = 0.3491 cg_residual = 0.2168 step_size = 0.3471 reward = -0.0000 fps = 12 mse_loss = 3.3315 
2022-07-08 10:18:44.201147 - gail/main.py:174 - [TRPO] iter = 237000 dist_mean = 0.4483 dist_std = 0.5265 vf_loss = 0.1186 grad_norm = 1.2416 nat_grad_norm = 0.4016 cg_residual = 0.3048 step_size = 0.3154 reward = 0.0000 fps = 9 mse_loss = 3.0479 
2022-07-08 10:19:10.134897 - gail/main.py:174 - [TRPO] iter = 238000 dist_mean = 0.4538 dist_std = 0.5215 vf_loss = 0.1877 grad_norm = 1.2099 nat_grad_norm = 0.4261 cg_residual = 0.2576 step_size = 0.3124 reward = 0.0000 fps = 7 mse_loss = 3.0582 
2022-07-08 10:19:38.901385 - gail/main.py:174 - [TRPO] iter = 239000 dist_mean = 0.4332 dist_std = 0.5197 vf_loss = 0.1595 grad_norm = 1.2400 nat_grad_norm = 0.3348 cg_residual = 0.1835 step_size = 0.3726 reward = 0.0000 fps = 6 mse_loss = 3.1663 
2022-07-08 10:20:07.178805 - gail/main.py:174 - [TRPO] iter = 240000 dist_mean = 0.4339 dist_std = 0.5196 vf_loss = 0.0919 grad_norm = 0.8761 nat_grad_norm = 0.4011 cg_residual = 0.1581 step_size = 0.3333 reward = 0.0000 fps = 5 mse_loss = 3.3661 
2022-07-08 10:20:07.984724 - gail/main.py:201 - [Discriminator] iter = 240000 loss = -4.1796 grad_norm = 2.8573 grad_penalty = 0.3726 regularization = 0.0000 true_logits = 0.6545 fake_logits = -3.8978 true_prob = 0.6280 fake_prob = 0.0324 
2022-07-08 10:21:01.659403 - gail/main.py:142 - [Evaluate] iter = 240000 episode={ returns = 364.6908 lengths = 137 } discounted_episode={ returns = 337.5256 lengths = 138 } 
2022-07-08 10:21:29.958347 - gail/main.py:174 - [TRPO] iter = 241000 dist_mean = 0.4224 dist_std = 0.5165 vf_loss = 0.2095 grad_norm = 1.3719 nat_grad_norm = 0.4102 cg_residual = 0.2293 step_size = 0.3078 reward = -0.0000 fps = 12 mse_loss = 2.9430 
2022-07-08 10:22:03.909069 - gail/main.py:174 - [TRPO] iter = 242000 dist_mean = 0.4195 dist_std = 0.5149 vf_loss = 0.1889 grad_norm = 0.9528 nat_grad_norm = 0.4233 cg_residual = 0.2601 step_size = 0.3461 reward = -0.0000 fps = 8 mse_loss = 3.2609 
2022-07-08 10:22:31.174949 - gail/main.py:174 - [TRPO] iter = 243000 dist_mean = 0.4342 dist_std = 0.5128 vf_loss = 0.2342 grad_norm = 1.0375 nat_grad_norm = 0.3764 cg_residual = 0.2198 step_size = 0.3398 reward = 0.0000 fps = 6 mse_loss = 3.5415 
2022-07-08 10:22:59.349579 - gail/main.py:174 - [TRPO] iter = 244000 dist_mean = 0.4093 dist_std = 0.5093 vf_loss = 0.1304 grad_norm = 1.6997 nat_grad_norm = 0.3285 cg_residual = 0.2778 step_size = 0.3425 reward = -0.0000 fps = 5 mse_loss = 3.3252 
2022-07-08 10:23:26.751051 - gail/main.py:174 - [TRPO] iter = 245000 dist_mean = 0.4379 dist_std = 0.5098 vf_loss = 0.2038 grad_norm = 1.2604 nat_grad_norm = 0.4127 cg_residual = 0.2289 step_size = 0.3275 reward = -0.0000 fps = 5 mse_loss = 3.3644 
2022-07-08 10:23:27.532781 - gail/main.py:201 - [Discriminator] iter = 245000 loss = -4.1631 grad_norm = 3.2450 grad_penalty = 0.3493 regularization = 0.0000 true_logits = 0.6726 fake_logits = -3.8397 true_prob = 0.6297 fake_prob = 0.0353 
2022-07-08 10:24:20.302396 - gail/main.py:142 - [Evaluate] iter = 245000 episode={ returns = 384.4382 lengths = 141 } discounted_episode={ returns = 353.0055 lengths = 141 } 
2022-07-08 10:24:49.522063 - gail/main.py:174 - [TRPO] iter = 246000 dist_mean = 0.4174 dist_std = 0.5079 vf_loss = 0.2067 grad_norm = 1.1409 nat_grad_norm = 0.3550 cg_residual = 0.2990 step_size = 0.3408 reward = 0.0000 fps = 12 mse_loss = 3.4423 
2022-07-08 10:25:17.716490 - gail/main.py:174 - [TRPO] iter = 247000 dist_mean = 0.4065 dist_std = 0.5054 vf_loss = 0.1570 grad_norm = 0.9813 nat_grad_norm = 0.3942 cg_residual = 0.2281 step_size = 0.3174 reward = -0.0000 fps = 9 mse_loss = 3.3846 
2022-07-08 10:25:46.244052 - gail/main.py:174 - [TRPO] iter = 248000 dist_mean = 0.4315 dist_std = 0.5064 vf_loss = 0.3280 grad_norm = 1.4855 nat_grad_norm = 0.4100 cg_residual = 0.3063 step_size = 0.3034 reward = -0.0000 fps = 7 mse_loss = 3.2273 
2022-07-08 10:26:14.815156 - gail/main.py:174 - [TRPO] iter = 249000 dist_mean = 0.4372 dist_std = 0.5069 vf_loss = 0.1504 grad_norm = 1.0494 nat_grad_norm = 0.4368 cg_residual = 0.4155 step_size = 0.3060 reward = -0.0000 fps = 5 mse_loss = 3.3225 
2022-07-08 10:26:44.421450 - gail/main.py:174 - [TRPO] iter = 250000 dist_mean = 0.4007 dist_std = 0.5056 vf_loss = 0.1920 grad_norm = 1.0670 nat_grad_norm = 0.3457 cg_residual = 0.2365 step_size = 0.3367 reward = -0.0000 fps = 5 mse_loss = 3.1183 
2022-07-08 10:26:45.413859 - gail/main.py:201 - [Discriminator] iter = 250000 loss = -4.1609 grad_norm = 3.1358 grad_penalty = 0.3596 regularization = 0.0000 true_logits = 0.6533 fake_logits = -3.8672 true_prob = 0.6244 fake_prob = 0.0357 
2022-07-08 10:27:41.938499 - gail/main.py:142 - [Evaluate] iter = 250000 episode={ returns = 393.7354 lengths = 141 } discounted_episode={ returns = 360.7939 lengths = 142 } 
2022-07-08 10:28:11.740683 - gail/main.py:174 - [TRPO] iter = 251000 dist_mean = 0.4282 dist_std = 0.5062 vf_loss = 0.1374 grad_norm = 1.4636 nat_grad_norm = 0.3945 cg_residual = 0.2884 step_size = 0.2996 reward = -0.0000 fps = 11 mse_loss = 3.2849 
2022-07-08 10:28:41.282086 - gail/main.py:174 - [TRPO] iter = 252000 dist_mean = 0.4227 dist_std = 0.5039 vf_loss = 0.1376 grad_norm = 1.1095 nat_grad_norm = 0.3446 cg_residual = 0.2417 step_size = 0.3471 reward = 0.0000 fps = 8 mse_loss = 3.4145 
2022-07-08 10:29:11.100102 - gail/main.py:174 - [TRPO] iter = 253000 dist_mean = 0.4120 dist_std = 0.5006 vf_loss = 0.1595 grad_norm = 1.3459 nat_grad_norm = 0.3937 cg_residual = 0.2511 step_size = 0.3088 reward = -0.0000 fps = 6 mse_loss = 3.1463 
2022-07-08 10:29:41.233152 - gail/main.py:174 - [TRPO] iter = 254000 dist_mean = 0.4080 dist_std = 0.4996 vf_loss = 0.1781 grad_norm = 1.5093 nat_grad_norm = 0.3787 cg_residual = 0.2668 step_size = 0.3102 reward = 0.0000 fps = 5 mse_loss = 3.2648 
2022-07-08 10:30:11.222159 - gail/main.py:174 - [TRPO] iter = 255000 dist_mean = 0.4151 dist_std = 0.4991 vf_loss = 0.1382 grad_norm = 1.1884 nat_grad_norm = 0.4038 cg_residual = 0.2860 step_size = 0.3174 reward = 0.0000 fps = 4 mse_loss = 3.3954 
2022-07-08 10:30:12.089855 - gail/main.py:201 - [Discriminator] iter = 255000 loss = -4.1433 grad_norm = 2.9086 grad_penalty = 0.3540 regularization = 0.0000 true_logits = 0.7917 fake_logits = -3.7056 true_prob = 0.6477 fake_prob = 0.0408 
2022-07-08 10:31:08.441213 - gail/main.py:142 - [Evaluate] iter = 255000 episode={ returns = 393.7726 lengths = 139 } discounted_episode={ returns = 361.8826 lengths = 139 } 
2022-07-08 10:31:45.289418 - gail/main.py:174 - [TRPO] iter = 256000 dist_mean = 0.4192 dist_std = 0.4937 vf_loss = 0.1557 grad_norm = 1.3370 nat_grad_norm = 0.3549 cg_residual = 0.2288 step_size = 0.3439 reward = -0.0000 fps = 10 mse_loss = 3.5893 
2022-07-08 10:32:07.388328 - gail/main.py:174 - [TRPO] iter = 257000 dist_mean = 0.4105 dist_std = 0.4936 vf_loss = 0.0720 grad_norm = 1.2527 nat_grad_norm = 0.3438 cg_residual = 0.1708 step_size = 0.3465 reward = -0.0000 fps = 8 mse_loss = 3.3916 
2022-07-08 10:32:14.580703 - gail/main.py:174 - [TRPO] iter = 258000 dist_mean = 0.3985 dist_std = 0.4915 vf_loss = 0.0902 grad_norm = 1.2781 nat_grad_norm = 0.3399 cg_residual = 0.2158 step_size = 0.3467 reward = -0.0000 fps = 8 mse_loss = 3.5002 
2022-07-08 10:32:24.158443 - gail/main.py:174 - [TRPO] iter = 259000 dist_mean = 0.4347 dist_std = 0.4878 vf_loss = 0.1193 grad_norm = 1.2215 nat_grad_norm = 0.3159 cg_residual = 0.1594 step_size = 0.3648 reward = -0.0000 fps = 7 mse_loss = 3.3822 
2022-07-08 10:32:33.671734 - gail/main.py:174 - [TRPO] iter = 260000 dist_mean = 0.4114 dist_std = 0.4860 vf_loss = 0.0862 grad_norm = 0.8929 nat_grad_norm = 0.4095 cg_residual = 0.3094 step_size = 0.3212 reward = 0.0000 fps = 7 mse_loss = 3.8700 
2022-07-08 10:32:34.078498 - gail/main.py:201 - [Discriminator] iter = 260000 loss = -4.2588 grad_norm = 3.7366 grad_penalty = 0.3712 regularization = 0.0000 true_logits = 0.8710 fake_logits = -3.7590 true_prob = 0.6558 fake_prob = 0.0424 
