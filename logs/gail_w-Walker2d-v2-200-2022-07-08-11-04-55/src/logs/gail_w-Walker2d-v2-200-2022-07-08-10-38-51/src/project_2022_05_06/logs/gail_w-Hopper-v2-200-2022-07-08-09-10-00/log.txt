2022-07-08 09:10:01.106129 - utils/flags.py:257 - log_dir = logs/gail_w-Hopper-v2-200-2022-07-08-09-10-00
2022-07-08 09:10:32.597292 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Hopper-v2
2022-07-08 09:11:01.839611 - gail/main.py:80 - Expert Reward 3582.436530
2022-07-08 09:11:03.372948 - gail/main.py:84 - Original dataset size 3000
2022-07-08 09:11:03.504901 - gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 09:11:03.529444 - gail/main.py:87 - np random: 864 random : 786
2022-07-08 09:11:03.574668 - gail/main.py:91 - Sampled obs: 0.4652, acs: 0.0749
2022-07-08 09:11:09.891774 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 09:11:48.802939 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 09:11:48.994851 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.3966653  -0.06165453 -0.19472611 -0.4584401   0.18350822  2.5732448
   0.00400542 -0.00549955 -0.04755233 -0.02386179  0.00759995]] 
 scale:[[0.16755195 0.05883223 0.15990146 0.34682125 0.5992658  0.6461788
  1.5187451  0.8811966  2.0685835  3.6282625  5.862049  ]]
2022-07-08 09:12:07.142456 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 09:12:07.178419 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(14, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 09:12:07.204510 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 09:12:11.449808 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 09:13:21.503964 - gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 151.7944 lengths = 165 } discounted_episode={ returns = 145.6909 lengths = 173 } 
2022-07-08 09:13:21.514423 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 09:13:59.441846 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 09:14:00.611055 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 09:14:02.422351 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 09:14:03.354775 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 09:14:09.487308 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 09:14:21.055448 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 09:14:22.031752 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 09:14:23.095296 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 09:14:25.084917 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 09:14:28.368057 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 09:14:29.359657 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 09:14:30.452318 - gail/main.py:174 - [TRPO] iter = 1000 dist_mean = -0.0000 dist_std = 1.0000 vf_loss = 0.2514 grad_norm = 0.3047 nat_grad_norm = 0.3393 cg_residual = 0.0000 step_size = 0.4765 reward = 0.0000 fps = 7 mse_loss = 0.3253 
2022-07-08 09:15:01.022895 - gail/main.py:174 - [TRPO] iter = 2000 dist_mean = 0.0570 dist_std = 1.0017 vf_loss = 0.3318 grad_norm = 0.3617 nat_grad_norm = 0.4168 cg_residual = 0.0000 step_size = 0.4072 reward = 0.0000 fps = 5 mse_loss = 0.3659 
2022-07-08 09:15:29.796228 - gail/main.py:174 - [TRPO] iter = 3000 dist_mean = 0.1010 dist_std = 0.9916 vf_loss = 0.2525 grad_norm = 0.3418 nat_grad_norm = 0.3390 cg_residual = 0.0000 step_size = 0.4626 reward = 0.0000 fps = 5 mse_loss = 0.3793 
2022-07-08 09:15:59.207563 - gail/main.py:174 - [TRPO] iter = 4000 dist_mean = 0.1515 dist_std = 0.9764 vf_loss = 0.3282 grad_norm = 0.2820 nat_grad_norm = 0.3051 cg_residual = 0.0000 step_size = 0.5470 reward = -0.0000 fps = 4 mse_loss = 0.3545 
2022-07-08 09:16:27.108737 - gail/main.py:174 - [TRPO] iter = 5000 dist_mean = 0.1659 dist_std = 0.9587 vf_loss = 0.3746 grad_norm = 0.2795 nat_grad_norm = 0.3719 cg_residual = 0.0000 step_size = 0.6178 reward = 0.0000 fps = 3 mse_loss = 0.4274 
2022-07-08 09:16:27.111080 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 09:16:36.157734 - gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.5168 grad_norm = 13.1276 grad_penalty = 1.5373 regularization = 0.0000 true_logits = -0.2267 fake_logits = -0.2472 true_prob = 0.4439 fake_prob = 0.4387 
2022-07-08 09:17:18.634672 - gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = 212.3677 lengths = 110 } discounted_episode={ returns = 202.3702 lengths = 111 } 
2022-07-08 09:17:47.409764 - gail/main.py:174 - [TRPO] iter = 6000 dist_mean = 0.2075 dist_std = 0.9529 vf_loss = 0.3781 grad_norm = 0.3119 nat_grad_norm = 0.3829 cg_residual = 0.0000 step_size = 0.5587 reward = 0.0000 fps = 14 mse_loss = 0.4183 
2022-07-08 09:18:14.935975 - gail/main.py:174 - [TRPO] iter = 7000 dist_mean = 0.1994 dist_std = 0.9398 vf_loss = 0.4616 grad_norm = 0.3044 nat_grad_norm = 0.4053 cg_residual = 0.0000 step_size = 0.5058 reward = 0.0000 fps = 10 mse_loss = 0.4898 
2022-07-08 09:18:42.721936 - gail/main.py:174 - [TRPO] iter = 8000 dist_mean = 0.2148 dist_std = 0.9394 vf_loss = 0.3368 grad_norm = 0.3283 nat_grad_norm = 0.2875 cg_residual = 0.0000 step_size = 0.6728 reward = -0.0000 fps = 7 mse_loss = 0.4930 
2022-07-08 09:19:11.610236 - gail/main.py:174 - [TRPO] iter = 9000 dist_mean = 0.2162 dist_std = 0.9513 vf_loss = 0.4786 grad_norm = 0.3392 nat_grad_norm = 0.3608 cg_residual = 0.0000 step_size = 0.5537 reward = -0.0000 fps = 6 mse_loss = 0.5917 
2022-07-08 09:19:39.559138 - gail/main.py:174 - [TRPO] iter = 10000 dist_mean = 0.2444 dist_std = 0.9428 vf_loss = 0.5203 grad_norm = 0.3483 nat_grad_norm = 0.3780 cg_residual = 0.0000 step_size = 0.5376 reward = -0.0000 fps = 5 mse_loss = 0.5879 
2022-07-08 09:19:40.317530 - gail/main.py:201 - [Discriminator] iter = 10000 loss = 1.1647 grad_norm = 11.8083 grad_penalty = 1.2152 regularization = 0.0000 true_logits = -0.2148 fake_logits = -0.2652 true_prob = 0.4468 fake_prob = 0.4343 
2022-07-08 09:20:17.884019 - gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = 212.8109 lengths = 102 } discounted_episode={ returns = 200.6702 lengths = 102 } 
2022-07-08 09:20:45.593526 - gail/main.py:174 - [TRPO] iter = 11000 dist_mean = 0.2034 dist_std = 0.9360 vf_loss = 0.3714 grad_norm = 0.4180 nat_grad_norm = 0.3630 cg_residual = 0.0000 step_size = 0.5608 reward = 0.0000 fps = 15 mse_loss = 0.5669 
2022-07-08 09:21:12.503321 - gail/main.py:174 - [TRPO] iter = 12000 dist_mean = 0.2222 dist_std = 0.9287 vf_loss = 0.3097 grad_norm = 0.3477 nat_grad_norm = 0.3733 cg_residual = 0.0001 step_size = 0.5640 reward = -0.0000 fps = 10 mse_loss = 0.6244 
2022-07-08 09:21:39.633084 - gail/main.py:174 - [TRPO] iter = 13000 dist_mean = 0.2226 dist_std = 0.9231 vf_loss = 0.3194 grad_norm = 0.3439 nat_grad_norm = 0.4140 cg_residual = 0.0001 step_size = 0.4991 reward = -0.0000 fps = 8 mse_loss = 0.6310 
2022-07-08 09:22:13.762718 - gail/main.py:174 - [TRPO] iter = 14000 dist_mean = 0.2330 dist_std = 0.9168 vf_loss = 0.1945 grad_norm = 0.3866 nat_grad_norm = 0.4637 cg_residual = 0.0001 step_size = 0.4829 reward = -0.0000 fps = 6 mse_loss = 0.6749 
2022-07-08 09:22:41.039714 - gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.2551 dist_std = 0.8989 vf_loss = 0.1861 grad_norm = 0.3426 nat_grad_norm = 0.3643 cg_residual = 0.0002 step_size = 0.6016 reward = -0.0000 fps = 5 mse_loss = 0.6948 
2022-07-08 09:22:41.888995 - gail/main.py:201 - [Discriminator] iter = 15000 loss = 0.6386 grad_norm = 8.3017 grad_penalty = 0.7459 regularization = 0.0000 true_logits = -0.1843 fake_logits = -0.2916 true_prob = 0.4543 fake_prob = 0.4279 
2022-07-08 09:23:09.815667 - gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = 155.8603 lengths = 75 } discounted_episode={ returns = 148.5311 lengths = 75 } 
2022-07-08 09:23:37.583597 - gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.2386 dist_std = 0.8888 vf_loss = 0.2245 grad_norm = 0.4049 nat_grad_norm = 0.3847 cg_residual = 0.0001 step_size = 0.5365 reward = -0.0000 fps = 17 mse_loss = 0.6923 
2022-07-08 09:24:04.671732 - gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.2551 dist_std = 0.8834 vf_loss = 0.3139 grad_norm = 0.3426 nat_grad_norm = 0.4557 cg_residual = 0.0002 step_size = 0.5624 reward = -0.0000 fps = 12 mse_loss = 0.7085 
2022-07-08 09:24:30.589519 - gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.2783 dist_std = 0.8784 vf_loss = 0.1582 grad_norm = 0.3786 nat_grad_norm = 0.3808 cg_residual = 0.0002 step_size = 0.5186 reward = -0.0000 fps = 9 mse_loss = 0.7464 
2022-07-08 09:24:56.218647 - gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.2793 dist_std = 0.8624 vf_loss = 0.1068 grad_norm = 0.4843 nat_grad_norm = 0.3254 cg_residual = 0.0001 step_size = 0.4530 reward = -0.0000 fps = 7 mse_loss = 0.8593 
2022-07-08 09:25:22.204645 - gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.2635 dist_std = 0.8452 vf_loss = 0.1228 grad_norm = 0.5489 nat_grad_norm = 0.3241 cg_residual = 0.0002 step_size = 0.5241 reward = 0.0000 fps = 6 mse_loss = 0.8033 
2022-07-08 09:25:22.941281 - gail/main.py:201 - [Discriminator] iter = 20000 loss = 0.3868 grad_norm = 5.3833 grad_penalty = 0.5608 regularization = 0.0000 true_logits = -0.1438 fake_logits = -0.3178 true_prob = 0.4644 fake_prob = 0.4216 
2022-07-08 09:25:47.385060 - gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = 140.3872 lengths = 69 } discounted_episode={ returns = 136.0499 lengths = 69 } 
2022-07-08 09:26:15.996334 - gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.2476 dist_std = 0.8274 vf_loss = 0.0758 grad_norm = 0.4850 nat_grad_norm = 0.2344 cg_residual = 0.0001 step_size = 0.6442 reward = -0.0000 fps = 18 mse_loss = 0.8782 
2022-07-08 09:26:43.936262 - gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.2456 dist_std = 0.8096 vf_loss = 0.0813 grad_norm = 0.4105 nat_grad_norm = 0.2989 cg_residual = 0.0002 step_size = 0.6027 reward = 0.0000 fps = 12 mse_loss = 0.8778 
2022-07-08 09:27:10.481803 - gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.2251 dist_std = 0.7965 vf_loss = 0.0423 grad_norm = 0.5567 nat_grad_norm = 0.3364 cg_residual = 0.0007 step_size = 0.4910 reward = -0.0000 fps = 9 mse_loss = 1.0011 
2022-07-08 09:27:36.216433 - gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.2032 dist_std = 0.7772 vf_loss = 0.0528 grad_norm = 0.5639 nat_grad_norm = 0.3291 cg_residual = 0.0009 step_size = 0.5261 reward = 0.0000 fps = 7 mse_loss = 0.9172 
2022-07-08 09:28:02.297321 - gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.1975 dist_std = 0.7621 vf_loss = 0.0547 grad_norm = 0.7780 nat_grad_norm = 0.3132 cg_residual = 0.0006 step_size = 0.4485 reward = -0.0000 fps = 6 mse_loss = 0.9994 
2022-07-08 09:28:03.112314 - gail/main.py:201 - [Discriminator] iter = 25000 loss = 0.2326 grad_norm = 5.2508 grad_penalty = 0.5157 regularization = 0.0000 true_logits = -0.1168 fake_logits = -0.3999 true_prob = 0.4711 fake_prob = 0.4020 
2022-07-08 09:28:28.412040 - gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = 151.4039 lengths = 72 } discounted_episode={ returns = 143.7783 lengths = 71 } 
2022-07-08 09:28:55.438087 - gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.2152 dist_std = 0.7457 vf_loss = 0.0552 grad_norm = 0.5437 nat_grad_norm = 0.2900 cg_residual = 0.0007 step_size = 0.5696 reward = -0.0000 fps = 19 mse_loss = 1.0861 
2022-07-08 09:29:22.465335 - gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.2367 dist_std = 0.7348 vf_loss = 0.0565 grad_norm = 0.5984 nat_grad_norm = 0.2684 cg_residual = 0.0006 step_size = 0.5448 reward = -0.0000 fps = 12 mse_loss = 1.2726 
2022-07-08 09:29:48.783804 - gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.1962 dist_std = 0.7214 vf_loss = 0.0336 grad_norm = 0.8070 nat_grad_norm = 0.3504 cg_residual = 0.0023 step_size = 0.4136 reward = 0.0000 fps = 9 mse_loss = 1.1631 
2022-07-08 09:30:14.663926 - gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.2077 dist_std = 0.7080 vf_loss = 0.0603 grad_norm = 0.8653 nat_grad_norm = 0.3128 cg_residual = 0.0019 step_size = 0.4225 reward = -0.0000 fps = 7 mse_loss = 1.2068 
2022-07-08 09:30:41.067210 - gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.2169 dist_std = 0.7044 vf_loss = 0.0729 grad_norm = 0.7730 nat_grad_norm = 0.3587 cg_residual = 0.0020 step_size = 0.4452 reward = -0.0000 fps = 6 mse_loss = 1.1024 
2022-07-08 09:30:41.774863 - gail/main.py:201 - [Discriminator] iter = 30000 loss = 0.0636 grad_norm = 5.2505 grad_penalty = 0.4787 regularization = 0.0000 true_logits = -0.0929 fake_logits = -0.5080 true_prob = 0.4772 fake_prob = 0.3767 
2022-07-08 09:31:09.881890 - gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = 181.4794 lengths = 81 } discounted_episode={ returns = 173.9151 lengths = 81 } 
2022-07-08 09:31:36.500789 - gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.2297 dist_std = 0.6905 vf_loss = 0.0663 grad_norm = 0.4081 nat_grad_norm = 0.3554 cg_residual = 0.0016 step_size = 0.5270 reward = 0.0000 fps = 18 mse_loss = 1.3083 
2022-07-08 09:32:02.475992 - gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.2110 dist_std = 0.6807 vf_loss = 0.0533 grad_norm = 0.6239 nat_grad_norm = 0.3122 cg_residual = 0.0025 step_size = 0.4790 reward = 0.0000 fps = 12 mse_loss = 1.3966 
2022-07-08 09:32:35.152311 - gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.2353 dist_std = 0.6679 vf_loss = 0.0466 grad_norm = 0.5990 nat_grad_norm = 0.3800 cg_residual = 0.0039 step_size = 0.5146 reward = 0.0000 fps = 8 mse_loss = 1.5581 
2022-07-08 09:33:00.843548 - gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.2349 dist_std = 0.6641 vf_loss = 0.0286 grad_norm = 0.4840 nat_grad_norm = 0.3888 cg_residual = 0.0039 step_size = 0.5091 reward = -0.0000 fps = 7 mse_loss = 1.6106 
2022-07-08 09:33:27.497571 - gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.2306 dist_std = 0.6598 vf_loss = 0.0426 grad_norm = 0.4497 nat_grad_norm = 0.3282 cg_residual = 0.0040 step_size = 0.5352 reward = -0.0000 fps = 6 mse_loss = 1.8104 
2022-07-08 09:33:28.215776 - gail/main.py:201 - [Discriminator] iter = 35000 loss = -0.1942 grad_norm = 5.6992 grad_penalty = 0.4096 regularization = 0.0000 true_logits = -0.0502 fake_logits = -0.6541 true_prob = 0.4878 fake_prob = 0.3438 
2022-07-08 09:33:56.846328 - gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 187.6796 lengths = 82 } discounted_episode={ returns = 178.5474 lengths = 83 } 
2022-07-08 09:34:22.059673 - gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.2137 dist_std = 0.6462 vf_loss = 0.0416 grad_norm = 0.5041 nat_grad_norm = 0.2427 cg_residual = 0.0026 step_size = 0.5977 reward = 0.0000 fps = 18 mse_loss = 1.9085 
2022-07-08 09:34:47.626145 - gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.2267 dist_std = 0.6399 vf_loss = 0.0427 grad_norm = 0.8805 nat_grad_norm = 0.3497 cg_residual = 0.0065 step_size = 0.5154 reward = 0.0000 fps = 12 mse_loss = 1.8510 
2022-07-08 09:35:13.524695 - gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.2104 dist_std = 0.6291 vf_loss = 0.0204 grad_norm = 0.7024 nat_grad_norm = 0.2511 cg_residual = 0.0030 step_size = 0.5782 reward = 0.0000 fps = 9 mse_loss = 1.7818 
2022-07-08 09:35:39.443366 - gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.2242 dist_std = 0.6199 vf_loss = 0.0282 grad_norm = 0.6286 nat_grad_norm = 0.2968 cg_residual = 0.0062 step_size = 0.5880 reward = 0.0000 fps = 7 mse_loss = 1.8711 
2022-07-08 09:36:03.910850 - gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.1909 dist_std = 0.6162 vf_loss = 0.0203 grad_norm = 0.5197 nat_grad_norm = 0.2785 cg_residual = 0.0061 step_size = 0.6007 reward = -0.0000 fps = 6 mse_loss = 1.8370 
2022-07-08 09:36:04.620733 - gail/main.py:201 - [Discriminator] iter = 40000 loss = -0.4049 grad_norm = 5.5519 grad_penalty = 0.3653 regularization = 0.0000 true_logits = -0.0584 fake_logits = -0.8287 true_prob = 0.4863 fake_prob = 0.3067 
2022-07-08 09:36:32.292098 - gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 185.1044 lengths = 82 } discounted_episode={ returns = 176.4178 lengths = 82 } 
2022-07-08 09:36:57.554392 - gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.2270 dist_std = 0.6042 vf_loss = 0.0375 grad_norm = 0.5923 nat_grad_norm = 0.4153 cg_residual = 0.0087 step_size = 0.4570 reward = -0.0000 fps = 18 mse_loss = 2.0923 
2022-07-08 09:37:21.968227 - gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.2205 dist_std = 0.5938 vf_loss = 0.0152 grad_norm = 0.9188 nat_grad_norm = 0.3256 cg_residual = 0.0056 step_size = 0.4723 reward = 0.0000 fps = 12 mse_loss = 1.8826 
2022-07-08 09:37:47.560900 - gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.2076 dist_std = 0.5898 vf_loss = 0.0196 grad_norm = 0.9524 nat_grad_norm = 0.3844 cg_residual = 0.0219 step_size = 0.4208 reward = -0.0000 fps = 9 mse_loss = 2.0372 
2022-07-08 09:38:12.562697 - gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.2036 dist_std = 0.5833 vf_loss = 0.0260 grad_norm = 0.7796 nat_grad_norm = 0.3481 cg_residual = 0.0428 step_size = 0.4877 reward = 0.0000 fps = 7 mse_loss = 1.9859 
2022-07-08 09:38:37.549737 - gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.2005 dist_std = 0.5716 vf_loss = 0.0432 grad_norm = 0.8479 nat_grad_norm = 0.3042 cg_residual = 0.0211 step_size = 0.4385 reward = -0.0000 fps = 6 mse_loss = 2.3184 
2022-07-08 09:38:38.342943 - gail/main.py:201 - [Discriminator] iter = 45000 loss = -0.5579 grad_norm = 4.9007 grad_penalty = 0.3805 regularization = 0.0000 true_logits = -0.0340 fake_logits = -0.9724 true_prob = 0.4928 fake_prob = 0.2785 
2022-07-08 09:39:06.581150 - gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 192.8000 lengths = 84 } discounted_episode={ returns = 183.5244 lengths = 84 } 
2022-07-08 09:39:32.065696 - gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.2004 dist_std = 0.5585 vf_loss = 0.0220 grad_norm = 1.0817 nat_grad_norm = 0.2836 cg_residual = 0.0448 step_size = 0.4759 reward = 0.0000 fps = 18 mse_loss = 2.3520 
2022-07-08 09:39:57.766552 - gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.1789 dist_std = 0.5493 vf_loss = 0.0337 grad_norm = 1.0988 nat_grad_norm = 0.2996 cg_residual = 0.0283 step_size = 0.4301 reward = -0.0000 fps = 12 mse_loss = 2.5246 
2022-07-08 09:40:23.886724 - gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.1807 dist_std = 0.5389 vf_loss = 0.0622 grad_norm = 1.2491 nat_grad_norm = 0.2004 cg_residual = 0.0407 step_size = 0.4819 reward = 0.0000 fps = 9 mse_loss = 2.5563 
2022-07-08 09:40:49.544175 - gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.1994 dist_std = 0.5332 vf_loss = 0.0467 grad_norm = 1.5604 nat_grad_norm = 0.3106 cg_residual = 0.0546 step_size = 0.4091 reward = -0.0000 fps = 7 mse_loss = 2.6147 
2022-07-08 09:41:14.298910 - gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.1871 dist_std = 0.5267 vf_loss = 0.0646 grad_norm = 1.1572 nat_grad_norm = 0.1967 cg_residual = 0.0274 step_size = 0.4869 reward = -0.0000 fps = 6 mse_loss = 2.4905 
2022-07-08 09:41:15.007271 - gail/main.py:201 - [Discriminator] iter = 50000 loss = -0.8306 grad_norm = 5.3214 grad_penalty = 0.3350 regularization = 0.0000 true_logits = -0.0386 fake_logits = -1.2042 true_prob = 0.4924 fake_prob = 0.2361 
2022-07-08 09:41:46.849477 - gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 236.7419 lengths = 95 } discounted_episode={ returns = 223.0379 lengths = 95 } 
2022-07-08 09:42:17.903756 - gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.1683 dist_std = 0.5185 vf_loss = 0.0812 grad_norm = 1.9120 nat_grad_norm = 0.2433 cg_residual = 0.1431 step_size = 0.3944 reward = -0.0000 fps = 15 mse_loss = 2.6689 
2022-07-08 09:42:43.010183 - gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.1597 dist_std = 0.5171 vf_loss = 0.0799 grad_norm = 2.0665 nat_grad_norm = 0.2276 cg_residual = 0.0272 step_size = 0.4056 reward = 0.0000 fps = 11 mse_loss = 2.8093 
2022-07-08 09:43:07.339042 - gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.1639 dist_std = 0.5221 vf_loss = 0.0402 grad_norm = 1.7922 nat_grad_norm = 0.2170 cg_residual = 0.0245 step_size = 0.4597 reward = 0.0000 fps = 8 mse_loss = 2.6074 
2022-07-08 09:43:30.892311 - gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.1356 dist_std = 0.5200 vf_loss = 0.0398 grad_norm = 1.6319 nat_grad_norm = 0.1887 cg_residual = 0.0306 step_size = 0.4781 reward = 0.0000 fps = 7 mse_loss = 2.6353 
2022-07-08 09:43:54.867560 - gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.1215 dist_std = 0.5182 vf_loss = 0.0680 grad_norm = 1.5209 nat_grad_norm = 0.2194 cg_residual = 0.0271 step_size = 0.4677 reward = -0.0000 fps = 6 mse_loss = 2.6093 
2022-07-08 09:43:55.603888 - gail/main.py:201 - [Discriminator] iter = 55000 loss = -1.0355 grad_norm = 4.1591 grad_penalty = 0.2803 regularization = 0.0000 true_logits = -0.0452 fake_logits = -1.3610 true_prob = 0.4921 fake_prob = 0.2112 
2022-07-08 09:44:28.464057 - gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 258.0774 lengths = 101 } discounted_episode={ returns = 242.3798 lengths = 101 } 
2022-07-08 09:44:52.643821 - gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.1102 dist_std = 0.5088 vf_loss = 0.0802 grad_norm = 1.4154 nat_grad_norm = 0.2481 cg_residual = 0.0588 step_size = 0.4327 reward = 0.0000 fps = 17 mse_loss = 2.8115 
2022-07-08 09:45:16.303395 - gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.0999 dist_std = 0.5079 vf_loss = 0.0440 grad_norm = 2.0247 nat_grad_norm = 0.2551 cg_residual = 0.0648 step_size = 0.4178 reward = 0.0000 fps = 12 mse_loss = 2.5531 
2022-07-08 09:45:40.473655 - gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.0984 dist_std = 0.5034 vf_loss = 0.0622 grad_norm = 2.3810 nat_grad_norm = 0.2053 cg_residual = 0.0349 step_size = 0.4392 reward = 0.0000 fps = 9 mse_loss = 2.6552 
2022-07-08 09:46:04.974147 - gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.0929 dist_std = 0.5075 vf_loss = 0.0645 grad_norm = 1.9058 nat_grad_norm = 0.2688 cg_residual = 0.0450 step_size = 0.4045 reward = 0.0000 fps = 7 mse_loss = 2.9088 
2022-07-08 09:46:29.089778 - gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.1018 dist_std = 0.4961 vf_loss = 0.1711 grad_norm = 1.9180 nat_grad_norm = 0.2571 cg_residual = 0.0622 step_size = 0.4048 reward = -0.0000 fps = 6 mse_loss = 2.7993 
2022-07-08 09:46:29.824976 - gail/main.py:201 - [Discriminator] iter = 60000 loss = -1.1345 grad_norm = 4.4884 grad_penalty = 0.2386 regularization = 0.0000 true_logits = -0.1144 fake_logits = -1.4876 true_prob = 0.4771 fake_prob = 0.1948 
2022-07-08 09:47:05.685598 - gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 288.8926 lengths = 108 } discounted_episode={ returns = 270.0255 lengths = 108 } 
2022-07-08 09:47:30.853139 - gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.1050 dist_std = 0.4961 vf_loss = 0.2081 grad_norm = 1.3136 nat_grad_norm = 0.3165 cg_residual = 0.0620 step_size = 0.4077 reward = 0.0000 fps = 16 mse_loss = 2.8284 
2022-07-08 09:47:55.346656 - gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.0965 dist_std = 0.4882 vf_loss = 0.0766 grad_norm = 1.3628 nat_grad_norm = 0.2430 cg_residual = 0.0281 step_size = 0.4707 reward = -0.0000 fps = 11 mse_loss = 2.7309 
2022-07-08 09:48:19.027849 - gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.0709 dist_std = 0.4839 vf_loss = 0.0930 grad_norm = 2.1558 nat_grad_norm = 0.2255 cg_residual = 0.0435 step_size = 0.3683 reward = 0.0000 fps = 9 mse_loss = 2.8125 
2022-07-08 09:48:43.136079 - gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.0852 dist_std = 0.4827 vf_loss = 0.0683 grad_norm = 1.7167 nat_grad_norm = 0.2288 cg_residual = 0.1404 step_size = 0.4399 reward = 0.0000 fps = 7 mse_loss = 2.7384 
2022-07-08 09:49:07.231680 - gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.0757 dist_std = 0.4753 vf_loss = 0.0803 grad_norm = 1.5177 nat_grad_norm = 0.2349 cg_residual = 0.1608 step_size = 0.4585 reward = -0.0000 fps = 6 mse_loss = 2.7207 
2022-07-08 09:49:07.984850 - gail/main.py:201 - [Discriminator] iter = 65000 loss = -1.2388 grad_norm = 3.7651 grad_penalty = 0.2464 regularization = 0.0000 true_logits = -0.0966 fake_logits = -1.5818 true_prob = 0.4816 fake_prob = 0.1842 
2022-07-08 09:49:46.173100 - gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 315.8386 lengths = 115 } discounted_episode={ returns = 296.2392 lengths = 115 } 
2022-07-08 09:50:13.009953 - gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.0715 dist_std = 0.4762 vf_loss = 0.0420 grad_norm = 1.1831 nat_grad_norm = 0.2214 cg_residual = 0.1158 step_size = 0.5430 reward = -0.0000 fps = 15 mse_loss = 2.8607 
2022-07-08 09:50:38.221682 - gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.0764 dist_std = 0.4773 vf_loss = 0.1023 grad_norm = 1.8436 nat_grad_norm = 0.2368 cg_residual = 0.2460 step_size = 0.4324 reward = -0.0000 fps = 11 mse_loss = 2.5576 
2022-07-08 09:51:01.517960 - gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.0685 dist_std = 0.4727 vf_loss = 0.0632 grad_norm = 1.1280 nat_grad_norm = 0.3254 cg_residual = 0.0576 step_size = 0.4660 reward = 0.0000 fps = 8 mse_loss = 2.8297 
2022-07-08 09:51:25.212345 - gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.0377 dist_std = 0.4706 vf_loss = 0.0471 grad_norm = 1.3872 nat_grad_norm = 0.2342 cg_residual = 0.2548 step_size = 0.5525 reward = 0.0000 fps = 7 mse_loss = 3.0923 
2022-07-08 09:51:48.476797 - gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.0612 dist_std = 0.4675 vf_loss = 0.0692 grad_norm = 1.1273 nat_grad_norm = 0.2733 cg_residual = 0.0513 step_size = 0.4433 reward = -0.0000 fps = 6 mse_loss = 2.9432 
2022-07-08 09:51:49.219555 - gail/main.py:201 - [Discriminator] iter = 70000 loss = -1.2906 grad_norm = 3.8430 grad_penalty = 0.2551 regularization = 0.0000 true_logits = -0.0855 fake_logits = -1.6312 true_prob = 0.4851 fake_prob = 0.1783 
2022-07-08 09:52:35.653619 - gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 341.6816 lengths = 121 } discounted_episode={ returns = 317.1510 lengths = 121 } 
2022-07-08 09:53:00.064521 - gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.0402 dist_std = 0.4698 vf_loss = 0.0464 grad_norm = 0.9538 nat_grad_norm = 0.1970 cg_residual = 0.0342 step_size = 0.5477 reward = 0.0000 fps = 14 mse_loss = 2.8640 
2022-07-08 09:53:25.533649 - gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.0400 dist_std = 0.4660 vf_loss = 0.0443 grad_norm = 0.9240 nat_grad_norm = 0.2842 cg_residual = 0.0634 step_size = 0.4931 reward = -0.0000 fps = 10 mse_loss = 2.9925 
2022-07-08 09:53:50.534968 - gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.0410 dist_std = 0.4631 vf_loss = 0.0581 grad_norm = 1.2830 nat_grad_norm = 0.2381 cg_residual = 0.1171 step_size = 0.5273 reward = 0.0000 fps = 8 mse_loss = 2.9179 
2022-07-08 09:54:16.239445 - gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.0332 dist_std = 0.4569 vf_loss = 0.1275 grad_norm = 1.4829 nat_grad_norm = 0.2133 cg_residual = 0.3049 step_size = 0.4616 reward = -0.0000 fps = 6 mse_loss = 2.9053 
2022-07-08 09:54:41.407265 - gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.0534 dist_std = 0.4580 vf_loss = 0.1106 grad_norm = 1.5426 nat_grad_norm = 0.2943 cg_residual = 0.0531 step_size = 0.4281 reward = -0.0000 fps = 5 mse_loss = 2.8938 
2022-07-08 09:54:42.177249 - gail/main.py:201 - [Discriminator] iter = 75000 loss = -1.2890 grad_norm = 3.6793 grad_penalty = 0.2328 regularization = 0.0000 true_logits = -0.0928 fake_logits = -1.6145 true_prob = 0.4828 fake_prob = 0.1805 
2022-07-08 09:55:21.533425 - gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 368.3868 lengths = 128 } discounted_episode={ returns = 341.4907 lengths = 128 } 
2022-07-08 09:55:44.551059 - gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.0553 dist_std = 0.4534 vf_loss = 0.0695 grad_norm = 1.1026 nat_grad_norm = 0.2114 cg_residual = 0.1962 step_size = 0.5978 reward = 0.0000 fps = 16 mse_loss = 3.1662 
2022-07-08 09:56:07.671982 - gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.0454 dist_std = 0.4581 vf_loss = 0.0546 grad_norm = 1.2326 nat_grad_norm = 0.3546 cg_residual = 0.1960 step_size = 0.3894 reward = 0.0000 fps = 11 mse_loss = 3.1279 
2022-07-08 09:56:29.907962 - gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.0588 dist_std = 0.4567 vf_loss = 0.0783 grad_norm = 1.5479 nat_grad_norm = 0.1890 cg_residual = 0.1228 step_size = 0.5084 reward = -0.0000 fps = 9 mse_loss = 3.1044 
2022-07-08 09:56:52.713668 - gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.0483 dist_std = 0.4516 vf_loss = 0.0822 grad_norm = 1.3911 nat_grad_norm = 0.2304 cg_residual = 0.0430 step_size = 0.4694 reward = -0.0000 fps = 7 mse_loss = 3.3125 
2022-07-08 09:57:16.095933 - gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.0395 dist_std = 0.4471 vf_loss = 0.0761 grad_norm = 0.6621 nat_grad_norm = 0.1953 cg_residual = 0.0401 step_size = 0.5939 reward = 0.0000 fps = 6 mse_loss = 3.1988 
2022-07-08 09:57:16.825400 - gail/main.py:201 - [Discriminator] iter = 80000 loss = -1.2838 grad_norm = 3.3050 grad_penalty = 0.2048 regularization = 0.0000 true_logits = -0.1021 fake_logits = -1.5908 true_prob = 0.4826 fake_prob = 0.1858 
2022-07-08 09:57:56.872065 - gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 388.7339 lengths = 135 } discounted_episode={ returns = 359.7117 lengths = 135 } 
2022-07-08 09:58:20.668795 - gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.0423 dist_std = 0.4413 vf_loss = 0.0878 grad_norm = 0.9069 nat_grad_norm = 0.2530 cg_residual = 0.1414 step_size = 0.5440 reward = -0.0000 fps = 15 mse_loss = 3.6082 
2022-07-08 09:58:45.617623 - gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.0330 dist_std = 0.4421 vf_loss = 0.1195 grad_norm = 1.5128 nat_grad_norm = 0.3176 cg_residual = 0.1481 step_size = 0.4403 reward = -0.0000 fps = 11 mse_loss = 3.7751 
2022-07-08 09:59:09.466496 - gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.0312 dist_std = 0.4379 vf_loss = 0.0756 grad_norm = 1.7340 nat_grad_norm = 0.2237 cg_residual = 0.1190 step_size = 0.4577 reward = -0.0000 fps = 8 mse_loss = 3.7723 
2022-07-08 09:59:34.168547 - gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.0505 dist_std = 0.4365 vf_loss = 0.1083 grad_norm = 1.9647 nat_grad_norm = 0.2378 cg_residual = 0.0888 step_size = 0.3876 reward = 0.0000 fps = 7 mse_loss = 3.7012 
2022-07-08 09:59:59.204369 - gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.0399 dist_std = 0.4309 vf_loss = 0.0770 grad_norm = 1.2408 nat_grad_norm = 0.2522 cg_residual = 0.0816 step_size = 0.4556 reward = 0.0000 fps = 6 mse_loss = 3.4736 
2022-07-08 09:59:59.964095 - gail/main.py:201 - [Discriminator] iter = 85000 loss = -1.2678 grad_norm = 2.8485 grad_penalty = 0.2134 regularization = 0.0000 true_logits = -0.0339 fake_logits = -1.5151 true_prob = 0.4992 fake_prob = 0.1995 
2022-07-08 10:00:45.490922 - gail/main.py:142 - [Evaluate] iter = 85000 episode={ returns = 411.4572 lengths = 141 } discounted_episode={ returns = 377.6954 lengths = 140 } 
2022-07-08 10:01:10.599767 - gail/main.py:174 - [TRPO] iter = 86000 dist_mean = 0.0401 dist_std = 0.4270 vf_loss = 0.0498 grad_norm = 0.9695 nat_grad_norm = 0.2455 cg_residual = 0.0686 step_size = 0.5191 reward = 0.0000 fps = 14 mse_loss = 3.6952 
2022-07-08 10:01:36.170501 - gail/main.py:174 - [TRPO] iter = 87000 dist_mean = 0.0518 dist_std = 0.4271 vf_loss = 0.0782 grad_norm = 1.5113 nat_grad_norm = 0.1923 cg_residual = 0.0488 step_size = 0.4534 reward = 0.0000 fps = 10 mse_loss = 3.4928 
2022-07-08 10:02:11.071977 - gail/main.py:174 - [TRPO] iter = 88000 dist_mean = 0.0566 dist_std = 0.4247 vf_loss = 0.3052 grad_norm = 1.9154 nat_grad_norm = 0.3382 cg_residual = 0.1632 step_size = 0.3602 reward = -0.0000 fps = 7 mse_loss = 3.7025 
2022-07-08 10:02:38.226499 - gail/main.py:174 - [TRPO] iter = 89000 dist_mean = 0.0565 dist_std = 0.4207 vf_loss = 0.1128 grad_norm = 1.2651 nat_grad_norm = 0.2360 cg_residual = 0.1024 step_size = 0.4890 reward = -0.0000 fps = 6 mse_loss = 3.5770 
2022-07-08 10:03:05.829739 - gail/main.py:174 - [TRPO] iter = 90000 dist_mean = 0.0685 dist_std = 0.4110 vf_loss = 0.0925 grad_norm = 1.7407 nat_grad_norm = 0.1728 cg_residual = 0.0853 step_size = 0.5029 reward = -0.0000 fps = 5 mse_loss = 3.6345 
2022-07-08 10:03:06.658552 - gail/main.py:201 - [Discriminator] iter = 90000 loss = -1.2255 grad_norm = 3.5347 grad_penalty = 0.2334 regularization = 0.0000 true_logits = 0.0246 fake_logits = -1.4343 true_prob = 0.5125 fake_prob = 0.2151 
2022-07-08 10:04:02.040067 - gail/main.py:142 - [Evaluate] iter = 90000 episode={ returns = 439.5732 lengths = 148 } discounted_episode={ returns = 402.3400 lengths = 148 } 
2022-07-08 10:04:29.407405 - gail/main.py:174 - [TRPO] iter = 91000 dist_mean = 0.0811 dist_std = 0.4120 vf_loss = 0.0916 grad_norm = 2.0489 nat_grad_norm = 0.2033 cg_residual = 0.1263 step_size = 0.4154 reward = -0.0000 fps = 12 mse_loss = 3.5312 
2022-07-08 10:04:56.554360 - gail/main.py:174 - [TRPO] iter = 92000 dist_mean = 0.1052 dist_std = 0.4083 vf_loss = 0.0828 grad_norm = 1.2835 nat_grad_norm = 0.1862 cg_residual = 0.0644 step_size = 0.5114 reward = 0.0000 fps = 9 mse_loss = 3.5255 
2022-07-08 10:05:23.779547 - gail/main.py:174 - [TRPO] iter = 93000 dist_mean = 0.1141 dist_std = 0.4071 vf_loss = 0.0599 grad_norm = 1.9158 nat_grad_norm = 0.2450 cg_residual = 0.1974 step_size = 0.4284 reward = -0.0000 fps = 7 mse_loss = 3.9537 
2022-07-08 10:05:51.966289 - gail/main.py:174 - [TRPO] iter = 94000 dist_mean = 0.0999 dist_std = 0.4081 vf_loss = 0.0793 grad_norm = 1.4278 nat_grad_norm = 0.2294 cg_residual = 0.0903 step_size = 0.4413 reward = 0.0000 fps = 6 mse_loss = 3.6160 
2022-07-08 10:06:19.882225 - gail/main.py:174 - [TRPO] iter = 95000 dist_mean = 0.1183 dist_std = 0.4051 vf_loss = 0.2020 grad_norm = 1.5228 nat_grad_norm = 0.2424 cg_residual = 0.1574 step_size = 0.4159 reward = -0.0000 fps = 5 mse_loss = 3.7480 
2022-07-08 10:06:20.852992 - gail/main.py:201 - [Discriminator] iter = 95000 loss = -1.1844 grad_norm = 3.3551 grad_penalty = 0.2330 regularization = 0.0000 true_logits = -0.0089 fake_logits = -1.4262 true_prob = 0.5038 fake_prob = 0.2187 
2022-07-08 10:07:21.081588 - gail/main.py:142 - [Evaluate] iter = 95000 episode={ returns = 506.1870 lengths = 167 } discounted_episode={ returns = 459.0010 lengths = 167 } 
2022-07-08 10:07:47.523330 - gail/main.py:174 - [TRPO] iter = 96000 dist_mean = 0.1490 dist_std = 0.4082 vf_loss = 0.1459 grad_norm = 1.1674 nat_grad_norm = 0.2166 cg_residual = 0.1740 step_size = 0.4750 reward = -0.0000 fps = 11 mse_loss = 3.4625 
2022-07-08 10:08:13.970819 - gail/main.py:174 - [TRPO] iter = 97000 dist_mean = 0.1381 dist_std = 0.4043 vf_loss = 0.0959 grad_norm = 1.1408 nat_grad_norm = 0.2168 cg_residual = 0.0652 step_size = 0.5002 reward = -0.0000 fps = 8 mse_loss = 3.4682 
2022-07-08 10:08:40.998490 - gail/main.py:174 - [TRPO] iter = 98000 dist_mean = 0.1450 dist_std = 0.3997 vf_loss = 0.8988 grad_norm = 1.4455 nat_grad_norm = 0.1575 cg_residual = 0.0836 step_size = 0.5485 reward = -0.0000 fps = 7 mse_loss = 3.4312 
2022-07-08 10:09:09.499932 - gail/main.py:174 - [TRPO] iter = 99000 dist_mean = 0.1712 dist_std = 0.4031 vf_loss = 0.1118 grad_norm = 1.5180 nat_grad_norm = 0.2320 cg_residual = 0.1164 step_size = 0.4156 reward = -0.0000 fps = 5 mse_loss = 3.6180 
2022-07-08 10:09:38.007882 - gail/main.py:174 - [TRPO] iter = 100000 dist_mean = 0.1863 dist_std = 0.3994 vf_loss = 1.1615 grad_norm = 0.9819 nat_grad_norm = 0.3064 cg_residual = 0.2654 step_size = 0.4064 reward = 0.0000 fps = 5 mse_loss = 3.6667 
2022-07-08 10:09:38.848691 - gail/main.py:201 - [Discriminator] iter = 100000 loss = -1.2713 grad_norm = 3.3957 grad_penalty = 0.2103 regularization = 0.0000 true_logits = 0.0539 fake_logits = -1.4277 true_prob = 0.5175 fake_prob = 0.2206 
2022-07-08 10:10:40.787834 - gail/main.py:142 - [Evaluate] iter = 100000 episode={ returns = 524.7527 lengths = 175 } discounted_episode={ returns = 475.2330 lengths = 175 } 
2022-07-08 10:11:08.557237 - gail/main.py:174 - [TRPO] iter = 101000 dist_mean = 0.2041 dist_std = 0.3985 vf_loss = 0.8901 grad_norm = 1.2679 nat_grad_norm = 0.2124 cg_residual = 0.0828 step_size = 0.5077 reward = 0.0000 fps = 11 mse_loss = 3.6057 
2022-07-08 10:11:37.069094 - gail/main.py:174 - [TRPO] iter = 102000 dist_mean = 0.2234 dist_std = 0.3983 vf_loss = 0.0907 grad_norm = 1.5035 nat_grad_norm = 0.1806 cg_residual = 0.1533 step_size = 0.4765 reward = 0.0000 fps = 8 mse_loss = 3.6670 
2022-07-08 10:12:11.704901 - gail/main.py:174 - [TRPO] iter = 103000 dist_mean = 0.2425 dist_std = 0.3953 vf_loss = 0.2632 grad_norm = 1.6037 nat_grad_norm = 0.2268 cg_residual = 0.1125 step_size = 0.3940 reward = 0.0000 fps = 6 mse_loss = 3.4946 
2022-07-08 10:12:38.674383 - gail/main.py:174 - [TRPO] iter = 104000 dist_mean = 0.2167 dist_std = 0.3997 vf_loss = 0.1114 grad_norm = 1.2151 nat_grad_norm = 0.2592 cg_residual = 0.1916 step_size = 0.3992 reward = -0.0000 fps = 5 mse_loss = 3.4841 
2022-07-08 10:13:06.407797 - gail/main.py:174 - [TRPO] iter = 105000 dist_mean = 0.2236 dist_std = 0.4015 vf_loss = 0.1225 grad_norm = 1.9894 nat_grad_norm = 0.1856 cg_residual = 0.0786 step_size = 0.4074 reward = 0.0000 fps = 4 mse_loss = 3.4272 
2022-07-08 10:13:07.209122 - gail/main.py:201 - [Discriminator] iter = 105000 loss = -1.2889 grad_norm = 3.0073 grad_penalty = 0.1953 regularization = 0.0000 true_logits = 0.0470 fake_logits = -1.4372 true_prob = 0.5153 fake_prob = 0.2179 
2022-07-08 10:14:09.133068 - gail/main.py:142 - [Evaluate] iter = 105000 episode={ returns = 551.8683 lengths = 181 } discounted_episode={ returns = 497.2430 lengths = 181 } 
2022-07-08 10:14:36.883615 - gail/main.py:174 - [TRPO] iter = 106000 dist_mean = 0.2710 dist_std = 0.3990 vf_loss = 0.1318 grad_norm = 1.1065 nat_grad_norm = 0.3114 cg_residual = 0.1327 step_size = 0.4126 reward = 0.0000 fps = 11 mse_loss = 3.4142 
2022-07-08 10:15:04.119150 - gail/main.py:174 - [TRPO] iter = 107000 dist_mean = 0.2569 dist_std = 0.3973 vf_loss = 0.1166 grad_norm = 1.0888 nat_grad_norm = 0.1977 cg_residual = 0.0996 step_size = 0.4868 reward = 0.0000 fps = 8 mse_loss = 3.3709 
2022-07-08 10:15:30.867353 - gail/main.py:174 - [TRPO] iter = 108000 dist_mean = 0.2647 dist_std = 0.3984 vf_loss = 0.8572 grad_norm = 1.6475 nat_grad_norm = 0.2812 cg_residual = 0.3161 step_size = 0.3804 reward = -0.0000 fps = 6 mse_loss = 3.4708 
2022-07-08 10:15:57.566940 - gail/main.py:174 - [TRPO] iter = 109000 dist_mean = 0.2227 dist_std = 0.3961 vf_loss = 0.3386 grad_norm = 2.1382 nat_grad_norm = 0.3171 cg_residual = 0.2337 step_size = 0.2880 reward = 0.0000 fps = 5 mse_loss = 3.1321 
2022-07-08 10:16:24.582884 - gail/main.py:174 - [TRPO] iter = 110000 dist_mean = 0.2502 dist_std = 0.3965 vf_loss = 0.1513 grad_norm = 1.1853 nat_grad_norm = 0.2747 cg_residual = 0.2065 step_size = 0.3700 reward = -0.0000 fps = 5 mse_loss = 3.2409 
2022-07-08 10:16:25.299964 - gail/main.py:201 - [Discriminator] iter = 110000 loss = -1.2612 grad_norm = 3.1251 grad_penalty = 0.1818 regularization = 0.0000 true_logits = -0.0005 fake_logits = -1.4435 true_prob = 0.5070 fake_prob = 0.2165 
2022-07-08 10:17:28.994936 - gail/main.py:142 - [Evaluate] iter = 110000 episode={ returns = 579.5104 lengths = 186 } discounted_episode={ returns = 518.0452 lengths = 186 } 
2022-07-08 10:17:57.075639 - gail/main.py:174 - [TRPO] iter = 111000 dist_mean = 0.2970 dist_std = 0.3974 vf_loss = 0.1395 grad_norm = 1.4569 nat_grad_norm = 0.2051 cg_residual = 0.1330 step_size = 0.4842 reward = 0.0000 fps = 10 mse_loss = 3.1945 
2022-07-08 10:18:23.169394 - gail/main.py:174 - [TRPO] iter = 112000 dist_mean = 0.2815 dist_std = 0.3946 vf_loss = 0.1070 grad_norm = 1.5769 nat_grad_norm = 0.1653 cg_residual = 0.0788 step_size = 0.5004 reward = -0.0000 fps = 8 mse_loss = 3.1864 
2022-07-08 10:18:49.643628 - gail/main.py:174 - [TRPO] iter = 113000 dist_mean = 0.2260 dist_std = 0.3966 vf_loss = 0.1652 grad_norm = 1.5362 nat_grad_norm = 0.2193 cg_residual = 0.1124 step_size = 0.4283 reward = -0.0000 fps = 6 mse_loss = 3.4142 
2022-07-08 10:19:15.114425 - gail/main.py:174 - [TRPO] iter = 114000 dist_mean = 0.2117 dist_std = 0.3987 vf_loss = 0.6352 grad_norm = 1.1333 nat_grad_norm = 0.2293 cg_residual = 0.0811 step_size = 0.4915 reward = -0.0000 fps = 5 mse_loss = 3.1417 
2022-07-08 10:19:42.145330 - gail/main.py:174 - [TRPO] iter = 115000 dist_mean = 0.2152 dist_std = 0.3972 vf_loss = 0.2558 grad_norm = 1.2342 nat_grad_norm = 0.3218 cg_residual = 0.5000 step_size = 0.3367 reward = 0.0000 fps = 5 mse_loss = 3.2336 
2022-07-08 10:19:42.981574 - gail/main.py:201 - [Discriminator] iter = 115000 loss = -1.3030 grad_norm = 3.2879 grad_penalty = 0.1813 regularization = 0.0000 true_logits = -0.0024 fake_logits = -1.4867 true_prob = 0.5038 fake_prob = 0.2126 
2022-07-08 10:20:53.035277 - gail/main.py:142 - [Evaluate] iter = 115000 episode={ returns = 634.4294 lengths = 198 } discounted_episode={ returns = 559.4973 lengths = 197 } 
2022-07-08 10:21:20.681883 - gail/main.py:174 - [TRPO] iter = 116000 dist_mean = 0.1658 dist_std = 0.3967 vf_loss = 1.3176 grad_norm = 1.4275 nat_grad_norm = 0.2367 cg_residual = 0.0955 step_size = 0.4370 reward = 0.0000 fps = 10 mse_loss = 3.1764 
2022-07-08 10:21:52.436680 - gail/main.py:174 - [TRPO] iter = 117000 dist_mean = 0.2594 dist_std = 0.3928 vf_loss = 0.5438 grad_norm = 0.9268 nat_grad_norm = 0.1985 cg_residual = 0.0809 step_size = 0.5314 reward = 0.0000 fps = 7 mse_loss = 3.2469 
2022-07-08 10:22:18.967755 - gail/main.py:174 - [TRPO] iter = 118000 dist_mean = 0.1876 dist_std = 0.3920 vf_loss = 0.6932 grad_norm = 1.0059 nat_grad_norm = 0.1949 cg_residual = 0.0745 step_size = 0.5464 reward = 0.0000 fps = 6 mse_loss = 3.0145 
2022-07-08 10:22:45.085323 - gail/main.py:174 - [TRPO] iter = 119000 dist_mean = 0.2484 dist_std = 0.3961 vf_loss = 0.4688 grad_norm = 1.1534 nat_grad_norm = 0.2064 cg_residual = 0.2092 step_size = 0.5018 reward = -0.0000 fps = 5 mse_loss = 3.2217 
2022-07-08 10:23:11.999483 - gail/main.py:174 - [TRPO] iter = 120000 dist_mean = 0.2344 dist_std = 0.3918 vf_loss = 0.0752 grad_norm = 1.2884 nat_grad_norm = 0.2471 cg_residual = 0.1969 step_size = 0.4096 reward = -0.0000 fps = 4 mse_loss = 3.0264 
2022-07-08 10:23:12.805776 - gail/main.py:201 - [Discriminator] iter = 120000 loss = -1.4717 grad_norm = 2.8676 grad_penalty = 0.1711 regularization = 0.0000 true_logits = 0.1216 fake_logits = -1.5212 true_prob = 0.5299 fake_prob = 0.2090 
2022-07-08 10:24:24.728007 - gail/main.py:142 - [Evaluate] iter = 120000 episode={ returns = 670.0493 lengths = 208 } discounted_episode={ returns = 592.3361 lengths = 208 } 
2022-07-08 10:24:52.753393 - gail/main.py:174 - [TRPO] iter = 121000 dist_mean = 0.1997 dist_std = 0.3919 vf_loss = 0.2914 grad_norm = 1.2676 nat_grad_norm = 0.2928 cg_residual = 0.1869 step_size = 0.3656 reward = 0.0000 fps = 10 mse_loss = 3.1594 
2022-07-08 10:25:19.300710 - gail/main.py:174 - [TRPO] iter = 122000 dist_mean = 0.2412 dist_std = 0.3929 vf_loss = 0.0866 grad_norm = 1.7838 nat_grad_norm = 0.2360 cg_residual = 0.1874 step_size = 0.4221 reward = 0.0000 fps = 7 mse_loss = 3.1025 
2022-07-08 10:25:46.162928 - gail/main.py:174 - [TRPO] iter = 123000 dist_mean = 0.2455 dist_std = 0.3970 vf_loss = 0.1011 grad_norm = 1.4211 nat_grad_norm = 0.2959 cg_residual = 0.1625 step_size = 0.3706 reward = -0.0000 fps = 6 mse_loss = 3.2058 
2022-07-08 10:26:14.112209 - gail/main.py:174 - [TRPO] iter = 124000 dist_mean = 0.1651 dist_std = 0.3964 vf_loss = 0.5938 grad_norm = 1.3631 nat_grad_norm = 0.2875 cg_residual = 0.1379 step_size = 0.3959 reward = 0.0000 fps = 5 mse_loss = 3.1740 
2022-07-08 10:26:42.076539 - gail/main.py:174 - [TRPO] iter = 125000 dist_mean = 0.2072 dist_std = 0.3965 vf_loss = 0.2093 grad_norm = 0.8094 nat_grad_norm = 0.2331 cg_residual = 0.1307 step_size = 0.4906 reward = 0.0000 fps = 4 mse_loss = 3.1363 
2022-07-08 10:26:42.951683 - gail/main.py:201 - [Discriminator] iter = 125000 loss = -1.3277 grad_norm = 3.1283 grad_penalty = 0.1581 regularization = 0.0000 true_logits = 0.0394 fake_logits = -1.4464 true_prob = 0.5108 fake_prob = 0.2220 
2022-07-08 10:28:01.019571 - gail/main.py:142 - [Evaluate] iter = 125000 episode={ returns = 705.1440 lengths = 219 } discounted_episode={ returns = 619.9434 lengths = 219 } 
2022-07-08 10:28:29.291697 - gail/main.py:174 - [TRPO] iter = 126000 dist_mean = 0.2110 dist_std = 0.3880 vf_loss = 0.1428 grad_norm = 1.0374 nat_grad_norm = 0.2599 cg_residual = 0.1605 step_size = 0.4786 reward = 0.0000 fps = 9 mse_loss = 3.0321 
2022-07-08 10:28:57.957671 - gail/main.py:174 - [TRPO] iter = 127000 dist_mean = 0.2474 dist_std = 0.3847 vf_loss = 0.5018 grad_norm = 0.9730 nat_grad_norm = 0.2026 cg_residual = 0.0757 step_size = 0.5471 reward = -0.0000 fps = 7 mse_loss = 3.0717 
2022-07-08 10:29:26.004490 - gail/main.py:174 - [TRPO] iter = 128000 dist_mean = 0.2414 dist_std = 0.3814 vf_loss = 0.2090 grad_norm = 1.1482 nat_grad_norm = 0.1770 cg_residual = 0.2000 step_size = 0.5616 reward = -0.0000 fps = 6 mse_loss = 3.3821 
2022-07-08 10:29:55.523658 - gail/main.py:174 - [TRPO] iter = 129000 dist_mean = 0.2341 dist_std = 0.3829 vf_loss = 0.2001 grad_norm = 1.5354 nat_grad_norm = 0.2398 cg_residual = 0.1553 step_size = 0.4188 reward = 0.0000 fps = 5 mse_loss = 3.1442 
2022-07-08 10:30:24.062875 - gail/main.py:174 - [TRPO] iter = 130000 dist_mean = 0.2087 dist_std = 0.3850 vf_loss = 0.0824 grad_norm = 0.9923 nat_grad_norm = 0.2399 cg_residual = 0.1738 step_size = 0.4826 reward = 0.0000 fps = 4 mse_loss = 3.1457 
2022-07-08 10:30:24.864797 - gail/main.py:201 - [Discriminator] iter = 130000 loss = -1.2916 grad_norm = 2.5748 grad_penalty = 0.1603 regularization = 0.0000 true_logits = 0.0490 fake_logits = -1.4029 true_prob = 0.5141 fake_prob = 0.2304 
