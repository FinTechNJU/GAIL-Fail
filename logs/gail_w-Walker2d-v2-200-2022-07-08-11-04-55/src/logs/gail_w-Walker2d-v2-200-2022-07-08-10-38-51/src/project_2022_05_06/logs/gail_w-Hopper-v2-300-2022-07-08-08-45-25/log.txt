2022-07-08 08:45:25.132025 - utils/flags.py:257 - log_dir = logs/gail_w-Hopper-v2-300-2022-07-08-08-45-25
2022-07-08 08:46:25.131415 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Hopper-v2
2022-07-08 08:46:32.712967 - gail/main.py:80 - Expert Reward 3582.436530
2022-07-08 08:46:33.016055 - gail/main.py:84 - Original dataset size 3000
2022-07-08 08:46:33.055760 - gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 08:46:33.056725 - gail/main.py:87 - np random: 864 random : 786
2022-07-08 08:46:33.062389 - gail/main.py:91 - Sampled obs: 0.4652, acs: 0.0749
2022-07-08 08:46:34.025959 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 08:46:41.258044 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 08:46:41.263041 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.3966653  -0.06165453 -0.19472611 -0.4584401   0.18350822  2.5732448
   0.00400542 -0.00549955 -0.04755233 -0.02386179  0.00759995]] 
 scale:[[0.16755195 0.05883223 0.15990146 0.34682125 0.5992658  0.6461788
  1.5187451  0.8811966  2.0685835  3.6282625  5.862049  ]]
2022-07-08 08:46:44.848411 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 08:46:44.861395 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(14, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 08:46:44.863687 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 08:46:45.793861 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 08:47:03.558885 - gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 176.4389 lengths = 193 } discounted_episode={ returns = 145.2316 lengths = 186 } 
2022-07-08 08:47:03.559348 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 08:47:13.908680 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 08:47:14.184616 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 08:47:14.662440 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 08:47:14.954189 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 08:47:16.436921 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 08:47:19.458605 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 08:47:19.778450 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 08:47:20.100510 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 08:47:20.575433 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 08:47:21.420899 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 08:47:21.747042 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 08:47:22.051037 - gail/main.py:174 - [TRPO] iter = 1000 dist_mean = 0.0000 dist_std = 1.0000 vf_loss = 0.0893 grad_norm = 0.2735 nat_grad_norm = 0.3080 cg_residual = 0.0000 step_size = 0.5282 reward = -0.0000 fps = 27 mse_loss = 0.3020 
2022-07-08 08:47:29.269343 - gail/main.py:174 - [TRPO] iter = 2000 dist_mean = 0.0518 dist_std = 0.9998 vf_loss = 0.1021 grad_norm = 0.1874 nat_grad_norm = 0.2988 cg_residual = 0.0000 step_size = 0.7212 reward = -0.0000 fps = 23 mse_loss = 0.2801 
2022-07-08 08:47:36.260197 - gail/main.py:174 - [TRPO] iter = 3000 dist_mean = 0.0605 dist_std = 1.0094 vf_loss = 0.0958 grad_norm = 0.2970 nat_grad_norm = 0.3500 cg_residual = 0.0000 step_size = 0.4870 reward = 0.0000 fps = 19 mse_loss = 0.3062 
2022-07-08 08:47:43.642610 - gail/main.py:174 - [TRPO] iter = 4000 dist_mean = 0.0843 dist_std = 1.0021 vf_loss = 0.0983 grad_norm = 0.2958 nat_grad_norm = 0.4074 cg_residual = 0.0000 step_size = 0.4906 reward = 0.0000 fps = 17 mse_loss = 0.3226 
2022-07-08 08:47:50.548170 - gail/main.py:174 - [TRPO] iter = 5000 dist_mean = 0.1118 dist_std = 0.9981 vf_loss = 0.1753 grad_norm = 0.3245 nat_grad_norm = 0.3193 cg_residual = 0.0000 step_size = 0.5108 reward = -0.0000 fps = 15 mse_loss = 0.3361 
2022-07-08 08:47:50.549687 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 08:47:52.858137 - gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.6857 grad_norm = 13.9240 grad_penalty = 1.7181 regularization = 0.0000 true_logits = -0.0537 fake_logits = -0.0862 true_prob = 0.4866 fake_prob = 0.4785 
2022-07-08 08:47:54.919991 - gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = 24.3797 lengths = 23 } discounted_episode={ returns = 24.1963 lengths = 23 } 
2022-07-08 08:48:01.404517 - gail/main.py:174 - [TRPO] iter = 6000 dist_mean = 0.1356 dist_std = 0.9838 vf_loss = 0.1885 grad_norm = 0.3739 nat_grad_norm = 0.3805 cg_residual = 0.0000 step_size = 0.4288 reward = -0.0000 fps = 117 mse_loss = 0.3522 
2022-07-08 08:48:08.020041 - gail/main.py:174 - [TRPO] iter = 7000 dist_mean = 0.1719 dist_std = 0.9871 vf_loss = 0.3947 grad_norm = 0.4376 nat_grad_norm = 0.3273 cg_residual = 0.0000 step_size = 0.4055 reward = -0.0000 fps = 66 mse_loss = 0.4048 
2022-07-08 08:48:15.122320 - gail/main.py:174 - [TRPO] iter = 8000 dist_mean = 0.2410 dist_std = 0.9820 vf_loss = 0.5669 grad_norm = 0.4189 nat_grad_norm = 0.4182 cg_residual = 0.0000 step_size = 0.4188 reward = 0.0000 fps = 44 mse_loss = 0.3722 
2022-07-08 08:48:22.361677 - gail/main.py:174 - [TRPO] iter = 9000 dist_mean = 0.2971 dist_std = 0.9815 vf_loss = 0.4890 grad_norm = 0.5694 nat_grad_norm = 0.3796 cg_residual = 0.0000 step_size = 0.3700 reward = 0.0000 fps = 33 mse_loss = 0.3895 
2022-07-08 08:48:29.332896 - gail/main.py:174 - [TRPO] iter = 10000 dist_mean = 0.3015 dist_std = 0.9738 vf_loss = 0.5037 grad_norm = 0.4065 nat_grad_norm = 0.4599 cg_residual = 0.0001 step_size = 0.4226 reward = -0.0000 fps = 27 mse_loss = 0.4640 
2022-07-08 08:48:29.551980 - gail/main.py:201 - [Discriminator] iter = 10000 loss = 0.6828 grad_norm = 9.0137 grad_penalty = 0.8898 regularization = 0.0000 true_logits = -0.0209 fake_logits = -0.2278 true_prob = 0.4948 fake_prob = 0.4435 
2022-07-08 08:48:35.123182 - gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = 88.7811 lengths = 60 } discounted_episode={ returns = 85.9995 lengths = 60 } 
2022-07-08 08:48:42.166059 - gail/main.py:174 - [TRPO] iter = 11000 dist_mean = 0.3543 dist_std = 0.9616 vf_loss = 0.5588 grad_norm = 0.4426 nat_grad_norm = 0.3434 cg_residual = 0.0000 step_size = 0.4756 reward = -0.0000 fps = 79 mse_loss = 0.4854 
2022-07-08 08:48:49.804990 - gail/main.py:174 - [TRPO] iter = 12000 dist_mean = 0.3449 dist_std = 0.9428 vf_loss = 0.6071 grad_norm = 0.3303 nat_grad_norm = 0.3769 cg_residual = 0.0002 step_size = 0.4952 reward = 0.0000 fps = 49 mse_loss = 0.4574 
2022-07-08 08:48:57.610637 - gail/main.py:174 - [TRPO] iter = 13000 dist_mean = 0.3460 dist_std = 0.9248 vf_loss = 0.4828 grad_norm = 0.4647 nat_grad_norm = 0.3377 cg_residual = 0.0003 step_size = 0.4662 reward = 0.0000 fps = 35 mse_loss = 0.5401 
2022-07-08 08:49:05.659607 - gail/main.py:174 - [TRPO] iter = 14000 dist_mean = 0.3678 dist_std = 0.9177 vf_loss = 0.3280 grad_norm = 0.4834 nat_grad_norm = 0.3665 cg_residual = 0.0005 step_size = 0.4692 reward = -0.0000 fps = 27 mse_loss = 0.6540 
2022-07-08 08:49:13.014885 - gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.4183 dist_std = 0.9068 vf_loss = 0.2204 grad_norm = 0.5655 nat_grad_norm = 0.3795 cg_residual = 0.0003 step_size = 0.4271 reward = 0.0000 fps = 23 mse_loss = 0.7990 
2022-07-08 08:49:13.227602 - gail/main.py:201 - [Discriminator] iter = 15000 loss = 0.3881 grad_norm = 8.2585 grad_penalty = 0.7118 regularization = 0.0000 true_logits = -0.0021 fake_logits = -0.3258 true_prob = 0.4996 fake_prob = 0.4197 
2022-07-08 08:49:18.261190 - gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = 93.8004 lengths = 61 } discounted_episode={ returns = 91.3223 lengths = 61 } 
2022-07-08 08:49:25.327242 - gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.4660 dist_std = 0.8948 vf_loss = 0.1118 grad_norm = 0.3669 nat_grad_norm = 0.3298 cg_residual = 0.0003 step_size = 0.5510 reward = -0.0000 fps = 82 mse_loss = 0.8771 
2022-07-08 08:49:32.192745 - gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.4318 dist_std = 0.8815 vf_loss = 0.0665 grad_norm = 0.4872 nat_grad_norm = 0.3167 cg_residual = 0.0002 step_size = 0.5254 reward = -0.0000 fps = 52 mse_loss = 0.8386 
2022-07-08 08:49:39.155313 - gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.4945 dist_std = 0.8704 vf_loss = 0.0552 grad_norm = 0.4926 nat_grad_norm = 0.3294 cg_residual = 0.0003 step_size = 0.4539 reward = -0.0000 fps = 38 mse_loss = 0.9216 
2022-07-08 08:49:46.299894 - gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.4956 dist_std = 0.8568 vf_loss = 0.0353 grad_norm = 0.5008 nat_grad_norm = 0.2871 cg_residual = 0.0003 step_size = 0.5071 reward = -0.0000 fps = 30 mse_loss = 0.9007 
2022-07-08 08:49:53.108504 - gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.5401 dist_std = 0.8394 vf_loss = 0.0499 grad_norm = 0.5223 nat_grad_norm = 0.3039 cg_residual = 0.0005 step_size = 0.4590 reward = 0.0000 fps = 25 mse_loss = 0.9233 
2022-07-08 08:49:53.350733 - gail/main.py:201 - [Discriminator] iter = 20000 loss = 0.0875 grad_norm = 6.1094 grad_penalty = 0.5830 regularization = 0.0000 true_logits = 0.0155 fake_logits = -0.4799 true_prob = 0.5041 fake_prob = 0.3830 
2022-07-08 08:49:58.297337 - gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = 87.1648 lengths = 55 } discounted_episode={ returns = 85.2060 lengths = 55 } 
2022-07-08 08:50:09.258589 - gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.5526 dist_std = 0.8208 vf_loss = 0.0402 grad_norm = 0.3878 nat_grad_norm = 0.3228 cg_residual = 0.0005 step_size = 0.5359 reward = 0.0000 fps = 62 mse_loss = 0.9190 
2022-07-08 08:50:17.633689 - gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.5684 dist_std = 0.8097 vf_loss = 0.0241 grad_norm = 0.5189 nat_grad_norm = 0.2876 cg_residual = 0.0007 step_size = 0.5116 reward = -0.0000 fps = 41 mse_loss = 1.0207 
2022-07-08 08:50:25.159104 - gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.5918 dist_std = 0.8014 vf_loss = 0.0287 grad_norm = 0.4687 nat_grad_norm = 0.2930 cg_residual = 0.0006 step_size = 0.5499 reward = -0.0000 fps = 31 mse_loss = 1.1172 
2022-07-08 08:50:32.035643 - gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.6220 dist_std = 0.7893 vf_loss = 0.0269 grad_norm = 0.7337 nat_grad_norm = 0.3734 cg_residual = 0.0019 step_size = 0.4126 reward = 0.0000 fps = 25 mse_loss = 1.0835 
2022-07-08 08:50:39.270701 - gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.5717 dist_std = 0.7863 vf_loss = 0.0373 grad_norm = 0.6201 nat_grad_norm = 0.2633 cg_residual = 0.0004 step_size = 0.5332 reward = 0.0000 fps = 21 mse_loss = 1.0986 
2022-07-08 08:50:39.496376 - gail/main.py:201 - [Discriminator] iter = 25000 loss = -0.1417 grad_norm = 6.0387 grad_penalty = 0.5568 regularization = 0.0000 true_logits = 0.0139 fake_logits = -0.6845 true_prob = 0.5040 fake_prob = 0.3369 
2022-07-08 08:50:44.602526 - gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = 95.2370 lengths = 58 } discounted_episode={ returns = 92.0204 lengths = 58 } 
2022-07-08 08:50:51.272766 - gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.6131 dist_std = 0.7816 vf_loss = 0.0365 grad_norm = 0.6994 nat_grad_norm = 0.2951 cg_residual = 0.0005 step_size = 0.5080 reward = 0.0000 fps = 84 mse_loss = 1.1452 
2022-07-08 08:50:58.366371 - gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.6012 dist_std = 0.7709 vf_loss = 0.0465 grad_norm = 0.8729 nat_grad_norm = 0.3613 cg_residual = 0.0012 step_size = 0.3990 reward = 0.0000 fps = 53 mse_loss = 1.1476 
2022-07-08 08:51:05.598392 - gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.5869 dist_std = 0.7633 vf_loss = 0.0283 grad_norm = 0.7586 nat_grad_norm = 0.2943 cg_residual = 0.0012 step_size = 0.5294 reward = 0.0000 fps = 38 mse_loss = 1.0216 
2022-07-08 08:51:12.543112 - gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.5655 dist_std = 0.7598 vf_loss = 0.0498 grad_norm = 0.7813 nat_grad_norm = 0.3359 cg_residual = 0.0013 step_size = 0.5000 reward = 0.0000 fps = 30 mse_loss = 1.0321 
2022-07-08 08:51:19.465895 - gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.5502 dist_std = 0.7489 vf_loss = 0.0319 grad_norm = 0.4918 nat_grad_norm = 0.3317 cg_residual = 0.0021 step_size = 0.5777 reward = 0.0000 fps = 25 mse_loss = 1.1751 
2022-07-08 08:51:19.683851 - gail/main.py:201 - [Discriminator] iter = 30000 loss = -0.5012 grad_norm = 5.6909 grad_penalty = 0.4362 regularization = 0.0000 true_logits = 0.0422 fake_logits = -0.8952 true_prob = 0.5113 fake_prob = 0.2933 
2022-07-08 08:51:25.222538 - gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = 107.6240 lengths = 62 } discounted_episode={ returns = 104.2008 lengths = 62 } 
2022-07-08 08:51:32.105075 - gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.5943 dist_std = 0.7443 vf_loss = 0.0365 grad_norm = 0.8799 nat_grad_norm = 0.3025 cg_residual = 0.0021 step_size = 0.5014 reward = -0.0000 fps = 80 mse_loss = 1.1433 
2022-07-08 08:51:38.825754 - gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.5600 dist_std = 0.7389 vf_loss = 0.0435 grad_norm = 0.7430 nat_grad_norm = 0.2922 cg_residual = 0.0016 step_size = 0.5696 reward = 0.0000 fps = 52 mse_loss = 1.1096 
2022-07-08 08:51:45.685172 - gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.5521 dist_std = 0.7374 vf_loss = 0.0165 grad_norm = 0.5302 nat_grad_norm = 0.3699 cg_residual = 0.0039 step_size = 0.5218 reward = 0.0000 fps = 38 mse_loss = 1.1412 
2022-07-08 08:51:52.377232 - gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.5530 dist_std = 0.7338 vf_loss = 0.1000 grad_norm = 0.6982 nat_grad_norm = 0.6139 cg_residual = 0.0052 step_size = 0.3122 reward = -0.0000 fps = 30 mse_loss = 1.2430 
2022-07-08 08:51:59.196346 - gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.5610 dist_std = 0.7302 vf_loss = 0.3655 grad_norm = 0.4167 nat_grad_norm = 0.4167 cg_residual = 0.0068 step_size = 0.5692 reward = -0.0000 fps = 25 mse_loss = 1.2588 
2022-07-08 08:51:59.454606 - gail/main.py:201 - [Discriminator] iter = 35000 loss = -0.7409 grad_norm = 5.1965 grad_penalty = 0.4136 regularization = 0.0000 true_logits = 0.0581 fake_logits = -1.0964 true_prob = 0.5161 fake_prob = 0.2584 
2022-07-08 08:52:05.201520 - gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 116.9039 lengths = 66 } discounted_episode={ returns = 112.8270 lengths = 66 } 
2022-07-08 08:52:11.915464 - gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.5538 dist_std = 0.7278 vf_loss = 0.2866 grad_norm = 0.8970 nat_grad_norm = 0.4513 cg_residual = 0.0095 step_size = 0.4177 reward = 0.0000 fps = 80 mse_loss = 1.2210 
2022-07-08 08:52:18.548862 - gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.4665 dist_std = 0.7255 vf_loss = 0.6317 grad_norm = 0.6327 nat_grad_norm = 0.4792 cg_residual = 0.0077 step_size = 0.4790 reward = -0.0000 fps = 52 mse_loss = 1.2945 
2022-07-08 08:52:25.568811 - gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.4092 dist_std = 0.7269 vf_loss = 0.8376 grad_norm = 0.8387 nat_grad_norm = 0.3284 cg_residual = 0.0093 step_size = 0.4964 reward = -0.0000 fps = 38 mse_loss = 1.2596 
2022-07-08 08:52:32.521938 - gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.3617 dist_std = 0.7214 vf_loss = 0.3769 grad_norm = 0.5800 nat_grad_norm = 0.3820 cg_residual = 0.0201 step_size = 0.5211 reward = 0.0000 fps = 30 mse_loss = 1.2779 
2022-07-08 08:52:39.063679 - gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.3399 dist_std = 0.7221 vf_loss = 0.1649 grad_norm = 0.8089 nat_grad_norm = 0.3147 cg_residual = 0.0079 step_size = 0.4996 reward = 0.0000 fps = 25 mse_loss = 1.3948 
2022-07-08 08:52:39.288908 - gail/main.py:201 - [Discriminator] iter = 40000 loss = -0.4835 grad_norm = 5.8566 grad_penalty = 0.5082 regularization = 0.0000 true_logits = 0.0599 fake_logits = -0.9317 true_prob = 0.5170 fake_prob = 0.3001 
2022-07-08 08:52:48.023045 - gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 249.5141 lengths = 101 } discounted_episode={ returns = 234.0070 lengths = 101 } 
2022-07-08 08:52:54.892285 - gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.2923 dist_std = 0.7262 vf_loss = 0.4023 grad_norm = 1.4171 nat_grad_norm = 0.8402 cg_residual = 0.1683 step_size = 0.2417 reward = 0.0000 fps = 64 mse_loss = 1.4647 
2022-07-08 08:53:01.529049 - gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.3061 dist_std = 0.7236 vf_loss = 0.1458 grad_norm = 0.6272 nat_grad_norm = 0.3380 cg_residual = 0.0050 step_size = 0.5074 reward = -0.0000 fps = 44 mse_loss = 1.4303 
2022-07-08 08:53:08.378970 - gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.3266 dist_std = 0.7178 vf_loss = 0.0887 grad_norm = 0.9288 nat_grad_norm = 0.4896 cg_residual = 0.0109 step_size = 0.3895 reward = 0.0000 fps = 34 mse_loss = 1.3716 
2022-07-08 08:53:15.247287 - gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.3295 dist_std = 0.7144 vf_loss = 0.3454 grad_norm = 1.0177 nat_grad_norm = 0.3538 cg_residual = 0.0333 step_size = 0.4502 reward = 0.0000 fps = 27 mse_loss = 1.2712 
2022-07-08 08:53:22.351829 - gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.2710 dist_std = 0.7122 vf_loss = 0.1543 grad_norm = 0.5951 nat_grad_norm = 0.4132 cg_residual = 0.0664 step_size = 0.4624 reward = -0.0000 fps = 23 mse_loss = 1.1029 
2022-07-08 08:53:22.553169 - gail/main.py:201 - [Discriminator] iter = 45000 loss = -0.8251 grad_norm = 5.5698 grad_penalty = 0.3405 regularization = 0.0000 true_logits = 0.0698 fake_logits = -1.0957 true_prob = 0.5198 fake_prob = 0.2675 
2022-07-08 08:53:32.423149 - gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 269.6948 lengths = 104 } discounted_episode={ returns = 253.5484 lengths = 104 } 
2022-07-08 08:53:39.437715 - gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.3070 dist_std = 0.7042 vf_loss = 0.1506 grad_norm = 0.3894 nat_grad_norm = 0.3312 cg_residual = 0.0066 step_size = 0.6270 reward = 0.0000 fps = 59 mse_loss = 1.0870 
2022-07-08 08:53:46.462429 - gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.2813 dist_std = 0.7014 vf_loss = 0.3584 grad_norm = 0.6880 nat_grad_norm = 0.4733 cg_residual = 0.0272 step_size = 0.4337 reward = 0.0000 fps = 41 mse_loss = 1.0862 
2022-07-08 08:53:53.443173 - gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.3196 dist_std = 0.6943 vf_loss = 0.3517 grad_norm = 1.1561 nat_grad_norm = 0.4025 cg_residual = 0.0160 step_size = 0.4302 reward = -0.0000 fps = 32 mse_loss = 1.1177 
2022-07-08 08:54:00.242646 - gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.2884 dist_std = 0.6933 vf_loss = 0.3162 grad_norm = 0.7013 nat_grad_norm = 0.4456 cg_residual = 0.0137 step_size = 0.4587 reward = -0.0000 fps = 26 mse_loss = 1.2251 
2022-07-08 08:54:07.015637 - gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.2963 dist_std = 0.6892 vf_loss = 0.3213 grad_norm = 1.0030 nat_grad_norm = 0.4625 cg_residual = 0.0397 step_size = 0.3907 reward = 0.0000 fps = 22 mse_loss = 1.1746 
2022-07-08 08:54:07.219327 - gail/main.py:201 - [Discriminator] iter = 50000 loss = -1.0419 grad_norm = 4.5450 grad_penalty = 0.2627 regularization = 0.0000 true_logits = 0.1010 fake_logits = -1.2035 true_prob = 0.5278 fake_prob = 0.2501 
2022-07-08 08:54:18.073825 - gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 387.6634 lengths = 132 } discounted_episode={ returns = 357.4410 lengths = 132 } 
2022-07-08 08:54:24.558327 - gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.2658 dist_std = 0.6819 vf_loss = 0.2332 grad_norm = 0.7937 nat_grad_norm = 0.3126 cg_residual = 0.0060 step_size = 0.4730 reward = 0.0000 fps = 57 mse_loss = 1.1847 
2022-07-08 08:54:31.264558 - gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.3177 dist_std = 0.6791 vf_loss = 0.2309 grad_norm = 0.8187 nat_grad_norm = 0.2923 cg_residual = 0.0094 step_size = 0.5217 reward = -0.0000 fps = 41 mse_loss = 1.1384 
2022-07-08 08:54:38.024692 - gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.2621 dist_std = 0.6780 vf_loss = 0.2392 grad_norm = 0.4685 nat_grad_norm = 0.3811 cg_residual = 0.0072 step_size = 0.5821 reward = 0.0000 fps = 32 mse_loss = 1.3298 
2022-07-08 08:54:44.514382 - gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.2744 dist_std = 0.6775 vf_loss = 0.3044 grad_norm = 0.8753 nat_grad_norm = 0.3416 cg_residual = 0.0341 step_size = 0.4986 reward = 0.0000 fps = 26 mse_loss = 1.1911 
2022-07-08 08:54:51.454416 - gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.2847 dist_std = 0.6777 vf_loss = 0.4324 grad_norm = 0.6144 nat_grad_norm = 0.5253 cg_residual = 0.0173 step_size = 0.4705 reward = -0.0000 fps = 22 mse_loss = 1.2620 
2022-07-08 08:54:51.681954 - gail/main.py:201 - [Discriminator] iter = 55000 loss = -1.0384 grad_norm = 3.6043 grad_penalty = 0.2384 regularization = 0.0000 true_logits = 0.1242 fake_logits = -1.1526 true_prob = 0.5349 fake_prob = 0.2675 
2022-07-08 08:55:04.867710 - gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 396.4137 lengths = 135 } discounted_episode={ returns = 359.1257 lengths = 134 } 
2022-07-08 08:55:12.828956 - gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.2668 dist_std = 0.6764 vf_loss = 0.3809 grad_norm = 0.6164 nat_grad_norm = 0.4197 cg_residual = 0.0164 step_size = 0.5125 reward = -0.0000 fps = 47 mse_loss = 1.2899 
2022-07-08 08:55:19.642507 - gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.2946 dist_std = 0.6732 vf_loss = 0.3610 grad_norm = 0.9290 nat_grad_norm = 0.4262 cg_residual = 0.0167 step_size = 0.4593 reward = -0.0000 fps = 35 mse_loss = 1.5308 
2022-07-08 08:55:26.336152 - gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.2372 dist_std = 0.6683 vf_loss = 0.2076 grad_norm = 1.0669 nat_grad_norm = 0.2910 cg_residual = 0.0328 step_size = 0.4353 reward = 0.0000 fps = 28 mse_loss = 1.4054 
2022-07-08 08:55:32.748854 - gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.2172 dist_std = 0.6674 vf_loss = 0.2869 grad_norm = 0.5749 nat_grad_norm = 0.4563 cg_residual = 0.0187 step_size = 0.5088 reward = -0.0000 fps = 24 mse_loss = 1.5511 
2022-07-08 08:55:39.321907 - gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.2388 dist_std = 0.6667 vf_loss = 0.3182 grad_norm = 0.6016 nat_grad_norm = 0.2856 cg_residual = 0.0099 step_size = 0.5681 reward = -0.0000 fps = 20 mse_loss = 1.4936 
2022-07-08 08:55:39.553674 - gail/main.py:201 - [Discriminator] iter = 60000 loss = -0.9528 grad_norm = 3.4734 grad_penalty = 0.2124 regularization = 0.0000 true_logits = 0.1531 fake_logits = -1.0121 true_prob = 0.5410 fake_prob = 0.3001 
2022-07-08 08:55:51.185257 - gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 392.2479 lengths = 135 } discounted_episode={ returns = 382.1903 lengths = 140 } 
2022-07-08 08:55:57.824971 - gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.2680 dist_std = 0.6571 vf_loss = 0.1754 grad_norm = 0.6547 nat_grad_norm = 0.3907 cg_residual = 0.0125 step_size = 0.5438 reward = -0.0000 fps = 54 mse_loss = 1.6730 
2022-07-08 08:56:04.401955 - gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.2536 dist_std = 0.6505 vf_loss = 0.4094 grad_norm = 0.7286 nat_grad_norm = 0.3580 cg_residual = 0.0190 step_size = 0.4788 reward = -0.0000 fps = 40 mse_loss = 1.5713 
2022-07-08 08:56:11.101902 - gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.2429 dist_std = 0.6531 vf_loss = 0.2746 grad_norm = 0.8377 nat_grad_norm = 0.3759 cg_residual = 0.0109 step_size = 0.5153 reward = -0.0000 fps = 31 mse_loss = 1.6926 
2022-07-08 08:56:17.694602 - gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.2243 dist_std = 0.6552 vf_loss = 0.4089 grad_norm = 1.0576 nat_grad_norm = 0.2894 cg_residual = 0.0174 step_size = 0.4766 reward = -0.0000 fps = 26 mse_loss = 1.5435 
2022-07-08 08:56:24.384895 - gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.1959 dist_std = 0.6523 vf_loss = 0.4015 grad_norm = 0.7647 nat_grad_norm = 0.3571 cg_residual = 0.0105 step_size = 0.4357 reward = -0.0000 fps = 22 mse_loss = 1.3887 
2022-07-08 08:56:24.622870 - gail/main.py:201 - [Discriminator] iter = 65000 loss = -0.7897 grad_norm = 3.5485 grad_penalty = 0.2271 regularization = 0.0000 true_logits = 0.1642 fake_logits = -0.8526 true_prob = 0.5439 fake_prob = 0.3357 
2022-07-08 08:56:39.312357 - gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 515.5308 lengths = 158 } discounted_episode={ returns = 457.1497 lengths = 155 } 
2022-07-08 08:56:46.324964 - gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.2158 dist_std = 0.6405 vf_loss = 0.9562 grad_norm = 0.6836 nat_grad_norm = 0.2952 cg_residual = 0.0076 step_size = 0.5658 reward = -0.0000 fps = 46 mse_loss = 1.2911 
2022-07-08 08:56:53.132782 - gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.2273 dist_std = 0.6362 vf_loss = 0.4548 grad_norm = 0.4732 nat_grad_norm = 0.3273 cg_residual = 0.0079 step_size = 0.5918 reward = -0.0000 fps = 35 mse_loss = 1.5626 
2022-07-08 08:57:00.166712 - gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.1866 dist_std = 0.6344 vf_loss = 1.2105 grad_norm = 1.2432 nat_grad_norm = 0.3999 cg_residual = 0.0289 step_size = 0.3746 reward = -0.0000 fps = 28 mse_loss = 1.4545 
2022-07-08 08:57:06.829573 - gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.2020 dist_std = 0.6337 vf_loss = 0.8162 grad_norm = 0.3731 nat_grad_norm = 0.3020 cg_residual = 0.0088 step_size = 0.6585 reward = 0.0000 fps = 23 mse_loss = 1.4920 
2022-07-08 08:57:13.388877 - gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.1698 dist_std = 0.6235 vf_loss = 0.5951 grad_norm = 0.6481 nat_grad_norm = 0.2858 cg_residual = 0.0118 step_size = 0.6211 reward = -0.0000 fps = 20 mse_loss = 1.4871 
2022-07-08 08:57:13.645236 - gail/main.py:201 - [Discriminator] iter = 70000 loss = -0.8747 grad_norm = 3.7693 grad_penalty = 0.2161 regularization = 0.0000 true_logits = 0.2275 fake_logits = -0.8633 true_prob = 0.5583 fake_prob = 0.3361 
2022-07-08 08:57:27.383844 - gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 530.3091 lengths = 161 } discounted_episode={ returns = 480.1704 lengths = 161 } 
2022-07-08 08:57:33.711616 - gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.2518 dist_std = 0.6233 vf_loss = 1.7859 grad_norm = 0.7846 nat_grad_norm = 0.3659 cg_residual = 0.0153 step_size = 0.4971 reward = -0.0000 fps = 49 mse_loss = 1.5907 
2022-07-08 08:57:40.317086 - gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.2284 dist_std = 0.6180 vf_loss = 1.0741 grad_norm = 0.8811 nat_grad_norm = 0.3857 cg_residual = 0.0165 step_size = 0.4237 reward = -0.0000 fps = 37 mse_loss = 1.6074 
2022-07-08 08:57:46.953133 - gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.1904 dist_std = 0.6184 vf_loss = 1.0293 grad_norm = 0.7808 nat_grad_norm = 0.3698 cg_residual = 0.0205 step_size = 0.5196 reward = 0.0000 fps = 30 mse_loss = 1.7902 
2022-07-08 08:57:53.653555 - gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.1302 dist_std = 0.6190 vf_loss = 0.6780 grad_norm = 0.5940 nat_grad_norm = 0.3355 cg_residual = 0.0122 step_size = 0.5519 reward = -0.0000 fps = 25 mse_loss = 1.6435 
2022-07-08 08:58:00.407649 - gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.1957 dist_std = 0.6159 vf_loss = 0.4423 grad_norm = 0.5200 nat_grad_norm = 0.3614 cg_residual = 0.0141 step_size = 0.5680 reward = -0.0000 fps = 21 mse_loss = 1.8368 
2022-07-08 08:58:00.641144 - gail/main.py:201 - [Discriminator] iter = 75000 loss = -0.9750 grad_norm = 3.4175 grad_penalty = 0.2223 regularization = 0.0000 true_logits = 0.2446 fake_logits = -0.9527 true_prob = 0.5614 fake_prob = 0.3210 
2022-07-08 08:58:15.583856 - gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 592.7360 lengths = 176 } discounted_episode={ returns = 526.1679 lengths = 175 } 
2022-07-08 08:58:22.246788 - gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.1706 dist_std = 0.6200 vf_loss = 0.7921 grad_norm = 0.6606 nat_grad_norm = 0.4371 cg_residual = 0.0533 step_size = 0.4576 reward = 0.0000 fps = 46 mse_loss = 2.0233 
2022-07-08 08:58:29.043720 - gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.1607 dist_std = 0.6184 vf_loss = 0.3531 grad_norm = 0.6384 nat_grad_norm = 0.3114 cg_residual = 0.0096 step_size = 0.5815 reward = 0.0000 fps = 35 mse_loss = 1.8667 
2022-07-08 08:58:35.619866 - gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.1755 dist_std = 0.6198 vf_loss = 1.1082 grad_norm = 0.8225 nat_grad_norm = 0.3934 cg_residual = 0.0137 step_size = 0.4686 reward = 0.0000 fps = 28 mse_loss = 2.0921 
2022-07-08 08:58:42.145656 - gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.1128 dist_std = 0.6205 vf_loss = 0.3544 grad_norm = 0.5292 nat_grad_norm = 0.2727 cg_residual = 0.0143 step_size = 0.5932 reward = 0.0000 fps = 24 mse_loss = 2.2972 
2022-07-08 08:58:49.024506 - gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.2042 dist_std = 0.6195 vf_loss = 0.7380 grad_norm = 0.4512 nat_grad_norm = 0.2323 cg_residual = 0.0106 step_size = 0.7216 reward = 0.0000 fps = 20 mse_loss = 1.7376 
2022-07-08 08:58:49.304732 - gail/main.py:201 - [Discriminator] iter = 80000 loss = -0.9242 grad_norm = 3.5417 grad_penalty = 0.2173 regularization = 0.0000 true_logits = 0.2386 fake_logits = -0.9029 true_prob = 0.5595 fake_prob = 0.3294 
2022-07-08 08:59:03.992480 - gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 606.3843 lengths = 180 } discounted_episode={ returns = 545.7226 lengths = 181 } 
2022-07-08 08:59:10.569848 - gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.1670 dist_std = 0.6217 vf_loss = 0.5135 grad_norm = 0.4847 nat_grad_norm = 0.2759 cg_residual = 0.0083 step_size = 0.6225 reward = -0.0000 fps = 47 mse_loss = 1.9001 
2022-07-08 08:59:17.261575 - gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.1598 dist_std = 0.6160 vf_loss = 0.4844 grad_norm = 0.6480 nat_grad_norm = 0.3220 cg_residual = 0.0101 step_size = 0.6054 reward = 0.0000 fps = 35 mse_loss = 1.7989 
2022-07-08 08:59:23.833503 - gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.1368 dist_std = 0.6140 vf_loss = 0.2602 grad_norm = 0.4419 nat_grad_norm = 0.2878 cg_residual = 0.0156 step_size = 0.6553 reward = 0.0000 fps = 28 mse_loss = 2.0075 
2022-07-08 08:59:30.226832 - gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.1682 dist_std = 0.6144 vf_loss = 0.2409 grad_norm = 0.5275 nat_grad_norm = 0.2615 cg_residual = 0.0153 step_size = 0.6342 reward = 0.0000 fps = 24 mse_loss = 2.0500 
2022-07-08 08:59:37.389213 - gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.3498 dist_std = 0.6138 vf_loss = 0.4670 grad_norm = 0.7836 nat_grad_norm = 0.2718 cg_residual = 0.0116 step_size = 0.5364 reward = 0.0000 fps = 20 mse_loss = 2.1565 
2022-07-08 08:59:37.630279 - gail/main.py:201 - [Discriminator] iter = 85000 loss = -1.0146 grad_norm = 3.3861 grad_penalty = 0.1987 regularization = 0.0000 true_logits = 0.1692 fake_logits = -1.0441 true_prob = 0.5458 fake_prob = 0.3108 
2022-07-08 08:59:54.058841 - gail/main.py:142 - [Evaluate] iter = 85000 episode={ returns = 642.9132 lengths = 193 } discounted_episode={ returns = 571.8689 lengths = 192 } 
2022-07-08 09:00:01.321684 - gail/main.py:174 - [TRPO] iter = 86000 dist_mean = 0.1211 dist_std = 0.6152 vf_loss = 0.4634 grad_norm = 0.8053 nat_grad_norm = 0.2973 cg_residual = 0.0162 step_size = 0.4836 reward = 0.0000 fps = 42 mse_loss = 2.3049 
2022-07-08 09:00:09.174479 - gail/main.py:174 - [TRPO] iter = 87000 dist_mean = 0.1341 dist_std = 0.6144 vf_loss = 0.2202 grad_norm = 0.4913 nat_grad_norm = 0.3395 cg_residual = 0.0196 step_size = 0.6013 reward = 0.0000 fps = 31 mse_loss = 2.3806 
2022-07-08 09:00:17.034427 - gail/main.py:174 - [TRPO] iter = 88000 dist_mean = 0.1771 dist_std = 0.6133 vf_loss = 1.0854 grad_norm = 0.7807 nat_grad_norm = 0.3839 cg_residual = 0.0324 step_size = 0.4378 reward = -0.0000 fps = 25 mse_loss = 2.6745 
2022-07-08 09:00:24.134056 - gail/main.py:174 - [TRPO] iter = 89000 dist_mean = 0.2055 dist_std = 0.6087 vf_loss = 0.1331 grad_norm = 0.6574 nat_grad_norm = 0.3458 cg_residual = 0.0183 step_size = 0.4961 reward = -0.0000 fps = 21 mse_loss = 2.7527 
2022-07-08 09:00:34.622917 - gail/main.py:174 - [TRPO] iter = 90000 dist_mean = 0.2252 dist_std = 0.6057 vf_loss = 0.9175 grad_norm = 1.0470 nat_grad_norm = 0.3823 cg_residual = 0.0242 step_size = 0.3914 reward = -0.0000 fps = 17 mse_loss = 2.8989 
2022-07-08 09:00:34.974327 - gail/main.py:201 - [Discriminator] iter = 90000 loss = -0.9164 grad_norm = 2.7552 grad_penalty = 0.1841 regularization = 0.0000 true_logits = 0.1874 fake_logits = -0.9131 true_prob = 0.5496 fake_prob = 0.3356 
2022-07-08 09:00:54.549785 - gail/main.py:142 - [Evaluate] iter = 90000 episode={ returns = 685.4149 lengths = 211 } discounted_episode={ returns = 605.6049 lengths = 210 } 
2022-07-08 09:01:01.316168 - gail/main.py:174 - [TRPO] iter = 91000 dist_mean = 0.1368 dist_std = 0.5998 vf_loss = 0.2232 grad_norm = 0.5688 nat_grad_norm = 0.3029 cg_residual = 0.0159 step_size = 0.5654 reward = 0.0000 fps = 37 mse_loss = 3.1119 
2022-07-08 09:01:07.964616 - gail/main.py:174 - [TRPO] iter = 92000 dist_mean = 0.1744 dist_std = 0.5969 vf_loss = 0.2805 grad_norm = 0.8325 nat_grad_norm = 0.2923 cg_residual = 0.0226 step_size = 0.4851 reward = 0.0000 fps = 30 mse_loss = 3.3532 
2022-07-08 09:01:15.094818 - gail/main.py:174 - [TRPO] iter = 93000 dist_mean = 0.1825 dist_std = 0.5895 vf_loss = 0.1488 grad_norm = 0.6732 nat_grad_norm = 0.3030 cg_residual = 0.0274 step_size = 0.5031 reward = 0.0000 fps = 24 mse_loss = 3.5367 
2022-07-08 09:01:21.866918 - gail/main.py:174 - [TRPO] iter = 94000 dist_mean = 0.2193 dist_std = 0.5856 vf_loss = 0.1219 grad_norm = 0.4764 nat_grad_norm = 0.3381 cg_residual = 0.0275 step_size = 0.5627 reward = 0.0000 fps = 21 mse_loss = 3.3459 
2022-07-08 09:01:28.357973 - gail/main.py:174 - [TRPO] iter = 95000 dist_mean = 0.1586 dist_std = 0.5800 vf_loss = 0.1246 grad_norm = 0.3911 nat_grad_norm = 0.2864 cg_residual = 0.0162 step_size = 0.6915 reward = 0.0000 fps = 18 mse_loss = 3.3344 
2022-07-08 09:01:28.572064 - gail/main.py:201 - [Discriminator] iter = 95000 loss = -0.7343 grad_norm = 2.6365 grad_penalty = 0.1834 regularization = 0.0000 true_logits = 0.1685 fake_logits = -0.7492 true_prob = 0.5453 fake_prob = 0.3645 
2022-07-08 09:01:47.162537 - gail/main.py:142 - [Evaluate] iter = 95000 episode={ returns = 793.1862 lengths = 236 } discounted_episode={ returns = 608.5683 lengths = 213 } 
2022-07-08 09:01:53.808910 - gail/main.py:174 - [TRPO] iter = 96000 dist_mean = 0.1359 dist_std = 0.5804 vf_loss = 0.1258 grad_norm = 0.7071 nat_grad_norm = 0.2521 cg_residual = 0.0215 step_size = 0.6326 reward = -0.0000 fps = 39 mse_loss = 3.7240 
2022-07-08 09:02:00.474762 - gail/main.py:174 - [TRPO] iter = 97000 dist_mean = 0.1989 dist_std = 0.5727 vf_loss = 0.2408 grad_norm = 0.4831 nat_grad_norm = 0.2755 cg_residual = 0.0169 step_size = 0.6054 reward = 0.0000 fps = 31 mse_loss = 3.8273 
2022-07-08 09:02:07.115917 - gail/main.py:174 - [TRPO] iter = 98000 dist_mean = 0.1872 dist_std = 0.5656 vf_loss = 0.1367 grad_norm = 0.6682 nat_grad_norm = 0.2786 cg_residual = 0.0412 step_size = 0.5231 reward = 0.0000 fps = 25 mse_loss = 3.9773 
2022-07-08 09:02:13.467919 - gail/main.py:174 - [TRPO] iter = 99000 dist_mean = 0.3145 dist_std = 0.5627 vf_loss = 0.3169 grad_norm = 0.3953 nat_grad_norm = 0.3098 cg_residual = 0.0228 step_size = 0.6429 reward = 0.0000 fps = 22 mse_loss = 3.9222 
2022-07-08 09:02:20.155273 - gail/main.py:174 - [TRPO] iter = 100000 dist_mean = 0.3123 dist_std = 0.5605 vf_loss = 0.2987 grad_norm = 0.4590 nat_grad_norm = 0.3709 cg_residual = 0.0450 step_size = 0.5054 reward = 0.0000 fps = 19 mse_loss = 4.0464 
2022-07-08 09:02:20.369305 - gail/main.py:201 - [Discriminator] iter = 100000 loss = -0.7392 grad_norm = 2.8810 grad_penalty = 0.1822 regularization = 0.0000 true_logits = 0.1342 fake_logits = -0.7871 true_prob = 0.5366 fake_prob = 0.3523 
2022-07-08 09:02:39.466984 - gail/main.py:142 - [Evaluate] iter = 100000 episode={ returns = 739.7403 lengths = 226 } discounted_episode={ returns = 615.7264 lengths = 215 } 
2022-07-08 09:02:46.110843 - gail/main.py:174 - [TRPO] iter = 101000 dist_mean = 0.2683 dist_std = 0.5617 vf_loss = 0.0824 grad_norm = 0.6892 nat_grad_norm = 0.2827 cg_residual = 0.0270 step_size = 0.5411 reward = 0.0000 fps = 38 mse_loss = 4.4756 
2022-07-08 09:02:53.070054 - gail/main.py:174 - [TRPO] iter = 102000 dist_mean = 0.2834 dist_std = 0.5568 vf_loss = 0.1451 grad_norm = 0.4862 nat_grad_norm = 0.2146 cg_residual = 0.0244 step_size = 0.6971 reward = -0.0000 fps = 30 mse_loss = 4.2480 
2022-07-08 09:02:59.973132 - gail/main.py:174 - [TRPO] iter = 103000 dist_mean = 0.1903 dist_std = 0.5587 vf_loss = 0.1718 grad_norm = 0.6120 nat_grad_norm = 0.2349 cg_residual = 0.0264 step_size = 0.6310 reward = -0.0000 fps = 25 mse_loss = 4.7658 
2022-07-08 09:03:07.032565 - gail/main.py:174 - [TRPO] iter = 104000 dist_mean = 0.2327 dist_std = 0.5496 vf_loss = 0.3675 grad_norm = 0.8474 nat_grad_norm = 0.3637 cg_residual = 0.0903 step_size = 0.4013 reward = 0.0000 fps = 21 mse_loss = 4.7110 
2022-07-08 09:03:13.789241 - gail/main.py:174 - [TRPO] iter = 105000 dist_mean = 0.2350 dist_std = 0.5498 vf_loss = 0.1053 grad_norm = 0.7795 nat_grad_norm = 0.2988 cg_residual = 0.0184 step_size = 0.4631 reward = 0.0000 fps = 18 mse_loss = 4.7865 
2022-07-08 09:03:14.032114 - gail/main.py:201 - [Discriminator] iter = 105000 loss = -0.7130 grad_norm = 3.0826 grad_penalty = 0.1673 regularization = 0.0000 true_logits = 0.1020 fake_logits = -0.7782 true_prob = 0.5284 fake_prob = 0.3517 
2022-07-08 09:03:37.183823 - gail/main.py:142 - [Evaluate] iter = 105000 episode={ returns = 924.2007 lengths = 268 } discounted_episode={ returns = 795.7664 lengths = 268 } 
2022-07-08 09:03:44.174072 - gail/main.py:174 - [TRPO] iter = 106000 dist_mean = 0.1486 dist_std = 0.5488 vf_loss = 0.1147 grad_norm = 0.6449 nat_grad_norm = 0.2300 cg_residual = 0.0320 step_size = 0.5532 reward = 0.0000 fps = 33 mse_loss = 4.6065 
2022-07-08 09:03:51.166405 - gail/main.py:174 - [TRPO] iter = 107000 dist_mean = 0.2748 dist_std = 0.5500 vf_loss = 0.2161 grad_norm = 0.4615 nat_grad_norm = 0.3021 cg_residual = 0.0430 step_size = 0.5695 reward = -0.0000 fps = 26 mse_loss = 4.5854 
2022-07-08 09:03:58.479664 - gail/main.py:174 - [TRPO] iter = 108000 dist_mean = 0.1962 dist_std = 0.5459 vf_loss = 0.1095 grad_norm = 0.7259 nat_grad_norm = 0.2677 cg_residual = 0.0329 step_size = 0.5702 reward = -0.0000 fps = 22 mse_loss = 4.9248 
2022-07-08 09:04:05.260211 - gail/main.py:174 - [TRPO] iter = 109000 dist_mean = 0.2645 dist_std = 0.5486 vf_loss = 0.1235 grad_norm = 0.8599 nat_grad_norm = 0.2649 cg_residual = 0.0306 step_size = 0.5709 reward = -0.0000 fps = 19 mse_loss = 4.3821 
2022-07-08 09:04:12.038607 - gail/main.py:174 - [TRPO] iter = 110000 dist_mean = 0.1471 dist_std = 0.5515 vf_loss = 0.0860 grad_norm = 0.7058 nat_grad_norm = 0.2244 cg_residual = 0.0246 step_size = 0.6361 reward = -0.0000 fps = 17 mse_loss = 4.8661 
2022-07-08 09:04:12.291042 - gail/main.py:201 - [Discriminator] iter = 110000 loss = -0.6923 grad_norm = 3.2211 grad_penalty = 0.1792 regularization = 0.0000 true_logits = 0.0717 fake_logits = -0.7998 true_prob = 0.5214 fake_prob = 0.3494 
2022-07-08 09:04:54.931525 - gail/main.py:142 - [Evaluate] iter = 110000 episode={ returns = 986.8518 lengths = 290 } discounted_episode={ returns = 840.4546 lengths = 293 } 
2022-07-08 09:05:08.552322 - gail/main.py:174 - [TRPO] iter = 111000 dist_mean = 0.2460 dist_std = 0.5465 vf_loss = 0.0797 grad_norm = 0.8799 nat_grad_norm = 0.2798 cg_residual = 0.0272 step_size = 0.5083 reward = 0.0000 fps = 17 mse_loss = 4.5868 
2022-07-08 09:05:25.968033 - gail/main.py:174 - [TRPO] iter = 112000 dist_mean = 0.2531 dist_std = 0.5455 vf_loss = 0.0723 grad_norm = 0.6710 nat_grad_norm = 0.2658 cg_residual = 0.0403 step_size = 0.5241 reward = -0.0000 fps = 13 mse_loss = 4.5019 
2022-07-08 09:05:43.008753 - gail/main.py:174 - [TRPO] iter = 113000 dist_mean = 0.2000 dist_std = 0.5467 vf_loss = 0.1147 grad_norm = 0.4209 nat_grad_norm = 0.3510 cg_residual = 0.0317 step_size = 0.5504 reward = -0.0000 fps = 11 mse_loss = 4.7589 
2022-07-08 09:05:59.111409 - gail/main.py:174 - [TRPO] iter = 114000 dist_mean = 0.2133 dist_std = 0.5408 vf_loss = 0.1570 grad_norm = 1.0021 nat_grad_norm = 0.5262 cg_residual = 0.1000 step_size = 0.3528 reward = -0.0000 fps = 9 mse_loss = 4.5801 
2022-07-08 09:06:14.711946 - gail/main.py:174 - [TRPO] iter = 115000 dist_mean = 0.1200 dist_std = 0.5406 vf_loss = 0.0476 grad_norm = 1.0090 nat_grad_norm = 0.2276 cg_residual = 0.0277 step_size = 0.4941 reward = -0.0000 fps = 8 mse_loss = 3.9366 
2022-07-08 09:06:15.193805 - gail/main.py:201 - [Discriminator] iter = 115000 loss = -0.6472 grad_norm = 2.5374 grad_penalty = 0.1668 regularization = 0.0000 true_logits = 0.0565 fake_logits = -0.7575 true_prob = 0.5188 fake_prob = 0.3571 
2022-07-08 09:07:10.041191 - gail/main.py:142 - [Evaluate] iter = 115000 episode={ returns = 927.5832 lengths = 268 } discounted_episode={ returns = 778.8448 lengths = 268 } 
2022-07-08 09:07:25.771295 - gail/main.py:174 - [TRPO] iter = 116000 dist_mean = 0.1884 dist_std = 0.5442 vf_loss = 0.1745 grad_norm = 0.4416 nat_grad_norm = 0.2697 cg_residual = 0.0378 step_size = 0.6178 reward = -0.0000 fps = 14 mse_loss = 4.3127 
2022-07-08 09:07:41.275411 - gail/main.py:174 - [TRPO] iter = 117000 dist_mean = 0.2013 dist_std = 0.5455 vf_loss = 0.0559 grad_norm = 0.7094 nat_grad_norm = 0.3757 cg_residual = 0.0487 step_size = 0.4543 reward = 0.0000 fps = 11 mse_loss = 3.8578 
2022-07-08 09:07:58.240038 - gail/main.py:174 - [TRPO] iter = 118000 dist_mean = 0.1908 dist_std = 0.5389 vf_loss = 0.1492 grad_norm = 0.6625 nat_grad_norm = 0.2943 cg_residual = 0.0319 step_size = 0.5276 reward = 0.0000 fps = 9 mse_loss = 4.3739 
2022-07-08 09:08:15.110891 - gail/main.py:174 - [TRPO] iter = 119000 dist_mean = 0.2076 dist_std = 0.5355 vf_loss = 0.1946 grad_norm = 0.5159 nat_grad_norm = 0.3312 cg_residual = 0.0364 step_size = 0.5220 reward = 0.0000 fps = 8 mse_loss = 4.2085 
2022-07-08 09:08:32.262653 - gail/main.py:174 - [TRPO] iter = 120000 dist_mean = 0.1496 dist_std = 0.5412 vf_loss = 0.2213 grad_norm = 0.5531 nat_grad_norm = 0.2256 cg_residual = 0.0428 step_size = 0.5980 reward = -0.0000 fps = 7 mse_loss = 4.3653 
2022-07-08 09:08:32.890413 - gail/main.py:201 - [Discriminator] iter = 120000 loss = -0.7529 grad_norm = 2.9447 grad_penalty = 0.1545 regularization = 0.0000 true_logits = 0.0149 fake_logits = -0.8925 true_prob = 0.5079 fake_prob = 0.3324 
2022-07-08 09:09:42.367072 - gail/main.py:142 - [Evaluate] iter = 120000 episode={ returns = 903.5499 lengths = 272 } discounted_episode={ returns = 773.5100 lengths = 274 } 
2022-07-08 09:10:01.505720 - gail/main.py:174 - [TRPO] iter = 121000 dist_mean = 0.2288 dist_std = 0.5365 vf_loss = 0.1517 grad_norm = 0.5913 nat_grad_norm = 0.2466 cg_residual = 0.0189 step_size = 0.6043 reward = 0.0000 fps = 11 mse_loss = 4.6887 
2022-07-08 09:10:26.789672 - gail/main.py:174 - [TRPO] iter = 122000 dist_mean = 0.2411 dist_std = 0.5284 vf_loss = 0.0926 grad_norm = 0.7287 nat_grad_norm = 0.2420 cg_residual = 0.0114 step_size = 0.6251 reward = -0.0000 fps = 8 mse_loss = 4.6802 
2022-07-08 09:10:53.284427 - gail/main.py:174 - [TRPO] iter = 123000 dist_mean = 0.2211 dist_std = 0.5317 vf_loss = 0.4605 grad_norm = 0.7379 nat_grad_norm = 0.2237 cg_residual = 0.0134 step_size = 0.6518 reward = 0.0000 fps = 7 mse_loss = 4.6504 
2022-07-08 09:11:26.081265 - gail/main.py:174 - [TRPO] iter = 124000 dist_mean = 0.1642 dist_std = 0.5343 vf_loss = 0.1218 grad_norm = 0.6115 nat_grad_norm = 0.2697 cg_residual = 0.0312 step_size = 0.5118 reward = 0.0000 fps = 5 mse_loss = 5.0297 
2022-07-08 09:11:51.679419 - gail/main.py:174 - [TRPO] iter = 125000 dist_mean = 0.1096 dist_std = 0.5221 vf_loss = 0.0879 grad_norm = 0.9248 nat_grad_norm = 0.2457 cg_residual = 0.0354 step_size = 0.5609 reward = 0.0000 fps = 5 mse_loss = 5.1224 
2022-07-08 09:11:52.383934 - gail/main.py:201 - [Discriminator] iter = 125000 loss = -0.7229 grad_norm = 2.4714 grad_penalty = 0.1364 regularization = 0.0000 true_logits = -0.0034 fake_logits = -0.8628 true_prob = 0.5036 fake_prob = 0.3366 
2022-07-08 09:13:25.456553 - gail/main.py:142 - [Evaluate] iter = 125000 episode={ returns = 897.8472 lengths = 258 } discounted_episode={ returns = 728.6023 lengths = 247 } 
2022-07-08 09:13:53.275279 - gail/main.py:174 - [TRPO] iter = 126000 dist_mean = 0.2916 dist_std = 0.5312 vf_loss = 0.2488 grad_norm = 0.8816 nat_grad_norm = 0.2663 cg_residual = 0.0515 step_size = 0.4977 reward = 0.0000 fps = 8 mse_loss = 5.4634 
2022-07-08 09:14:20.296896 - gail/main.py:174 - [TRPO] iter = 127000 dist_mean = 0.1561 dist_std = 0.5246 vf_loss = 0.2720 grad_norm = 0.5917 nat_grad_norm = 0.2045 cg_residual = 0.0289 step_size = 0.6238 reward = 0.0000 fps = 6 mse_loss = 6.2383 
2022-07-08 09:14:49.152838 - gail/main.py:174 - [TRPO] iter = 128000 dist_mean = 0.0783 dist_std = 0.5187 vf_loss = 0.0931 grad_norm = 0.6696 nat_grad_norm = 0.2177 cg_residual = 0.0211 step_size = 0.6643 reward = 0.0000 fps = 5 mse_loss = 6.7128 
2022-07-08 09:15:18.443091 - gail/main.py:174 - [TRPO] iter = 129000 dist_mean = 0.1709 dist_std = 0.5257 vf_loss = 0.8291 grad_norm = 0.8308 nat_grad_norm = 0.2723 cg_residual = 0.0413 step_size = 0.4997 reward = 0.0000 fps = 4 mse_loss = 6.6929 
2022-07-08 09:15:46.607781 - gail/main.py:174 - [TRPO] iter = 130000 dist_mean = 0.1057 dist_std = 0.5228 vf_loss = 0.0743 grad_norm = 0.7878 nat_grad_norm = 0.2294 cg_residual = 0.0369 step_size = 0.5968 reward = -0.0000 fps = 4 mse_loss = 7.1515 
2022-07-08 09:15:47.431368 - gail/main.py:201 - [Discriminator] iter = 130000 loss = -0.6378 grad_norm = 2.2359 grad_penalty = 0.1414 regularization = 0.0000 true_logits = -0.0277 fake_logits = -0.8069 true_prob = 0.4992 fake_prob = 0.3472 
2022-07-08 09:17:22.831974 - gail/main.py:142 - [Evaluate] iter = 130000 episode={ returns = 920.8492 lengths = 260 } discounted_episode={ returns = 792.2397 lengths = 263 } 
2022-07-08 09:17:51.029720 - gail/main.py:174 - [TRPO] iter = 131000 dist_mean = 0.1803 dist_std = 0.5172 vf_loss = 0.1104 grad_norm = 0.7440 nat_grad_norm = 0.2725 cg_residual = 0.0491 step_size = 0.5568 reward = 0.0000 fps = 8 mse_loss = 6.8007 
2022-07-08 09:18:17.264573 - gail/main.py:174 - [TRPO] iter = 132000 dist_mean = 0.1231 dist_std = 0.5146 vf_loss = 0.0772 grad_norm = 0.6568 nat_grad_norm = 0.2710 cg_residual = 0.0568 step_size = 0.5498 reward = 0.0000 fps = 6 mse_loss = 6.8679 
2022-07-08 09:18:44.655581 - gail/main.py:174 - [TRPO] iter = 133000 dist_mean = 0.1741 dist_std = 0.5081 vf_loss = 0.1516 grad_norm = 1.0395 nat_grad_norm = 0.2916 cg_residual = 0.0306 step_size = 0.4863 reward = 0.0000 fps = 5 mse_loss = 6.4543 
2022-07-08 09:19:12.978125 - gail/main.py:174 - [TRPO] iter = 134000 dist_mean = 0.1215 dist_std = 0.5025 vf_loss = 0.0869 grad_norm = 0.9689 nat_grad_norm = 0.2676 cg_residual = 0.0699 step_size = 0.4820 reward = 0.0000 fps = 4 mse_loss = 6.5404 
2022-07-08 09:19:40.090304 - gail/main.py:174 - [TRPO] iter = 135000 dist_mean = 0.1754 dist_std = 0.5014 vf_loss = 0.1241 grad_norm = 0.5894 nat_grad_norm = 0.1886 cg_residual = 0.0192 step_size = 0.6340 reward = 0.0000 fps = 4 mse_loss = 6.7048 
2022-07-08 09:19:40.883585 - gail/main.py:201 - [Discriminator] iter = 135000 loss = -0.7553 grad_norm = 2.4079 grad_penalty = 0.1384 regularization = 0.0000 true_logits = 0.0026 fake_logits = -0.8911 true_prob = 0.5059 fake_prob = 0.3259 
2022-07-08 09:21:15.764170 - gail/main.py:142 - [Evaluate] iter = 135000 episode={ returns = 958.8441 lengths = 273 } discounted_episode={ returns = 825.1908 lengths = 278 } 
2022-07-08 09:21:41.832555 - gail/main.py:174 - [TRPO] iter = 136000 dist_mean = 0.1162 dist_std = 0.5034 vf_loss = 0.0971 grad_norm = 0.5599 nat_grad_norm = 0.2572 cg_residual = 0.0361 step_size = 0.5617 reward = 0.0000 fps = 8 mse_loss = 6.4441 
2022-07-08 09:22:14.852575 - gail/main.py:174 - [TRPO] iter = 137000 dist_mean = 0.1472 dist_std = 0.4956 vf_loss = 0.0768 grad_norm = 0.7732 nat_grad_norm = 0.3219 cg_residual = 0.0410 step_size = 0.4837 reward = -0.0000 fps = 6 mse_loss = 5.8448 
2022-07-08 09:22:41.717264 - gail/main.py:174 - [TRPO] iter = 138000 dist_mean = 0.0883 dist_std = 0.4891 vf_loss = 0.1340 grad_norm = 0.8408 nat_grad_norm = 0.2324 cg_residual = 0.0660 step_size = 0.5017 reward = -0.0000 fps = 5 mse_loss = 5.6633 
2022-07-08 09:23:09.041574 - gail/main.py:174 - [TRPO] iter = 139000 dist_mean = 0.1506 dist_std = 0.4896 vf_loss = 0.0730 grad_norm = 0.7434 nat_grad_norm = 0.2571 cg_residual = 0.0527 step_size = 0.5722 reward = 0.0000 fps = 4 mse_loss = 5.6236 
2022-07-08 09:23:35.771555 - gail/main.py:174 - [TRPO] iter = 140000 dist_mean = 0.0902 dist_std = 0.4907 vf_loss = 0.0898 grad_norm = 0.8234 nat_grad_norm = 0.2471 cg_residual = 0.0328 step_size = 0.5261 reward = 0.0000 fps = 4 mse_loss = 5.4369 
2022-07-08 09:23:36.613387 - gail/main.py:201 - [Discriminator] iter = 140000 loss = -0.6828 grad_norm = 2.4832 grad_penalty = 0.1261 regularization = 0.0000 true_logits = 0.0069 fake_logits = -0.8020 true_prob = 0.5059 fake_prob = 0.3447 
2022-07-08 09:25:13.820826 - gail/main.py:142 - [Evaluate] iter = 140000 episode={ returns = 1015.6996 lengths = 296 } discounted_episode={ returns = 859.8271 lengths = 296 } 
2022-07-08 09:25:39.894812 - gail/main.py:174 - [TRPO] iter = 141000 dist_mean = 0.1064 dist_std = 0.4899 vf_loss = 0.3118 grad_norm = 0.9019 nat_grad_norm = 0.2813 cg_residual = 0.0646 step_size = 0.4305 reward = -0.0000 fps = 8 mse_loss = 5.4447 
2022-07-08 09:26:07.386625 - gail/main.py:174 - [TRPO] iter = 142000 dist_mean = 0.1450 dist_std = 0.4798 vf_loss = 0.0621 grad_norm = 0.7228 nat_grad_norm = 0.2871 cg_residual = 0.0810 step_size = 0.5161 reward = -0.0000 fps = 6 mse_loss = 5.4630 
2022-07-08 09:26:34.034132 - gail/main.py:174 - [TRPO] iter = 143000 dist_mean = 0.1391 dist_std = 0.4677 vf_loss = 0.0855 grad_norm = 1.0950 nat_grad_norm = 0.2967 cg_residual = 0.0664 step_size = 0.4732 reward = 0.0000 fps = 5 mse_loss = 5.4966 
2022-07-08 09:26:59.949627 - gail/main.py:174 - [TRPO] iter = 144000 dist_mean = 0.0988 dist_std = 0.4655 vf_loss = 0.0637 grad_norm = 0.6164 nat_grad_norm = 0.2681 cg_residual = 0.0788 step_size = 0.5440 reward = -0.0000 fps = 4 mse_loss = 5.9605 
2022-07-08 09:27:24.970686 - gail/main.py:174 - [TRPO] iter = 145000 dist_mean = 0.0848 dist_std = 0.4577 vf_loss = 0.1257 grad_norm = 0.7282 nat_grad_norm = 0.2465 cg_residual = 0.0268 step_size = 0.5979 reward = -0.0000 fps = 4 mse_loss = 5.4613 
2022-07-08 09:27:25.764582 - gail/main.py:201 - [Discriminator] iter = 145000 loss = -0.6538 grad_norm = 2.2681 grad_penalty = 0.1346 regularization = 0.0000 true_logits = -0.0026 fake_logits = -0.7910 true_prob = 0.5041 fake_prob = 0.3467 
2022-07-08 09:28:56.794094 - gail/main.py:142 - [Evaluate] iter = 145000 episode={ returns = 990.8190 lengths = 278 } discounted_episode={ returns = 843.1232 lengths = 277 } 
2022-07-08 09:29:22.589645 - gail/main.py:174 - [TRPO] iter = 146000 dist_mean = 0.1200 dist_std = 0.4583 vf_loss = 0.0839 grad_norm = 0.9439 nat_grad_norm = 0.2235 cg_residual = 0.0619 step_size = 0.5556 reward = 0.0000 fps = 8 mse_loss = 5.4036 
2022-07-08 09:29:47.902754 - gail/main.py:174 - [TRPO] iter = 147000 dist_mean = 0.1299 dist_std = 0.4564 vf_loss = 0.0795 grad_norm = 0.8779 nat_grad_norm = 0.2792 cg_residual = 0.0538 step_size = 0.4859 reward = 0.0000 fps = 7 mse_loss = 5.0583 
2022-07-08 09:30:13.284532 - gail/main.py:174 - [TRPO] iter = 148000 dist_mean = 0.0895 dist_std = 0.4477 vf_loss = 0.0596 grad_norm = 0.9266 nat_grad_norm = 0.2657 cg_residual = 0.0462 step_size = 0.5467 reward = 0.0000 fps = 5 mse_loss = 5.2415 
2022-07-08 09:30:38.669106 - gail/main.py:174 - [TRPO] iter = 149000 dist_mean = 0.1252 dist_std = 0.4470 vf_loss = 0.0544 grad_norm = 0.7169 nat_grad_norm = 0.2562 cg_residual = 0.0732 step_size = 0.5237 reward = -0.0000 fps = 5 mse_loss = 5.3217 
2022-07-08 09:31:04.029636 - gail/main.py:174 - [TRPO] iter = 150000 dist_mean = 0.0705 dist_std = 0.4409 vf_loss = 0.1017 grad_norm = 0.8322 nat_grad_norm = 0.3184 cg_residual = 0.0768 step_size = 0.4517 reward = 0.0000 fps = 4 mse_loss = 5.4098 
2022-07-08 09:31:04.942140 - gail/main.py:201 - [Discriminator] iter = 150000 loss = -0.5955 grad_norm = 2.8535 grad_penalty = 0.1347 regularization = 0.0000 true_logits = 0.0114 fake_logits = -0.7188 true_prob = 0.5078 fake_prob = 0.3557 
2022-07-08 09:32:48.254352 - gail/main.py:142 - [Evaluate] iter = 150000 episode={ returns = 1036.2871 lengths = 295 } discounted_episode={ returns = 878.7361 lengths = 296 } 
2022-07-08 09:33:13.174891 - gail/main.py:174 - [TRPO] iter = 151000 dist_mean = 0.1077 dist_std = 0.4338 vf_loss = 0.0677 grad_norm = 0.8369 nat_grad_norm = 0.1887 cg_residual = 0.0546 step_size = 0.5905 reward = -0.0000 fps = 7 mse_loss = 5.5257 
2022-07-08 09:33:38.007319 - gail/main.py:174 - [TRPO] iter = 152000 dist_mean = 0.0924 dist_std = 0.4303 vf_loss = 0.7239 grad_norm = 1.1603 nat_grad_norm = 0.2953 cg_residual = 0.1255 step_size = 0.4317 reward = -0.0000 fps = 6 mse_loss = 5.8935 
2022-07-08 09:34:02.864214 - gail/main.py:174 - [TRPO] iter = 153000 dist_mean = 0.1033 dist_std = 0.4228 vf_loss = 0.0639 grad_norm = 0.7611 nat_grad_norm = 0.1947 cg_residual = 0.0565 step_size = 0.6363 reward = -0.0000 fps = 5 mse_loss = 5.9399 
2022-07-08 09:34:26.859587 - gail/main.py:174 - [TRPO] iter = 154000 dist_mean = 0.1489 dist_std = 0.4215 vf_loss = 0.0592 grad_norm = 0.9271 nat_grad_norm = 0.2779 cg_residual = 0.0882 step_size = 0.4258 reward = 0.0000 fps = 4 mse_loss = 5.6674 
2022-07-08 09:34:52.182978 - gail/main.py:174 - [TRPO] iter = 155000 dist_mean = 0.1081 dist_std = 0.4216 vf_loss = 0.0448 grad_norm = 0.6162 nat_grad_norm = 0.1455 cg_residual = 0.0182 step_size = 0.7176 reward = 0.0000 fps = 4 mse_loss = 5.2727 
2022-07-08 09:34:52.865393 - gail/main.py:201 - [Discriminator] iter = 155000 loss = -0.6608 grad_norm = 3.0013 grad_penalty = 0.1308 regularization = 0.0000 true_logits = 0.0050 fake_logits = -0.7866 true_prob = 0.5054 fake_prob = 0.3426 
2022-07-08 09:36:37.406960 - gail/main.py:142 - [Evaluate] iter = 155000 episode={ returns = 1149.9841 lengths = 330 } discounted_episode={ returns = 954.3383 lengths = 330 } 
2022-07-08 09:37:02.822942 - gail/main.py:174 - [TRPO] iter = 156000 dist_mean = 0.0745 dist_std = 0.4175 vf_loss = 0.0553 grad_norm = 1.0684 nat_grad_norm = 0.2350 cg_residual = 0.0493 step_size = 0.4562 reward = 0.0000 fps = 7 mse_loss = 5.2170 
2022-07-08 09:37:27.902644 - gail/main.py:174 - [TRPO] iter = 157000 dist_mean = 0.1250 dist_std = 0.4072 vf_loss = 0.0353 grad_norm = 0.8804 nat_grad_norm = 0.1941 cg_residual = 0.0453 step_size = 0.5863 reward = -0.0000 fps = 6 mse_loss = 4.8906 
2022-07-08 09:37:52.705855 - gail/main.py:174 - [TRPO] iter = 158000 dist_mean = 0.1385 dist_std = 0.4040 vf_loss = 0.0548 grad_norm = 0.8969 nat_grad_norm = 0.2171 cg_residual = 0.0933 step_size = 0.5266 reward = 0.0000 fps = 5 mse_loss = 4.7281 
2022-07-08 09:38:17.115872 - gail/main.py:174 - [TRPO] iter = 159000 dist_mean = 0.0855 dist_std = 0.3974 vf_loss = 0.0605 grad_norm = 1.0413 nat_grad_norm = 0.2631 cg_residual = 0.0685 step_size = 0.4725 reward = -0.0000 fps = 4 mse_loss = 4.8758 
2022-07-08 09:38:41.612832 - gail/main.py:174 - [TRPO] iter = 160000 dist_mean = 0.0933 dist_std = 0.3933 vf_loss = 0.0540 grad_norm = 0.9001 nat_grad_norm = 0.2327 cg_residual = 0.0437 step_size = 0.5391 reward = 0.0000 fps = 4 mse_loss = 4.4834 
2022-07-08 09:38:42.373992 - gail/main.py:201 - [Discriminator] iter = 160000 loss = -0.4724 grad_norm = 2.8516 grad_penalty = 0.1237 regularization = 0.0000 true_logits = 0.0259 fake_logits = -0.5702 true_prob = 0.5098 fake_prob = 0.3800 
2022-07-08 09:40:35.075316 - gail/main.py:142 - [Evaluate] iter = 160000 episode={ returns = 1188.4217 lengths = 358 } discounted_episode={ returns = 910.6661 lengths = 347 } 
2022-07-08 09:40:59.119138 - gail/main.py:174 - [TRPO] iter = 161000 dist_mean = 0.1309 dist_std = 0.3847 vf_loss = 0.0933 grad_norm = 1.0019 nat_grad_norm = 0.2072 cg_residual = 0.0413 step_size = 0.5284 reward = -0.0000 fps = 7 mse_loss = 4.4572 
2022-07-08 09:41:23.208752 - gail/main.py:174 - [TRPO] iter = 162000 dist_mean = 0.1095 dist_std = 0.3865 vf_loss = 0.0520 grad_norm = 0.7519 nat_grad_norm = 0.2391 cg_residual = 0.1010 step_size = 0.5186 reward = 0.0000 fps = 6 mse_loss = 4.5425 
2022-07-08 09:41:47.689094 - gail/main.py:174 - [TRPO] iter = 163000 dist_mean = 0.1072 dist_std = 0.3821 vf_loss = 0.0446 grad_norm = 1.2984 nat_grad_norm = 0.1948 cg_residual = 0.0690 step_size = 0.4718 reward = -0.0000 fps = 5 mse_loss = 4.1942 
2022-07-08 09:42:17.860833 - gail/main.py:174 - [TRPO] iter = 164000 dist_mean = 0.1103 dist_std = 0.3796 vf_loss = 0.1061 grad_norm = 0.8309 nat_grad_norm = 0.1554 cg_residual = 0.0286 step_size = 0.6686 reward = 0.0000 fps = 4 mse_loss = 4.6540 
2022-07-08 09:42:42.513988 - gail/main.py:174 - [TRPO] iter = 165000 dist_mean = 0.0837 dist_std = 0.3729 vf_loss = 0.0341 grad_norm = 0.7148 nat_grad_norm = 0.1701 cg_residual = 0.0536 step_size = 0.6271 reward = 0.0000 fps = 4 mse_loss = 4.2808 
2022-07-08 09:42:43.189508 - gail/main.py:201 - [Discriminator] iter = 165000 loss = -0.4351 grad_norm = 3.0061 grad_penalty = 0.1259 regularization = 0.0000 true_logits = -0.0087 fake_logits = -0.5697 true_prob = 0.5026 fake_prob = 0.3815 
2022-07-08 09:44:50.579722 - gail/main.py:142 - [Evaluate] iter = 165000 episode={ returns = 1536.9412 lengths = 427 } discounted_episode={ returns = 1178.1036 lengths = 414 } 
2022-07-08 09:45:13.921255 - gail/main.py:174 - [TRPO] iter = 166000 dist_mean = 0.0936 dist_std = 0.3707 vf_loss = 0.2387 grad_norm = 1.4570 nat_grad_norm = 0.2869 cg_residual = 0.0995 step_size = 0.4054 reward = -0.0000 fps = 6 mse_loss = 4.2164 
2022-07-08 09:45:37.231770 - gail/main.py:174 - [TRPO] iter = 167000 dist_mean = 0.1196 dist_std = 0.3700 vf_loss = 0.0634 grad_norm = 0.9693 nat_grad_norm = 0.3730 cg_residual = 0.1648 step_size = 0.3956 reward = 0.0000 fps = 5 mse_loss = 4.3770 
2022-07-08 09:46:00.767519 - gail/main.py:174 - [TRPO] iter = 168000 dist_mean = 0.1180 dist_std = 0.3687 vf_loss = 0.0416 grad_norm = 1.0013 nat_grad_norm = 0.2021 cg_residual = 0.0697 step_size = 0.5183 reward = -0.0000 fps = 5 mse_loss = 4.1816 
2022-07-08 09:46:24.181591 - gail/main.py:174 - [TRPO] iter = 169000 dist_mean = 0.0602 dist_std = 0.3697 vf_loss = 0.0531 grad_norm = 0.7615 nat_grad_norm = 0.1843 cg_residual = 0.0523 step_size = 0.6497 reward = 0.0000 fps = 4 mse_loss = 3.9428 
2022-07-08 09:46:48.747972 - gail/main.py:174 - [TRPO] iter = 170000 dist_mean = 0.1368 dist_std = 0.3632 vf_loss = 0.0858 grad_norm = 1.1730 nat_grad_norm = 0.3091 cg_residual = 0.1262 step_size = 0.4332 reward = 0.0000 fps = 4 mse_loss = 4.1360 
2022-07-08 09:46:49.491755 - gail/main.py:201 - [Discriminator] iter = 170000 loss = -0.6022 grad_norm = 2.2531 grad_penalty = 0.1177 regularization = 0.0000 true_logits = -0.0005 fake_logits = -0.7205 true_prob = 0.5032 fake_prob = 0.3536 
2022-07-08 09:48:42.832073 - gail/main.py:142 - [Evaluate] iter = 170000 episode={ returns = 1338.4992 lengths = 371 } discounted_episode={ returns = 1058.0207 lengths = 359 } 
2022-07-08 09:49:06.750257 - gail/main.py:174 - [TRPO] iter = 171000 dist_mean = 0.1011 dist_std = 0.3642 vf_loss = 0.0638 grad_norm = 0.7071 nat_grad_norm = 0.1801 cg_residual = 0.0497 step_size = 0.5867 reward = 0.0000 fps = 7 mse_loss = 4.1778 
2022-07-08 09:49:30.895183 - gail/main.py:174 - [TRPO] iter = 172000 dist_mean = 0.1020 dist_std = 0.3612 vf_loss = 0.0640 grad_norm = 0.9918 nat_grad_norm = 0.2202 cg_residual = 0.1014 step_size = 0.5289 reward = -0.0000 fps = 6 mse_loss = 4.1249 
2022-07-08 09:49:57.761643 - gail/main.py:174 - [TRPO] iter = 173000 dist_mean = 0.0692 dist_std = 0.3595 vf_loss = 0.0596 grad_norm = 1.0377 nat_grad_norm = 0.1933 cg_residual = 0.0498 step_size = 0.5623 reward = 0.0000 fps = 5 mse_loss = 3.9639 
2022-07-08 09:50:23.068067 - gail/main.py:174 - [TRPO] iter = 174000 dist_mean = 0.0942 dist_std = 0.3587 vf_loss = 0.0949 grad_norm = 0.9370 nat_grad_norm = 0.2719 cg_residual = 0.1003 step_size = 0.4564 reward = 0.0000 fps = 4 mse_loss = 3.9406 
2022-07-08 09:50:45.798243 - gail/main.py:174 - [TRPO] iter = 175000 dist_mean = 0.0564 dist_std = 0.3522 vf_loss = 0.0706 grad_norm = 0.7407 nat_grad_norm = 0.2236 cg_residual = 0.0549 step_size = 0.5478 reward = -0.0000 fps = 4 mse_loss = 3.9320 
2022-07-08 09:50:46.547607 - gail/main.py:201 - [Discriminator] iter = 175000 loss = -0.5048 grad_norm = 2.5363 grad_penalty = 0.1122 regularization = 0.0000 true_logits = -0.0033 fake_logits = -0.6203 true_prob = 0.5022 fake_prob = 0.3737 
2022-07-08 09:52:39.975253 - gail/main.py:142 - [Evaluate] iter = 175000 episode={ returns = 1248.1575 lengths = 349 } discounted_episode={ returns = 1026.8928 lengths = 349 } 
2022-07-08 09:53:04.530310 - gail/main.py:174 - [TRPO] iter = 176000 dist_mean = 0.0855 dist_std = 0.3457 vf_loss = 0.2649 grad_norm = 1.2023 nat_grad_norm = 0.2093 cg_residual = 0.0869 step_size = 0.5001 reward = -0.0000 fps = 7 mse_loss = 3.9253 
2022-07-08 09:53:29.709938 - gail/main.py:174 - [TRPO] iter = 177000 dist_mean = 0.1056 dist_std = 0.3437 vf_loss = 0.0722 grad_norm = 1.2578 nat_grad_norm = 0.2086 cg_residual = 0.1055 step_size = 0.4740 reward = 0.0000 fps = 6 mse_loss = 3.9670 
2022-07-08 09:53:54.765682 - gail/main.py:174 - [TRPO] iter = 178000 dist_mean = 0.0755 dist_std = 0.3435 vf_loss = 0.0888 grad_norm = 1.0599 nat_grad_norm = 0.2173 cg_residual = 0.1225 step_size = 0.4488 reward = 0.0000 fps = 5 mse_loss = 3.8259 
2022-07-08 09:54:20.319425 - gail/main.py:174 - [TRPO] iter = 179000 dist_mean = 0.0254 dist_std = 0.3427 vf_loss = 0.0562 grad_norm = 1.1596 nat_grad_norm = 0.1841 cg_residual = 0.0755 step_size = 0.5213 reward = 0.0000 fps = 4 mse_loss = 3.7651 
2022-07-08 09:54:44.843317 - gail/main.py:174 - [TRPO] iter = 180000 dist_mean = 0.0576 dist_std = 0.3348 vf_loss = 0.0597 grad_norm = 1.3740 nat_grad_norm = 0.1872 cg_residual = 0.0614 step_size = 0.5077 reward = -0.0000 fps = 4 mse_loss = 3.6710 
2022-07-08 09:54:45.550033 - gail/main.py:201 - [Discriminator] iter = 180000 loss = -0.3095 grad_norm = 2.4311 grad_penalty = 0.1050 regularization = 0.0000 true_logits = 0.0407 fake_logits = -0.3738 true_prob = 0.5124 fake_prob = 0.4176 
2022-07-08 09:57:13.467784 - gail/main.py:142 - [Evaluate] iter = 180000 episode={ returns = 1924.6085 lengths = 535 } discounted_episode={ returns = 1339.5732 lengths = 484 } 
2022-07-08 09:57:36.929983 - gail/main.py:174 - [TRPO] iter = 181000 dist_mean = 0.0980 dist_std = 0.3321 vf_loss = 0.0775 grad_norm = 0.8623 nat_grad_norm = 0.2575 cg_residual = 0.1382 step_size = 0.5386 reward = 0.0000 fps = 5 mse_loss = 3.6151 
2022-07-08 09:58:00.119071 - gail/main.py:174 - [TRPO] iter = 182000 dist_mean = 0.1029 dist_std = 0.3281 vf_loss = 0.2252 grad_norm = 0.7964 nat_grad_norm = 0.2147 cg_residual = 0.0791 step_size = 0.4916 reward = 0.0000 fps = 5 mse_loss = 3.5195 
2022-07-08 09:58:24.217089 - gail/main.py:174 - [TRPO] iter = 183000 dist_mean = 0.1091 dist_std = 0.3228 vf_loss = 0.1378 grad_norm = 1.1097 nat_grad_norm = 0.2058 cg_residual = 0.0555 step_size = 0.5365 reward = -0.0000 fps = 4 mse_loss = 3.4194 
2022-07-08 09:58:49.510492 - gail/main.py:174 - [TRPO] iter = 184000 dist_mean = 0.1389 dist_std = 0.3173 vf_loss = 0.1053 grad_norm = 0.9318 nat_grad_norm = 0.1670 cg_residual = 0.0548 step_size = 0.6044 reward = -0.0000 fps = 4 mse_loss = 3.3055 
2022-07-08 09:59:12.676806 - gail/main.py:174 - [TRPO] iter = 185000 dist_mean = 0.0790 dist_std = 0.3158 vf_loss = 0.0558 grad_norm = 0.8811 nat_grad_norm = 0.1671 cg_residual = 0.0391 step_size = 0.6510 reward = 0.0000 fps = 3 mse_loss = 3.3468 
2022-07-08 09:59:13.372456 - gail/main.py:201 - [Discriminator] iter = 185000 loss = -0.5328 grad_norm = 2.4819 grad_penalty = 0.1054 regularization = 0.0000 true_logits = -0.0023 fake_logits = -0.6405 true_prob = 0.5023 fake_prob = 0.3680 
2022-07-08 10:01:26.761580 - gail/main.py:142 - [Evaluate] iter = 185000 episode={ returns = 1537.5605 lengths = 429 } discounted_episode={ returns = 1176.8844 lengths = 409 } 
2022-07-08 10:01:55.136661 - gail/main.py:174 - [TRPO] iter = 186000 dist_mean = 0.0748 dist_std = 0.3128 vf_loss = 0.0356 grad_norm = 0.8506 nat_grad_norm = 0.1613 cg_residual = 0.0828 step_size = 0.6542 reward = 0.0000 fps = 6 mse_loss = 3.4539 
2022-07-08 10:02:29.339426 - gail/main.py:174 - [TRPO] iter = 187000 dist_mean = 0.1574 dist_std = 0.3131 vf_loss = 0.0654 grad_norm = 1.0033 nat_grad_norm = 0.1804 cg_residual = 0.0896 step_size = 0.5671 reward = -0.0000 fps = 5 mse_loss = 3.2645 
2022-07-08 10:02:56.966259 - gail/main.py:174 - [TRPO] iter = 188000 dist_mean = 0.1698 dist_std = 0.3168 vf_loss = 0.1236 grad_norm = 1.1478 nat_grad_norm = 0.1790 cg_residual = 0.0956 step_size = 0.5554 reward = 0.0000 fps = 4 mse_loss = 3.3335 
2022-07-08 10:03:24.249439 - gail/main.py:174 - [TRPO] iter = 189000 dist_mean = 0.1609 dist_std = 0.3160 vf_loss = 0.0959 grad_norm = 1.0199 nat_grad_norm = 0.2065 cg_residual = 0.0877 step_size = 0.5770 reward = -0.0000 fps = 3 mse_loss = 3.3540 
2022-07-08 10:03:51.896616 - gail/main.py:174 - [TRPO] iter = 190000 dist_mean = 0.1537 dist_std = 0.3172 vf_loss = 0.1455 grad_norm = 0.6072 nat_grad_norm = 0.2172 cg_residual = 0.1332 step_size = 0.5326 reward = 0.0000 fps = 3 mse_loss = 3.2022 
2022-07-08 10:03:52.782741 - gail/main.py:201 - [Discriminator] iter = 190000 loss = -0.9072 grad_norm = 2.4834 grad_penalty = 0.1231 regularization = 0.0000 true_logits = 0.0171 fake_logits = -1.0132 true_prob = 0.5064 fake_prob = 0.3087 
2022-07-08 10:04:07.616481 - gail/main.py:142 - [Evaluate] iter = 190000 episode={ returns = 69.2719 lengths = 40 } discounted_episode={ returns = 68.2292 lengths = 40 } 
2022-07-08 10:04:35.216858 - gail/main.py:174 - [TRPO] iter = 191000 dist_mean = 0.2132 dist_std = 0.3190 vf_loss = 0.3091 grad_norm = 1.0663 nat_grad_norm = 0.1829 cg_residual = 0.0865 step_size = 0.5632 reward = -0.0000 fps = 23 mse_loss = 3.4340 
2022-07-08 10:05:02.899256 - gail/main.py:174 - [TRPO] iter = 192000 dist_mean = 0.0938 dist_std = 0.3191 vf_loss = 0.1434 grad_norm = 0.8649 nat_grad_norm = 0.1674 cg_residual = 0.0847 step_size = 0.5931 reward = -0.0000 fps = 14 mse_loss = 3.6034 
2022-07-08 10:05:29.906291 - gail/main.py:174 - [TRPO] iter = 193000 dist_mean = 0.1799 dist_std = 0.3156 vf_loss = 0.2211 grad_norm = 1.3541 nat_grad_norm = 0.2633 cg_residual = 0.2199 step_size = 0.4354 reward = -0.0000 fps = 10 mse_loss = 3.7290 
2022-07-08 10:05:57.078448 - gail/main.py:174 - [TRPO] iter = 194000 dist_mean = 0.1092 dist_std = 0.3130 vf_loss = 0.1032 grad_norm = 1.1049 nat_grad_norm = 0.1787 cg_residual = 0.0775 step_size = 0.5527 reward = -0.0000 fps = 8 mse_loss = 3.6390 
2022-07-08 10:06:24.848929 - gail/main.py:174 - [TRPO] iter = 195000 dist_mean = 0.1352 dist_std = 0.3115 vf_loss = 0.3564 grad_norm = 1.2199 nat_grad_norm = 0.2023 cg_residual = 0.2054 step_size = 0.4366 reward = -0.0000 fps = 6 mse_loss = 3.8136 
2022-07-08 10:06:25.577994 - gail/main.py:201 - [Discriminator] iter = 195000 loss = -0.7015 grad_norm = 2.2805 grad_penalty = 0.1082 regularization = 0.0000 true_logits = 0.0268 fake_logits = -0.7829 true_prob = 0.5094 fake_prob = 0.3488 
2022-07-08 10:08:44.777144 - gail/main.py:142 - [Evaluate] iter = 195000 episode={ returns = 1397.3498 lengths = 396 } discounted_episode={ returns = 1117.9529 lengths = 395 } 
2022-07-08 10:09:13.151558 - gail/main.py:174 - [TRPO] iter = 196000 dist_mean = 0.1214 dist_std = 0.3105 vf_loss = 0.0606 grad_norm = 0.6781 nat_grad_norm = 0.1751 cg_residual = 0.0832 step_size = 0.5971 reward = -0.0000 fps = 5 mse_loss = 3.8745 
2022-07-08 10:09:40.846402 - gail/main.py:174 - [TRPO] iter = 197000 dist_mean = 0.0866 dist_std = 0.3120 vf_loss = 0.1025 grad_norm = 0.9595 nat_grad_norm = 0.1643 cg_residual = 0.0867 step_size = 0.5300 reward = 0.0000 fps = 5 mse_loss = 3.9033 
2022-07-08 10:10:08.368660 - gail/main.py:174 - [TRPO] iter = 198000 dist_mean = 0.0947 dist_std = 0.3087 vf_loss = 0.0777 grad_norm = 0.8190 nat_grad_norm = 0.1827 cg_residual = 0.1014 step_size = 0.6021 reward = 0.0000 fps = 4 mse_loss = 3.8098 
2022-07-08 10:10:35.558847 - gail/main.py:174 - [TRPO] iter = 199000 dist_mean = 0.1370 dist_std = 0.3120 vf_loss = 0.1342 grad_norm = 0.6723 nat_grad_norm = 0.2078 cg_residual = 0.1132 step_size = 0.6497 reward = -0.0000 fps = 4 mse_loss = 4.0082 
2022-07-08 10:11:02.126999 - gail/main.py:174 - [TRPO] iter = 200000 dist_mean = 0.0845 dist_std = 0.3145 vf_loss = 0.1486 grad_norm = 1.2782 nat_grad_norm = 0.1798 cg_residual = 0.0974 step_size = 0.4996 reward = -0.0000 fps = 3 mse_loss = 3.9106 
2022-07-08 10:11:02.968927 - gail/main.py:201 - [Discriminator] iter = 200000 loss = -0.4327 grad_norm = 2.6370 grad_penalty = 0.0934 regularization = 0.0000 true_logits = 0.0230 fake_logits = -0.5031 true_prob = 0.5099 fake_prob = 0.3946 
2022-07-08 10:16:16.335226 - gail/main.py:142 - [Evaluate] iter = 200000 episode={ returns = 3021.2807 lengths = 837 } discounted_episode={ returns = 2059.9441 lengths = 891 } 
2022-07-08 10:16:43.746661 - gail/main.py:174 - [TRPO] iter = 201000 dist_mean = 0.0596 dist_std = 0.3164 vf_loss = 0.1492 grad_norm = 0.9669 nat_grad_norm = 0.1998 cg_residual = 0.1251 step_size = 0.5570 reward = -0.0000 fps = 2 mse_loss = 3.8940 
2022-07-08 10:17:10.192826 - gail/main.py:174 - [TRPO] iter = 202000 dist_mean = 0.1283 dist_std = 0.3134 vf_loss = 0.0845 grad_norm = 1.4816 nat_grad_norm = 0.2027 cg_residual = 0.0651 step_size = 0.5038 reward = 0.0000 fps = 2 mse_loss = 3.8171 
2022-07-08 10:17:36.462432 - gail/main.py:174 - [TRPO] iter = 203000 dist_mean = 0.1208 dist_std = 0.3064 vf_loss = 0.3051 grad_norm = 0.9145 nat_grad_norm = 0.1398 cg_residual = 0.0631 step_size = 0.6781 reward = 0.0000 fps = 2 mse_loss = 4.0597 
2022-07-08 10:18:04.108675 - gail/main.py:174 - [TRPO] iter = 204000 dist_mean = 0.0905 dist_std = 0.3071 vf_loss = 0.1193 grad_norm = 1.1950 nat_grad_norm = 0.1766 cg_residual = 0.1048 step_size = 0.4962 reward = 0.0000 fps = 2 mse_loss = 3.7821 
2022-07-08 10:18:30.517972 - gail/main.py:174 - [TRPO] iter = 205000 dist_mean = 0.1492 dist_std = 0.3042 vf_loss = 0.1673 grad_norm = 1.3413 nat_grad_norm = 0.2517 cg_residual = 0.2892 step_size = 0.3678 reward = 0.0000 fps = 2 mse_loss = 3.3800 
2022-07-08 10:18:31.330446 - gail/main.py:201 - [Discriminator] iter = 205000 loss = -0.4143 grad_norm = 2.5658 grad_penalty = 0.0853 regularization = 0.0000 true_logits = 0.0765 fake_logits = -0.4231 true_prob = 0.5211 fake_prob = 0.4099 
2022-07-08 10:23:42.814417 - gail/main.py:142 - [Evaluate] iter = 205000 episode={ returns = 3074.3996 lengths = 854 } discounted_episode={ returns = 2072.2668 lengths = 920 } 
2022-07-08 10:24:10.500574 - gail/main.py:174 - [TRPO] iter = 206000 dist_mean = 0.2253 dist_std = 0.3063 vf_loss = 0.6426 grad_norm = 1.7566 nat_grad_norm = 0.1404 cg_residual = 0.0434 step_size = 0.5612 reward = 0.0000 fps = 2 mse_loss = 3.3675 
2022-07-08 10:24:38.180208 - gail/main.py:174 - [TRPO] iter = 207000 dist_mean = 0.2197 dist_std = 0.3040 vf_loss = 0.1991 grad_norm = 1.3918 nat_grad_norm = 0.2686 cg_residual = 0.2014 step_size = 0.3836 reward = 0.0000 fps = 2 mse_loss = 3.5086 
2022-07-08 10:25:05.350100 - gail/main.py:174 - [TRPO] iter = 208000 dist_mean = 0.2485 dist_std = 0.3023 vf_loss = 0.2821 grad_norm = 0.8332 nat_grad_norm = 0.2119 cg_residual = 0.1005 step_size = 0.4835 reward = 0.0000 fps = 2 mse_loss = 3.5025 
2022-07-08 10:25:31.668397 - gail/main.py:174 - [TRPO] iter = 209000 dist_mean = 0.1627 dist_std = 0.3051 vf_loss = 0.1538 grad_norm = 0.9950 nat_grad_norm = 0.2101 cg_residual = 0.1802 step_size = 0.5384 reward = 0.0000 fps = 2 mse_loss = 3.5958 
2022-07-08 10:25:58.341205 - gail/main.py:174 - [TRPO] iter = 210000 dist_mean = 0.2494 dist_std = 0.3018 vf_loss = 0.2877 grad_norm = 1.4880 nat_grad_norm = 0.2814 cg_residual = 0.2145 step_size = 0.3841 reward = 0.0000 fps = 2 mse_loss = 3.7118 
2022-07-08 10:25:59.065332 - gail/main.py:201 - [Discriminator] iter = 210000 loss = -1.0482 grad_norm = 3.0074 grad_penalty = 0.1166 regularization = 0.0000 true_logits = 0.0713 fake_logits = -1.0934 true_prob = 0.5200 fake_prob = 0.2951 
2022-07-08 10:26:11.699090 - gail/main.py:142 - [Evaluate] iter = 210000 episode={ returns = 56.1029 lengths = 33 } discounted_episode={ returns = 54.9412 lengths = 32 } 
2022-07-08 10:26:40.091498 - gail/main.py:174 - [TRPO] iter = 211000 dist_mean = 0.1547 dist_std = 0.2961 vf_loss = 0.1798 grad_norm = 1.0546 nat_grad_norm = 0.2067 cg_residual = 0.1746 step_size = 0.5260 reward = 0.0000 fps = 24 mse_loss = 3.8183 
2022-07-08 10:27:07.604038 - gail/main.py:174 - [TRPO] iter = 212000 dist_mean = 0.1798 dist_std = 0.2921 vf_loss = 0.2540 grad_norm = 1.1281 nat_grad_norm = 0.2835 cg_residual = 0.2778 step_size = 0.4220 reward = 0.0000 fps = 14 mse_loss = 4.0430 
2022-07-08 10:27:35.365861 - gail/main.py:174 - [TRPO] iter = 213000 dist_mean = 0.1300 dist_std = 0.2866 vf_loss = 0.1037 grad_norm = 1.0310 nat_grad_norm = 0.1628 cg_residual = 0.1375 step_size = 0.6002 reward = -0.0000 fps = 10 mse_loss = 3.8538 
2022-07-08 10:28:03.459269 - gail/main.py:174 - [TRPO] iter = 214000 dist_mean = 0.1083 dist_std = 0.2869 vf_loss = 0.1484 grad_norm = 0.8744 nat_grad_norm = 0.2001 cg_residual = 0.1407 step_size = 0.5088 reward = 0.0000 fps = 8 mse_loss = 3.9417 
2022-07-08 10:28:32.204302 - gail/main.py:174 - [TRPO] iter = 215000 dist_mean = 0.1751 dist_std = 0.2884 vf_loss = 1.0650 grad_norm = 1.4166 nat_grad_norm = 0.2113 cg_residual = 0.1309 step_size = 0.4676 reward = -0.0000 fps = 6 mse_loss = 3.7908 
2022-07-08 10:28:33.076072 - gail/main.py:201 - [Discriminator] iter = 215000 loss = -1.0423 grad_norm = 2.5034 grad_penalty = 0.1189 regularization = 0.0000 true_logits = 0.1024 fake_logits = -1.0588 true_prob = 0.5273 fake_prob = 0.3079 
2022-07-08 10:28:44.870561 - gail/main.py:142 - [Evaluate] iter = 215000 episode={ returns = 54.9420 lengths = 32 } discounted_episode={ returns = 54.4512 lengths = 32 } 
2022-07-08 10:29:12.756232 - gail/main.py:174 - [TRPO] iter = 216000 dist_mean = 0.1224 dist_std = 0.2859 vf_loss = 0.8833 grad_norm = 1.7167 nat_grad_norm = 0.1449 cg_residual = 0.0822 step_size = 0.5713 reward = -0.0000 fps = 25 mse_loss = 4.0993 
2022-07-08 10:29:40.547408 - gail/main.py:174 - [TRPO] iter = 217000 dist_mean = 0.0825 dist_std = 0.2837 vf_loss = 0.3163 grad_norm = 1.4700 nat_grad_norm = 0.1698 cg_residual = 0.1082 step_size = 0.5347 reward = 0.0000 fps = 14 mse_loss = 3.8407 
2022-07-08 10:30:10.088099 - gail/main.py:174 - [TRPO] iter = 218000 dist_mean = 0.2540 dist_std = 0.2843 vf_loss = 0.4555 grad_norm = 1.7945 nat_grad_norm = 0.2011 cg_residual = 0.1121 step_size = 0.4745 reward = 0.0000 fps = 10 mse_loss = 3.7788 
2022-07-08 10:30:38.497492 - gail/main.py:174 - [TRPO] iter = 219000 dist_mean = 0.1337 dist_std = 0.2851 vf_loss = 0.2856 grad_norm = 1.2873 nat_grad_norm = 0.1887 cg_residual = 0.1010 step_size = 0.5104 reward = -0.0000 fps = 7 mse_loss = 3.8469 
2022-07-08 10:31:06.604278 - gail/main.py:174 - [TRPO] iter = 220000 dist_mean = 0.1020 dist_std = 0.2910 vf_loss = 0.0665 grad_norm = 0.8451 nat_grad_norm = 0.1592 cg_residual = 0.1036 step_size = 0.5749 reward = -0.0000 fps = 6 mse_loss = 3.9322 
2022-07-08 10:31:07.432970 - gail/main.py:201 - [Discriminator] iter = 220000 loss = -0.7307 grad_norm = 2.5913 grad_penalty = 0.0967 regularization = 0.0000 true_logits = 0.1153 fake_logits = -0.7121 true_prob = 0.5304 fake_prob = 0.3692 
2022-07-08 10:33:12.743724 - gail/main.py:142 - [Evaluate] iter = 220000 episode={ returns = 2898.4565 lengths = 807 } discounted_episode={ returns = 1567.0557 lengths = 694 } 
2022-07-08 10:33:21.981748 - gail/main.py:174 - [TRPO] iter = 221000 dist_mean = 0.0553 dist_std = 0.2914 vf_loss = 0.1509 grad_norm = 1.1507 nat_grad_norm = 0.1802 cg_residual = 0.1517 step_size = 0.5326 reward = 0.0000 fps = 7 mse_loss = 4.1298 
2022-07-08 10:33:31.867671 - gail/main.py:174 - [TRPO] iter = 222000 dist_mean = 0.0791 dist_std = 0.2904 vf_loss = 0.0769 grad_norm = 1.0072 nat_grad_norm = 0.1813 cg_residual = 0.1109 step_size = 0.5655 reward = -0.0000 fps = 6 mse_loss = 4.1369 
2022-07-08 10:33:41.717706 - gail/main.py:174 - [TRPO] iter = 223000 dist_mean = 0.0985 dist_std = 0.2918 vf_loss = 0.1322 grad_norm = 1.6280 nat_grad_norm = 0.1937 cg_residual = 0.1454 step_size = 0.4880 reward = 0.0000 fps = 6 mse_loss = 4.2027 
2022-07-08 10:33:51.128451 - gail/main.py:174 - [TRPO] iter = 224000 dist_mean = 0.0628 dist_std = 0.2901 vf_loss = 0.4201 grad_norm = 1.0401 nat_grad_norm = 0.1414 cg_residual = 0.0328 step_size = 0.6423 reward = -0.0000 fps = 6 mse_loss = 4.6072 
