2022-07-08 08:45:23.597457 - utils/flags.py:257 - log_dir = logs/gail_w-Hopper-v2-200-2022-07-08-08-45-23
2022-07-08 08:46:24.200843 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/GitHub/GAIL-Fail/project_2022_05_06/dataset/sac/Hopper-v2
2022-07-08 08:46:32.892302 - gail/main.py:80 - Expert Reward 3582.436530
2022-07-08 08:46:33.171043 - gail/main.py:84 - Original dataset size 3000
2022-07-08 08:46:33.201911 - gail/main.py:86 - Subsampled dataset size 3000
2022-07-08 08:46:33.204848 - gail/main.py:87 - np random: 864 random : 786
2022-07-08 08:46:33.207250 - gail/main.py:91 - Sampled obs: 0.4652, acs: 0.0749
2022-07-08 08:46:34.242706 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-07-08 08:46:41.532222 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-07-08 08:46:41.535640 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.3966653  -0.06165453 -0.19472611 -0.4584401   0.18350822  2.5732448
   0.00400542 -0.00549955 -0.04755233 -0.02386179  0.00759995]] 
 scale:[[0.16755195 0.05883223 0.15990146 0.34682125 0.5992658  0.6461788
  1.5187451  0.8811966  2.0685835  3.6282625  5.862049  ]]
2022-07-08 08:46:45.132683 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-07-08 08:46:45.137030 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(14, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-07-08 08:46:45.139404 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-07-08 08:46:46.105297 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-07-08 08:47:01.268607 - gail/main.py:142 - [Evaluate] iter = 0 episode={ returns = 151.7944 lengths = 165 } discounted_episode={ returns = 145.6909 lengths = 173 } 
2022-07-08 08:47:01.270454 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-07-08 08:47:11.593538 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-07-08 08:47:11.887903 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-07-08 08:47:12.426461 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-07-08 08:47:12.716747 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-07-08 08:47:14.352549 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-07-08 08:47:16.975511 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-07-08 08:47:17.286348 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-07-08 08:47:17.570470 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-07-08 08:47:18.095730 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-07-08 08:47:19.057377 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-07-08 08:47:19.388599 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-07-08 08:47:19.694662 - gail/main.py:174 - [TRPO] iter = 1000 dist_mean = -0.0000 dist_std = 1.0000 vf_loss = 0.2514 grad_norm = 0.3047 nat_grad_norm = 0.3393 cg_residual = 0.0000 step_size = 0.4765 reward = 0.0000 fps = 30 mse_loss = 0.3253 
2022-07-08 08:47:26.616254 - gail/main.py:174 - [TRPO] iter = 2000 dist_mean = 0.0570 dist_std = 1.0017 vf_loss = 0.3318 grad_norm = 0.3617 nat_grad_norm = 0.4168 cg_residual = 0.0000 step_size = 0.4072 reward = 0.0000 fps = 24 mse_loss = 0.3659 
2022-07-08 08:47:34.010164 - gail/main.py:174 - [TRPO] iter = 3000 dist_mean = 0.1010 dist_std = 0.9916 vf_loss = 0.2525 grad_norm = 0.3418 nat_grad_norm = 0.3390 cg_residual = 0.0000 step_size = 0.4626 reward = 0.0000 fps = 20 mse_loss = 0.3793 
2022-07-08 08:47:41.020816 - gail/main.py:174 - [TRPO] iter = 4000 dist_mean = 0.1515 dist_std = 0.9764 vf_loss = 0.3282 grad_norm = 0.2820 nat_grad_norm = 0.3051 cg_residual = 0.0000 step_size = 0.5470 reward = -0.0000 fps = 18 mse_loss = 0.3545 
2022-07-08 08:47:48.362736 - gail/main.py:174 - [TRPO] iter = 5000 dist_mean = 0.1659 dist_std = 0.9587 vf_loss = 0.3746 grad_norm = 0.2795 nat_grad_norm = 0.3719 cg_residual = 0.0000 step_size = 0.6178 reward = 0.0000 fps = 16 mse_loss = 0.4274 
2022-07-08 08:47:48.364293 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-07-08 08:47:50.886229 - gail/main.py:201 - [Discriminator] iter = 5000 loss = 1.5168 grad_norm = 13.1276 grad_penalty = 1.5373 regularization = 0.0000 true_logits = -0.2267 fake_logits = -0.2472 true_prob = 0.4439 fake_prob = 0.4387 
2022-07-08 08:48:00.588294 - gail/main.py:142 - [Evaluate] iter = 5000 episode={ returns = 212.3677 lengths = 110 } discounted_episode={ returns = 202.3702 lengths = 111 } 
2022-07-08 08:48:07.020654 - gail/main.py:174 - [TRPO] iter = 6000 dist_mean = 0.2075 dist_std = 0.9529 vf_loss = 0.3781 grad_norm = 0.3119 nat_grad_norm = 0.3829 cg_residual = 0.0000 step_size = 0.5587 reward = 0.0000 fps = 62 mse_loss = 0.4183 
2022-07-08 08:48:13.765605 - gail/main.py:174 - [TRPO] iter = 7000 dist_mean = 0.1994 dist_std = 0.9398 vf_loss = 0.4616 grad_norm = 0.3044 nat_grad_norm = 0.4053 cg_residual = 0.0000 step_size = 0.5058 reward = 0.0000 fps = 43 mse_loss = 0.4898 
2022-07-08 08:48:20.829195 - gail/main.py:174 - [TRPO] iter = 8000 dist_mean = 0.2148 dist_std = 0.9394 vf_loss = 0.3368 grad_norm = 0.3283 nat_grad_norm = 0.2875 cg_residual = 0.0000 step_size = 0.6728 reward = -0.0000 fps = 33 mse_loss = 0.4930 
2022-07-08 08:48:27.520499 - gail/main.py:174 - [TRPO] iter = 9000 dist_mean = 0.2162 dist_std = 0.9513 vf_loss = 0.4786 grad_norm = 0.3392 nat_grad_norm = 0.3608 cg_residual = 0.0000 step_size = 0.5537 reward = -0.0000 fps = 27 mse_loss = 0.5917 
2022-07-08 08:48:35.003566 - gail/main.py:174 - [TRPO] iter = 10000 dist_mean = 0.2444 dist_std = 0.9428 vf_loss = 0.5203 grad_norm = 0.3483 nat_grad_norm = 0.3780 cg_residual = 0.0000 step_size = 0.5376 reward = -0.0000 fps = 22 mse_loss = 0.5879 
2022-07-08 08:48:35.265332 - gail/main.py:201 - [Discriminator] iter = 10000 loss = 1.1647 grad_norm = 11.8083 grad_penalty = 1.2152 regularization = 0.0000 true_logits = -0.2148 fake_logits = -0.2652 true_prob = 0.4468 fake_prob = 0.4343 
2022-07-08 08:48:44.553787 - gail/main.py:142 - [Evaluate] iter = 10000 episode={ returns = 212.8109 lengths = 102 } discounted_episode={ returns = 200.6702 lengths = 102 } 
2022-07-08 08:48:52.531395 - gail/main.py:174 - [TRPO] iter = 11000 dist_mean = 0.2034 dist_std = 0.9360 vf_loss = 0.3714 grad_norm = 0.4180 nat_grad_norm = 0.3630 cg_residual = 0.0000 step_size = 0.5608 reward = 0.0000 fps = 57 mse_loss = 0.5669 
2022-07-08 08:49:00.753858 - gail/main.py:174 - [TRPO] iter = 12000 dist_mean = 0.2222 dist_std = 0.9287 vf_loss = 0.3097 grad_norm = 0.3477 nat_grad_norm = 0.3733 cg_residual = 0.0001 step_size = 0.5640 reward = -0.0000 fps = 39 mse_loss = 0.6244 
2022-07-08 08:49:08.274190 - gail/main.py:174 - [TRPO] iter = 13000 dist_mean = 0.2226 dist_std = 0.9231 vf_loss = 0.3194 grad_norm = 0.3439 nat_grad_norm = 0.4140 cg_residual = 0.0001 step_size = 0.4991 reward = -0.0000 fps = 30 mse_loss = 0.6310 
2022-07-08 08:49:15.522230 - gail/main.py:174 - [TRPO] iter = 14000 dist_mean = 0.2330 dist_std = 0.9168 vf_loss = 0.1945 grad_norm = 0.3866 nat_grad_norm = 0.4637 cg_residual = 0.0001 step_size = 0.4829 reward = -0.0000 fps = 24 mse_loss = 0.6749 
2022-07-08 08:49:22.675341 - gail/main.py:174 - [TRPO] iter = 15000 dist_mean = 0.2551 dist_std = 0.8989 vf_loss = 0.1861 grad_norm = 0.3426 nat_grad_norm = 0.3643 cg_residual = 0.0002 step_size = 0.6016 reward = -0.0000 fps = 21 mse_loss = 0.6948 
2022-07-08 08:49:22.890279 - gail/main.py:201 - [Discriminator] iter = 15000 loss = 0.6386 grad_norm = 8.3017 grad_penalty = 0.7459 regularization = 0.0000 true_logits = -0.1843 fake_logits = -0.2916 true_prob = 0.4543 fake_prob = 0.4279 
2022-07-08 08:49:29.871724 - gail/main.py:142 - [Evaluate] iter = 15000 episode={ returns = 155.8603 lengths = 75 } discounted_episode={ returns = 148.5311 lengths = 75 } 
2022-07-08 08:49:36.845278 - gail/main.py:174 - [TRPO] iter = 16000 dist_mean = 0.2386 dist_std = 0.8888 vf_loss = 0.2245 grad_norm = 0.4049 nat_grad_norm = 0.3847 cg_residual = 0.0001 step_size = 0.5365 reward = -0.0000 fps = 71 mse_loss = 0.6923 
2022-07-08 08:49:43.973374 - gail/main.py:174 - [TRPO] iter = 17000 dist_mean = 0.2551 dist_std = 0.8834 vf_loss = 0.3139 grad_norm = 0.3426 nat_grad_norm = 0.4557 cg_residual = 0.0002 step_size = 0.5624 reward = -0.0000 fps = 47 mse_loss = 0.7085 
2022-07-08 08:49:51.245707 - gail/main.py:174 - [TRPO] iter = 18000 dist_mean = 0.2783 dist_std = 0.8784 vf_loss = 0.1582 grad_norm = 0.3786 nat_grad_norm = 0.3808 cg_residual = 0.0002 step_size = 0.5186 reward = -0.0000 fps = 35 mse_loss = 0.7464 
2022-07-08 08:49:58.111692 - gail/main.py:174 - [TRPO] iter = 19000 dist_mean = 0.2793 dist_std = 0.8624 vf_loss = 0.1068 grad_norm = 0.4843 nat_grad_norm = 0.3254 cg_residual = 0.0001 step_size = 0.4530 reward = -0.0000 fps = 28 mse_loss = 0.8593 
2022-07-08 08:50:08.584495 - gail/main.py:174 - [TRPO] iter = 20000 dist_mean = 0.2635 dist_std = 0.8452 vf_loss = 0.1228 grad_norm = 0.5489 nat_grad_norm = 0.3241 cg_residual = 0.0002 step_size = 0.5241 reward = 0.0000 fps = 21 mse_loss = 0.8033 
2022-07-08 08:50:09.033184 - gail/main.py:201 - [Discriminator] iter = 20000 loss = 0.3868 grad_norm = 5.3833 grad_penalty = 0.5608 regularization = 0.0000 true_logits = -0.1438 fake_logits = -0.3178 true_prob = 0.4644 fake_prob = 0.4216 
2022-07-08 08:50:16.813076 - gail/main.py:142 - [Evaluate] iter = 20000 episode={ returns = 140.3872 lengths = 69 } discounted_episode={ returns = 136.0499 lengths = 69 } 
2022-07-08 08:50:24.126827 - gail/main.py:174 - [TRPO] iter = 21000 dist_mean = 0.2476 dist_std = 0.8274 vf_loss = 0.0758 grad_norm = 0.4850 nat_grad_norm = 0.2344 cg_residual = 0.0001 step_size = 0.6442 reward = -0.0000 fps = 66 mse_loss = 0.8782 
2022-07-08 08:50:31.059189 - gail/main.py:174 - [TRPO] iter = 22000 dist_mean = 0.2456 dist_std = 0.8096 vf_loss = 0.0813 grad_norm = 0.4105 nat_grad_norm = 0.2989 cg_residual = 0.0002 step_size = 0.6027 reward = 0.0000 fps = 45 mse_loss = 0.8778 
2022-07-08 08:50:38.322972 - gail/main.py:174 - [TRPO] iter = 23000 dist_mean = 0.2251 dist_std = 0.7965 vf_loss = 0.0423 grad_norm = 0.5567 nat_grad_norm = 0.3364 cg_residual = 0.0007 step_size = 0.4910 reward = -0.0000 fps = 34 mse_loss = 1.0011 
2022-07-08 08:50:45.260808 - gail/main.py:174 - [TRPO] iter = 24000 dist_mean = 0.2032 dist_std = 0.7772 vf_loss = 0.0528 grad_norm = 0.5639 nat_grad_norm = 0.3291 cg_residual = 0.0009 step_size = 0.5261 reward = 0.0000 fps = 27 mse_loss = 0.9172 
2022-07-08 08:50:52.187401 - gail/main.py:174 - [TRPO] iter = 25000 dist_mean = 0.1975 dist_std = 0.7621 vf_loss = 0.0547 grad_norm = 0.7780 nat_grad_norm = 0.3132 cg_residual = 0.0006 step_size = 0.4485 reward = -0.0000 fps = 23 mse_loss = 0.9994 
2022-07-08 08:50:52.394707 - gail/main.py:201 - [Discriminator] iter = 25000 loss = 0.2326 grad_norm = 5.2508 grad_penalty = 0.5157 regularization = 0.0000 true_logits = -0.1168 fake_logits = -0.3999 true_prob = 0.4711 fake_prob = 0.4020 
2022-07-08 08:50:59.195611 - gail/main.py:142 - [Evaluate] iter = 25000 episode={ returns = 151.4039 lengths = 72 } discounted_episode={ returns = 143.7783 lengths = 71 } 
2022-07-08 08:51:07.006136 - gail/main.py:174 - [TRPO] iter = 26000 dist_mean = 0.2152 dist_std = 0.7457 vf_loss = 0.0552 grad_norm = 0.5437 nat_grad_norm = 0.2900 cg_residual = 0.0007 step_size = 0.5696 reward = -0.0000 fps = 68 mse_loss = 1.0861 
2022-07-08 08:51:13.630258 - gail/main.py:174 - [TRPO] iter = 27000 dist_mean = 0.2367 dist_std = 0.7348 vf_loss = 0.0565 grad_norm = 0.5984 nat_grad_norm = 0.2684 cg_residual = 0.0006 step_size = 0.5448 reward = -0.0000 fps = 47 mse_loss = 1.2726 
2022-07-08 08:51:20.609280 - gail/main.py:174 - [TRPO] iter = 28000 dist_mean = 0.1962 dist_std = 0.7214 vf_loss = 0.0336 grad_norm = 0.8070 nat_grad_norm = 0.3504 cg_residual = 0.0023 step_size = 0.4136 reward = 0.0000 fps = 35 mse_loss = 1.1631 
2022-07-08 08:51:27.374070 - gail/main.py:174 - [TRPO] iter = 29000 dist_mean = 0.2077 dist_std = 0.7080 vf_loss = 0.0603 grad_norm = 0.8653 nat_grad_norm = 0.3128 cg_residual = 0.0019 step_size = 0.4225 reward = -0.0000 fps = 28 mse_loss = 1.2068 
2022-07-08 08:51:34.117135 - gail/main.py:174 - [TRPO] iter = 30000 dist_mean = 0.2169 dist_std = 0.7044 vf_loss = 0.0729 grad_norm = 0.7730 nat_grad_norm = 0.3587 cg_residual = 0.0020 step_size = 0.4452 reward = -0.0000 fps = 23 mse_loss = 1.1024 
2022-07-08 08:51:34.343336 - gail/main.py:201 - [Discriminator] iter = 30000 loss = 0.0636 grad_norm = 5.2505 grad_penalty = 0.4787 regularization = 0.0000 true_logits = -0.0929 fake_logits = -0.5080 true_prob = 0.4772 fake_prob = 0.3767 
2022-07-08 08:51:41.677928 - gail/main.py:142 - [Evaluate] iter = 30000 episode={ returns = 181.4794 lengths = 81 } discounted_episode={ returns = 173.9151 lengths = 81 } 
2022-07-08 08:51:48.364595 - gail/main.py:174 - [TRPO] iter = 31000 dist_mean = 0.2297 dist_std = 0.6905 vf_loss = 0.0663 grad_norm = 0.4081 nat_grad_norm = 0.3554 cg_residual = 0.0016 step_size = 0.5270 reward = 0.0000 fps = 71 mse_loss = 1.3083 
2022-07-08 08:51:55.464525 - gail/main.py:174 - [TRPO] iter = 32000 dist_mean = 0.2110 dist_std = 0.6807 vf_loss = 0.0533 grad_norm = 0.6239 nat_grad_norm = 0.3122 cg_residual = 0.0025 step_size = 0.4790 reward = 0.0000 fps = 47 mse_loss = 1.3966 
2022-07-08 08:52:02.399023 - gail/main.py:174 - [TRPO] iter = 33000 dist_mean = 0.2353 dist_std = 0.6679 vf_loss = 0.0466 grad_norm = 0.5990 nat_grad_norm = 0.3800 cg_residual = 0.0039 step_size = 0.5146 reward = 0.0000 fps = 35 mse_loss = 1.5581 
2022-07-08 08:52:09.069980 - gail/main.py:174 - [TRPO] iter = 34000 dist_mean = 0.2349 dist_std = 0.6641 vf_loss = 0.0286 grad_norm = 0.4840 nat_grad_norm = 0.3888 cg_residual = 0.0039 step_size = 0.5091 reward = -0.0000 fps = 28 mse_loss = 1.6106 
2022-07-08 08:52:15.759441 - gail/main.py:174 - [TRPO] iter = 35000 dist_mean = 0.2306 dist_std = 0.6598 vf_loss = 0.0426 grad_norm = 0.4497 nat_grad_norm = 0.3282 cg_residual = 0.0040 step_size = 0.5352 reward = -0.0000 fps = 24 mse_loss = 1.8104 
2022-07-08 08:52:15.984831 - gail/main.py:201 - [Discriminator] iter = 35000 loss = -0.1942 grad_norm = 5.6992 grad_penalty = 0.4096 regularization = 0.0000 true_logits = -0.0502 fake_logits = -0.6541 true_prob = 0.4878 fake_prob = 0.3438 
2022-07-08 08:52:23.566916 - gail/main.py:142 - [Evaluate] iter = 35000 episode={ returns = 187.6796 lengths = 82 } discounted_episode={ returns = 178.5474 lengths = 83 } 
2022-07-08 08:52:30.523070 - gail/main.py:174 - [TRPO] iter = 36000 dist_mean = 0.2137 dist_std = 0.6462 vf_loss = 0.0416 grad_norm = 0.5041 nat_grad_norm = 0.2427 cg_residual = 0.0026 step_size = 0.5977 reward = 0.0000 fps = 68 mse_loss = 1.9085 
2022-07-08 08:52:37.355027 - gail/main.py:174 - [TRPO] iter = 37000 dist_mean = 0.2267 dist_std = 0.6399 vf_loss = 0.0427 grad_norm = 0.8805 nat_grad_norm = 0.3497 cg_residual = 0.0065 step_size = 0.5154 reward = 0.0000 fps = 46 mse_loss = 1.8510 
2022-07-08 08:52:44.223139 - gail/main.py:174 - [TRPO] iter = 38000 dist_mean = 0.2104 dist_std = 0.6291 vf_loss = 0.0204 grad_norm = 0.7024 nat_grad_norm = 0.2511 cg_residual = 0.0030 step_size = 0.5782 reward = 0.0000 fps = 35 mse_loss = 1.7818 
2022-07-08 08:52:50.990969 - gail/main.py:174 - [TRPO] iter = 39000 dist_mean = 0.2242 dist_std = 0.6199 vf_loss = 0.0282 grad_norm = 0.6286 nat_grad_norm = 0.2968 cg_residual = 0.0062 step_size = 0.5880 reward = 0.0000 fps = 28 mse_loss = 1.8711 
2022-07-08 08:52:57.916809 - gail/main.py:174 - [TRPO] iter = 40000 dist_mean = 0.1909 dist_std = 0.6162 vf_loss = 0.0203 grad_norm = 0.5197 nat_grad_norm = 0.2785 cg_residual = 0.0061 step_size = 0.6007 reward = -0.0000 fps = 23 mse_loss = 1.8370 
2022-07-08 08:52:58.146486 - gail/main.py:201 - [Discriminator] iter = 40000 loss = -0.4049 grad_norm = 5.5519 grad_penalty = 0.3653 regularization = 0.0000 true_logits = -0.0584 fake_logits = -0.8287 true_prob = 0.4863 fake_prob = 0.3067 
2022-07-08 08:53:05.551271 - gail/main.py:142 - [Evaluate] iter = 40000 episode={ returns = 185.1044 lengths = 82 } discounted_episode={ returns = 176.4178 lengths = 82 } 
2022-07-08 08:53:12.298053 - gail/main.py:174 - [TRPO] iter = 41000 dist_mean = 0.2270 dist_std = 0.6042 vf_loss = 0.0375 grad_norm = 0.5923 nat_grad_norm = 0.4153 cg_residual = 0.0087 step_size = 0.4570 reward = -0.0000 fps = 70 mse_loss = 2.0923 
2022-07-08 08:53:19.215626 - gail/main.py:174 - [TRPO] iter = 42000 dist_mean = 0.2205 dist_std = 0.5938 vf_loss = 0.0152 grad_norm = 0.9188 nat_grad_norm = 0.3256 cg_residual = 0.0056 step_size = 0.4723 reward = 0.0000 fps = 47 mse_loss = 1.8826 
2022-07-08 08:53:26.410523 - gail/main.py:174 - [TRPO] iter = 43000 dist_mean = 0.2076 dist_std = 0.5898 vf_loss = 0.0196 grad_norm = 0.9524 nat_grad_norm = 0.3844 cg_residual = 0.0219 step_size = 0.4208 reward = -0.0000 fps = 35 mse_loss = 2.0372 
2022-07-08 08:53:34.054962 - gail/main.py:174 - [TRPO] iter = 44000 dist_mean = 0.2036 dist_std = 0.5833 vf_loss = 0.0260 grad_norm = 0.7796 nat_grad_norm = 0.3481 cg_residual = 0.0428 step_size = 0.4877 reward = 0.0000 fps = 27 mse_loss = 1.9859 
2022-07-08 08:53:41.301721 - gail/main.py:174 - [TRPO] iter = 45000 dist_mean = 0.2005 dist_std = 0.5716 vf_loss = 0.0432 grad_norm = 0.8479 nat_grad_norm = 0.3042 cg_residual = 0.0211 step_size = 0.4385 reward = -0.0000 fps = 23 mse_loss = 2.3184 
2022-07-08 08:53:41.517504 - gail/main.py:201 - [Discriminator] iter = 45000 loss = -0.5579 grad_norm = 4.9007 grad_penalty = 0.3805 regularization = 0.0000 true_logits = -0.0340 fake_logits = -0.9724 true_prob = 0.4928 fake_prob = 0.2785 
2022-07-08 08:53:48.880464 - gail/main.py:142 - [Evaluate] iter = 45000 episode={ returns = 192.8000 lengths = 84 } discounted_episode={ returns = 183.5244 lengths = 84 } 
2022-07-08 08:53:55.742359 - gail/main.py:174 - [TRPO] iter = 46000 dist_mean = 0.2004 dist_std = 0.5585 vf_loss = 0.0220 grad_norm = 1.0817 nat_grad_norm = 0.2836 cg_residual = 0.0448 step_size = 0.4759 reward = 0.0000 fps = 70 mse_loss = 2.3520 
2022-07-08 08:54:02.336482 - gail/main.py:174 - [TRPO] iter = 47000 dist_mean = 0.1789 dist_std = 0.5493 vf_loss = 0.0337 grad_norm = 1.0988 nat_grad_norm = 0.2996 cg_residual = 0.0283 step_size = 0.4301 reward = -0.0000 fps = 48 mse_loss = 2.5246 
2022-07-08 08:54:09.249805 - gail/main.py:174 - [TRPO] iter = 48000 dist_mean = 0.1807 dist_std = 0.5389 vf_loss = 0.0622 grad_norm = 1.2491 nat_grad_norm = 0.2004 cg_residual = 0.0407 step_size = 0.4819 reward = 0.0000 fps = 36 mse_loss = 2.5563 
2022-07-08 08:54:16.221385 - gail/main.py:174 - [TRPO] iter = 49000 dist_mean = 0.1994 dist_std = 0.5332 vf_loss = 0.0467 grad_norm = 1.5604 nat_grad_norm = 0.3106 cg_residual = 0.0546 step_size = 0.4091 reward = -0.0000 fps = 28 mse_loss = 2.6147 
2022-07-08 08:54:22.951137 - gail/main.py:174 - [TRPO] iter = 50000 dist_mean = 0.1871 dist_std = 0.5267 vf_loss = 0.0646 grad_norm = 1.1572 nat_grad_norm = 0.1967 cg_residual = 0.0274 step_size = 0.4869 reward = -0.0000 fps = 24 mse_loss = 2.4905 
2022-07-08 08:54:23.155296 - gail/main.py:201 - [Discriminator] iter = 50000 loss = -0.8306 grad_norm = 5.3214 grad_penalty = 0.3350 regularization = 0.0000 true_logits = -0.0386 fake_logits = -1.2042 true_prob = 0.4924 fake_prob = 0.2361 
2022-07-08 08:54:31.796303 - gail/main.py:142 - [Evaluate] iter = 50000 episode={ returns = 236.7419 lengths = 95 } discounted_episode={ returns = 223.0379 lengths = 95 } 
2022-07-08 08:54:38.719356 - gail/main.py:174 - [TRPO] iter = 51000 dist_mean = 0.1683 dist_std = 0.5185 vf_loss = 0.0812 grad_norm = 1.9120 nat_grad_norm = 0.2433 cg_residual = 0.1431 step_size = 0.3944 reward = -0.0000 fps = 64 mse_loss = 2.6689 
2022-07-08 08:54:45.394813 - gail/main.py:174 - [TRPO] iter = 52000 dist_mean = 0.1597 dist_std = 0.5171 vf_loss = 0.0799 grad_norm = 2.0665 nat_grad_norm = 0.2276 cg_residual = 0.0272 step_size = 0.4056 reward = 0.0000 fps = 44 mse_loss = 2.8093 
2022-07-08 08:54:52.371514 - gail/main.py:174 - [TRPO] iter = 53000 dist_mean = 0.1639 dist_std = 0.5221 vf_loss = 0.0402 grad_norm = 1.7922 nat_grad_norm = 0.2170 cg_residual = 0.0245 step_size = 0.4597 reward = 0.0000 fps = 34 mse_loss = 2.6074 
2022-07-08 08:55:00.054300 - gail/main.py:174 - [TRPO] iter = 54000 dist_mean = 0.1356 dist_std = 0.5200 vf_loss = 0.0398 grad_norm = 1.6319 nat_grad_norm = 0.1887 cg_residual = 0.0306 step_size = 0.4781 reward = 0.0000 fps = 27 mse_loss = 2.6353 
2022-07-08 08:55:08.225194 - gail/main.py:174 - [TRPO] iter = 55000 dist_mean = 0.1215 dist_std = 0.5182 vf_loss = 0.0680 grad_norm = 1.5209 nat_grad_norm = 0.2194 cg_residual = 0.0271 step_size = 0.4677 reward = -0.0000 fps = 22 mse_loss = 2.6093 
2022-07-08 08:55:08.475540 - gail/main.py:201 - [Discriminator] iter = 55000 loss = -1.0355 grad_norm = 4.1591 grad_penalty = 0.2803 regularization = 0.0000 true_logits = -0.0452 fake_logits = -1.3610 true_prob = 0.4921 fake_prob = 0.2112 
2022-07-08 08:55:18.052760 - gail/main.py:142 - [Evaluate] iter = 55000 episode={ returns = 258.0774 lengths = 101 } discounted_episode={ returns = 242.3798 lengths = 101 } 
2022-07-08 08:55:25.141158 - gail/main.py:174 - [TRPO] iter = 56000 dist_mean = 0.1102 dist_std = 0.5088 vf_loss = 0.0802 grad_norm = 1.4154 nat_grad_norm = 0.2481 cg_residual = 0.0588 step_size = 0.4327 reward = 0.0000 fps = 60 mse_loss = 2.8115 
2022-07-08 08:55:31.911811 - gail/main.py:174 - [TRPO] iter = 57000 dist_mean = 0.0999 dist_std = 0.5079 vf_loss = 0.0440 grad_norm = 2.0247 nat_grad_norm = 0.2551 cg_residual = 0.0648 step_size = 0.4178 reward = 0.0000 fps = 42 mse_loss = 2.5531 
2022-07-08 08:55:38.709978 - gail/main.py:174 - [TRPO] iter = 58000 dist_mean = 0.0984 dist_std = 0.5034 vf_loss = 0.0622 grad_norm = 2.3810 nat_grad_norm = 0.2053 cg_residual = 0.0349 step_size = 0.4392 reward = 0.0000 fps = 33 mse_loss = 2.6552 
2022-07-08 08:55:45.681718 - gail/main.py:174 - [TRPO] iter = 59000 dist_mean = 0.0929 dist_std = 0.5075 vf_loss = 0.0645 grad_norm = 1.9058 nat_grad_norm = 0.2688 cg_residual = 0.0450 step_size = 0.4045 reward = 0.0000 fps = 26 mse_loss = 2.9088 
2022-07-08 08:55:52.423373 - gail/main.py:174 - [TRPO] iter = 60000 dist_mean = 0.1018 dist_std = 0.4961 vf_loss = 0.1711 grad_norm = 1.9180 nat_grad_norm = 0.2571 cg_residual = 0.0622 step_size = 0.4048 reward = -0.0000 fps = 22 mse_loss = 2.7993 
2022-07-08 08:55:52.605125 - gail/main.py:201 - [Discriminator] iter = 60000 loss = -1.1345 grad_norm = 4.4884 grad_penalty = 0.2386 regularization = 0.0000 true_logits = -0.1144 fake_logits = -1.4876 true_prob = 0.4771 fake_prob = 0.1948 
2022-07-08 08:56:01.476169 - gail/main.py:142 - [Evaluate] iter = 60000 episode={ returns = 288.8926 lengths = 108 } discounted_episode={ returns = 270.0255 lengths = 108 } 
2022-07-08 08:56:08.303146 - gail/main.py:174 - [TRPO] iter = 61000 dist_mean = 0.1050 dist_std = 0.4961 vf_loss = 0.2081 grad_norm = 1.3136 nat_grad_norm = 0.3165 cg_residual = 0.0620 step_size = 0.4077 reward = 0.0000 fps = 63 mse_loss = 2.8284 
2022-07-08 08:56:14.789476 - gail/main.py:174 - [TRPO] iter = 62000 dist_mean = 0.0965 dist_std = 0.4882 vf_loss = 0.0766 grad_norm = 1.3628 nat_grad_norm = 0.2430 cg_residual = 0.0281 step_size = 0.4707 reward = -0.0000 fps = 45 mse_loss = 2.7309 
2022-07-08 08:56:21.476299 - gail/main.py:174 - [TRPO] iter = 63000 dist_mean = 0.0709 dist_std = 0.4839 vf_loss = 0.0930 grad_norm = 2.1558 nat_grad_norm = 0.2255 cg_residual = 0.0435 step_size = 0.3683 reward = 0.0000 fps = 34 mse_loss = 2.8125 
2022-07-08 08:56:28.342751 - gail/main.py:174 - [TRPO] iter = 64000 dist_mean = 0.0852 dist_std = 0.4827 vf_loss = 0.0683 grad_norm = 1.7167 nat_grad_norm = 0.2288 cg_residual = 0.1404 step_size = 0.4399 reward = 0.0000 fps = 27 mse_loss = 2.7384 
2022-07-08 08:56:35.581070 - gail/main.py:174 - [TRPO] iter = 65000 dist_mean = 0.0757 dist_std = 0.4753 vf_loss = 0.0803 grad_norm = 1.5177 nat_grad_norm = 0.2349 cg_residual = 0.1608 step_size = 0.4585 reward = -0.0000 fps = 23 mse_loss = 2.7207 
2022-07-08 08:56:35.795757 - gail/main.py:201 - [Discriminator] iter = 65000 loss = -1.2388 grad_norm = 3.7651 grad_penalty = 0.2464 regularization = 0.0000 true_logits = -0.0966 fake_logits = -1.5818 true_prob = 0.4816 fake_prob = 0.1842 
2022-07-08 08:56:46.183609 - gail/main.py:142 - [Evaluate] iter = 65000 episode={ returns = 315.8386 lengths = 115 } discounted_episode={ returns = 296.2392 lengths = 115 } 
2022-07-08 08:56:53.020149 - gail/main.py:174 - [TRPO] iter = 66000 dist_mean = 0.0715 dist_std = 0.4762 vf_loss = 0.0420 grad_norm = 1.1831 nat_grad_norm = 0.2214 cg_residual = 0.1158 step_size = 0.5430 reward = -0.0000 fps = 58 mse_loss = 2.8607 
2022-07-08 08:56:59.797221 - gail/main.py:174 - [TRPO] iter = 67000 dist_mean = 0.0764 dist_std = 0.4773 vf_loss = 0.1023 grad_norm = 1.8436 nat_grad_norm = 0.2368 cg_residual = 0.2460 step_size = 0.4324 reward = -0.0000 fps = 41 mse_loss = 2.5576 
2022-07-08 08:57:06.695176 - gail/main.py:174 - [TRPO] iter = 68000 dist_mean = 0.0685 dist_std = 0.4727 vf_loss = 0.0632 grad_norm = 1.1280 nat_grad_norm = 0.3254 cg_residual = 0.0576 step_size = 0.4660 reward = 0.0000 fps = 32 mse_loss = 2.8297 
2022-07-08 08:57:13.352288 - gail/main.py:174 - [TRPO] iter = 69000 dist_mean = 0.0377 dist_std = 0.4706 vf_loss = 0.0471 grad_norm = 1.3872 nat_grad_norm = 0.2342 cg_residual = 0.2548 step_size = 0.5525 reward = 0.0000 fps = 26 mse_loss = 3.0923 
2022-07-08 08:57:19.972135 - gail/main.py:174 - [TRPO] iter = 70000 dist_mean = 0.0612 dist_std = 0.4675 vf_loss = 0.0692 grad_norm = 1.1273 nat_grad_norm = 0.2733 cg_residual = 0.0513 step_size = 0.4433 reward = -0.0000 fps = 22 mse_loss = 2.9432 
2022-07-08 08:57:20.232568 - gail/main.py:201 - [Discriminator] iter = 70000 loss = -1.2906 grad_norm = 3.8430 grad_penalty = 0.2551 regularization = 0.0000 true_logits = -0.0855 fake_logits = -1.6312 true_prob = 0.4851 fake_prob = 0.1783 
2022-07-08 08:57:30.743780 - gail/main.py:142 - [Evaluate] iter = 70000 episode={ returns = 341.6816 lengths = 121 } discounted_episode={ returns = 317.1510 lengths = 121 } 
2022-07-08 08:57:37.321905 - gail/main.py:174 - [TRPO] iter = 71000 dist_mean = 0.0402 dist_std = 0.4698 vf_loss = 0.0464 grad_norm = 0.9538 nat_grad_norm = 0.1970 cg_residual = 0.0342 step_size = 0.5477 reward = 0.0000 fps = 58 mse_loss = 2.8640 
2022-07-08 08:57:44.029266 - gail/main.py:174 - [TRPO] iter = 72000 dist_mean = 0.0400 dist_std = 0.4660 vf_loss = 0.0443 grad_norm = 0.9240 nat_grad_norm = 0.2842 cg_residual = 0.0634 step_size = 0.4931 reward = -0.0000 fps = 42 mse_loss = 2.9925 
2022-07-08 08:57:50.675089 - gail/main.py:174 - [TRPO] iter = 73000 dist_mean = 0.0410 dist_std = 0.4631 vf_loss = 0.0581 grad_norm = 1.2830 nat_grad_norm = 0.2381 cg_residual = 0.1171 step_size = 0.5273 reward = 0.0000 fps = 32 mse_loss = 2.9179 
2022-07-08 08:57:57.447033 - gail/main.py:174 - [TRPO] iter = 74000 dist_mean = 0.0332 dist_std = 0.4569 vf_loss = 0.1275 grad_norm = 1.4829 nat_grad_norm = 0.2133 cg_residual = 0.3049 step_size = 0.4616 reward = -0.0000 fps = 26 mse_loss = 2.9053 
2022-07-08 08:58:04.147031 - gail/main.py:174 - [TRPO] iter = 75000 dist_mean = 0.0534 dist_std = 0.4580 vf_loss = 0.1106 grad_norm = 1.5426 nat_grad_norm = 0.2943 cg_residual = 0.0531 step_size = 0.4281 reward = -0.0000 fps = 22 mse_loss = 2.8938 
2022-07-08 08:58:04.364226 - gail/main.py:201 - [Discriminator] iter = 75000 loss = -1.2890 grad_norm = 3.6793 grad_penalty = 0.2328 regularization = 0.0000 true_logits = -0.0928 fake_logits = -1.6145 true_prob = 0.4828 fake_prob = 0.1805 
2022-07-08 08:58:15.194540 - gail/main.py:142 - [Evaluate] iter = 75000 episode={ returns = 368.3868 lengths = 128 } discounted_episode={ returns = 341.4907 lengths = 128 } 
2022-07-08 08:58:21.929541 - gail/main.py:174 - [TRPO] iter = 76000 dist_mean = 0.0553 dist_std = 0.4534 vf_loss = 0.0695 grad_norm = 1.1026 nat_grad_norm = 0.2114 cg_residual = 0.1962 step_size = 0.5978 reward = 0.0000 fps = 56 mse_loss = 3.1662 
2022-07-08 08:58:28.866351 - gail/main.py:174 - [TRPO] iter = 77000 dist_mean = 0.0454 dist_std = 0.4581 vf_loss = 0.0546 grad_norm = 1.2326 nat_grad_norm = 0.3546 cg_residual = 0.1960 step_size = 0.3894 reward = 0.0000 fps = 40 mse_loss = 3.1279 
2022-07-08 08:58:35.575415 - gail/main.py:174 - [TRPO] iter = 78000 dist_mean = 0.0588 dist_std = 0.4567 vf_loss = 0.0783 grad_norm = 1.5479 nat_grad_norm = 0.1890 cg_residual = 0.1228 step_size = 0.5084 reward = -0.0000 fps = 32 mse_loss = 3.1044 
2022-07-08 08:58:42.399505 - gail/main.py:174 - [TRPO] iter = 79000 dist_mean = 0.0483 dist_std = 0.4516 vf_loss = 0.0822 grad_norm = 1.3911 nat_grad_norm = 0.2304 cg_residual = 0.0430 step_size = 0.4694 reward = -0.0000 fps = 26 mse_loss = 3.3125 
2022-07-08 08:58:49.333742 - gail/main.py:174 - [TRPO] iter = 80000 dist_mean = 0.0395 dist_std = 0.4471 vf_loss = 0.0761 grad_norm = 0.6621 nat_grad_norm = 0.1953 cg_residual = 0.0401 step_size = 0.5939 reward = 0.0000 fps = 22 mse_loss = 3.1988 
2022-07-08 08:58:49.565377 - gail/main.py:201 - [Discriminator] iter = 80000 loss = -1.2838 grad_norm = 3.3050 grad_penalty = 0.2048 regularization = 0.0000 true_logits = -0.1021 fake_logits = -1.5908 true_prob = 0.4826 fake_prob = 0.1858 
2022-07-08 08:59:00.826226 - gail/main.py:142 - [Evaluate] iter = 80000 episode={ returns = 388.7339 lengths = 135 } discounted_episode={ returns = 359.7117 lengths = 135 } 
2022-07-08 08:59:07.316813 - gail/main.py:174 - [TRPO] iter = 81000 dist_mean = 0.0423 dist_std = 0.4413 vf_loss = 0.0878 grad_norm = 0.9069 nat_grad_norm = 0.2530 cg_residual = 0.1414 step_size = 0.5440 reward = -0.0000 fps = 56 mse_loss = 3.6082 
2022-07-08 08:59:14.191616 - gail/main.py:174 - [TRPO] iter = 82000 dist_mean = 0.0330 dist_std = 0.4421 vf_loss = 0.1195 grad_norm = 1.5128 nat_grad_norm = 0.3176 cg_residual = 0.1481 step_size = 0.4403 reward = -0.0000 fps = 40 mse_loss = 3.7751 
2022-07-08 08:59:20.763949 - gail/main.py:174 - [TRPO] iter = 83000 dist_mean = 0.0312 dist_std = 0.4379 vf_loss = 0.0756 grad_norm = 1.7340 nat_grad_norm = 0.2237 cg_residual = 0.1190 step_size = 0.4577 reward = -0.0000 fps = 32 mse_loss = 3.7723 
2022-07-08 08:59:27.323771 - gail/main.py:174 - [TRPO] iter = 84000 dist_mean = 0.0505 dist_std = 0.4365 vf_loss = 0.1083 grad_norm = 1.9647 nat_grad_norm = 0.2378 cg_residual = 0.0888 step_size = 0.3876 reward = 0.0000 fps = 26 mse_loss = 3.7012 
2022-07-08 08:59:34.490410 - gail/main.py:174 - [TRPO] iter = 85000 dist_mean = 0.0399 dist_std = 0.4309 vf_loss = 0.0770 grad_norm = 1.2408 nat_grad_norm = 0.2522 cg_residual = 0.0816 step_size = 0.4556 reward = 0.0000 fps = 22 mse_loss = 3.4736 
2022-07-08 08:59:34.735702 - gail/main.py:201 - [Discriminator] iter = 85000 loss = -1.2678 grad_norm = 2.8485 grad_penalty = 0.2134 regularization = 0.0000 true_logits = -0.0339 fake_logits = -1.5151 true_prob = 0.4992 fake_prob = 0.1995 
2022-07-08 08:59:47.115190 - gail/main.py:142 - [Evaluate] iter = 85000 episode={ returns = 411.4572 lengths = 141 } discounted_episode={ returns = 377.6954 lengths = 140 } 
2022-07-08 08:59:53.700881 - gail/main.py:174 - [TRPO] iter = 86000 dist_mean = 0.0401 dist_std = 0.4270 vf_loss = 0.0498 grad_norm = 0.9695 nat_grad_norm = 0.2455 cg_residual = 0.0686 step_size = 0.5191 reward = 0.0000 fps = 52 mse_loss = 3.6952 
2022-07-08 09:00:00.644593 - gail/main.py:174 - [TRPO] iter = 87000 dist_mean = 0.0518 dist_std = 0.4271 vf_loss = 0.0782 grad_norm = 1.5113 nat_grad_norm = 0.1923 cg_residual = 0.0488 step_size = 0.4534 reward = 0.0000 fps = 38 mse_loss = 3.4928 
2022-07-08 09:00:08.223122 - gail/main.py:174 - [TRPO] iter = 88000 dist_mean = 0.0566 dist_std = 0.4247 vf_loss = 0.3052 grad_norm = 1.9154 nat_grad_norm = 0.3382 cg_residual = 0.1632 step_size = 0.3602 reward = -0.0000 fps = 29 mse_loss = 3.7025 
2022-07-08 09:00:15.922696 - gail/main.py:174 - [TRPO] iter = 89000 dist_mean = 0.0565 dist_std = 0.4207 vf_loss = 0.1128 grad_norm = 1.2651 nat_grad_norm = 0.2360 cg_residual = 0.1024 step_size = 0.4890 reward = -0.0000 fps = 24 mse_loss = 3.5770 
2022-07-08 09:00:23.505632 - gail/main.py:174 - [TRPO] iter = 90000 dist_mean = 0.0685 dist_std = 0.4110 vf_loss = 0.0925 grad_norm = 1.7407 nat_grad_norm = 0.1728 cg_residual = 0.0853 step_size = 0.5029 reward = -0.0000 fps = 20 mse_loss = 3.6345 
2022-07-08 09:00:23.723445 - gail/main.py:201 - [Discriminator] iter = 90000 loss = -1.2255 grad_norm = 3.5347 grad_penalty = 0.2334 regularization = 0.0000 true_logits = 0.0246 fake_logits = -1.4343 true_prob = 0.5125 fake_prob = 0.2151 
2022-07-08 09:00:42.126451 - gail/main.py:142 - [Evaluate] iter = 90000 episode={ returns = 439.5732 lengths = 148 } discounted_episode={ returns = 402.3400 lengths = 148 } 
2022-07-08 09:00:48.984459 - gail/main.py:174 - [TRPO] iter = 91000 dist_mean = 0.0811 dist_std = 0.4120 vf_loss = 0.0916 grad_norm = 2.0489 nat_grad_norm = 0.2033 cg_residual = 0.1263 step_size = 0.4154 reward = -0.0000 fps = 39 mse_loss = 3.5312 
2022-07-08 09:00:55.767730 - gail/main.py:174 - [TRPO] iter = 92000 dist_mean = 0.1052 dist_std = 0.4083 vf_loss = 0.0828 grad_norm = 1.2835 nat_grad_norm = 0.1862 cg_residual = 0.0644 step_size = 0.5114 reward = 0.0000 fps = 31 mse_loss = 3.5255 
2022-07-08 09:01:02.381684 - gail/main.py:174 - [TRPO] iter = 93000 dist_mean = 0.1141 dist_std = 0.4071 vf_loss = 0.0599 grad_norm = 1.9158 nat_grad_norm = 0.2450 cg_residual = 0.1974 step_size = 0.4284 reward = -0.0000 fps = 25 mse_loss = 3.9537 
2022-07-08 09:01:09.305636 - gail/main.py:174 - [TRPO] iter = 94000 dist_mean = 0.0999 dist_std = 0.4081 vf_loss = 0.0793 grad_norm = 1.4278 nat_grad_norm = 0.2294 cg_residual = 0.0903 step_size = 0.4413 reward = 0.0000 fps = 21 mse_loss = 3.6160 
2022-07-08 09:01:16.355471 - gail/main.py:174 - [TRPO] iter = 95000 dist_mean = 0.1183 dist_std = 0.4051 vf_loss = 0.2020 grad_norm = 1.5228 nat_grad_norm = 0.2424 cg_residual = 0.1574 step_size = 0.4159 reward = -0.0000 fps = 19 mse_loss = 3.7480 
2022-07-08 09:01:16.564118 - gail/main.py:201 - [Discriminator] iter = 95000 loss = -1.1844 grad_norm = 3.3551 grad_penalty = 0.2330 regularization = 0.0000 true_logits = -0.0089 fake_logits = -1.4262 true_prob = 0.5038 fake_prob = 0.2187 
2022-07-08 09:01:30.782376 - gail/main.py:142 - [Evaluate] iter = 95000 episode={ returns = 506.1870 lengths = 167 } discounted_episode={ returns = 459.0010 lengths = 167 } 
2022-07-08 09:01:37.284770 - gail/main.py:174 - [TRPO] iter = 96000 dist_mean = 0.1490 dist_std = 0.4082 vf_loss = 0.1459 grad_norm = 1.1674 nat_grad_norm = 0.2166 cg_residual = 0.1740 step_size = 0.4750 reward = -0.0000 fps = 48 mse_loss = 3.4625 
2022-07-08 09:01:43.958014 - gail/main.py:174 - [TRPO] iter = 97000 dist_mean = 0.1381 dist_std = 0.4043 vf_loss = 0.0959 grad_norm = 1.1408 nat_grad_norm = 0.2168 cg_residual = 0.0652 step_size = 0.5002 reward = -0.0000 fps = 36 mse_loss = 3.4682 
2022-07-08 09:01:50.637470 - gail/main.py:174 - [TRPO] iter = 98000 dist_mean = 0.1450 dist_std = 0.3997 vf_loss = 0.8988 grad_norm = 1.4455 nat_grad_norm = 0.1575 cg_residual = 0.0836 step_size = 0.5485 reward = -0.0000 fps = 29 mse_loss = 3.4312 
2022-07-08 09:01:57.218520 - gail/main.py:174 - [TRPO] iter = 99000 dist_mean = 0.1712 dist_std = 0.4031 vf_loss = 0.1118 grad_norm = 1.5180 nat_grad_norm = 0.2320 cg_residual = 0.1164 step_size = 0.4156 reward = -0.0000 fps = 24 mse_loss = 3.6180 
2022-07-08 09:02:03.803420 - gail/main.py:174 - [TRPO] iter = 100000 dist_mean = 0.1863 dist_std = 0.3994 vf_loss = 1.1615 grad_norm = 0.9819 nat_grad_norm = 0.3064 cg_residual = 0.2654 step_size = 0.4064 reward = 0.0000 fps = 21 mse_loss = 3.6667 
2022-07-08 09:02:04.053490 - gail/main.py:201 - [Discriminator] iter = 100000 loss = -1.2713 grad_norm = 3.3957 grad_penalty = 0.2103 regularization = 0.0000 true_logits = 0.0539 fake_logits = -1.4277 true_prob = 0.5175 fake_prob = 0.2206 
2022-07-08 09:02:18.596676 - gail/main.py:142 - [Evaluate] iter = 100000 episode={ returns = 524.7527 lengths = 175 } discounted_episode={ returns = 475.2330 lengths = 175 } 
2022-07-08 09:02:25.412037 - gail/main.py:174 - [TRPO] iter = 101000 dist_mean = 0.2041 dist_std = 0.3985 vf_loss = 0.8901 grad_norm = 1.2679 nat_grad_norm = 0.2124 cg_residual = 0.0828 step_size = 0.5077 reward = 0.0000 fps = 46 mse_loss = 3.6057 
2022-07-08 09:02:32.076269 - gail/main.py:174 - [TRPO] iter = 102000 dist_mean = 0.2234 dist_std = 0.3983 vf_loss = 0.0907 grad_norm = 1.5035 nat_grad_norm = 0.1806 cg_residual = 0.1533 step_size = 0.4765 reward = 0.0000 fps = 35 mse_loss = 3.6670 
2022-07-08 09:02:39.428479 - gail/main.py:174 - [TRPO] iter = 103000 dist_mean = 0.2425 dist_std = 0.3953 vf_loss = 0.2632 grad_norm = 1.6037 nat_grad_norm = 0.2268 cg_residual = 0.1125 step_size = 0.3940 reward = 0.0000 fps = 28 mse_loss = 3.4946 
2022-07-08 09:02:46.343035 - gail/main.py:174 - [TRPO] iter = 104000 dist_mean = 0.2167 dist_std = 0.3997 vf_loss = 0.1114 grad_norm = 1.2151 nat_grad_norm = 0.2592 cg_residual = 0.1916 step_size = 0.3992 reward = -0.0000 fps = 23 mse_loss = 3.4841 
2022-07-08 09:02:53.433179 - gail/main.py:174 - [TRPO] iter = 105000 dist_mean = 0.2236 dist_std = 0.4015 vf_loss = 0.1225 grad_norm = 1.9894 nat_grad_norm = 0.1856 cg_residual = 0.0786 step_size = 0.4074 reward = 0.0000 fps = 20 mse_loss = 3.4272 
2022-07-08 09:02:53.684593 - gail/main.py:201 - [Discriminator] iter = 105000 loss = -1.2889 grad_norm = 3.0073 grad_penalty = 0.1953 regularization = 0.0000 true_logits = 0.0470 fake_logits = -1.4372 true_prob = 0.5153 fake_prob = 0.2179 
2022-07-08 09:03:10.095692 - gail/main.py:142 - [Evaluate] iter = 105000 episode={ returns = 551.8683 lengths = 181 } discounted_episode={ returns = 497.2430 lengths = 181 } 
2022-07-08 09:03:16.940815 - gail/main.py:174 - [TRPO] iter = 106000 dist_mean = 0.2710 dist_std = 0.3990 vf_loss = 0.1318 grad_norm = 1.1065 nat_grad_norm = 0.3114 cg_residual = 0.1327 step_size = 0.4126 reward = 0.0000 fps = 43 mse_loss = 3.4142 
2022-07-08 09:03:24.267678 - gail/main.py:174 - [TRPO] iter = 107000 dist_mean = 0.2569 dist_std = 0.3973 vf_loss = 0.1166 grad_norm = 1.0888 nat_grad_norm = 0.1977 cg_residual = 0.0996 step_size = 0.4868 reward = 0.0000 fps = 32 mse_loss = 3.3709 
2022-07-08 09:03:31.612216 - gail/main.py:174 - [TRPO] iter = 108000 dist_mean = 0.2647 dist_std = 0.3984 vf_loss = 0.8572 grad_norm = 1.6475 nat_grad_norm = 0.2812 cg_residual = 0.3161 step_size = 0.3804 reward = -0.0000 fps = 26 mse_loss = 3.4708 
2022-07-08 09:03:38.528110 - gail/main.py:174 - [TRPO] iter = 109000 dist_mean = 0.2227 dist_std = 0.3961 vf_loss = 0.3386 grad_norm = 2.1382 nat_grad_norm = 0.3171 cg_residual = 0.2337 step_size = 0.2880 reward = 0.0000 fps = 22 mse_loss = 3.1321 
2022-07-08 09:03:45.337030 - gail/main.py:174 - [TRPO] iter = 110000 dist_mean = 0.2502 dist_std = 0.3965 vf_loss = 0.1513 grad_norm = 1.1853 nat_grad_norm = 0.2747 cg_residual = 0.2065 step_size = 0.3700 reward = -0.0000 fps = 19 mse_loss = 3.2409 
2022-07-08 09:03:45.573884 - gail/main.py:201 - [Discriminator] iter = 110000 loss = -1.2612 grad_norm = 3.1251 grad_penalty = 0.1818 regularization = 0.0000 true_logits = -0.0005 fake_logits = -1.4435 true_prob = 0.5070 fake_prob = 0.2165 
2022-07-08 09:04:01.923398 - gail/main.py:142 - [Evaluate] iter = 110000 episode={ returns = 579.5104 lengths = 186 } discounted_episode={ returns = 518.0452 lengths = 186 } 
2022-07-08 09:04:08.800559 - gail/main.py:174 - [TRPO] iter = 111000 dist_mean = 0.2970 dist_std = 0.3974 vf_loss = 0.1395 grad_norm = 1.4569 nat_grad_norm = 0.2051 cg_residual = 0.1330 step_size = 0.4842 reward = 0.0000 fps = 43 mse_loss = 3.1945 
2022-07-08 09:04:16.422252 - gail/main.py:174 - [TRPO] iter = 112000 dist_mean = 0.2815 dist_std = 0.3946 vf_loss = 0.1070 grad_norm = 1.5769 nat_grad_norm = 0.1653 cg_residual = 0.0788 step_size = 0.5004 reward = -0.0000 fps = 32 mse_loss = 3.1864 
2022-07-08 09:04:27.406172 - gail/main.py:174 - [TRPO] iter = 113000 dist_mean = 0.2260 dist_std = 0.3966 vf_loss = 0.1652 grad_norm = 1.5362 nat_grad_norm = 0.2193 cg_residual = 0.1124 step_size = 0.4283 reward = -0.0000 fps = 23 mse_loss = 3.4142 
2022-07-08 09:04:40.440419 - gail/main.py:174 - [TRPO] iter = 114000 dist_mean = 0.2117 dist_std = 0.3987 vf_loss = 0.6352 grad_norm = 1.1333 nat_grad_norm = 0.2293 cg_residual = 0.0811 step_size = 0.4915 reward = -0.0000 fps = 18 mse_loss = 3.1417 
2022-07-08 09:04:53.232260 - gail/main.py:174 - [TRPO] iter = 115000 dist_mean = 0.2152 dist_std = 0.3972 vf_loss = 0.2558 grad_norm = 1.2342 nat_grad_norm = 0.3218 cg_residual = 0.5000 step_size = 0.3367 reward = 0.0000 fps = 14 mse_loss = 3.2336 
2022-07-08 09:04:53.745100 - gail/main.py:201 - [Discriminator] iter = 115000 loss = -1.3030 grad_norm = 3.2879 grad_penalty = 0.1813 regularization = 0.0000 true_logits = -0.0024 fake_logits = -1.4867 true_prob = 0.5038 fake_prob = 0.2126 
2022-07-08 09:05:32.727727 - gail/main.py:142 - [Evaluate] iter = 115000 episode={ returns = 634.4294 lengths = 198 } discounted_episode={ returns = 559.4973 lengths = 197 } 
2022-07-08 09:05:49.555427 - gail/main.py:174 - [TRPO] iter = 116000 dist_mean = 0.1658 dist_std = 0.3967 vf_loss = 1.3176 grad_norm = 1.4275 nat_grad_norm = 0.2367 cg_residual = 0.0955 step_size = 0.4370 reward = 0.0000 fps = 17 mse_loss = 3.1764 
2022-07-08 09:06:04.955421 - gail/main.py:174 - [TRPO] iter = 117000 dist_mean = 0.2594 dist_std = 0.3928 vf_loss = 0.5438 grad_norm = 0.9268 nat_grad_norm = 0.1985 cg_residual = 0.0809 step_size = 0.5314 reward = 0.0000 fps = 14 mse_loss = 3.2469 
2022-07-08 09:06:20.841200 - gail/main.py:174 - [TRPO] iter = 118000 dist_mean = 0.1876 dist_std = 0.3920 vf_loss = 0.6932 grad_norm = 1.0059 nat_grad_norm = 0.1949 cg_residual = 0.0745 step_size = 0.5464 reward = 0.0000 fps = 11 mse_loss = 3.0145 
2022-07-08 09:06:37.134118 - gail/main.py:174 - [TRPO] iter = 119000 dist_mean = 0.2484 dist_std = 0.3961 vf_loss = 0.4688 grad_norm = 1.1534 nat_grad_norm = 0.2064 cg_residual = 0.2092 step_size = 0.5018 reward = -0.0000 fps = 9 mse_loss = 3.2217 
2022-07-08 09:06:54.130986 - gail/main.py:174 - [TRPO] iter = 120000 dist_mean = 0.2344 dist_std = 0.3918 vf_loss = 0.0752 grad_norm = 1.2884 nat_grad_norm = 0.2471 cg_residual = 0.1969 step_size = 0.4096 reward = -0.0000 fps = 8 mse_loss = 3.0264 
2022-07-08 09:06:54.618031 - gail/main.py:201 - [Discriminator] iter = 120000 loss = -1.4717 grad_norm = 2.8676 grad_penalty = 0.1711 regularization = 0.0000 true_logits = 0.1216 fake_logits = -1.5212 true_prob = 0.5299 fake_prob = 0.2090 
2022-07-08 09:07:36.008189 - gail/main.py:142 - [Evaluate] iter = 120000 episode={ returns = 670.0493 lengths = 208 } discounted_episode={ returns = 592.3361 lengths = 208 } 
2022-07-08 09:07:52.779195 - gail/main.py:174 - [TRPO] iter = 121000 dist_mean = 0.1997 dist_std = 0.3919 vf_loss = 0.2914 grad_norm = 1.2676 nat_grad_norm = 0.2928 cg_residual = 0.1869 step_size = 0.3656 reward = 0.0000 fps = 17 mse_loss = 3.1594 
2022-07-08 09:08:09.481235 - gail/main.py:174 - [TRPO] iter = 122000 dist_mean = 0.2412 dist_std = 0.3929 vf_loss = 0.0866 grad_norm = 1.7838 nat_grad_norm = 0.2360 cg_residual = 0.1874 step_size = 0.4221 reward = 0.0000 fps = 13 mse_loss = 3.1025 
2022-07-08 09:08:26.770796 - gail/main.py:174 - [TRPO] iter = 123000 dist_mean = 0.2455 dist_std = 0.3970 vf_loss = 0.1011 grad_norm = 1.4211 nat_grad_norm = 0.2959 cg_residual = 0.1625 step_size = 0.3706 reward = -0.0000 fps = 10 mse_loss = 3.2058 
2022-07-08 09:08:42.260509 - gail/main.py:174 - [TRPO] iter = 124000 dist_mean = 0.1651 dist_std = 0.3964 vf_loss = 0.5938 grad_norm = 1.3631 nat_grad_norm = 0.2875 cg_residual = 0.1379 step_size = 0.3959 reward = 0.0000 fps = 9 mse_loss = 3.1740 
2022-07-08 09:08:59.589283 - gail/main.py:174 - [TRPO] iter = 125000 dist_mean = 0.2072 dist_std = 0.3965 vf_loss = 0.2093 grad_norm = 0.8094 nat_grad_norm = 0.2331 cg_residual = 0.1307 step_size = 0.4906 reward = 0.0000 fps = 8 mse_loss = 3.1363 
2022-07-08 09:09:00.250837 - gail/main.py:201 - [Discriminator] iter = 125000 loss = -1.3277 grad_norm = 3.1283 grad_penalty = 0.1581 regularization = 0.0000 true_logits = 0.0394 fake_logits = -1.4464 true_prob = 0.5108 fake_prob = 0.2220 
2022-07-08 09:10:02.151037 - gail/main.py:142 - [Evaluate] iter = 125000 episode={ returns = 705.1440 lengths = 219 } discounted_episode={ returns = 619.9434 lengths = 219 } 
2022-07-08 09:10:28.907975 - gail/main.py:174 - [TRPO] iter = 126000 dist_mean = 0.2110 dist_std = 0.3880 vf_loss = 0.1428 grad_norm = 1.0374 nat_grad_norm = 0.2599 cg_residual = 0.1605 step_size = 0.4786 reward = 0.0000 fps = 11 mse_loss = 3.0321 
2022-07-08 09:10:55.523341 - gail/main.py:174 - [TRPO] iter = 127000 dist_mean = 0.2474 dist_std = 0.3847 vf_loss = 0.5018 grad_norm = 0.9730 nat_grad_norm = 0.2026 cg_residual = 0.0757 step_size = 0.5471 reward = -0.0000 fps = 8 mse_loss = 3.0717 
2022-07-08 09:11:27.756628 - gail/main.py:174 - [TRPO] iter = 128000 dist_mean = 0.2414 dist_std = 0.3814 vf_loss = 0.2090 grad_norm = 1.1482 nat_grad_norm = 0.1770 cg_residual = 0.2000 step_size = 0.5616 reward = -0.0000 fps = 6 mse_loss = 3.3821 
2022-07-08 09:11:54.134300 - gail/main.py:174 - [TRPO] iter = 129000 dist_mean = 0.2341 dist_std = 0.3829 vf_loss = 0.2001 grad_norm = 1.5354 nat_grad_norm = 0.2398 cg_residual = 0.1553 step_size = 0.4188 reward = 0.0000 fps = 5 mse_loss = 3.1442 
2022-07-08 09:12:22.108095 - gail/main.py:174 - [TRPO] iter = 130000 dist_mean = 0.2087 dist_std = 0.3850 vf_loss = 0.0824 grad_norm = 0.9923 nat_grad_norm = 0.2399 cg_residual = 0.1738 step_size = 0.4826 reward = 0.0000 fps = 4 mse_loss = 3.1457 
2022-07-08 09:12:22.895808 - gail/main.py:201 - [Discriminator] iter = 130000 loss = -1.2916 grad_norm = 2.5748 grad_penalty = 0.1603 regularization = 0.0000 true_logits = 0.0490 fake_logits = -1.4029 true_prob = 0.5141 fake_prob = 0.2304 
2022-07-08 09:13:59.741081 - gail/main.py:142 - [Evaluate] iter = 130000 episode={ returns = 854.6264 lengths = 257 } discounted_episode={ returns = 736.5277 lengths = 258 } 
2022-07-08 09:14:27.982500 - gail/main.py:174 - [TRPO] iter = 131000 dist_mean = 0.1936 dist_std = 0.3850 vf_loss = 0.1252 grad_norm = 1.4671 nat_grad_norm = 0.2565 cg_residual = 0.2149 step_size = 0.4039 reward = -0.0000 fps = 7 mse_loss = 3.2059 
2022-07-08 09:14:57.929828 - gail/main.py:174 - [TRPO] iter = 132000 dist_mean = 0.2105 dist_std = 0.3863 vf_loss = 0.1953 grad_norm = 1.2491 nat_grad_norm = 0.2094 cg_residual = 0.1240 step_size = 0.4791 reward = -0.0000 fps = 6 mse_loss = 3.0665 
2022-07-08 09:15:25.481995 - gail/main.py:174 - [TRPO] iter = 133000 dist_mean = 0.2471 dist_std = 0.3813 vf_loss = 0.0590 grad_norm = 1.2716 nat_grad_norm = 0.2724 cg_residual = 0.1466 step_size = 0.4051 reward = -0.0000 fps = 5 mse_loss = 2.9845 
2022-07-08 09:15:53.947674 - gail/main.py:174 - [TRPO] iter = 134000 dist_mean = 0.2125 dist_std = 0.3767 vf_loss = 0.0865 grad_norm = 1.0278 nat_grad_norm = 0.2067 cg_residual = 0.1319 step_size = 0.4473 reward = -0.0000 fps = 4 mse_loss = 2.9073 
2022-07-08 09:16:22.092757 - gail/main.py:174 - [TRPO] iter = 135000 dist_mean = 0.2199 dist_std = 0.3771 vf_loss = 0.1137 grad_norm = 1.0668 nat_grad_norm = 0.2538 cg_residual = 0.0942 step_size = 0.4772 reward = 0.0000 fps = 4 mse_loss = 3.0757 
2022-07-08 09:16:22.939392 - gail/main.py:201 - [Discriminator] iter = 135000 loss = -1.3327 grad_norm = 2.7502 grad_penalty = 0.1555 regularization = 0.0000 true_logits = 0.0749 fake_logits = -1.4132 true_prob = 0.5201 fake_prob = 0.2295 
2022-07-08 09:18:03.706161 - gail/main.py:142 - [Evaluate] iter = 135000 episode={ returns = 931.6046 lengths = 277 } discounted_episode={ returns = 792.0731 lengths = 277 } 
2022-07-08 09:18:29.831329 - gail/main.py:174 - [TRPO] iter = 136000 dist_mean = 0.2628 dist_std = 0.3783 vf_loss = 0.2250 grad_norm = 0.6556 nat_grad_norm = 0.1890 cg_residual = 0.0748 step_size = 0.6141 reward = 0.0000 fps = 7 mse_loss = 3.0308 
2022-07-08 09:18:57.270669 - gail/main.py:174 - [TRPO] iter = 137000 dist_mean = 0.2432 dist_std = 0.3810 vf_loss = 0.1191 grad_norm = 1.3099 nat_grad_norm = 0.2838 cg_residual = 0.2046 step_size = 0.4261 reward = -0.0000 fps = 6 mse_loss = 3.1111 
2022-07-08 09:19:25.208409 - gail/main.py:174 - [TRPO] iter = 138000 dist_mean = 0.2360 dist_std = 0.3830 vf_loss = 0.2628 grad_norm = 1.1254 nat_grad_norm = 0.2970 cg_residual = 0.1988 step_size = 0.4199 reward = -0.0000 fps = 5 mse_loss = 3.2604 
2022-07-08 09:19:51.659536 - gail/main.py:174 - [TRPO] iter = 139000 dist_mean = 0.2561 dist_std = 0.3833 vf_loss = 0.0988 grad_norm = 1.2697 nat_grad_norm = 0.2393 cg_residual = 0.0947 step_size = 0.4696 reward = 0.0000 fps = 4 mse_loss = 3.1882 
2022-07-08 09:20:18.930470 - gail/main.py:174 - [TRPO] iter = 140000 dist_mean = 0.2652 dist_std = 0.3854 vf_loss = 0.0788 grad_norm = 1.1660 nat_grad_norm = 0.1973 cg_residual = 0.1012 step_size = 0.5181 reward = 0.0000 fps = 4 mse_loss = 2.8779 
2022-07-08 09:20:19.762232 - gail/main.py:201 - [Discriminator] iter = 140000 loss = -1.2072 grad_norm = 2.4555 grad_penalty = 0.1221 regularization = 0.0000 true_logits = 0.0491 fake_logits = -1.2803 true_prob = 0.5139 fake_prob = 0.2526 
2022-07-08 09:21:37.258481 - gail/main.py:142 - [Evaluate] iter = 140000 episode={ returns = 669.5957 lengths = 225 } discounted_episode={ returns = 588.6885 lengths = 225 } 
2022-07-08 09:22:10.518691 - gail/main.py:174 - [TRPO] iter = 141000 dist_mean = 0.2704 dist_std = 0.3854 vf_loss = 0.2027 grad_norm = 0.7670 nat_grad_norm = 0.1578 cg_residual = 0.1094 step_size = 0.6646 reward = 0.0000 fps = 9 mse_loss = 2.9968 
2022-07-08 09:22:37.266120 - gail/main.py:174 - [TRPO] iter = 142000 dist_mean = 0.1916 dist_std = 0.3831 vf_loss = 0.2336 grad_norm = 0.8789 nat_grad_norm = 0.2191 cg_residual = 0.1266 step_size = 0.5237 reward = 0.0000 fps = 7 mse_loss = 2.9757 
2022-07-08 09:23:05.279875 - gail/main.py:174 - [TRPO] iter = 143000 dist_mean = 0.2460 dist_std = 0.3773 vf_loss = 0.0929 grad_norm = 0.9200 nat_grad_norm = 0.2192 cg_residual = 0.1023 step_size = 0.5370 reward = -0.0000 fps = 6 mse_loss = 3.0183 
2022-07-08 09:23:32.695116 - gail/main.py:174 - [TRPO] iter = 144000 dist_mean = 0.2202 dist_std = 0.3815 vf_loss = 0.1574 grad_norm = 1.0836 nat_grad_norm = 0.2327 cg_residual = 0.1881 step_size = 0.4310 reward = 0.0000 fps = 5 mse_loss = 2.6945 
2022-07-08 09:23:59.269606 - gail/main.py:174 - [TRPO] iter = 145000 dist_mean = 0.2371 dist_std = 0.3782 vf_loss = 0.1088 grad_norm = 0.9382 nat_grad_norm = 0.2275 cg_residual = 0.1548 step_size = 0.4711 reward = 0.0000 fps = 4 mse_loss = 2.7898 
2022-07-08 09:24:00.129806 - gail/main.py:201 - [Discriminator] iter = 145000 loss = -1.1916 grad_norm = 2.4128 grad_penalty = 0.1322 regularization = 0.0000 true_logits = 0.0744 fake_logits = -1.2494 true_prob = 0.5194 fake_prob = 0.2569 
2022-07-08 09:25:12.660566 - gail/main.py:142 - [Evaluate] iter = 145000 episode={ returns = 654.9872 lengths = 227 } discounted_episode={ returns = 573.7024 lengths = 226 } 
2022-07-08 09:25:38.549840 - gail/main.py:174 - [TRPO] iter = 146000 dist_mean = 0.2226 dist_std = 0.3732 vf_loss = 0.0836 grad_norm = 1.2723 nat_grad_norm = 0.2293 cg_residual = 0.1923 step_size = 0.4185 reward = -0.0000 fps = 10 mse_loss = 2.6801 
2022-07-08 09:26:06.131898 - gail/main.py:174 - [TRPO] iter = 147000 dist_mean = 0.2623 dist_std = 0.3727 vf_loss = 0.0595 grad_norm = 1.6478 nat_grad_norm = 0.2128 cg_residual = 0.0914 step_size = 0.4567 reward = 0.0000 fps = 7 mse_loss = 2.6929 
2022-07-08 09:26:33.656011 - gail/main.py:174 - [TRPO] iter = 148000 dist_mean = 0.2080 dist_std = 0.3714 vf_loss = 0.1346 grad_norm = 1.6447 nat_grad_norm = 0.1925 cg_residual = 0.1437 step_size = 0.4692 reward = -0.0000 fps = 6 mse_loss = 2.7800 
2022-07-08 09:26:59.525019 - gail/main.py:174 - [TRPO] iter = 149000 dist_mean = 0.2428 dist_std = 0.3679 vf_loss = 0.0637 grad_norm = 1.2451 nat_grad_norm = 0.2000 cg_residual = 0.0967 step_size = 0.4683 reward = -0.0000 fps = 5 mse_loss = 2.6485 
2022-07-08 09:27:24.416837 - gail/main.py:174 - [TRPO] iter = 150000 dist_mean = 0.2797 dist_std = 0.3645 vf_loss = 0.1888 grad_norm = 1.9648 nat_grad_norm = 0.1714 cg_residual = 0.1171 step_size = 0.4208 reward = 0.0000 fps = 4 mse_loss = 2.9334 
2022-07-08 09:27:25.181341 - gail/main.py:201 - [Discriminator] iter = 150000 loss = -1.2339 grad_norm = 2.3245 grad_penalty = 0.1252 regularization = 0.0000 true_logits = 0.1046 fake_logits = -1.2545 true_prob = 0.5250 fake_prob = 0.2587 
2022-07-08 09:28:45.313550 - gail/main.py:142 - [Evaluate] iter = 150000 episode={ returns = 761.1321 lengths = 251 } discounted_episode={ returns = 612.7337 lengths = 238 } 
2022-07-08 09:29:11.735866 - gail/main.py:174 - [TRPO] iter = 151000 dist_mean = 0.2858 dist_std = 0.3623 vf_loss = 0.0585 grad_norm = 1.5824 nat_grad_norm = 0.1772 cg_residual = 0.1946 step_size = 0.5209 reward = 0.0000 fps = 9 mse_loss = 2.8140 
2022-07-08 09:29:36.095449 - gail/main.py:174 - [TRPO] iter = 152000 dist_mean = 0.1953 dist_std = 0.3617 vf_loss = 0.0491 grad_norm = 1.0409 nat_grad_norm = 0.2347 cg_residual = 0.2056 step_size = 0.4327 reward = 0.0000 fps = 7 mse_loss = 2.8052 
2022-07-08 09:30:01.367319 - gail/main.py:174 - [TRPO] iter = 153000 dist_mean = 0.2120 dist_std = 0.3611 vf_loss = 0.0435 grad_norm = 1.7929 nat_grad_norm = 0.2235 cg_residual = 0.1591 step_size = 0.3887 reward = -0.0000 fps = 6 mse_loss = 2.8822 
2022-07-08 09:30:27.207014 - gail/main.py:174 - [TRPO] iter = 154000 dist_mean = 0.2219 dist_std = 0.3601 vf_loss = 0.0677 grad_norm = 1.0391 nat_grad_norm = 0.1987 cg_residual = 0.1502 step_size = 0.5107 reward = -0.0000 fps = 5 mse_loss = 2.8931 
2022-07-08 09:30:52.446819 - gail/main.py:174 - [TRPO] iter = 155000 dist_mean = 0.2131 dist_std = 0.3537 vf_loss = 0.0647 grad_norm = 1.7965 nat_grad_norm = 0.2879 cg_residual = 0.2385 step_size = 0.3581 reward = -0.0000 fps = 4 mse_loss = 3.0226 
2022-07-08 09:30:53.194161 - gail/main.py:201 - [Discriminator] iter = 155000 loss = -1.4216 grad_norm = 2.6961 grad_penalty = 0.1364 regularization = 0.0000 true_logits = 0.1575 fake_logits = -1.4005 true_prob = 0.5375 fake_prob = 0.2298 
2022-07-08 09:32:44.922802 - gail/main.py:142 - [Evaluate] iter = 155000 episode={ returns = 1062.6007 lengths = 321 } discounted_episode={ returns = 875.7387 lengths = 318 } 
2022-07-08 09:33:10.127222 - gail/main.py:174 - [TRPO] iter = 156000 dist_mean = 0.2297 dist_std = 0.3536 vf_loss = 0.0349 grad_norm = 2.3243 nat_grad_norm = 0.1979 cg_residual = 0.1311 step_size = 0.4088 reward = 0.0000 fps = 7 mse_loss = 2.8654 
2022-07-08 09:33:34.921362 - gail/main.py:174 - [TRPO] iter = 157000 dist_mean = 0.1931 dist_std = 0.3525 vf_loss = 0.0465 grad_norm = 1.4019 nat_grad_norm = 0.2241 cg_residual = 0.1821 step_size = 0.4518 reward = 0.0000 fps = 6 mse_loss = 3.0312 
2022-07-08 09:34:00.481605 - gail/main.py:174 - [TRPO] iter = 158000 dist_mean = 0.1953 dist_std = 0.3515 vf_loss = 0.0408 grad_norm = 1.7523 nat_grad_norm = 0.2083 cg_residual = 0.2979 step_size = 0.4033 reward = -0.0000 fps = 5 mse_loss = 2.8636 
2022-07-08 09:34:25.214906 - gail/main.py:174 - [TRPO] iter = 159000 dist_mean = 0.1676 dist_std = 0.3482 vf_loss = 0.0326 grad_norm = 1.1717 nat_grad_norm = 0.2710 cg_residual = 0.3375 step_size = 0.4194 reward = 0.0000 fps = 4 mse_loss = 2.8701 
2022-07-08 09:34:50.111171 - gail/main.py:174 - [TRPO] iter = 160000 dist_mean = 0.1683 dist_std = 0.3454 vf_loss = 0.0723 grad_norm = 1.3323 nat_grad_norm = 0.1965 cg_residual = 0.1925 step_size = 0.4681 reward = 0.0000 fps = 4 mse_loss = 3.0338 
2022-07-08 09:34:50.909464 - gail/main.py:201 - [Discriminator] iter = 160000 loss = -1.1825 grad_norm = 2.7062 grad_penalty = 0.1193 regularization = 0.0000 true_logits = 0.1433 fake_logits = -1.1584 true_prob = 0.5329 fake_prob = 0.2715 
2022-07-08 09:36:31.911066 - gail/main.py:142 - [Evaluate] iter = 160000 episode={ returns = 1041.2787 lengths = 315 } discounted_episode={ returns = 873.2800 lengths = 315 } 
2022-07-08 09:36:56.880579 - gail/main.py:174 - [TRPO] iter = 161000 dist_mean = 0.1122 dist_std = 0.3432 vf_loss = 0.0606 grad_norm = 1.5452 nat_grad_norm = 0.2291 cg_residual = 0.3435 step_size = 0.4137 reward = 0.0000 fps = 7 mse_loss = 2.9519 
2022-07-08 09:37:21.373395 - gail/main.py:174 - [TRPO] iter = 162000 dist_mean = 0.1394 dist_std = 0.3382 vf_loss = 0.1065 grad_norm = 1.6017 nat_grad_norm = 0.2306 cg_residual = 0.2730 step_size = 0.4422 reward = 0.0000 fps = 6 mse_loss = 2.8012 
2022-07-08 09:37:45.603172 - gail/main.py:174 - [TRPO] iter = 163000 dist_mean = 0.1667 dist_std = 0.3373 vf_loss = 0.1409 grad_norm = 1.6633 nat_grad_norm = 0.2143 cg_residual = 0.3527 step_size = 0.3915 reward = 0.0000 fps = 5 mse_loss = 2.8985 
2022-07-08 09:38:10.164793 - gail/main.py:174 - [TRPO] iter = 164000 dist_mean = 0.1295 dist_std = 0.3356 vf_loss = 0.0529 grad_norm = 1.2731 nat_grad_norm = 0.1738 cg_residual = 0.2239 step_size = 0.5025 reward = -0.0000 fps = 5 mse_loss = 3.0385 
2022-07-08 09:38:34.831770 - gail/main.py:174 - [TRPO] iter = 165000 dist_mean = 0.0991 dist_std = 0.3364 vf_loss = 0.0610 grad_norm = 1.0438 nat_grad_norm = 0.1988 cg_residual = 0.2489 step_size = 0.5035 reward = 0.0000 fps = 4 mse_loss = 3.0597 
2022-07-08 09:38:35.478960 - gail/main.py:201 - [Discriminator] iter = 165000 loss = -1.1929 grad_norm = 2.6866 grad_penalty = 0.1161 regularization = 0.0000 true_logits = 0.2384 fake_logits = -1.0706 true_prob = 0.5528 fake_prob = 0.2893 
2022-07-08 09:40:13.045275 - gail/main.py:142 - [Evaluate] iter = 165000 episode={ returns = 1022.2670 lengths = 305 } discounted_episode={ returns = 867.5605 lengths = 308 } 
2022-07-08 09:40:38.447202 - gail/main.py:174 - [TRPO] iter = 166000 dist_mean = 0.1375 dist_std = 0.3389 vf_loss = 0.0397 grad_norm = 1.6996 nat_grad_norm = 0.1691 cg_residual = 0.1608 step_size = 0.5105 reward = -0.0000 fps = 8 mse_loss = 3.0315 
2022-07-08 09:41:02.043041 - gail/main.py:174 - [TRPO] iter = 167000 dist_mean = 0.1010 dist_std = 0.3383 vf_loss = 0.0353 grad_norm = 1.8007 nat_grad_norm = 0.1896 cg_residual = 0.2552 step_size = 0.4797 reward = -0.0000 fps = 6 mse_loss = 3.1052 
2022-07-08 09:41:26.837828 - gail/main.py:174 - [TRPO] iter = 168000 dist_mean = 0.0942 dist_std = 0.3343 vf_loss = 0.3019 grad_norm = 1.5327 nat_grad_norm = 0.1614 cg_residual = 0.2014 step_size = 0.5125 reward = -0.0000 fps = 5 mse_loss = 2.8657 
2022-07-08 09:41:51.161513 - gail/main.py:174 - [TRPO] iter = 169000 dist_mean = 0.1074 dist_std = 0.3332 vf_loss = 0.0378 grad_norm = 1.0949 nat_grad_norm = 0.2399 cg_residual = 0.3628 step_size = 0.4148 reward = -0.0000 fps = 5 mse_loss = 2.9778 
2022-07-08 09:42:21.337831 - gail/main.py:174 - [TRPO] iter = 170000 dist_mean = 0.0562 dist_std = 0.3310 vf_loss = 0.2058 grad_norm = 1.9029 nat_grad_norm = 0.1800 cg_residual = 0.1125 step_size = 0.4157 reward = -0.0000 fps = 4 mse_loss = 2.8058 
2022-07-08 09:42:22.040778 - gail/main.py:201 - [Discriminator] iter = 170000 loss = -1.1285 grad_norm = 2.7149 grad_penalty = 0.1264 regularization = 0.0000 true_logits = 0.2182 fake_logits = -1.0366 true_prob = 0.5475 fake_prob = 0.2964 
2022-07-08 09:43:28.257225 - gail/main.py:142 - [Evaluate] iter = 170000 episode={ returns = 724.3066 lengths = 221 } discounted_episode={ returns = 636.4271 lengths = 220 } 
2022-07-08 09:43:52.411412 - gail/main.py:174 - [TRPO] iter = 171000 dist_mean = 0.0826 dist_std = 0.3305 vf_loss = 0.0685 grad_norm = 1.2222 nat_grad_norm = 0.1888 cg_residual = 0.2983 step_size = 0.4585 reward = -0.0000 fps = 11 mse_loss = 2.6457 
2022-07-08 09:44:16.372433 - gail/main.py:174 - [TRPO] iter = 172000 dist_mean = 0.0665 dist_std = 0.3267 vf_loss = 0.0983 grad_norm = 1.4923 nat_grad_norm = 0.1637 cg_residual = 0.1924 step_size = 0.4670 reward = -0.0000 fps = 8 mse_loss = 2.5823 
2022-07-08 09:44:40.299153 - gail/main.py:174 - [TRPO] iter = 173000 dist_mean = 0.1195 dist_std = 0.3243 vf_loss = 0.0453 grad_norm = 1.3424 nat_grad_norm = 0.1435 cg_residual = 0.1584 step_size = 0.5023 reward = 0.0000 fps = 7 mse_loss = 2.6520 
2022-07-08 09:45:03.285888 - gail/main.py:174 - [TRPO] iter = 174000 dist_mean = 0.1305 dist_std = 0.3208 vf_loss = 0.0816 grad_norm = 1.9818 nat_grad_norm = 0.2109 cg_residual = 0.1932 step_size = 0.3799 reward = 0.0000 fps = 6 mse_loss = 2.4978 
2022-07-08 09:45:26.297617 - gail/main.py:174 - [TRPO] iter = 175000 dist_mean = 0.1198 dist_std = 0.3205 vf_loss = 0.0956 grad_norm = 1.7239 nat_grad_norm = 0.1415 cg_residual = 0.1588 step_size = 0.5300 reward = 0.0000 fps = 5 mse_loss = 2.6484 
2022-07-08 09:45:27.006210 - gail/main.py:201 - [Discriminator] iter = 175000 loss = -0.9885 grad_norm = 2.6397 grad_penalty = 0.1083 regularization = 0.0000 true_logits = 0.2790 fake_logits = -0.8177 true_prob = 0.5614 fake_prob = 0.3383 
2022-07-08 09:46:49.872516 - gail/main.py:142 - [Evaluate] iter = 175000 episode={ returns = 925.7042 lengths = 275 } discounted_episode={ returns = 772.1148 lengths = 268 } 
2022-07-08 09:47:13.690954 - gail/main.py:174 - [TRPO] iter = 176000 dist_mean = 0.0756 dist_std = 0.3200 vf_loss = 0.0476 grad_norm = 1.4040 nat_grad_norm = 0.1741 cg_residual = 0.1855 step_size = 0.4994 reward = -0.0000 fps = 9 mse_loss = 2.6589 
2022-07-08 09:47:37.227022 - gail/main.py:174 - [TRPO] iter = 177000 dist_mean = 0.1071 dist_std = 0.3186 vf_loss = 0.0482 grad_norm = 1.7159 nat_grad_norm = 0.1855 cg_residual = 0.2259 step_size = 0.4218 reward = 0.0000 fps = 7 mse_loss = 2.6742 
2022-07-08 09:48:01.333149 - gail/main.py:174 - [TRPO] iter = 178000 dist_mean = 0.0753 dist_std = 0.3167 vf_loss = 0.0767 grad_norm = 1.8833 nat_grad_norm = 0.1455 cg_residual = 0.2686 step_size = 0.4810 reward = 0.0000 fps = 6 mse_loss = 2.7760 
2022-07-08 09:48:24.601764 - gail/main.py:174 - [TRPO] iter = 179000 dist_mean = 0.0939 dist_std = 0.3169 vf_loss = 0.0855 grad_norm = 1.5969 nat_grad_norm = 0.1771 cg_residual = 0.2704 step_size = 0.4604 reward = 0.0000 fps = 5 mse_loss = 2.6775 
2022-07-08 09:48:48.366647 - gail/main.py:174 - [TRPO] iter = 180000 dist_mean = 0.0845 dist_std = 0.3147 vf_loss = 0.0606 grad_norm = 0.9762 nat_grad_norm = 0.1821 cg_residual = 0.5810 step_size = 0.5236 reward = 0.0000 fps = 4 mse_loss = 2.6348 
2022-07-08 09:48:49.096661 - gail/main.py:201 - [Discriminator] iter = 180000 loss = -1.1836 grad_norm = 2.9385 grad_penalty = 0.1120 regularization = 0.0000 true_logits = 0.3237 fake_logits = -0.9718 true_prob = 0.5717 fake_prob = 0.3054 
2022-07-08 09:50:42.852494 - gail/main.py:142 - [Evaluate] iter = 180000 episode={ returns = 1260.0928 lengths = 359 } discounted_episode={ returns = 1033.1466 lengths = 358 } 
2022-07-08 09:51:06.469750 - gail/main.py:174 - [TRPO] iter = 181000 dist_mean = 0.1032 dist_std = 0.3132 vf_loss = 0.0870 grad_norm = 1.7144 nat_grad_norm = 0.2017 cg_residual = 0.5869 step_size = 0.4377 reward = -0.0000 fps = 7 mse_loss = 2.6114 
2022-07-08 09:51:29.566755 - gail/main.py:174 - [TRPO] iter = 182000 dist_mean = 0.0354 dist_std = 0.3127 vf_loss = 0.0652 grad_norm = 1.6391 nat_grad_norm = 0.2181 cg_residual = 0.3018 step_size = 0.4830 reward = 0.0000 fps = 6 mse_loss = 2.6424 
2022-07-08 09:51:53.775884 - gail/main.py:174 - [TRPO] iter = 183000 dist_mean = 0.0785 dist_std = 0.3078 vf_loss = 0.0527 grad_norm = 2.0120 nat_grad_norm = 0.1739 cg_residual = 0.4350 step_size = 0.4415 reward = -0.0000 fps = 5 mse_loss = 2.7588 
2022-07-08 09:52:25.065646 - gail/main.py:174 - [TRPO] iter = 184000 dist_mean = 0.0642 dist_std = 0.3067 vf_loss = 0.0439 grad_norm = 1.8010 nat_grad_norm = 0.1788 cg_residual = 0.3528 step_size = 0.4766 reward = -0.0000 fps = 4 mse_loss = 2.6255 
2022-07-08 09:52:49.140600 - gail/main.py:174 - [TRPO] iter = 185000 dist_mean = 0.0742 dist_std = 0.3083 vf_loss = 0.0692 grad_norm = 1.2807 nat_grad_norm = 0.1715 cg_residual = 0.1830 step_size = 0.4724 reward = 0.0000 fps = 4 mse_loss = 2.7511 
2022-07-08 09:52:49.846376 - gail/main.py:201 - [Discriminator] iter = 185000 loss = -1.0220 grad_norm = 3.2118 grad_penalty = 0.1176 regularization = 0.0000 true_logits = 0.3098 fake_logits = -0.8299 true_prob = 0.5686 fake_prob = 0.3337 
2022-07-08 09:54:29.053256 - gail/main.py:142 - [Evaluate] iter = 185000 episode={ returns = 1088.8581 lengths = 312 } discounted_episode={ returns = 897.7583 lengths = 307 } 
2022-07-08 09:54:53.975352 - gail/main.py:174 - [TRPO] iter = 186000 dist_mean = 0.0725 dist_std = 0.3082 vf_loss = 0.4768 grad_norm = 3.2984 nat_grad_norm = 0.2279 cg_residual = 0.1670 step_size = 0.3477 reward = 0.0000 fps = 8 mse_loss = 2.7504 
2022-07-08 09:55:17.540167 - gail/main.py:174 - [TRPO] iter = 187000 dist_mean = 0.0611 dist_std = 0.3058 vf_loss = 0.0582 grad_norm = 1.4251 nat_grad_norm = 0.1971 cg_residual = 0.3823 step_size = 0.4459 reward = 0.0000 fps = 6 mse_loss = 2.6699 
2022-07-08 09:55:40.477596 - gail/main.py:174 - [TRPO] iter = 188000 dist_mean = 0.0915 dist_std = 0.3066 vf_loss = 0.0832 grad_norm = 1.8906 nat_grad_norm = 0.1770 cg_residual = 0.2104 step_size = 0.4452 reward = -0.0000 fps = 5 mse_loss = 2.5369 
2022-07-08 09:56:03.172848 - gail/main.py:174 - [TRPO] iter = 189000 dist_mean = 0.0888 dist_std = 0.3037 vf_loss = 0.0393 grad_norm = 2.2954 nat_grad_norm = 0.1496 cg_residual = 0.1281 step_size = 0.4455 reward = 0.0000 fps = 5 mse_loss = 2.6538 
2022-07-08 09:56:25.578763 - gail/main.py:174 - [TRPO] iter = 190000 dist_mean = 0.0995 dist_std = 0.3026 vf_loss = 0.0786 grad_norm = 1.3910 nat_grad_norm = 0.1704 cg_residual = 0.1554 step_size = 0.4727 reward = 0.0000 fps = 4 mse_loss = 2.5963 
2022-07-08 09:56:26.273969 - gail/main.py:201 - [Discriminator] iter = 190000 loss = -0.9610 grad_norm = 2.9373 grad_penalty = 0.1117 regularization = 0.0000 true_logits = 0.3837 fake_logits = -0.6891 true_prob = 0.5834 fake_prob = 0.3567 
2022-07-08 09:58:49.775207 - gail/main.py:142 - [Evaluate] iter = 190000 episode={ returns = 1670.1895 lengths = 482 } discounted_episode={ returns = 1277.7962 lengths = 479 } 
2022-07-08 09:59:12.948121 - gail/main.py:174 - [TRPO] iter = 191000 dist_mean = 0.1031 dist_std = 0.3008 vf_loss = 0.0344 grad_norm = 1.6195 nat_grad_norm = 0.1293 cg_residual = 0.1842 step_size = 0.5248 reward = -0.0000 fps = 5 mse_loss = 2.4652 
2022-07-08 09:59:37.665320 - gail/main.py:174 - [TRPO] iter = 192000 dist_mean = 0.1527 dist_std = 0.2993 vf_loss = 0.0614 grad_norm = 1.5430 nat_grad_norm = 0.1631 cg_residual = 0.3833 step_size = 0.5203 reward = 0.0000 fps = 5 mse_loss = 2.6283 
2022-07-08 10:00:01.594447 - gail/main.py:174 - [TRPO] iter = 193000 dist_mean = 0.1038 dist_std = 0.2945 vf_loss = 0.0651 grad_norm = 1.8518 nat_grad_norm = 0.1390 cg_residual = 0.3832 step_size = 0.5746 reward = -0.0000 fps = 4 mse_loss = 2.5393 
2022-07-08 10:00:26.063892 - gail/main.py:174 - [TRPO] iter = 194000 dist_mean = 0.0921 dist_std = 0.2913 vf_loss = 0.0599 grad_norm = 1.8289 nat_grad_norm = 0.1428 cg_residual = 0.2488 step_size = 0.4811 reward = -0.0000 fps = 4 mse_loss = 2.5365 
2022-07-08 10:00:51.281414 - gail/main.py:174 - [TRPO] iter = 195000 dist_mean = 0.1102 dist_std = 0.2912 vf_loss = 0.0557 grad_norm = 2.0022 nat_grad_norm = 0.1615 cg_residual = 0.3199 step_size = 0.4325 reward = 0.0000 fps = 3 mse_loss = 2.4885 
2022-07-08 10:00:52.007702 - gail/main.py:201 - [Discriminator] iter = 195000 loss = -0.9866 grad_norm = 3.2741 grad_penalty = 0.1120 regularization = 0.0000 true_logits = 0.4727 fake_logits = -0.6260 true_prob = 0.6008 fake_prob = 0.3662 
2022-07-08 10:06:38.311085 - gail/main.py:142 - [Evaluate] iter = 195000 episode={ returns = 3379.3755 lengths = 1000 } discounted_episode={ returns = 2022.4646 lengths = 947 } 
2022-07-08 10:07:05.152913 - gail/main.py:174 - [TRPO] iter = 196000 dist_mean = 0.1402 dist_std = 0.2934 vf_loss = 0.0465 grad_norm = 2.1378 nat_grad_norm = 0.1596 cg_residual = 0.2218 step_size = 0.4857 reward = 0.0000 fps = 2 mse_loss = 2.4998 
2022-07-08 10:07:30.811778 - gail/main.py:174 - [TRPO] iter = 197000 dist_mean = 0.1096 dist_std = 0.2924 vf_loss = 0.0590 grad_norm = 2.1764 nat_grad_norm = 0.1599 cg_residual = 0.1669 step_size = 0.4744 reward = 0.0000 fps = 2 mse_loss = 2.6574 
2022-07-08 10:07:57.101566 - gail/main.py:174 - [TRPO] iter = 198000 dist_mean = 0.0790 dist_std = 0.2916 vf_loss = 0.0674 grad_norm = 1.5192 nat_grad_norm = 0.2274 cg_residual = 0.3994 step_size = 0.3977 reward = -0.0000 fps = 2 mse_loss = 2.4471 
2022-07-08 10:08:23.193536 - gail/main.py:174 - [TRPO] iter = 199000 dist_mean = 0.0514 dist_std = 0.2926 vf_loss = 0.0739 grad_norm = 2.0757 nat_grad_norm = 0.1767 cg_residual = 0.3150 step_size = 0.3850 reward = -0.0000 fps = 2 mse_loss = 2.4561 
2022-07-08 10:08:50.093645 - gail/main.py:174 - [TRPO] iter = 200000 dist_mean = 0.0971 dist_std = 0.2918 vf_loss = 0.0452 grad_norm = 1.5407 nat_grad_norm = 0.2009 cg_residual = 0.3473 step_size = 0.4632 reward = -0.0000 fps = 2 mse_loss = 2.4850 
2022-07-08 10:08:50.867737 - gail/main.py:201 - [Discriminator] iter = 200000 loss = -0.9878 grad_norm = 2.8991 grad_penalty = 0.1085 regularization = 0.0000 true_logits = 0.4041 fake_logits = -0.6922 true_prob = 0.5855 fake_prob = 0.3540 
2022-07-08 10:11:05.899516 - gail/main.py:142 - [Evaluate] iter = 200000 episode={ returns = 1289.5201 lengths = 383 } discounted_episode={ returns = 1015.1057 lengths = 371 } 
2022-07-08 10:11:33.010975 - gail/main.py:174 - [TRPO] iter = 201000 dist_mean = 0.1187 dist_std = 0.2927 vf_loss = 0.0491 grad_norm = 1.3662 nat_grad_norm = 0.1411 cg_residual = 0.3009 step_size = 0.5284 reward = -0.0000 fps = 6 mse_loss = 2.5983 
2022-07-08 10:12:07.278962 - gail/main.py:174 - [TRPO] iter = 202000 dist_mean = 0.0735 dist_std = 0.2917 vf_loss = 0.0480 grad_norm = 1.0713 nat_grad_norm = 0.1796 cg_residual = 0.3924 step_size = 0.5039 reward = -0.0000 fps = 5 mse_loss = 2.4368 
2022-07-08 10:12:34.837850 - gail/main.py:174 - [TRPO] iter = 203000 dist_mean = 0.0777 dist_std = 0.2910 vf_loss = 0.0591 grad_norm = 1.8951 nat_grad_norm = 0.1483 cg_residual = 0.1791 step_size = 0.4772 reward = -0.0000 fps = 4 mse_loss = 2.3601 
2022-07-08 10:13:01.808878 - gail/main.py:174 - [TRPO] iter = 204000 dist_mean = 0.0963 dist_std = 0.2919 vf_loss = 0.0403 grad_norm = 1.5987 nat_grad_norm = 0.1654 cg_residual = 0.1977 step_size = 0.4778 reward = 0.0000 fps = 3 mse_loss = 2.3418 
2022-07-08 10:13:27.828178 - gail/main.py:174 - [TRPO] iter = 205000 dist_mean = 0.0776 dist_std = 0.2924 vf_loss = 0.0494 grad_norm = 2.2470 nat_grad_norm = 0.1612 cg_residual = 0.1827 step_size = 0.4231 reward = 0.0000 fps = 3 mse_loss = 2.3579 
2022-07-08 10:13:28.572843 - gail/main.py:201 - [Discriminator] iter = 205000 loss = -0.9567 grad_norm = 2.4825 grad_penalty = 0.1095 regularization = 0.0000 true_logits = 0.4955 fake_logits = -0.5707 true_prob = 0.6072 fake_prob = 0.3801 
2022-07-08 10:16:54.431670 - gail/main.py:142 - [Evaluate] iter = 205000 episode={ returns = 2015.4305 lengths = 578 } discounted_episode={ returns = 1499.6762 lengths = 605 } 
2022-07-08 10:17:21.286378 - gail/main.py:174 - [TRPO] iter = 206000 dist_mean = 0.0809 dist_std = 0.2899 vf_loss = 0.0424 grad_norm = 1.7832 nat_grad_norm = 0.1516 cg_residual = 0.3483 step_size = 0.4319 reward = 0.0000 fps = 4 mse_loss = 2.2242 
2022-07-08 10:17:47.332310 - gail/main.py:174 - [TRPO] iter = 207000 dist_mean = 0.0662 dist_std = 0.2898 vf_loss = 0.0755 grad_norm = 1.5139 nat_grad_norm = 0.1859 cg_residual = 0.6599 step_size = 0.4628 reward = 0.0000 fps = 3 mse_loss = 2.3378 
2022-07-08 10:18:12.939518 - gail/main.py:174 - [TRPO] iter = 208000 dist_mean = 0.0255 dist_std = 0.2925 vf_loss = 0.0576 grad_norm = 1.7140 nat_grad_norm = 0.1532 cg_residual = 0.1323 step_size = 0.5020 reward = 0.0000 fps = 3 mse_loss = 2.2398 
2022-07-08 10:18:38.492617 - gail/main.py:174 - [TRPO] iter = 209000 dist_mean = 0.0905 dist_std = 0.2935 vf_loss = 0.0503 grad_norm = 1.3585 nat_grad_norm = 0.1342 cg_residual = 0.3714 step_size = 0.5245 reward = -0.0000 fps = 3 mse_loss = 2.1209 
2022-07-08 10:19:02.553381 - gail/main.py:174 - [TRPO] iter = 210000 dist_mean = 0.0733 dist_std = 0.2900 vf_loss = 0.0327 grad_norm = 1.6657 nat_grad_norm = 0.1835 cg_residual = 0.4459 step_size = 0.4500 reward = 0.0000 fps = 2 mse_loss = 2.3105 
2022-07-08 10:19:03.301422 - gail/main.py:201 - [Discriminator] iter = 210000 loss = -1.0323 grad_norm = 2.5433 grad_penalty = 0.1076 regularization = 0.0000 true_logits = 0.5364 fake_logits = -0.6035 true_prob = 0.6143 fake_prob = 0.3730 
2022-07-08 10:22:23.458951 - gail/main.py:142 - [Evaluate] iter = 210000 episode={ returns = 1916.9126 lengths = 558 } discounted_episode={ returns = 1404.2446 lengths = 557 } 
2022-07-08 10:22:49.648674 - gail/main.py:174 - [TRPO] iter = 211000 dist_mean = 0.1031 dist_std = 0.2871 vf_loss = 0.0702 grad_norm = 1.8352 nat_grad_norm = 0.1324 cg_residual = 0.4704 step_size = 0.5177 reward = -0.0000 fps = 4 mse_loss = 2.3080 
2022-07-08 10:23:15.767897 - gail/main.py:174 - [TRPO] iter = 212000 dist_mean = 0.0711 dist_std = 0.2850 vf_loss = 0.0775 grad_norm = 1.8044 nat_grad_norm = 0.1237 cg_residual = 0.1983 step_size = 0.5309 reward = -0.0000 fps = 3 mse_loss = 2.2133 
2022-07-08 10:23:41.543928 - gail/main.py:174 - [TRPO] iter = 213000 dist_mean = 0.0892 dist_std = 0.2839 vf_loss = 0.0458 grad_norm = 2.8825 nat_grad_norm = 0.1493 cg_residual = 0.1634 step_size = 0.4252 reward = 0.0000 fps = 3 mse_loss = 2.2351 
2022-07-08 10:24:08.184252 - gail/main.py:174 - [TRPO] iter = 214000 dist_mean = 0.0666 dist_std = 0.2837 vf_loss = 0.0305 grad_norm = 2.1044 nat_grad_norm = 0.1402 cg_residual = 0.2542 step_size = 0.4823 reward = 0.0000 fps = 3 mse_loss = 2.1832 
2022-07-08 10:24:35.196594 - gail/main.py:174 - [TRPO] iter = 215000 dist_mean = 0.0942 dist_std = 0.2834 vf_loss = 0.0923 grad_norm = 2.2307 nat_grad_norm = 0.1381 cg_residual = 0.1988 step_size = 0.4299 reward = 0.0000 fps = 3 mse_loss = 2.2221 
2022-07-08 10:24:36.052139 - gail/main.py:201 - [Discriminator] iter = 215000 loss = -0.8843 grad_norm = 2.5895 grad_penalty = 0.0968 regularization = 0.0000 true_logits = 0.5982 fake_logits = -0.3830 true_prob = 0.6260 fake_prob = 0.4166 
2022-07-08 10:28:50.230599 - gail/main.py:142 - [Evaluate] iter = 215000 episode={ returns = 2207.2806 lengths = 629 } discounted_episode={ returns = 1841.0899 lengths = 799 } 
2022-07-08 10:29:17.605314 - gail/main.py:174 - [TRPO] iter = 216000 dist_mean = 0.0454 dist_std = 0.2834 vf_loss = 0.0626 grad_norm = 1.2712 nat_grad_norm = 0.1704 cg_residual = 0.2887 step_size = 0.5159 reward = 0.0000 fps = 3 mse_loss = 2.3048 
2022-07-08 10:29:46.437341 - gail/main.py:174 - [TRPO] iter = 217000 dist_mean = 0.0475 dist_std = 0.2822 vf_loss = 0.0431 grad_norm = 1.3608 nat_grad_norm = 0.2338 cg_residual = 0.3856 step_size = 0.3957 reward = -0.0000 fps = 3 mse_loss = 2.4302 
2022-07-08 10:30:14.191172 - gail/main.py:174 - [TRPO] iter = 218000 dist_mean = 0.0482 dist_std = 0.2817 vf_loss = 0.0627 grad_norm = 2.0501 nat_grad_norm = 0.1937 cg_residual = 0.3383 step_size = 0.4340 reward = 0.0000 fps = 2 mse_loss = 2.3290 
2022-07-08 10:30:41.759037 - gail/main.py:174 - [TRPO] iter = 219000 dist_mean = 0.0454 dist_std = 0.2779 vf_loss = 0.0399 grad_norm = 1.5931 nat_grad_norm = 0.1869 cg_residual = 0.3088 step_size = 0.4528 reward = -0.0000 fps = 2 mse_loss = 2.3860 
2022-07-08 10:31:10.014570 - gail/main.py:174 - [TRPO] iter = 220000 dist_mean = 0.0730 dist_std = 0.2747 vf_loss = 0.0362 grad_norm = 1.4304 nat_grad_norm = 0.1358 cg_residual = 0.1968 step_size = 0.5252 reward = 0.0000 fps = 2 mse_loss = 2.4490 
2022-07-08 10:31:10.856252 - gail/main.py:201 - [Discriminator] iter = 220000 loss = -0.8109 grad_norm = 2.4996 grad_penalty = 0.1047 regularization = 0.0000 true_logits = 0.5702 fake_logits = -0.3454 true_prob = 0.6221 fake_prob = 0.4256 
2022-07-08 10:33:37.886650 - gail/main.py:142 - [Evaluate] iter = 220000 episode={ returns = 3361.2695 lengths = 985 } discounted_episode={ returns = 1950.6486 lengths = 903 } 
2022-07-08 10:33:46.697503 - gail/main.py:174 - [TRPO] iter = 221000 dist_mean = 0.0809 dist_std = 0.2745 vf_loss = 0.0430 grad_norm = 1.7290 nat_grad_norm = 0.1139 cg_residual = 0.1426 step_size = 0.5540 reward = -0.0000 fps = 6 mse_loss = 2.4033 
2022-07-08 10:33:55.816662 - gail/main.py:174 - [TRPO] iter = 222000 dist_mean = 0.0780 dist_std = 0.2737 vf_loss = 0.0459 grad_norm = 2.4393 nat_grad_norm = 0.1207 cg_residual = 0.1588 step_size = 0.4870 reward = -0.0000 fps = 6 mse_loss = 2.3221 
